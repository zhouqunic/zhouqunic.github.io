<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux下的Mongodb部署应用梳理]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FLinux%E4%B8%8B%E7%9A%84Mongodb%E9%83%A8%E7%BD%B2%E5%BA%94%E7%94%A8%E6%A2%B3%E7%90%86%2F</url>
    <content type="text"><![CDATA[[toc] 一、Mongodb简介123456官网地址：http://www.mongodb.org/ MongoDB是一个高性能，开源，无模式的文档型数据库，是当前NoSql数据库中比较热门的一种。MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它在许多场景下可用于替代传统的关系型数据库或键/值存储方式。它是由C++语言编写的一个基于分布式文件存储的开源数据库系统，它的目的在于为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB是一个介于关系型数据库和非关系型数据库之间的产品，是非关系型数据库当中功能最丰富，最像关系型数据库的。它支持的数据结构非常松散，会将数据存储为一个文档，数据结构由键值对(key=&gt;value)组成，是类似于json的bson格式，字段值可以包含其它文档、数组和文档数组，因此可以存储比较复杂的数据类型。 二、Mongodb特点1234567891011121314MongoDB特点是高性能、易部署、易使用，存储数据非常方便，最大的特点在于它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系型数据库单表查询的绝大部分功能，而且还支持对数据建立索引。MongoDB的主要特点总结如下：1）提供了一个面向集合的文档存储，易存储对象类型的数据，操作起来比较简单和容易的非关系型数据库2）使用update()命令可以实现替换完成的文档(数据)或者一些指定的数据字段。3）支持动态查询。4）支持完全索引，包含内部对象，可以在MongoDB记录中设置任何属性的索引来实现更快的排序。5）支持复制和故障恢复。6）使用高效的二进制数据存储，包括大型对象（如视频等）。7）GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。8）自动处理碎片，以支持云计算层次的扩展性；如果负载的增加(需要更多的存储空间和更强的处理能力)，它可以分布在计算机网络中的其它节点上，这就是所谓的分片。9）支持RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。10）文件存储格式为BSON（一种JSON的扩展），MongoDB支持丰富的查询表达式，查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象和数组。11）MongoDB允许在服务端执行脚本，可以用JavaScript编写某个函数，直接在服务端执行，也可以吧函数的定义存储在服务端，下次直接调用即可。12）可通过网络访问，可以通过本地u或者网络创建数据镜像，这使得MongoDB含有更强的扩展性。 三、Mongodb的不足之处12345678910111）在集群分片中的数据分布不均匀2）单机可靠性比较差3）大数据量持续插入，写入性能有较大波动4）不支持事务操作。所以事务要求严格的系统(如果银行系统)肯定不能用它。5）磁盘空间占用比较大。空间占用大的原因如下： 1) 空间的预分配:为避免形成过多的硬盘碎片,mongodb 每次空间不足时都会申请生成一大块的硬盘空 间,而且申请的量从 64M、128M、256M 那样的指数递增,直到2G为单个文件 的最大体积。随着数据量 的增加,你可以在其数据目录里看到这些整块生成容量不断递增的文件。 2) 字段名所占用的空间:为了保持每个记录内的结构信息用于查询,mongodb 需要把每个字段的 key-value 都以 BSON 的形式存储,如果 value 域相对于 key 域并不大,比如 存放数值型的数据,则数据的 overhead 是最大的。一种减少空间占用的方法是把字段名尽量取短一些,这样占用 空间就小了,但这就要求在易读 性与空间占用上作为权衡了。 3) 删除记录不释放空间:这很容易理解,为避免记录删除后的数据的大规模挪动,原记录空间不删除,只 标记“已删除”即可,以后还可以重复利用。 4) 可以定期运行 db.repairDatabase()来整理记录,但这个过程会比较缓慢 四、Mongodb功能12345671）面向集合的存储：适合存储对象及JSON形式的数据。2）动态查询：Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。3）完整的索引支持：包括文档内嵌对象及数组。Mongo的查询优化器会分析查询表达式，并生成一个高效的查询计划。4）查询监视：Mongo包含一个监视工具用于分析数据库操作的性能。5）复制及自动故障转移：Mongo数据库支持服务器之间的数据复制，支持主-从模式及服务器之间的相互复制。复制的主要目标是提供冗余及自动故障转移。6）高效的传统存储方式：支持二进制数据及大型对象（如照片或图片）7）自动分片以支持云级别的伸缩性：自动分片功能支持水平的数据库集群，可动态添加额外的机器。 五、Mongodb使用场景123456适用场景：网站实时数据处理。它非常适合实时的插入、更新与查询，并具备网站实时数据存储所需的复制及高度伸缩性；缓存，由于性能很高，它适合作为信息基础设施的缓存层。在系统重启之后，由它搭建的持久化缓存层可以避免下层的数据源过载。高伸缩性的场景。非常适合由数十或数百台服务器组成的数据库，它的路线图中已经包含对MapReduce引擎的内置支持。 不适用场景：要求高度事务性的系统。传统的商业智能应用。复杂的跨文档（表）级联查询。 六、Mongodb安装使用官网下载地址：http://www.mongodb.org/downloads 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461）安装mongodb[root@data-server src]# cd /usr/local/src/[root@data-server src]# tar -zvxf mongodb-linux-x86_64-rhel62-3.4.4[root@data-server src]# mv mongodb-linux-x86_64-rhel62-3.4.4 /usr/local/mongodb[root@data-server src]# cd /usr/local/mongodb //Mongodb主目录[root@data-server mongodb]# ll总用量 120drwxr-xr-x. 2 root root 4096 6月 3 14:51 bin-rw-r--r--. 1 root root 34520 4月 21 06:19 GNU-AGPL-3.0-rw-r--r--. 1 root root 16726 4月 21 06:19 MPL-2-rw-r--r--. 1 root root 1359 4月 21 06:19 README-rw-r--r--. 1 root root 55625 4月 21 06:19 THIRD-PARTY-NOTICES[root@data-server mongodb]# mkdir /usr/local/mongodb/data //Mongodb数据目录，可以存放在一个独立的大分区上[root@data-server mongodb]# mkdir /usr/local/mongodb/log //Mongodb日志目录 2）启动Mongodb使用mongod命令建立一个mongodb数据库链接，端口号设置为10001，数据库的路径为/usr/local/mongodb/data，日志路径为/usr/local/mongodb/log/mongo.logmongodb的启动程序放在后台执行，下面命令执行后，按ctrl＋c[root@data-server mongodb]# nohup /usr/local/mongodb/bin/mongod --dbpath=/usr/local/mongodb/data/ --logpath=/usr/local/mongodb/log/mongo.log &amp; mongodb默认端口是27017[root@data-server mongodb]# ps -ef|grep mongodbroot 14858 14518 1 15:01 pts/1 00:00:01 /usr/local/mongodb/bin/mongod --dbpath=/usr/local/mongodb/data/ --logpath=/usr/local/mongodb/log/mongo.logroot 14887 14518 0 15:02 pts/1 00:00:00 grep mongodb[root@data-server bin]# netstat -tunlp|grep 14858tcp 0 0 0.0.0.0:27017 0.0.0.0:* LISTEN 14858/mongod[root@data-server mongodb]# lsof -i:27017COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmongod 14858 root 7u IPv4 145311 0t0 TCP *:27017 (LISTEN) 3）设置mongodb的环境变量[root@data-server ~]# vim /etc/profile.......export PATH=$PATH:/usr/local/mongodb/bin/[root@data-server ~]# source /etc/profile 4）为了更方便的启动和关闭MongoDB，我们可以使用Shell写脚本，当然也可以加入到service中 更好的方式是采用配置文件，把MongoDB需要的参数写入配置文件，然后在脚本中引用；[root@data-server ~]# cat /usr/local/mongodb/mongodb.conf#代表端口号，如果不指定则默认为27017port=27017#MongoDB数据文件目录dbpath=/usr/local/mongodb/data#MongoDB日志文件目录logpath=/usr/local/mongodb/log/mongo.log#日志文件自动累加logappend=true 编写启动脚本[root@data-server ~]# vim /etc/init.d/mongodb#!/bin/bash## mongod Start up the MongoDB server daemon# # source function library. /etc/rc.d/init.d/functions#定义命令CMD=/usr/local/mongodb/bin/mongod#定义配置文件路径INITFILE=/usr/local/mongodb/mongodb.confstart()&#123; #&amp;表示后台启动，也可以使用fork参数 $CMD -f $INITFILE &amp; echo &quot;MongoDB is running background...&quot;&#125; stop()&#123; pkill mongod echo &quot;MongoDB is stopped.&quot;&#125; case &quot;$1&quot; in start) start ;; stop) stop ;; *) echo $&quot;Usage: $0 &#123;start|stop&#125;&quot;esac[root@data-server ~]# chmod 755 /etc/init.d/mongodb[root@data-server ~]# /etc/init.d/mongodb status用法：/etc/init.d/mongodb &#123;start|stop&#125;[root@data-server ~]# /etc/init.d/mongodb stop已终止[root@data-server ~]# lsof -i:27017[root@data-server ~]# /etc/init.d/mongodb startMongoDB is running background...[root@data-server ~]# lsof -i:27017COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmongod 15138 root 7u IPv4 147713 0t0 TCP *:27017 (LISTEN)通过 shell 连接 MongoDB 服务：(在客户机上连接本机mongodb：mongo 182.48.115.238:27017)[root@data-server ~]# mongoMongoDB shell version v3.4.4connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.4Welcome to the MongoDB shell.For interactive help, type &quot;help&quot;.For more comprehensive documentation, see http://docs.mongodb.org/Questions? Try the support group http://groups.google.com/group/mongodb-userServer has startup warnings:2018-01-04T15:17:54.695+0800 I STORAGE [initandlisten]2018-01-04T15:17:54.695+0800 I STORAGE [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine2018-01-04T15:17:54.695+0800 I STORAGE [initandlisten] ** See http://dochub.mongodb.org/core/prodnotes-filesystem2018-01-04T15:17:55.699+0800 I CONTROL [initandlisten]2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten] ** WARNING: Access control is not enabled for the database.2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten] ** Read and write access to data and configuration is unrestricted.2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten]2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten]2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is &apos;always&apos;.2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten] ** We suggest setting it to &apos;never&apos;2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten]2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is &apos;always&apos;.2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten] ** We suggest setting it to &apos;never&apos;2018-01-04T15:17:55.700+0800 I CONTROL [initandlisten]&gt; help db.help() help on db methods db.mycoll.help() help on collection methods sh.help() sharding helpers rs.help() replica set helpers help admin administrative help help connect connecting to a db help help keys key shortcuts help misc misc things to know help mr mapreduce show dbs show database names show collections show collections in current database show users show users in current database show profile show most recent system.profile entries with time &gt;= 1ms show logs show the accessible logger names show log [name] prints out the last segment of log in memory, &apos;global&apos; is default use &lt;db_name&gt; set current database db.foo.find() list objects in collection foo db.foo.find( &#123; a : 1 &#125; ) list objects in foo where a == 1 it result of the last line evaluated; use to further iterate DBQuery.shellBatchSize = x set default number of items to display on shell exit quit the mongo shell 七、mongodb非正常关闭导致启动失败问题1234567891011121314151617之前强制关闭了mongodb，后续再次启动的时候，发现报错：[root@i-omxpbsuo ~]# /usr/local/mongodb/bin/mongod --logpath /usr/local/mongodb/log/system.log --logappend --dbpath /data/mongodb --directoryperdb --auth --journal --profile=1 --slowms=5 --forkforked process: 4853all output going to: /usr/local/mongodb/log/system.log解决办法:1）删除数据目录/data/mongodb 下的 mongod.lock[root@i-omxpbsuo ~]# rm -rf /data/mongodb/mongod.lock2)修复mongodb[root@i-omxpbsuo ~]# /usr/local/mongodb/bin/mongod --logpath --dbpath /data/mongodb --repair3)删除/data/mongodb/journal 下的 j._4 文件(或者将journal下的文件清空)[root@i-omxpbsuo ~]# rm -rf /data/mongodb/journal/*j._44）然后再次启动mongodb就ok了[root@i-omxpbsuo ~]# /usr/local/mongodb/bin/mongod --logpath --dbpath /data/mongodb --directoryperdb --auth --journal --profile=1 --slowms=5 --fork &amp; 八、正确关闭mongod 的方法：进入mongo shell1234567&gt; use admin&gt; db.shutdownServer() 也可以按照文档粗暴的杀掉它，它内部应该有KILL信号处理程序。# killall mongod 请不要 kill -9 ，会造成文件数据混乱丢失repair也无力回天。 九、yum的方式安装mongodb，操作记录如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091）创建repo[root@data-server ~]# vim /etc/yum.repos.d/mongodb-org-3.2.repo[mongodb-org-3.2]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.2/x86_64/gpgcheck=0enabled=1 2）安装MongoDB和相关工具[root@data-server ~]# yum install -y mongodb-org 3）启动Mongodb[root@data-server ~]# service mongod startStarting mongod: [ OK ][root@data-server ~]# chkconfig mongod on[root@data-server ~]# lsof -i:27017COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmongod 26130 mongod 6u IPv4 2773161 0t0 TCP localhost:27017 (LISTEN) 日志文件：/var/log/mongodb/mongod.log配置文件：/etc/mongod.conf数据目录：/var/lib/mongo/ 配置文件解释：[root@data-server ~]# cat /etc/mongod.conf# mongo.conf #where to log logpath=/var/log/mongo/mongod.log logappend=true #以追加方式写入日志 # fork and run in background fork = true #port = 27017 #端口 dbpath=/var/lib/mongo #数据库文件保存位置 directoryperdb=true# Enables periodic logging of CPU utilization and I/O wait #启用定期记录CPU利用率和 I/O 等待 #cpu = true # Turn on/off security. Off is currently the default # 是否以安全认证方式运行，默认是不认证的非安全方式 #noauth = true #auth = true # Verbose logging output. # 详细记录输出 #verbose = true # Inspect all client data for validity on receipt (useful for # developing drivers)用于开发驱动程序时的检查客户端接收数据的有效性 #objcheck = true # Enable db quota management 启用数据库配额管理，默认每个db可以有8个文件，可以用quotaFiles参数设置 #quota = true # 设置oplog记录等级 # Set oplogging level where n is # 0=off (default) # 1=W # 2=R # 3=both # 7=W+some reads #oplog = 0 # Diagnostic/debugging option 动态调试项 #nocursors = true # Ignore query hints 忽略查询提示 #nohints = true # 禁用http界面，默认为localhost：28017 # Disable the HTTP interface (Defaults to localhost:27018).这个端口号写的是错的 #nohttpinterface = true # 关闭服务器端脚本，这将极大的限制功能 # Turns off server-side scripting. This will result in greatly limited # functionality #noscripting = true # 关闭扫描表，任何查询将会是扫描失败 # Turns off table scans. Any query that would do a table scan fails. #notablescan = true # 关闭数据文件预分配 # Disable data file preallocation. #noprealloc = true # 为新数据库指定.ns文件的大小，单位:MB # Specify .ns file size for new databases. # nssize = &lt;size&gt; # Accout token for Mongo monitoring server. #mms-token = &lt;token&gt; # mongo监控服务器的名称 # Server name for Mongo monitoring server. #mms-name = &lt;server-name&gt; # mongo监控服务器的ping 间隔 # Ping interval for Mongo monitoring server. #mms-interval = &lt;seconds&gt; # Replication Options 复制选项 # in replicated mongo databases, specify here whether this is a slave or master 在复制中，指定当前是从属关系 #slave = true #source = master.example.com # Slave only: specify a single database to replicate #only = master.example.com # or #master = true #source = slave.example.com 十、Mongodb的日常操作命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077081）登陆和退出..........................................mongo 命令直接加MongoDB服务器的IP地址就可以利用 Mongo 的默认端口号(27017)登陆 Mongo,然后便能够进行简单的命令行操作。至于退出,直接 exit,然后回车就好了。 如果默认bind绑定的ip是127.0.0.1以及端口是27017，那么登陆可以直接用下面两种都可以：[root@master-node ~]# mongo[root@master-node ~]# mongo 127.0.0.1:27017 如果是绑定了固定的ip地址，如bind_ip=182.48.115.236,那么连接mongodb命令是：[root@master-node ~]# mongo 182.48.115.238:27017 如果是连接某个库，命令是[root@master-node ~]# mongo ip:port/库名 -u用户名 -p密码 &gt; help登陆mongodb数据库后，可以直接执行help命令进行帮助查看 &gt; show collections从以上可以看出,登录后 mongo 会自动连上一个名为 test 的数据库。如果这个数据库不存 在,那么 mongo 会自动建立一个名为 test 的数据库。上面的例子,由于 Mongo 服务器上没 有名为 test 的 db,因此,mongo 新建了一个空的名为 test 的 db。其中,没有任何 collection。 2）database级操作.......................................... 2.1 查看服务器上的数据库&gt; show dbsadmin 0.000GBlocal 0.000GBmaster_slave 0.000GBwangshibo 0.000GB 2.2 切换数据库切换到wangshibo数据库(从默认的 test 数据库)&gt; use wangshibo；switched to db wangshibo；mongo 中,db 代表当前使用的数据库。这样,db 就从原来的 test,变为现在的 wangshibo 数据库，如果没有这个库，就会自动创建 2.3 查看当前数据库中的所有集合&gt; show collectionspersonstest 2.4 创建数据库mongo 中创建数据库采用的也是 use 命令,如果 use 后面跟的数据库名不存在,那么 mongo 将会新建该数据库。不过,实际上只执行 use 命令后,mongo 是不会新建该数据库的,直到 你像该数据库中插入了数据。&gt; use huanqiuswitched to db huanqiu&gt; show dbsadmin 0.000GBlocal 0.000GBmaster_slave 0.000GBwangshibo 0.000GB到这里并没有看到刚才新建的 huanqiu 数据库。 &gt; db.huanqiu.insert(&#123;&quot;name&quot;:&quot;testdb&quot;&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)该操作会在 huanqiu 数据库中新建一个 hello 集合,并在其中插入一条记录。 &gt; show dbsadmin 0.000GBhuanqiu 0.000GBlocal 0.000GBmaster_slave 0.000GBwangshibo 0.000GB这样,便可以看到 mongo 的确创建了 huanqiu 数据库,其中有一个 hello 集合。 2.5 删除数据库删除当前所在库。比如这里已经切换到huanqiu库，那么就删除huanku库&gt; db.dropDatabase()&#123; &quot;dropped&quot; : &quot;huanqiu&quot;, &quot;ok&quot; : 1 &#125; &gt; show dbsadmin 0.000GBlocal 0.000GBmaster_slave 0.000GBwangshibo 0.000GB 2.6 查看当前数据库&gt; dbhuanqiu &gt; db.getName(); //这个上面的命令是一样的wangshibo 可以看出删除 huanqiu 数据库之后,当前的 db 还是指向它,只有当切换数据库之后,huanqiu 才会彻底消失。&gt; use wangshiboswitched to db wangshibo&gt; dbwangshibo&gt; show dbsadmin 0.000GBlocal 0.000GBmaster_slave 0.000GBwangshibo 0.000GB 2.6.1 修复当前数据库&gt; db.repairDatabase();&#123; &quot;ok&quot; : 1 &#125; 2.6.2 查看当前数据库状态&gt; db.stats();&#123; &quot;db&quot; : &quot;wangshibo&quot;, &quot;collections&quot; : 3, &quot;views&quot; : 0, &quot;objects&quot; : 6, &quot;avgObjSize&quot; : 75.5, &quot;dataSize&quot; : 453, &quot;storageSize&quot; : 73728, &quot;numExtents&quot; : 0, &quot;indexes&quot; : 4, &quot;indexSize&quot; : 53248, &quot;ok&quot; : 1&#125; 2.6.3 当前db版本&gt; db.version();3.4.4 2.6.4 查看当前db的链接机器地址&gt; db.getMongo();connection to 182.48.115.238:27017 2.6.5 从指定主机上克隆数据库&gt; db.cloneDatabase(&quot;182.48.115.236&quot;);&#123; &quot;clonedColls&quot; : [ ], &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;a collection &apos;wangshibo.wangshibo&apos; already exists&quot;, &quot;code&quot; : 48, &quot;codeName&quot; : &quot;NamespaceExists&quot;&#125; 2.6.6 从指定的机器上复制指定数据库数据到某个数据库将本机的master_slave的数据复制到wangshibo数据库中&gt; db.copyDatabase(&quot;master_slave&quot;, &quot;wangshibo&quot;, &quot;127.0.0.1&quot;);&#123; &quot;ok&quot; : 1 &#125; 3）collection 级操作.......................................... 3.1 新建 collection&gt; db.createCollection(&quot;Hello&quot;)&#123; &quot;ok&quot; : 1 &#125;&gt; show collectionsHellowangshibo 直接向一个不存在的 collection 中插入数据也能创建一个 collection。&gt; db.hello2.insert(&#123;&quot;name&quot;:&quot;lfqy&quot;&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; show collectionsHellohello2wangshibo 3.2 删除 collection&gt; db.Hello.drop()true返回 true 说明删除成功,false 说明没有删除成功。 &gt; db.Hello.drop()false不存在名为 hello 的 collection,因此,删除失败。 3.3 重命名 collection将 hello2 集合重命名为 HELLO&gt; show collectionshello2wangshibo&gt; db.hello2.renameCollection(&quot;HELLO&quot;)&#123; &quot;ok&quot; : 1 &#125;&gt; show collectionsHELLOwangshibo 3.4 查看当前数据库中的所有 collection&gt; show collectionsHELLOwangshibo 3.5 建立索引在 HELLO 集合上,建立对 ID 字段的索引,1 代表升序。&gt; db.HELLO.ensureIndex(&#123;ID:1&#125;)&#123; &quot;createdCollectionAutomatically&quot; : false, &quot;numIndexesBefore&quot; : 1, &quot;numIndexesAfter&quot; : 2, &quot;ok&quot; : 1&#125; 4）Record 级的操作................................ 4.1 插入操作4.1.1 向 user 集合中插入两条记录&gt; db.user.insert(&#123;&apos;name&apos;:&apos;GalGadot&apos;,&apos;gender&apos;:&apos;female&apos;,&apos;age&apos;:28,&apos;salary&apos;:11000&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; db.user.insert(&#123;&apos;name&apos;:&apos;Mikie Hara&apos;,&apos;gender&apos;:&apos;female&apos;,&apos;age&apos;:26,&apos;salary&apos;:7000&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 4.1.2 同样也可以用 save 完成类似的插入操作&gt; db.user.save(&#123;&apos;name&apos;:&apos;Wentworth Earl Miller&apos;,&apos;gender&apos;:&apos;male&apos;,&apos;age&apos;:41,&apos;salary&apos;:33000&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 4.2 查找操作4.2.1 查找集合中的所有记录&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 4.2.2 查找集合中的符合条件的记录(1)单一条件查询 age 为26 的数据&gt; db.user.find(&#123;&quot;age&quot;:26&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125; 查询 salary 大于 7000 的数据&gt; db.user.find(&#123;salary:&#123;$gt:7000&#125;&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 查询 name 中包含&apos;ent&apos;的数据&gt; db.user.find(&#123;name:/ent/&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 查询 name 以 G 打头的数据&gt; db.user.find(&#123;name:/^G/&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125; 查询 name 以 t 结尾的数据&gt; db.user.find(&#123;name:/t$/&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125; (2)多条件&quot;与&quot;查询 age 小于 30,salary 大于 7000 的数据&gt; db.user.find(&#123;age:&#123;$lt:30&#125;,salary:&#123;$gt:7000&#125;&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125; (3)多条件&quot;或&quot;查询 age 小于 30,或者 salary 大于 10000 的记录&gt; db.user.find(&#123;$or:[&#123;salary:&#123;$gt:10000&#125;&#125;,&#123;age:&#123;$lt:30&#125;&#125;]&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 4.2.3 查询第一条记录将上面的 find 替换为 findOne()可以查找符合条件的第一条记录。&gt; db.user.findOne(&#123;$or:[&#123;salary:&#123;$gt:10000&#125;&#125;,&#123;age:&#123;$lt:25&#125;&#125;]&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000&#125; 4.2.4 查询记录的指定字段查询 user 集合中所有记录的 name,age,salary,sex_orientation 字段&gt; db.user.find(&#123;&#125;,&#123;name:1,age:1,salary:1,sex_orientation:true&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 注意:这里的 1 表示显示此列的意思,也可以用 true 表示。&gt; db.user.find(&#123;&#125;,&#123;name:1,age:1,salary:true,sex_orientation:1&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 4.2.5 查询指定字段的数据,并去重。查询 gender 字段的数据,并去掉重复数据&gt; db.user.distinct(&apos;gender&apos;)[ &quot;female&quot;, &quot;male&quot; ] 4.2.6 对查询结果集的操作(1)Pretty Print为了方便,mongo 也提供了 pretty print 工具,db.collection.pretty()或者是 db.collection.forEach(printjson)&gt; db.user.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000&#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000&#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000&#125; (2)指定结果集显示的条目a)显示结果集中的前 3 条记录&gt; db.user.find().limit(3)&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; b)查询第 1 条以后的所有数据&gt; db.user.find().skip(1)&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 查询跳过前2条以后的所有数据&gt; db.user.find().skip(2)&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&gt; c)对结果集排序升序&gt; db.user.find().sort(&#123;salary:1&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 降序&gt; db.user.find().sort(&#123;salary:-1&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125; 4.2.7 统计查询结果中记录的条数(1)统计集合中的所有记录条数&gt; db.user.find().count()3 (2)查询符合条件的记录数查询 salary 小于 4000 或大于 10000 的记录数&gt; db.user.find(&#123;$or: [&#123;salary: &#123;$lt:4000&#125;&#125;, &#123;salary: &#123;$gt:10000&#125;&#125;]&#125;).count()2 4.3 删除操作4.3.1 删除整个集合中的所有数据 &gt; db.wangshibo.find()&#123; &quot;_id&quot; : ObjectId(&quot;5932683b156e298477cdf3ad&quot;), &quot;name&quot; : &quot;菜鸟教程&quot; &#125;&gt; db.wangshibo.remove(&#123;&#125;)WriteResult(&#123; &quot;nRemoved&quot; : 1 &#125;)&gt; db.wangshibo.find()&gt;可见 wangshibo中的记录全部被删除。 mongo在删除数据的时候不支持 all * 全部删除选择&#123;&#125;就可以全部删除了删除mongodb集合中的数据可以使用remove()函数。remove()函数可以接受一个查询文档作为可选参数来有选择性的删除符合条件的文档。remove()函数不会删除集合本身，同时，原有的索引也同样不会被删除。删除文档是永久性的，不能撤销，也不能恢复的。因此，在执行remove()函数前先用find()命令来查看下是否正确，是个比较好的习惯啦。 注意 db.collection.remove()和 drop()的区别,remove()只是删除了集合中所有的记录, 而集合中原有的索引等信息还在,而drop()则把集合相关信息整个删除(包括索引)。 4.3.2 删除集合中符合条件的所有记录&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;59328c8aa7865327915046ae&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&gt; db.user.remove(&#123;name:&apos;GalGadot&apos;&#125;)WriteResult(&#123; &quot;nRemoved&quot; : 1 &#125;)&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125; 4.3.3 删除集合中符合条件的一条记录&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;59328c9da7865327915046af&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&gt; db.user.remove(&#123;salary :&#123;$lt:30000&#125;&#125;,1)WriteResult(&#123; &quot;nRemoved&quot; : 1 &#125;)&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&gt; 当然,也可以是命令：db.user.remove(&#123;salary :&#123;$lt:30000&#125;&#125;,true),因为true和1是一个意思 4.4 更新操作4.4.1 赋值更新db.collection.update(criteria, objNew, upsert, multi )criteria:update 的查询条件,类似 sql update 查询内 where 后面的objNew:update 的对象和一些更新的操作符(如$,$inc...)等,也可以理解为 sql update 查询内 set 后面的。upsert : 如果不存在 update 的记录,是否插入 objNew,true 为插入,默认是 false,不插 入。multi : mongodb 默认是 false,只更新找到的第一条记录,如果这个参数为 true,就把按条 件查出来多条记录全部更新。 &gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;593293e2a7865327915046b2&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;593293f0a7865327915046b3&quot;), &quot;name&quot; : &quot;Gasdfdst&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 58, &quot;salary&quot; : 60000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59329401a7865327915046b4&quot;), &quot;name&quot; : &quot;huihui&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 18, &quot;salary&quot; : 23100 &#125;&gt; db.user.update(&#123;name:&apos;huihui&apos;&#125;,&#123;$set:&#123;age:23&#125;&#125;,false,true)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;593293e2a7865327915046b2&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;593293f0a7865327915046b3&quot;), &quot;name&quot; : &quot;Gasdfdst&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 58, &quot;salary&quot; : 60000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59329401a7865327915046b4&quot;), &quot;name&quot; : &quot;huihui&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 23, &quot;salary&quot; : 23100 &#125; &gt; db.user.update(&#123;name:&apos;lfqy1&apos;&#125;,&#123;$set:&#123;age:23&#125;&#125;,true,true)WriteResult(&#123; &quot;nMatched&quot; : 0, &quot;nUpserted&quot; : 1, &quot;nModified&quot; : 0, &quot;_id&quot; : ObjectId(&quot;5932946c9758703fe04b0f73&quot;)&#125;)&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;59328cd6a7865327915046b0&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;593293e2a7865327915046b2&quot;), &quot;name&quot; : &quot;GalGadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;593293f0a7865327915046b3&quot;), &quot;name&quot; : &quot;Gasdfdst&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 58, &quot;salary&quot; : 60000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;59329401a7865327915046b4&quot;), &quot;name&quot; : &quot;huihui&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 23, &quot;salary&quot; : 23100 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5932946c9758703fe04b0f73&quot;), &quot;name&quot; : &quot;lfqy1&quot;, &quot;age&quot; : 23 &#125; 4.4.2 增值更新&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;52453cfb25e437dfea8fd4f4&quot;), &quot;name&quot; : &quot;Gal Gadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;52453d8525e437dfea8fd4f5&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;52453e2125e437dfea8fd4f6&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;52454155d8947fb70d000000&quot;), &quot;name&quot; : &quot;not known&quot;, &quot;sex_orientation&quot; : &quot;male&quot;, &quot;age&quot; : 13, &quot;salary&quot; : 30000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5245610881c83a5bf26fc285&quot;), &quot;age&quot; : 23, &quot;name&quot; : &quot;lfqy1&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;52455f8925e437dfea8fd4fd&quot;), &quot;age&quot; : 23, &quot;gender&quot; : &quot;male&quot;, &quot;interest&quot; : &quot;NBA&quot;, &quot;name&quot; : &quot;lfqy&quot;, &quot;salary&quot; : 1 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5245607525e437dfea8fd4fe&quot;), &quot;age&quot; : 23, &quot;gender&quot; : &quot;male&quot;, &quot;interest&quot; : &quot;NBA&quot;, &quot;name&quot; : &quot;lfqy&quot;, &quot;salary&quot; : 2 &#125; &gt; db.user.update(&#123;gender:&apos;female&apos;&#125;,&#123;$inc:&#123;salary:50&#125;&#125;,false,true) &gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;52453cfb25e437dfea8fd4f4&quot;), &quot;name&quot; : &quot;Gal Gadot&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 11050 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;52453d8525e437dfea8fd4f5&quot;), &quot;name&quot; : &quot;Mikie Hara&quot;, &quot;gender&quot; : &quot;female&quot;, &quot;age&quot; : 26, &quot;salary&quot; : 7050 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;52453e2125e437dfea8fd4f6&quot;), &quot;name&quot; : &quot;Wentworth Earl Miller&quot;, &quot;gender&quot; : &quot;male&quot;, &quot;age&quot; : 41, &quot;salary&quot; : 33000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;52454155d8947fb70d000000&quot;), &quot;name&quot; : &quot;not known&quot;, &quot;sex_orientation&quot; : &quot;male&quot;, &quot;age&quot; : 13, &quot;salary&quot; : 30000 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5245610881c83a5bf26fc285&quot;), &quot;age&quot; : 23, &quot;name&quot; : &quot;lfqy1&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;52455f8925e437dfea8fd4fd&quot;), &quot;age&quot; : 23, &quot;gender&quot; : &quot;male&quot;, &quot;interest&quot; : &quot;NBA&quot;, &quot;name&quot; : &quot;lfqy&quot;, &quot;salary&quot; : 1 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5245607525e437dfea8fd4fe&quot;), &quot;age&quot; : 23, &quot;gender&quot; : &quot;male&quot;, &quot;interest&quot; : &quot;NBA&quot;, &quot;name&quot; : &quot;lfqy&quot;, &quot;salary&quot; : 2 &#125;关于更新操作(db.collection.update(criteria, objNew, upsert, multi )),要说明的 是,如果 upsert 为 true,那么在没有找到符合更新条件的情况下,mongo 会在集合中插入 一条记录其值满足更新条件的记录(其中的字段只有更新条件中涉及的字段,字段的值满足 更新条件),然后将其更新(注意,如果更新条件是$lt 这种不等式条件,那么 upsert 插入 --------------------------------------------------------------------------------------其它命令操作：1、创建一个聚集集合（table）db.createCollection(“collName”, &#123;size: 20, capped: 5, max: 100&#125;);//创建成功会显示&#123;“ok”:1&#125;//判断集合是否为定容量db.collName.isCapped(); 2、得到指定名称的聚集集合（table）db.getCollection(&quot;account&quot;); 3、得到当前db的所有聚集集合db.getCollectionNames(); 4、显示当前db所有聚集索引的状态db.printCollectionStats(); 三、用户相关1、添加一个用户db.addUser(&quot;name&quot;);db.addUser(&quot;userName&quot;, &quot;pwd123&quot;, true); 添加用户、设置密码、是否只读 2、数据库认证、安全模式db.auth(&quot;userName&quot;, &quot;123123&quot;); 3、显示当前所有用户show users; 4、删除用户db.removeUser(&quot;userName&quot;); 四、聚集集合查询1、查询所有记录db.userInfo.find();相当于：select* from userInfo;默认每页显示20条记录，当显示不下的情况下，可以用it迭代命令查询下一页数据。注意：键入it命令不能带“；”但是你可以设置每页显示数据的大小，用DBQuery.shellBatchSize= 50;这样每页就显示50条记录了。 2、查询去掉后的当前聚集集合中的某列的重复数据db.userInfo.distinct(&quot;name&quot;);会过滤掉name中的相同数据相当于：select distict name from userInfo; 3、查询age = 22的记录db.userInfo.find(&#123;&quot;age&quot;: 22&#125;);相当于： select * from userInfo where age = 22; 4、查询age &gt; 22的记录db.userInfo.find(&#123;age: &#123;$gt: 22&#125;&#125;);相当于：select * from userInfo where age &gt;22; 5、查询age &lt; 22的记录db.userInfo.find(&#123;age: &#123;$lt: 22&#125;&#125;);相当于：select * from userInfo where age &lt;22; 6、查询age &gt;= 25的记录db.userInfo.find(&#123;age: &#123;$gte: 25&#125;&#125;);相当于：select * from userInfo where age &gt;= 25; 7、查询age &lt;= 25的记录db.userInfo.find(&#123;age: &#123;$lte: 25&#125;&#125;); 8、查询age &gt;= 23 并且 age &lt;= 26db.userInfo.find(&#123;age: &#123;$gte: 23, $lte: 26&#125;&#125;); 9、查询name中包含 mongo的数据db.userInfo.find(&#123;name: /mongo/&#125;);//相当于%%[code]select * from userInfo where name like ‘%mongo%&apos;; 10、查询name中以mongo开头的db.userInfo.find(&#123;name: /^mongo/&#125;);select * from userInfo where name like ‘mongo%&apos;; 11、查询指定列name、age数据db.userInfo.find(&#123;&#125;, &#123;name: 1, age: 1&#125;);相当于：select name, age from userInfo;当然name也可以用true或false,当用ture的情况下河name:1效果一样，如果用false就是排除name，显示name以外的列信息。 12、查询指定列name、age数据, age &gt; 25db.userInfo.find(&#123;age: &#123;$gt: 25&#125;&#125;, &#123;name: 1, age: 1&#125;);相当于：select name, age from userInfo where age &gt;25; 13、按照年龄排序升序：db.userInfo.find().sort(&#123;age: 1&#125;);降序：db.userInfo.find().sort(&#123;age: -1&#125;); 14、查询name = zhangsan, age = 22的数据db.userInfo.find(&#123;name: &apos;zhangsan&apos;, age: 22&#125;);相当于：select * from userInfo where name = ‘zhangsan&apos; and age = ‘22&apos;; 15、查询前5条数据db.userInfo.find().limit(5);相当于：selecttop 5 * from userInfo; 16、查询10条以后的数据db.userInfo.find().skip(10);相当于：select * from userInfo where id not in (selecttop 10 * from userInfo); 17、查询在5-10之间的数据db.userInfo.find().limit(10).skip(5); 可用于分页，limit是pageSize，skip是第几页*pageSize 18、or与 查询db.userInfo.find(&#123;$or: [&#123;age: 22&#125;, &#123;age: 25&#125;]&#125;);相当于：select * from userInfo where age = 22 or age = 25; 19、查询第一条数据db.userInfo.findOne();相当于：selecttop 1 * from userInfo;db.userInfo.find().limit(1); 20、查询某个结果集的记录条数db.userInfo.find(&#123;age: &#123;$gte: 25&#125;&#125;).count();相当于：select count(*) from userInfo where age &gt;= 20; 21、按照某列进行排序db.userInfo.find(&#123;sex: &#123;$exists: true&#125;&#125;).count();相当于：select count(sex) from userInfo; 五、索引1、创建索引db.userInfo.ensureIndex(&#123;name: 1&#125;);db.userInfo.ensureIndex(&#123;name: 1, ts: -1&#125;); 2、查询当前聚集集合所有索引db.userInfo.getIndexes(); 3、查看总索引记录大小db.userInfo.totalIndexSize(); 4、读取当前集合的所有index信息db.users.reIndex(); 5、删除指定索引db.users.dropIndex(&quot;name_1&quot;); 6、删除所有索引索引db.users.dropIndexes(); 六、修改、添加、删除集合数据1、添加db.users.save(&#123;name: ‘zhangsan&apos;, age: 25, sex: true&#125;);添加的数据的数据列，没有固定，根据添加的数据为准 2、修改db.users.update(&#123;age: 25&#125;, &#123;$set: &#123;name: &apos;changeName&apos;&#125;&#125;, false, true);相当于：update users set name = ‘changeName&apos; where age = 25;db.users.update(&#123;name: &apos;Lisi&apos;&#125;, &#123;$inc: &#123;age: 50&#125;&#125;, false, true);相当于：update users set age = age + 50 where name = ‘Lisi&apos;;db.users.update(&#123;name: &apos;Lisi&apos;&#125;, &#123;$inc: &#123;age: 50&#125;, $set: &#123;name: &apos;hoho&apos;&#125;&#125;, false, true);相当于：update users set age = age + 50, name = ‘hoho&apos; where name = ‘Lisi&apos;; 3、删除db.users.remove(&#123;age: 132&#125;); 4、查询修改删除db.users.findAndModify(&#123; query: &#123;age: &#123;$gte: 25&#125;&#125;, sort: &#123;age: -1&#125;, update: &#123;$set: &#123;name: &apos;a2&apos;&#125;, $inc: &#123;age: 2&#125;&#125;, remove: true&#125;);db.runCommand(&#123; findandmodify : &quot;users&quot;, query: &#123;age: &#123;$gte: 25&#125;&#125;, sort: &#123;age: -1&#125;, update: &#123;$set: &#123;name: &apos;a2&apos;&#125;, $inc: &#123;age: 2&#125;&#125;, remove: true&#125;); update 或 remove 其中一个是必须的参数; 其他参数可选。参数 详解 默认值query 查询过滤条件 &#123;&#125;sort 如果多个文档符合查询过滤条件，将以该参数指定的排列方式选择出排在首位的对象，该对象将被操作 &#123;&#125;remove 若为true，被选中对象将在返回前被删除 N/Aupdate 一个 修改器对象N/Anew 若为true，将返回修改后的对象而不是原始对象。在删除操作中，该参数被忽略。 falsefields 参见Retrieving a Subset of Fields (1.5.0+)All fieldsupsert 创建新对象若查询结果为空。 示例 (1.5.4+)false 七、语句块操作1、简单Hello Worldprint(&quot;Hello World!&quot;);这种写法调用了print函数，和直接写入&quot;Hello World!&quot;的效果是一样的； 2、将一个对象转换成jsontojson(new Object());tojson(new Object(&apos;a&apos;)); 3、循环添加数据&gt; for (var i = 0; i &lt; 30; i++) &#123;... db.users.save(&#123;name: &quot;u_&quot; + i, age: 22 + i, sex: i % 2&#125;);... &#125;; 这样就循环添加了30条数据，同样也可以省略括号的写法&gt; for (var i = 0; i &lt; 30; i++) db.users.save(&#123;name: &quot;u_&quot; + i, age: 22 + i, sex: i % 2&#125;); 也是可以的，当你用db.users.find()查询的时候，显示多条数据而无法一页显示的情况下，可以用it查看下一页的信息； 4、find 游标查询&gt; var cursor = db.users.find();&gt; while (cursor.hasNext()) &#123; printjson(cursor.next());&#125;这样就查询所有的users信息，同样可以这样写var cursor = db.users.find();while (cursor.hasNext()) &#123; printjson(cursor.next); &#125;同样可以省略&#123;&#125;号 5、forEach迭代循环db.users.find().forEach(printjson);forEach中必须传递一个函数来处理每条迭代的数据信息 6、将find游标当数组处理var cursor = db.users.find();cursor[4];取得下标索引为4的那条数据既然可以当做数组处理，那么就可以获得它的长度：cursor.length();或者cursor.count();那样我们也可以用循环显示数据 for (var i = 0, len = c.length(); i &lt; len; i++) printjson(c[i]); 7、将find游标转换成数组&gt; var arr = db.users.find().toArray();&gt; printjson(arr[2]); 用toArray方法将其转换为数组 8、定制我们自己的查询结果只显示age &lt;= 28的并且只显示age这列数据db.users.find(&#123;age: &#123;$lte: 28&#125;&#125;, &#123;age: 1&#125;).forEach(printjson);db.users.find(&#123;age: &#123;$lte: 28&#125;&#125;, &#123;age: true&#125;).forEach(printjson); 排除age的列db.users.find(&#123;age: &#123;$lte: 28&#125;&#125;, &#123;age: false&#125;).forEach(printjson); 9、forEach传递函数显示信息db.things.find(&#123;x:4&#125;).forEach(function(x) &#123;print(tojson(x));&#125;); 八、其他1、查询之前的错误信息db.getPrevError(); 2、清除错误记录db.resetError(); 查看聚集集合基本信息1、查看帮助 db.yourColl.help();2、查询当前集合的数据条数 db.yourColl.count();3、查看数据空间大小 db.userInfo.dataSize();4、得到当前聚集集合所在的db db.userInfo.getDB();5、得到当前聚集的状态 db.userInfo.stats();6、得到聚集集合总大小 db.userInfo.totalSize();7、聚集集合储存空间大小 db.userInfo.storageSize();8、Shard版本信息 db.userInfo.getShardVersion()9、聚集集合重命名 db.userInfo.renameCollection(&quot;users&quot;); 将userInfo重命名为users10、删除当前聚集集合 db.userInfo.drop(); show dbs:显示数据库列表show collections：显示当前数据库中的集合（类似关系数据库中的表）show users：显示用户use &lt;db name&gt;：切换当前数据库，这和MS-SQL里面的意思一样db.help()：显示数据库操作命令，里面有很多的命令db.foo.help()：显示集合操作命令，同样有很多的命令，foo指的是当前数据库下，一个叫foo的集合，并非真正意义上的命令db.foo.find()：对于当前数据库中的foo集合进行数据查找（由于没有条件，会列出所有数据）db.foo.find( &#123; a : 1 &#125; )：对于当前数据库中的foo集合进行查找，条件是数据中有一个属性叫a，且a的值为1]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mongodb 备份(mongodump)脚本]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FMongo%20%E5%A4%87%E4%BB%BD(mongodump)%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[脚本如下 12345678910111213141516171819202122232425262728293031#!/bin/sh #备份Mongo 数据库：PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binecho &quot;1.初始化。。。。。&quot;export PATH bakDir=&quot;/data_backup/mongodb_bak/h77&quot;dbName=&quot;数据库名称&quot;fileName=$dbName&quot;`date +%Y%m%d`.tar&quot;timeStr=&quot;`date +%Y%m%d`&quot;realDbBakDir=$bakDir/$timeStrif [ ! -x &quot;$bakDir&quot; ];thenmkdir $bakDirficd $bakdirecho &quot;备份的数据库为:&quot; $dbNameecho &quot;备份目录为：&quot; $bakDirecho $dbName &quot;数据库备份文件目录为：&quot; $realDbBakDirecho &quot;2.备份开始：&quot;mongodump -h 127.0.0.1:27017 -u &apos;数据库账号&apos; -p &apos;数据库密码&apos; -d $dbName -o $realDbBakDirecho &quot;3.备份结束，开始打包&quot;for((i=1;i&lt;10;i++)) do echo &quot;当前等待时间&quot; $i &quot;秒&quot; sleep 1 doneecho &quot;备份文件：&quot; $realDbBakDir/$dbName/$fileNametar -czvf $realDbBakDir/$fileName $realDbBakDir/$dbName/echo &quot;4.打包完成,开始scp上传&quot;#scp $realDbBakDir/$fileName root@h121:$bakDirecho &quot;5.上传成功&quot;echo &quot;备份成功日志`date`&quot; &gt;&gt; bak.log]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2Fnew%20post%2F</url>
    <content type="text"></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MongoDB副本集(一主两从)读写分离、故障转移功能环境部署记录]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FMongoDB%E5%89%AF%E6%9C%AC%E9%9B%86(%E4%B8%80%E4%B8%BB%E4%B8%A4%E4%BB%8E)%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E3%80%81%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E5%8A%9F%E8%83%BD%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[[toc] Mongodb是一种非关系数据库(NoSQL)，非关系型数据库的产生就是为了解决大数据量、高扩展性、高性能、灵活数据模型、高可用性。MongoDB官方已经不建议使用主从模式了，替代方案是采用副本集的模式。主从模式其实就是一个单副本的应用，没有很好的扩展性和容错性，而Mongodb副本集具有多个副本保证了容错性，就算一个副本挂掉了还有很多副本存在，主节点挂掉后，整个集群内会实现自动切换。 Mongodb副本集的工作原理 客户端连接到整个Mongodb副本集，不关心具体哪一台节点机是否挂掉。主节点机负责整个副本集的读写，副本集定期同步数据备份，一但主节点挂掉，副本节点就会选举一个新的主服务器，这一切对于应用服务器不需要关心。副本集中的副本节点在主节点挂掉后通过心跳机制检测到后，就会在集群内发起主节点的选举机制，自动选举一位新的主服务器。 看起来Mongodb副本集很牛X的样子，下面就演示下副本集环境部署过程，官方推荐的Mongodb副本集机器数量为至少3个节点，这里我就选择三个节点，一个主节点，两个从节点，暂不使用仲裁节点。 一、环境准备123456789101112131415161718192021222324ip地址 主机名 角色172.16.60.205 mongodb-master01 副本集主节点172.16.60.206 mongodb-slave01 副本集副本节点172.16.60.207 mongodb-slave02 副本集副本节点 三个节点机均设置好各自的主机名，并如下设置好hosts绑定[root@mongodb-master01 ~]# cat /etc/hosts............172.16.60.205 mongodb-master01172.16.60.206 mongodb-slave01172.16.60.207 mongodb-slave02 三个节点机均关闭selinux，为了测试方便，将iptables也关闭[root@mongodb-master01 ~]# setenforce 0[root@mongodb-master01 ~]# cat /etc/sysconfig/selinux...........SELINUX=disabled [root@mongodb-master01 ~]# iptables -F[root@mongodb-master01 ~]# /etc/init.d/iptables stop[root@mongodb-master01 ~]# /etc/init.d/iptables stopiptables: Setting chains to policy ACCEPT: filter [ OK ]iptables: Flushing firewall rules: [ OK ]iptables: Unloading modules: [ OK ] 二、Mongodb安装、副本集配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871) 在三个节点机上建立mongodb副本集测试文件夹，用于存放整个副本集文件[root@mongodb-master01 ~]# mkdir -p /data/mongodb/data/replset/ 2）在三个节点机上安装mongodb下载地址：https://www.mongodb.org/dl/linux/x86_64-rhel62 [root@mongodb-master01 ~]# wget http://downloads.mongodb.org/linux/mongodb-linux-x86_64-rhel62-v3.6-latest.tgz[root@mongodb-master01 ~]# tar -zvxf mongodb-linux-x86_64-rhel62-v3.6-latest.tgz 3）分别在每个节点机上启动mongodb（启动时指明--bind_ip地址，默认是127.0.0.1，需要改成本机ip，否则远程连接时失败）[root@mongodb-master01 ~]# mv mongodb-linux-x86_64-rhel62-3.6.11-rc0-2-g2151d1d219 /usr/local/mongodb[root@mongodb-master01 ~]# nohup /usr/local/mongodb/bin/mongod -dbpath /data/mongodb/data/replset -replSet repset --bind_ip=172.16.60.205 --port=27017 &amp; [root@mongodb-master01 ~]# ps -ef|grep mongodbroot 7729 6977 1 15:10 pts/1 00:00:01 /usr/local/mongodb/bin/mongod -dbpath /data/mongodb/data/replset -replSet repsetroot 7780 6977 0 15:11 pts/1 00:00:00 grep mongodb [root@mongodb-master01 ~]# lsof -i:27017COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmongod 7729 root 10u IPv4 6554476 0t0 TCP localhost:27017 (LISTEN) 4）初始化副本集在三个节点中的任意一个节点机上操作（比如在172.16.60.205节点机） 登陆mongodb[root@mongodb-master01 ~]# /usr/local/mongodb/bin/mongo 172.16.60.205:27017.........#使用admin数据库&gt; use adminswitched to db admin #定义副本集配置变量，这里的 _id:”repset” 和上面命令参数“ –replSet repset” 要保持一样。&gt; config = &#123; _id:&quot;repset&quot;, members:[&#123;_id:0,host:&quot;172.16.60.205:27017&quot;&#125;,&#123;_id:1,host:&quot;172.16.60.206:27017&quot;&#125;,&#123;_id:2,host:&quot;172.16.60.207:27017&quot;&#125;]&#125;&#123; &quot;_id&quot; : &quot;repset&quot;, &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;host&quot; : &quot;172.16.60.205:27017&quot; &#125;, &#123; &quot;_id&quot; : 1, &quot;host&quot; : &quot;172.16.60.206:27017&quot; &#125;, &#123; &quot;_id&quot; : 2, &quot;host&quot; : &quot;172.16.60.207:27017&quot; &#125; ]&#125; #初始化副本集配置&gt; rs.initiate(config);&#123; &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1551166191, 1), &quot;$clusterTime&quot; : &#123; &quot;clusterTime&quot; : Timestamp(1551166191, 1), &quot;signature&quot; : &#123; &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) &#125; &#125;&#125; #查看集群节点的状态repset:SECONDARY&gt; rs.status();&#123; &quot;set&quot; : &quot;repset&quot;, &quot;date&quot; : ISODate(&quot;2019-02-26T07:31:07.766Z&quot;), &quot;myState&quot; : 1, &quot;term&quot; : NumberLong(1), &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;heartbeatIntervalMillis&quot; : NumberLong(2000), &quot;optimes&quot; : &#123; &quot;lastCommittedOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;readConcernMajorityOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;appliedOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;durableOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125; &#125;, &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;name&quot; : &quot;172.16.60.205:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 270, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2019-02-26T07:31:03Z&quot;), &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;could not find member to sync from&quot;, &quot;electionTime&quot; : Timestamp(1551166202, 1), &quot;electionDate&quot; : ISODate(&quot;2019-02-26T07:30:02Z&quot;), &quot;configVersion&quot; : 1, &quot;self&quot; : true, &quot;lastHeartbeatMessage&quot; : &quot;&quot; &#125;, &#123; &quot;_id&quot; : 1, &quot;name&quot; : &quot;172.16.60.206:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 76, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDurable&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2019-02-26T07:31:03Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;2019-02-26T07:31:03Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2019-02-26T07:31:06.590Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2019-02-26T07:31:06.852Z&quot;), &quot;pingMs&quot; : NumberLong(0), &quot;lastHeartbeatMessage&quot; : &quot;&quot;, &quot;syncingTo&quot; : &quot;172.16.60.205:27017&quot;, &quot;syncSourceHost&quot; : &quot;172.16.60.205:27017&quot;, &quot;syncSourceId&quot; : 0, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : 1 &#125;, &#123; &quot;_id&quot; : 2, &quot;name&quot; : &quot;172.16.60.207:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 76, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDurable&quot; : &#123; &quot;ts&quot; : Timestamp(1551166263, 1), &quot;t&quot; : NumberLong(1) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2019-02-26T07:31:03Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;2019-02-26T07:31:03Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2019-02-26T07:31:06.589Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2019-02-26T07:31:06.958Z&quot;), &quot;pingMs&quot; : NumberLong(0), &quot;lastHeartbeatMessage&quot; : &quot;&quot;, &quot;syncingTo&quot; : &quot;172.16.60.205:27017&quot;, &quot;syncSourceHost&quot; : &quot;172.16.60.205:27017&quot;, &quot;syncSourceId&quot; : 0, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : 1 &#125; ], &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1551166263, 1), &quot;$clusterTime&quot; : &#123; &quot;clusterTime&quot; : Timestamp(1551166263, 1), &quot;signature&quot; : &#123; &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) &#125; &#125;&#125; 如上信息表明：副本集配置成功后，172.16.60.205为主节点PRIMARY，172.16.60.206/207为副本节点SECONDARY。health：1 1表明状态是正常，0表明异常state:1 值小的是primary节点、值大的是secondary节点 三、测试Mongodb副本集数据复制功能&lt;mongodb默认是从主节点读写数据的，副本节点上不允许读，需要设置副本节点可以读&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849501）在主节点172.16.60.205上连接到终端[root@mongodb-master01 ~]# /usr/local/mongodb/bin/mongo 172.16.60.205:27017................#建立test 数据库repset:PRIMARY&gt; use test;switched to db test #往testdb表插入测试数据repset:PRIMARY&gt; db.testdb.insert(&#123;&quot;test1&quot;:&quot;testval1&quot;&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 2）在副本节点172.16.60.206、172.16.60.207上连接到mongodb查看数据是否复制过来。这里在172.16.60.206副本节点上进行查看[root@mongodb-slave01 ~]# /usr/local/mongodb/bin/mongo 172.16.60.206:27017................repset:SECONDARY&gt; use test;switched to db testrepset:SECONDARY&gt; show tables;2019-02-26T15:37:46.446+0800 E QUERY [thread1] Error: listCollections failed: &#123; &quot;operationTime&quot; : Timestamp(1551166663, 1), &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not master and slaveOk=false&quot;, &quot;code&quot; : 13435, &quot;codeName&quot; : &quot;NotMasterNoSlaveOk&quot;, &quot;$clusterTime&quot; : &#123; &quot;clusterTime&quot; : Timestamp(1551166663, 1), &quot;signature&quot; : &#123; &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) &#125; &#125;&#125; :_getErrorWithCode@src/mongo/shell/utils.js:25:13DB.prototype._getCollectionInfosCommand@src/mongo/shell/db.js:941:1DB.prototype.getCollectionInfos@src/mongo/shell/db.js:953:19DB.prototype.getCollectionNames@src/mongo/shell/db.js:964:16shellHelper.show@src/mongo/shell/utils.js:853:9shellHelper@src/mongo/shell/utils.js:750:15@(shellhelp2):1:1 上面出现了报错！这是因为mongodb默认是从主节点读写数据的，副本节点上不允许读，需要设置副本节点可以读repset:SECONDARY&gt; db.getMongo().setSlaveOk();repset:SECONDARY&gt; db.testdb.find();&#123; &quot;_id&quot; : ObjectId(&quot;5c74ec9267d8c3d06506449b&quot;), &quot;test1&quot; : &quot;testval1&quot; &#125;repset:SECONDARY&gt; show tables;testdb 如上发现已经在副本节点上发现了测试数据，即已经从主节点复制过来了。（在另一个副本节点172.16.60.207也如上操作即可） 四、测试副本集故障转移功能先停掉主节点172.16.60.205，查看mongodb副本集状态，可以看到经过一系列的投票选择操作，172.16.60.206当选主节点，172.16.60.207从172.16.60.206同步数据过来。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742751）停掉原来的主节点172.16.60.205的mongodb，模拟故障[root@mongodb-master01 ~]# ps -ef|grep mongodb|grep -v grep|awk &apos;&#123;print $2&#125;&apos;|xargs kill -9[root@mongodb-master01 ~]# lsof -i:27017[root@mongodb-master01 ~]# 2）接着登录到另外两个正常的从节点172.16.60.206、172.16.60.207中的任意一个节点的mongodb，查看副本集状态[root@mongodb-slave01 ~]# /usr/local/mongodb/bin/mongo 172.16.60.206:27017.................repset:PRIMARY&gt; rs.status();&#123; &quot;set&quot; : &quot;repset&quot;, &quot;date&quot; : ISODate(&quot;2019-02-26T08:06:02.996Z&quot;), &quot;myState&quot; : 1, &quot;term&quot; : NumberLong(2), &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;heartbeatIntervalMillis&quot; : NumberLong(2000), &quot;optimes&quot; : &#123; &quot;lastCommittedOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168359, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;readConcernMajorityOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168359, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;appliedOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168359, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;durableOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168359, 1), &quot;t&quot; : NumberLong(2) &#125; &#125;, &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;name&quot; : &quot;172.16.60.205:27017&quot;, &quot;health&quot; : 0, &quot;state&quot; : 8, &quot;stateStr&quot; : &quot;(not reachable/healthy)&quot;, &quot;uptime&quot; : 0, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(0, 0), &quot;t&quot; : NumberLong(-1) &#125;, &quot;optimeDurable&quot; : &#123; &quot;ts&quot; : Timestamp(0, 0), &quot;t&quot; : NumberLong(-1) &#125;, &quot;optimeDate&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2019-02-26T08:06:02.917Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2019-02-26T08:03:37.492Z&quot;), &quot;pingMs&quot; : NumberLong(0), &quot;lastHeartbeatMessage&quot; : &quot;Connection refused&quot;, &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : -1 &#125;, &#123; &quot;_id&quot; : 1, &quot;name&quot; : &quot;172.16.60.206:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 2246, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168359, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2019-02-26T08:05:59Z&quot;), &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;&quot;, &quot;electionTime&quot; : Timestamp(1551168228, 1), &quot;electionDate&quot; : ISODate(&quot;2019-02-26T08:03:48Z&quot;), &quot;configVersion&quot; : 1, &quot;self&quot; : true, &quot;lastHeartbeatMessage&quot; : &quot;&quot; &#125;, &#123; &quot;_id&quot; : 2, &quot;name&quot; : &quot;172.16.60.207:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 2169, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168359, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;optimeDurable&quot; : &#123; &quot;ts&quot; : Timestamp(1551168359, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2019-02-26T08:05:59Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;2019-02-26T08:05:59Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2019-02-26T08:06:02.861Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2019-02-26T08:06:02.991Z&quot;), &quot;pingMs&quot; : NumberLong(0), &quot;lastHeartbeatMessage&quot; : &quot;&quot;, &quot;syncingTo&quot; : &quot;172.16.60.206:27017&quot;, &quot;syncSourceHost&quot; : &quot;172.16.60.206:27017&quot;, &quot;syncSourceId&quot; : 1, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : 1 &#125; ], &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1551168359, 1), &quot;$clusterTime&quot; : &#123; &quot;clusterTime&quot; : Timestamp(1551168359, 1), &quot;signature&quot; : &#123; &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) &#125; &#125;&#125; 发现当原来的主节点172.16.60.205宕掉后，经过选举，原来的从节点172.16.60.206被推举为新的主节点。 3）现在在172.16.60.206新主节点上创建测试数据repset:PRIMARY&gt; use kevin;switched to db kevinrepset:PRIMARY&gt; db.kevin.insert(&#123;&quot;shibo&quot;:&quot;hahaha&quot;&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 4）另一个从节点172.16.60.207上登录mongodb查看[root@mongodb-slave02 ~]# /usr/local/mongodb/bin/mongo 172.16.60.207:27017................repset:SECONDARY&gt; use kevin;switched to db kevinrepset:SECONDARY&gt; db.getMongo().setSlaveOk();repset:SECONDARY&gt; show tables;kevinrepset:SECONDARY&gt; db.kevin.find();&#123; &quot;_id&quot; : ObjectId(&quot;5c74f42bb0b339ed6eb68e9c&quot;), &quot;shibo&quot; : &quot;hahaha&quot; &#125; 发现从节点172.16.60.207可以同步新的主节点172.16.60.206的数据 5）再重新启动原来的主节点172.16.60.205的mongodb[root@mongodb-master01 ~]# nohup /usr/local/mongodb/bin/mongod -dbpath /data/mongodb/data/replset -replSet repset --bind_ip=172.16.60.205 --port=27017 &amp; mongod 9162 root 49u IPv4 6561201 0t0 TCP mongodb-master01:55236-&gt;mongodb-slave01:27017 (ESTABLISHED)[root@mongodb-master01 ~]# ps -ef|grep mongodbroot 9162 6977 4 16:14 pts/1 00:00:01 /usr/local/mongodb/bin/mongod -dbpath /data/mongodb/data/replset -replSet repset --bind_ip=172.16.60.205 --port=27017root 9244 6977 0 16:14 pts/1 00:00:00 grep mongodb 再次登录到三个节点中的任意一个的mongodb，查看副本集状态[root@mongodb-master01 ~]# /usr/local/mongodb/bin/mongo 172.16.60.205:27017....................repset:SECONDARY&gt; rs.status();&#123; &quot;set&quot; : &quot;repset&quot;, &quot;date&quot; : ISODate(&quot;2019-02-26T08:16:11.741Z&quot;), &quot;myState&quot; : 2, &quot;term&quot; : NumberLong(2), &quot;syncingTo&quot; : &quot;172.16.60.206:27017&quot;, &quot;syncSourceHost&quot; : &quot;172.16.60.206:27017&quot;, &quot;syncSourceId&quot; : 1, &quot;heartbeatIntervalMillis&quot; : NumberLong(2000), &quot;optimes&quot; : &#123; &quot;lastCommittedOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;readConcernMajorityOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;appliedOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;durableOpTime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125; &#125;, &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;name&quot; : &quot;172.16.60.205:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 129, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2019-02-26T08:16:09Z&quot;), &quot;syncingTo&quot; : &quot;172.16.60.206:27017&quot;, &quot;syncSourceHost&quot; : &quot;172.16.60.206:27017&quot;, &quot;syncSourceId&quot; : 1, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : 1, &quot;self&quot; : true, &quot;lastHeartbeatMessage&quot; : &quot;&quot; &#125;, &#123; &quot;_id&quot; : 1, &quot;name&quot; : &quot;172.16.60.206:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 127, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;optimeDurable&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2019-02-26T08:16:09Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;2019-02-26T08:16:09Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2019-02-26T08:16:10.990Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2019-02-26T08:16:11.518Z&quot;), &quot;pingMs&quot; : NumberLong(0), &quot;lastHeartbeatMessage&quot; : &quot;&quot;, &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;&quot;, &quot;electionTime&quot; : Timestamp(1551168228, 1), &quot;electionDate&quot; : ISODate(&quot;2019-02-26T08:03:48Z&quot;), &quot;configVersion&quot; : 1 &#125;, &#123; &quot;_id&quot; : 2, &quot;name&quot; : &quot;172.16.60.207:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 2, &quot;stateStr&quot; : &quot;SECONDARY&quot;, &quot;uptime&quot; : 127, &quot;optime&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;optimeDurable&quot; : &#123; &quot;ts&quot; : Timestamp(1551168969, 1), &quot;t&quot; : NumberLong(2) &#125;, &quot;optimeDate&quot; : ISODate(&quot;2019-02-26T08:16:09Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;2019-02-26T08:16:09Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2019-02-26T08:16:10.990Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;2019-02-26T08:16:11.655Z&quot;), &quot;pingMs&quot; : NumberLong(0), &quot;lastHeartbeatMessage&quot; : &quot;&quot;, &quot;syncingTo&quot; : &quot;172.16.60.206:27017&quot;, &quot;syncSourceHost&quot; : &quot;172.16.60.206:27017&quot;, &quot;syncSourceId&quot; : 1, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : 1 &#125; ], &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1551168969, 1), &quot;$clusterTime&quot; : &#123; &quot;clusterTime&quot; : Timestamp(1551168969, 1), &quot;signature&quot; : &#123; &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) &#125; &#125;&#125; 发现原来的主节点172.16.60.205在故障恢复后，变成了新的主节点172.16.60.206的从节点 五、Mongodb读写分离目前来看。Mongodb副本集可以完美支持故障转移。至于主节点的读写压力过大如何解决？常见的解决方案是读写分离。 12345678910111213141516171819202122232425262728一般情况下，常规写操作来说并没有读操作多，所以在Mongodb副本集中，一台主节点负责写操作，两台副本节点负责读操作。1）设置读写分离需要先在副本节点SECONDARY 设置 setSlaveOk。2）在程序中设置副本节点负责读操作，如下代码：&lt;br&gt;public class TestMongoDBReplSetReadSplit &#123;public static void main(String[] args) &#123;try &#123;List&lt;ServerAddress&gt; addresses = new ArrayList&lt;ServerAddress&gt;();ServerAddress address1 = new ServerAddress(&quot;172.16.60.205&quot; , 27017);ServerAddress address2 = new ServerAddress(&quot;172.16.60.206&quot; , 27017);ServerAddress address3 = new ServerAddress(&quot;172.16.60.207&quot; , 27017);addresses.add(address1);addresses.add(address2);addresses.add(address3);MongoClient client = new MongoClient(addresses);DB db = client.getDB( &quot;test&quot; );DBCollection coll = db.getCollection( &quot;testdb&quot; );BasicDBObject object = new BasicDBObject();object.append( &quot;test2&quot; , &quot;testval2&quot; ); //读操作从副本节点读取ReadPreference preference = ReadPreference. secondary();DBObject dbObject = coll.findOne(object, null , preference);System. out .println(dbObject);&#125; catch (Exception e) &#123;e.printStackTrace();&#125;&#125;&#125; 六、参数解析123456读参数除了secondary一共还有五个参数：primary、primaryPreferred、secondary、secondaryPreferred、nearest。primary：默认参数，只从主节点上进行读取操作；primaryPreferred：大部分从主节点上读取数据,只有主节点不可用时从secondary节点读取数据。secondary：只从secondary节点上进行读取操作，存在的问题是secondary节点的数据会比primary节点数据“旧”。secondaryPreferred：优先从secondary节点进行读取操作，secondary节点不可用时从主节点读取数据；nearest：不管是主节点、secondary节点，从网络延迟最低的节点上读取数据。 读写分离做好后，就可以进行数据分流，减轻压力，解决了”主节点的读写压力过大如何解决？”这个问题。 七、仲裁节点介绍不过当副本节点增多时，主节点的复制压力会加大有什么办法解决吗？基于这个问题，Mongodb已有了相应的解决方案 - 引用仲裁节点：在Mongodb副本集中，仲裁节点不存储数据，只是负责故障转移的群体投票，这样就少了数据复制的压力。看起来想的很周到啊，其实不只是主节点、副本节点、仲裁节点，还有Secondary-Only、Hidden、Delayed、Non-Voting，其中： 1234Secondary-Only：不能成为primary节点，只能作为secondary副本节点，防止一些性能不高的节点成为主节点。Hidden：这类节点是不能够被客户端制定IP引用，也不能被设置为主节点，但是可以投票，一般用于备份数据。Delayed：可以指定一个时间延迟从primary节点同步数据。主要用于备份数据，如果实时同步，误删除数据马上同步到从节点，恢复又恢复不了。Non-Voting：没有选举权的secondary节点，纯粹的备份数据节点。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵模式（sentinel）部署记录]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FRedis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%EF%BC%88sentinel%EF%BC%89%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[[toc] 1.redis主从复制的大致过程：1）当一个从数据库启动时，会向主数据库发送sync命令，2）主数据库接收到sync命令后会开始在后台保存快照（执行rdb操作），并将保存期间接收到的命令缓存起来3）当快照完成后，redis会将快照文件和所有缓存的命令发送给从数据库。4）从数据库收到后，会载入快照文件并执行收到的缓存的命令。注意：redis2.8之前的版本：当主从数据库同步的时候从数据库因为网络原因断开重连后会重新执行上述操作，不支持断点续传。redis2.8之后支持断点续传。 2.Redis主从结构支持一主多从+n个sentinel模式，信息如下：1234567891011121314192.168.10.202 redis-master redis（6379）、sentinel（26379）192.168.10.203 redis-slave01 redis（6379）、sentinel（26379）192.168.10.205 redis-slave02 redis（6379）、sentinel（26379） 关闭三个节点机器的iptables和selinux（所有节点机器上都要操作）[root@redis-master ~]# /etc/init.d/iptables stop[root@redis-master ~]# vim /etc/sysconfig/selinux......SELINUX=disabled[root@redis-master ~]# setenforce 0[root@redis-master ~]# getenforcePermissive 注意：本案例采用1主2从+3 sentinel的集群模式，所有从节点的配置都一样。 3.redis一键安装（三个节点上都要操作）123456789101112131415161718192021222324252627282930[root@redis-master ~]# cd /usr/local/src/[root@redis-master src]# vim install_redis.sh#!/usr/bin/env bash# It&apos;s Used to be install redis.# Created on 2018/01/08# Version: 1.0 function install_redis () &#123;################################################################################################# cd /usr/local/src if [ ! -f &quot; redis-4.0.1.tar.gz&quot; ]; then wget http://download.redis.io/releases/redis-4.0.1.tar.gz fi cd /usr/local/src tar -zxvf /usr/local/src/redis-4.0.1.tar.gz cd redis-4.0.1 make PREFIX=/usr/local/redis install mkdir -p /usr/local/redis/&#123;etc,var&#125; rsync -avz redis.conf /usr/local/redis/etc/ sed -i &apos;s@pidfile.*@pidfile /var/run/redis-server.pid@&apos; /usr/local/redis/etc/redis.conf sed -i &quot;s@logfile.*@logfile /usr/local/redis/var/redis.log@&quot; /usr/local/redis/etc/redis.conf sed -i &quot;s@^dir.*@dir /usr/local/redis/var@&quot; /usr/local/redis/etc/redis.conf sed -i &apos;s/daemonize no/daemonize yes/g&apos; /usr/local/redis/etc/redis.conf sed -i &apos;s/^# bind 127.0.0.1/bind 0.0.0.0/g&apos; /usr/local/redis/etc/redis.conf #################################################################################################&#125; install_redis[root@redis-master src]# chmod 755 install_redis.sh[root@redis-master src]# sh -x install_redis.sh 4. redis启停脚本（三个节点上都要操作）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106[root@redis-master src]# vim /etc/init.d/redis-server#!/bin/bash## redis - this script starts and stops the redis-server daemon## chkconfig: - 85 15# description: Redis is a persistent key-value database# processname: redis-server# config: /usr/local/redis/etc/redis.conf# config: /etc/sysconfig/redis# pidfile: /usr/local/redis/var/redis-server.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0 redis=&quot;/usr/local/redis/bin/redis-server&quot;prog=$(basename $redis) REDIS_CONF_FILE=&quot;/usr/local/redis/etc/redis.conf&quot; [ -f /etc/sysconfig/redis ] &amp;&amp; . /etc/sysconfig/redis lockfile=/var/lock/subsys/redis-server start() &#123; [ -x $redis ] || exit 5 [ -f $REDIS_CONF_FILE ] || exit 6 echo -n $&quot;Starting $prog: &quot; daemon $redis $REDIS_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; stop start&#125; reload() &#123; echo -n $&quot;Reloading $prog: &quot; killproc $redis -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload&#125;&quot; exit 2esac 执行权限[root@redis-master src]# chmod 755 /etc/init.d/redis-server 5.redis-sentinel启停脚本示例（三个节点上都要操作）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106[root@redis-master src]# vim /etc/init.d/redis-sentinel#!/bin/bash## redis-sentinel - this script starts and stops the redis-server sentinel daemon## chkconfig: - 85 15# description: Redis sentinel# processname: redis-server# config: /usr/local/redis/etc/sentinel.conf# config: /etc/sysconfig/redis# pidfile: /usr/local/redis/var/redis-sentinel.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0 redis=&quot;/usr/local/redis/bin/redis-sentinel&quot;prog=$(basename $redis) REDIS_CONF_FILE=&quot;/usr/local/redis/etc/sentinel.conf&quot; [ -f /etc/sysconfig/redis ] &amp;&amp; . /etc/sysconfig/redis lockfile=/var/lock/subsys/redis-sentinel start() &#123; [ -x $redis ] || exit 5 [ -f $REDIS_CONF_FILE ] || exit 6 echo -n $&quot;Starting $prog: &quot; daemon $redis $REDIS_CONF_FILE --sentinel retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; stop start&#125; reload() &#123; echo -n $&quot;Reloading $prog: &quot; killproc $redis -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload&#125;&quot; exit 2esac 执行权限：[root@redis-master src]# chmod 755 /etc/init.d/redis-sentinel 6.配置redis.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117a）编辑redis-master主节点的redis.conf文件[root@redis-master src]# mkdir -p /usr/local/redis/data/redis[root@redis-master src]# cp /usr/local/redis/etc/redis.conf /usr/local/redis/etc/redis.conf.bak[root@redis-master src]# vim /usr/local/redis/etc/redis.confbind 0.0.0.0daemonize yespidfile &quot;/usr/local/redis/var/redis-server.pid&quot;port 6379tcp-backlog 128timeout 0tcp-keepalive 0loglevel noticelogfile &quot;/usr/local/redis/var/redis-server.log&quot;databases 16save 900 1 save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir &quot;/usr/local/redis/data/redis&quot;#masterauth &quot;20180408&quot; #master设置密码保护，即slave连接master时的密码#requirepass &quot;20180408&quot; #设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-disable-tcp-nodelay noslave-priority 100appendonly yes #打开aof持久化appendfilename &quot;appendonly.aof&quot;appendfsync everysec # 每秒一次aof写no-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yeslua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128latency-monitor-threshold 0notify-keyspace-events &quot;&quot;hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yes 注意：上面配置中masterauth和requirepass表示设置密码保护，如果设置了密码，则连接redis后需要执行&quot;auth 20180408&quot;密码后才能操作其他命令。这里我不设置密码。 b）编辑redis-slave01和redis-slave02两个从节点的redis.conf文件[root@redis-slave01 src]# mkdir -p /usr/local/redis/data/redis[root@redis-slave01 src]# cp /usr/local/redis/etc/redis.conf /usr/local/redis/etc/redis.conf.bak[root@redis-slave01 src]# vim /usr/local/redis/etc/redis.confbind 0.0.0.0daemonize yespidfile &quot;/usr/local/redis/var/redis-server.pid&quot;port 6379tcp-backlog 128timeout 0tcp-keepalive 0loglevel noticelogfile &quot;/usr/local/redis/var/redis-server.log&quot;databases 16save 900 1 save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir &quot;/usr/local/redis/data/redis&quot;#masterauth &quot;20180408&quot; #requirepass &quot;20180408&quot; slaveof 192.168.10.202 6379 #相对主redis配置，多添加了此行 slave-serve-stale-data yesslave-read-only yes #从节点只读，不能写入repl-diskless-sync norepl-diskless-sync-delay 5repl-disable-tcp-nodelay noslave-priority 100appendonly yes appendfilename &quot;appendonly.aof&quot;appendfsync everysec no-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yeslua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128latency-monitor-threshold 0notify-keyspace-events &quot;&quot;hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yes 7.配置sentinel.conf（这个默认没有，需要自建）。三个节点的配置一样。123456789101112[root@redis-master src]# mkdir -p /usr/local/redis/data/sentinel[root@redis-master src]# vim /usr/local/redis/etc/sentinel.confport 26379pidfile &quot;/usr/local/redis/var/redis-sentinel.pid&quot;dir &quot;/usr/local/redis/data/sentinel&quot;daemonize yesprotected-mode nologfile &quot;/usr/local/redis/var/redis-sentinel.log&quot;sentinel monitor redisMaster 192.168.10.202 6379 2 sentinel down-after-milliseconds redisMaster 10000 sentinel parallel-syncs redisMaster 1sentinel failover-timeout redisMaster 60000 8. 启动redis和sentinel（三个节点都要操作）12345678910111213141516171819202122设置系统变量[root@redis-slave02 src]# vim /etc/profile.......export PATH=$PATH:/usr/local/redis/bin[root@redis-slave02 src]# source /etc/profile 启动redis和sentinel[root@redis-master src]# /etc/init.d/redis-server startStarting redis-server: [ OK ][root@redis-master src]# /etc/init.d/redis-sentinel startStarting redis-sentinel: [ OK ][root@redis-master src]# lsof -i:6379COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEredis-ser 2297 root 6u IPv4 7819726 0t0 TCP *:6379 (LISTEN)redis-ser 2297 root 8u IPv4 7819778 0t0 TCP 192.168.10.202:6379-&gt;192.168.10.202:56226 (ESTABLISHED)redis-ser 2297 root 9u IPv4 7819780 0t0 TCP 192.168.10.202:6379-&gt;192.168.10.202:56228 (ESTABLISHED)redis-sen 2315 root 8u IPv4 7819777 0t0 TCP 192.168.10.202:56226-&gt;192.168.10.202:6379 (ESTABLISHED)redis-sen 2315 root 9u IPv4 7819779 0t0 TCP 192.168.10.202:56228-&gt;192.168.10.202:6379 (ESTABLISHED)[root@redis-master src]# lsof -i:26379COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEredis-sen 2315 root 6u IPv6 7819772 0t0 TCP *:26379 (LISTEN)redis-sen 2315 root 7u IPv4 7819773 0t0 TCP *:26379 (LISTEN) 9.查看redis和sentinel信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631）查看三个节点的redis的主从关系[root@redis-master src]# redis-cli -h 192.168.10.202 -p 6379 INFO|grep rolerole:master[root@redis-master src]# redis-cli -h 192.168.10.203 -p 6379 INFO|grep rolerole:slave[root@redis-master src]# redis-cli -h 192.168.10.205 -p 6379 INFO|grep rolerole:slave 从上面信息可以看出，192.168.10.202是master，192.168.10.203和192.168.10.205是slave 2）查看Master节点信息：[root@redis-master src]# redis-cli -h 192.168.10.202 -p 6379 info Replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.10.203,port=6379,state=online,offset=61480,lag=0slave1:ip=192.168.10.205,port=6379,state=online,offset=61480,lag=0master_replid:96a1fd63d0ad9e7903851a82382e32d690667bccmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:61626second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:61626 从上面信息看出，此时192.168.10.202的角色为master，有两个slave（203和205）被连接成功. 此时打开master的sentinel.conf，在末尾可看到如下自动写入的内容：[root@redis-master src]# cat /usr/local/redis/etc/sentinel.confport 26379pidfile &quot;/usr/local/redis/var/redis-sentinel.pid&quot;dir &quot;/usr/local/redis/data/sentinel&quot;daemonize yesprotected-mode nologfile &quot;/usr/local/redis/var/redis-sentinel.log&quot;sentinel myid c165761901b5ea3cd2d622bbf13f4c99eb73c1bcsentinel monitor redisMaster 192.168.10.202 6379 2sentinel down-after-milliseconds redisMaster 10000sentinel failover-timeout redisMaster 60000# Generated by CONFIG REWRITEsentinel config-epoch redisMaster 0sentinel leader-epoch redisMaster 0sentinel known-slave redisMaster 192.168.10.203 6379sentinel known-slave redisMaster 192.168.10.205 6379sentinel known-sentinel redisMaster 192.168.10.205 26379 cc25d5f0e37803e888732d63deae3761c9f91e1dsentinel known-sentinel redisMaster 192.168.10.203 26379 e1505ffc65f787871febfde2f27b762f70cddd71sentinel current-epoch 0 [root@redis-master ~]# redis-cli -h 192.168.10.205 -p 26379 info Sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=redisMaster,status=ok,address=192.168.10.202:6379,slaves=2,sentinels=3 3）查看Slave节点信息： 先查看salve01节点信息[root@redis-slave01 src]# redis-cli -h 192.168.10.203 -p 6379 info Replication# Replicationrole:slavemaster_host:192.168.10.202master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:96744slave_priority:100slave_read_only:1connected_slaves:0master_replid:96a1fd63d0ad9e7903851a82382e32d690667bccmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:96744second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:96744 此时192.168.10.203的角色为slave，它们所属的master为220。此时打开slave的sentinel.conf，在末尾可看到如下自动写入的内容：[root@redis-slave01 src]# cat /usr/local/redis/etc/sentinel.confport 26379pidfile &quot;/usr/local/redis/var/redis-sentinel.pid&quot;dir &quot;/usr/local/redis/data/sentinel&quot;daemonize yesprotected-mode nologfile &quot;/usr/local/redis/var/redis-sentinel.log&quot;sentinel myid e1505ffc65f787871febfde2f27b762f70cddd71sentinel monitor redisMaster 192.168.10.202 6379 2sentinel down-after-milliseconds redisMaster 10000sentinel failover-timeout redisMaster 60000# Generated by CONFIG REWRITEsentinel config-epoch redisMaster 0sentinel leader-epoch redisMaster 0sentinel known-slave redisMaster 192.168.10.203 6379sentinel known-slave redisMaster 192.168.10.205 6379sentinel known-sentinel redisMaster 192.168.10.205 26379 cc25d5f0e37803e888732d63deae3761c9f91e1dsentinel known-sentinel redisMaster 192.168.10.202 26379 c165761901b5ea3cd2d622bbf13f4c99eb73c1bcsentinel current-epoch 0 [root@redis-slave01 ~]# redis-cli -h 192.168.10.203 -p 26379 info Sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=redisMaster,status=ok,address=192.168.10.202:6379,slaves=2,sentinels=3 同样查看slave02节点的信息[root@redis-slave02 src]# redis-cli -h 192.168.10.205 -p 6379 info Replication# Replicationrole:slavemaster_host:192.168.10.202master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:99678slave_priority:100slave_read_only:1connected_slaves:0master_replid:96a1fd63d0ad9e7903851a82382e32d690667bccmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:99678second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:170repl_backlog_histlen:99509 [root@redis-slave02 src]# cat /usr/local/redis/etc/sentinel.confport 26379pidfile &quot;/usr/local/redis/var/redis-sentinel.pid&quot;dir &quot;/usr/local/redis/data/sentinel&quot;daemonize yesprotected-mode nologfile &quot;/usr/local/redis/var/redis-sentinel.log&quot;sentinel myid cc25d5f0e37803e888732d63deae3761c9f91e1dsentinel monitor redisMaster 192.168.10.202 6379 2sentinel down-after-milliseconds redisMaster 10000sentinel failover-timeout redisMaster 60000# Generated by CONFIG REWRITEsentinel config-epoch redisMaster 0sentinel leader-epoch redisMaster 0sentinel known-slave redisMaster 192.168.10.205 6379sentinel known-slave redisMaster 192.168.10.203 6379sentinel known-sentinel redisMaster 192.168.10.203 26379 e1505ffc65f787871febfde2f27b762f70cddd71sentinel known-sentinel redisMaster 192.168.10.202 26379 c165761901b5ea3cd2d622bbf13f4c99eb73c1bcsentinel current-epoch 0 [root@redis-slave02 ~]# redis-cli -h 192.168.10.205 -p 26379 info Sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=redisMaster,status=ok,address=192.168.10.202:6379,slaves=2,sentinels=3 10.客户端写入测试数据1234567891011121314151617181920212223客户端连接master节点，写入一条数据[root@redis-master src]# redis-cli -h 192.168.10.202 -p 6379192.168.10.202:6379&gt; set name kevin;OK192.168.10.202:6379&gt; get name;&quot;kevin&quot;; 然后客户端再连接任意slave节点，通过get获取上面的那条数据[root@redis-master src]# redis-cli -h 192.168.10.203 -p 6379192.168.10.203:6379&gt; get name&quot;kevin;&quot;192.168.10.203:6379&gt; set name grace;(error) READONLY You can&apos;t write against a read only slave.192.168.10.203:6379&gt; [root@redis-master src]# redis-cli -h 192.168.10.205 -p 6379192.168.10.205:6379&gt; get name&quot;kevin;&quot;192.168.10.205:6379&gt; set name grace;(error) READONLY You can&apos;t write against a read only slave.192.168.10.205:6379&gt; 由上面测试信息可知，master节点可以写入，可以读取；而slave节点默认只能读取，不能写入！这就实现了主从复制，读写分离了！ 11.模拟故障（通过sentinel实现主从切换，sentinel也要部署多台，即集群模式，防止单台sentinel挂掉情况）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981991）关掉任意一个slave节点（比如关闭掉slave01节点），所有节点的sentinel都可以检测到，出现如下示例信息：[root@redis-master src]# redis-cli -h 192.168.10.203 -p 6379192.168.10.203:6379&gt; get name&quot;kevin;&quot;192.168.10.203:6379&gt; set name grace;(error) READONLY You can&apos;t write against a read only slave.192.168.10.203:6379&gt; shutdown not connected&gt; 说明：shutdown命令表示关闭redis 从上可看出203被sentinel检测到已处于关闭状态，此时再来查看剩余节点的主从信息，它们的角色不会发生变化，只是master上的connected_slaves变为了1。[root@redis-master src]# redis-cli -h 192.168.10.202 -p 6379 info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.10.205,port=6379,state=online,offset=219376,lag=1master_replid:96a1fd63d0ad9e7903851a82382e32d690667bccmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:219376second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:219376 查看sentinel日志（任意节点上查看），发现203节点已经进入&quot;+sdown&quot;状态[root@redis-master src]# tail -f /usr/local/redis/var/redis-sentinel.log2315:X 08 May 18:49:51.429 * Increased maximum number of open files to 10032 (it was originally set to 1024).2315:X 08 May 18:49:51.431 * Running mode=sentinel, port=26379.2315:X 08 May 18:49:51.431 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.2315:X 08 May 18:49:51.463 # Sentinel ID is c165761901b5ea3cd2d622bbf13f4c99eb73c1bc2315:X 08 May 18:49:51.463 # +monitor master redisMaster 192.168.10.202 6379 quorum 22315:X 08 May 18:50:11.544 * +slave slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 18:50:11.574 * +slave slave 192.168.10.205:6379 192.168.10.205 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 18:50:15.088 * +sentinel sentinel e1505ffc65f787871febfde2f27b762f70cddd71 192.168.10.203 26379 @ redisMaster 192.168.10.202 63792315:X 08 May 18:50:16.075 * +sentinel sentinel cc25d5f0e37803e888732d63deae3761c9f91e1d 192.168.10.205 26379 @ redisMaster 192.168.10.202 63792315:X 08 May 19:06:07.669 # +sdown slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 6379 然后重启上面被关闭的slave节点（即192.168.10.203），所有节点的sentinel都可以检测到，可看出221又被sentinel检测到已处于可用状态，此时再来查看节点的主从信息，它们的角色仍然不会发生变化，master上的connected_slaves又变为了2[root@redis-slave01 src]# /etc/init.d/redis-server restartStopping redis-server: [FAILED]Starting redis-server: [ OK ][root@redis-slave01 src]# /etc/init.d/redis-server restartStopping redis-server: [ OK ]Starting redis-server: [ OK ] [root@redis-master src]# redis-cli -h 192.168.10.202 -p 6379 info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.10.205,port=6379,state=online,offset=268216,lag=0slave1:ip=192.168.10.203,port=6379,state=online,offset=268070,lag=1master_replid:96a1fd63d0ad9e7903851a82382e32d690667bccmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:268216second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:268216 查看sentinel日志（任意节点上查看），发现203节点已经进入&quot;-sdown&quot;状态[root@redis-master src]# tail -f /usr/local/redis/var/redis-sentinel.log2315:X 08 May 18:49:51.429 * Increased maximum number of open files to 10032 (it was originally set to 1024).2315:X 08 May 18:49:51.431 * Running mode=sentinel, port=26379.2315:X 08 May 18:49:51.431 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.2315:X 08 May 18:49:51.463 # Sentinel ID is c165761901b5ea3cd2d622bbf13f4c99eb73c1bc2315:X 08 May 18:49:51.463 # +monitor master redisMaster 192.168.10.202 6379 quorum 22315:X 08 May 18:50:11.544 * +slave slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 18:50:11.574 * +slave slave 192.168.10.205:6379 192.168.10.205 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 18:50:15.088 * +sentinel sentinel e1505ffc65f787871febfde2f27b762f70cddd71 192.168.10.203 26379 @ redisMaster 192.168.10.202 63792315:X 08 May 18:50:16.075 * +sentinel sentinel cc25d5f0e37803e888732d63deae3761c9f91e1d 192.168.10.205 26379 @ redisMaster 192.168.10.202 63792315:X 08 May 19:06:07.669 # +sdown slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 19:10:14.965 * +reboot slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 19:10:15.020 # -sdown slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 6379 =======================================================================================================2）关掉master节点（即192.168.10.202），待所有节点的sentinel都检测到后（稍等一会，2-3秒钟时间），再来查看两个Slave节点的主从信息，发现其中一个节点的角色通过选举后会成为master节点了！[root@redis-master src]# redis-cli -h 192.168.10.202 -p 6379192.168.10.202:6379&gt; shutdownnot connected&gt; 查看sentinel日志（任意节点上查看），发现202节点已经进入&quot;+sdown&quot;状态[root@redis-master src]# tail -f /usr/local/redis/var/redis-sentinel.log2315:X 08 May 19:17:03.722 # +failover-state-reconf-slaves master redisMaster 192.168.10.202 63792315:X 08 May 19:17:03.760 * +slave-reconf-sent slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 19:17:04.015 * +slave-reconf-inprog slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 19:17:04.459 # -odown master redisMaster 192.168.10.202 63792315:X 08 May 19:17:05.047 * +slave-reconf-done slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.202 63792315:X 08 May 19:17:05.131 # +failover-end master redisMaster 192.168.10.202 63792315:X 08 May 19:17:05.131 # +switch-master redisMaster 192.168.10.202 6379 192.168.10.205 63792315:X 08 May 19:17:05.131 * +slave slave 192.168.10.203:6379 192.168.10.203 6379 @ redisMaster 192.168.10.205 63792315:X 08 May 19:17:05.131 * +slave slave 192.168.10.202:6379 192.168.10.202 6379 @ redisMaster 192.168.10.205 63792315:X 08 May 19:17:15.170 # +sdown slave 192.168.10.202:6379 192.168.10.202 6379 @ redisMaster 192.168.10.205 6379 [root@redis-slave01 src]# redis-cli -h 192.168.10.203 -p 6379 INFO|grep rolerole:slave[root@redis-slave01 src]# redis-cli -h 192.168.10.205 -p 6379 INFO|grep role role:master [root@redis-slave01 src]# redis-cli -h 192.168.10.205 -p 6379 info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.10.203,port=6379,state=online,offset=348860,lag=1master_replid:a51f87958cea0b1e8fe2c83542ca6cebace53bf7master_replid2:96a1fd63d0ad9e7903851a82382e32d690667bccmaster_repl_offset:349152second_repl_offset:342824repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:170repl_backlog_histlen:348983 [root@redis-slave01 src]# redis-cli -h 192.168.10.203 -p 6379 info replication# Replicationrole:slavemaster_host:192.168.10.205master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:347546slave_priority:100slave_read_only:1connected_slaves:0master_replid:a51f87958cea0b1e8fe2c83542ca6cebace53bf7master_replid2:96a1fd63d0ad9e7903851a82382e32d690667bccmaster_repl_offset:347546second_repl_offset:342824repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:283207repl_backlog_histlen:64340 由上可知，当master节点（即192.168.10.202）的redis关闭后，slave02节点（即192.168.10.205）变成了新的master节点，而slave01（即192.168.10.203）成为了slave02的从节点！ 192.168.10.205节点此时被选举为master，此时打开的205节点的redis.conf文件，slaveof配置项已被自动删除了。而203从节点的redis.conf文件中slaveof配置项的值被自动修改为192.168.10.205 6379。[root@redis-slave02 src]# cat /usr/local/redis/etc/redis.conf|grep slaveof[root@redis-slave01 src]# cat /usr/local/redis/etc/redis.conf|grep slaveofslaveof 192.168.10.205 6379 在这个新master上（即192.168.10.205）执行诸如set这样的写入操作将被成功执行[root@redis-slave01 src]# redis-cli -h 192.168.10.205 -p 6379192.168.10.205:6379&gt; set name beijing;OK [root@redis-master src]# redis-cli -h 192.168.10.203 -p 6379192.168.10.203:6379&gt; get name&quot;beijing;&quot;192.168.10.203:6379&gt; set name tianjin;(error) READONLY You can&apos;t write against a read only slave.192.168.10.203:6379&gt; 重启192.168.10.202节点的redis，待所有节点的sentinel都检测到后，再来查看所有节点的主从信息，此时192.168.10.205节点的master角色不会被重新抢占，而192.168.10.202节点的角色会从原来的master变为了slave。[root@redis-master src]# /etc/init.d/redis-server restartStopping redis-server: [FAILED]Starting redis-server: [ OK ][root@redis-master src]# /etc/init.d/redis-server restartStopping redis-server: [ OK ]Starting redis-server: [ OK ] [root@redis-master src]# redis-cli -h 192.168.10.202 -p 6379 INFO|grep rolerole:slave[root@redis-master src]# redis-cli -h 192.168.10.203 -p 6379 INFO|grep rolerole:slave[root@redis-master src]# redis-cli -h 192.168.10.205 -p 6379 INFO|grep rolerole:master[root@redis-master src]# redis-cli -h 192.168.10.205 -p 6379 info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.10.203,port=6379,state=online,offset=545410,lag=1slave1:ip=192.168.10.202,port=6379,state=online,offset=545410,lag=1master_replid:a51f87958cea0b1e8fe2c83542ca6cebace53bf7master_replid2:96a1fd63d0ad9e7903851a82382e32d690667bccmaster_repl_offset:545556second_repl_offset:342824repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:170repl_backlog_histlen:545387 [root@redis-master src]# redis-cli -h 192.168.10.202 -p 6379192.168.10.202:6379&gt; get name&quot;beijing;&quot; 此时登录192.168.10.202节点的redis，执行&quot;get name&quot;得到的值为beijing，而不是原来的kevin，因为192.168.10.202节点的redis重启后会自动从新的master中同步数据。此时打开192.168.10.202节点的redis.conf文件，会在末尾找到如下信息：[root@redis-master src]# cat /usr/local/redis/etc/redis.conf|grep slaveofslaveof 192.168.10.205 6379 到此，已经验证出了redis sentinel可以自行实现主从的故障切换了！ 12. 客户端如何连接redis sentinel？123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107客户端配置连接的是sentinel信息，比如连接sentinel.conf文件中定义的master名称。在sentinel监听时，当master节点挂了，它会在slave节点中自动选举出新的master节点，而当挂了的老master节点重新恢复后就会成为新的slave节点。对于客户端来说，redis主从切换后它不需要修改连接配置。 下面列出几个客户端连接redis sentinel的例子 1）java客户端在jedis中使用redis sentinel哨兵方式连接&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;&gt; &lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;property name=&quot;maxTotal&quot; value=&quot;1000&quot;/&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;10&quot;/&gt; &lt;property name=&quot;minIdle&quot; value=&quot;1&quot;/&gt; &lt;property name=&quot;maxWaitMillis&quot; value=&quot;30000&quot;/&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;cacheService&quot; class=&quot;sentinel.CacheServiceImpl&quot; destroy-method=&quot;destroy&quot;&gt; &lt;property name=&quot;jedisSentinlePool&quot;&gt; &lt;bean class=&quot;redis.clients.jedis.JedisSentinelPool&quot;&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;mymaster&quot; /&gt; &lt;constructor-arg index=&quot;1&quot;&gt; &lt;set&gt; &lt;value&gt;192.168.10.202:26379&lt;/value&gt; &lt;value&gt;192.168.10.203:26379&lt;/value&gt; &lt;value&gt;192.168.10.205:26379&lt;/value&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;constructor-arg index=&quot;2&quot; ref=&quot;jedisPoolConfig&quot; /&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 2）python连接redis sentinel集群（需要安装python redis客户端，即执行&quot;pip install redis&quot;）#!/usr/bin/env python# -*- coding:utf-8 -*- import redisfrom redis.sentinel import Sentinel # 连接哨兵服务器(主机名也可以用域名)sentinel = Sentinel([(&apos;192.168.10.202&apos;, 26379), (&apos;192.168.10.203&apos;, 26379), (&apos;192.168.10.205&apos;, 26379) ], socket_timeout=0.5) # 获取主服务器地址master = sentinel.discover_master(&apos;mymaster&apos;)print(master)# 输出：(&apos;192.168.10.202&apos;, 26379) # 获取从服务器地址slave = sentinel.discover_slaves(&apos;mymaster&apos;)print(slave)# 输出：[(&apos;192.168.10.203&apos;, 26379), (&apos;192.168.10.205&apos;, 26379), (&apos;172.31.0.5&apos;, 26379)] # 获取主服务器进行写入master = sentinel.master_for(&apos;mymaster&apos;, socket_timeout=0.5, password=&apos;redis_auth_pass&apos;, db=15)w_ret = master.set(&apos;foo&apos;, &apos;bar&apos;)# 输出：True # # 获取从服务器进行读取（默认是round-roubin）slave = sentinel.slave_for(&apos;mymaster&apos;, socket_timeout=0.5, password=&apos;redis_auth_pass&apos;, db=15)r_ret = slave.get(&apos;foo&apos;)print(r_ret)# # 输出：bar 3）Java客户端连接Redis（单sentinel）.下面例子中好的redisMaster和20180408是在sentinel.conf中定义的master名称和连接密码package com.hiifit.cloudplatform.gaia.test;import java.util.HashSet;import java.util.Set; import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisSentinelPool; public class RedisSentinelTest &#123; @SuppressWarnings(&quot;deprecation&quot;) public static void main(String[] args) &#123; Set&lt;String&gt; sentinels = new HashSet&lt;String&gt;(); String hostAndPort1 = &quot;192.168.10.205:26379&quot;; sentinels.add(hostAndPort1); String clusterName = &quot;redisMaster&quot;; String password = &quot;20180408&quot;; JedisSentinelPool redisSentinelJedisPool = new JedisSentinelPool(clusterName,sentinels,password); Jedis jedis = null; try &#123; jedis = redisSentinelJedisPool.getResource(); jedis.set(&quot;key&quot;, &quot;value&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; redisSentinelJedisPool.returnBrokenResource(jedis); &#125; redisSentinelJedisPool.close(); &#125; &#125;]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis日常操作命令小结]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FRedis%E6%97%A5%E5%B8%B8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Redis缓存服务是运维工作中比较常见的一种维护工作，下面就redis日常操作命令在此做一简单小结，以备查用： 1.连接redis服务命令123# redis-cli -h redis主机ip或主机域名 -p redis端口 -a redis密码[root@redis-test01 ~]# /data/redis-4.0.1/src/redis-cli -h 192.168.10.10 -p 6379 -a redis@123192.168.10.10:6379&gt; 2.在tomcat下的redis.properties可查看相关参数12345678#服务器地址redis.host #服务器端口redis.port #授权密码redis.password 3.关于key的相关操作命令1234567891011121314151617181920212223242526272829查看或取出所有的key值keys * 查看含SHOP的key值keys SHOP_* 查看所有包括kevin字样的key值keys kevin* 查key中已保存的value值lrange key 0 -1 查看redis下，当前的key值是否存在。如查看kevin这个key值是否存在exists key kevin 删除当前的key值，如删除kevin这个key值del kevin 设置过期时间，比如设置kevin这个key值20秒过期expire kevin 20 清空当前数据库flushdb 批量删除key的集合redis-cli -h 192.168.10.10 -p 6379 keys &quot;web*&quot;| xargs redis-cli -h 192.168.10.10 -p 6379 del清除redis中指定的key值（比如清除redis中包含kevin的key值）[root@redis-test01 ~]# /data/redis-4.0.1/src/redis-cli -h 192.168.10.10 -p 6379 -a redis@123 keys &quot;kevin*&quot; |xargs /data/redis-4.0.1/src/redis-cli -h 192.168.10.10 -p 6379 -a redis@123 del 停掉redis1[root@redis-test01 ~]# /data/redis-4.0.1/src/redis-cli -h 192.168.10.10 -p 6379 -a redis@123 shutdown 相关实例keys/rename/del/exists/move/renamenx命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192查看当前数据库所有的keys192.168.10.10:6379&gt; keys * 清空当前选择的数据库192.168.10.10:6379&gt; flushdbOK 添加String类型的模拟数据192.168.10.10:6379&gt; set mykey 2OK192.168.10.10:6379&gt; set mykey2 &quot;hello&quot;OK 添加Set类型的模拟数据。192.168.10.10:6379&gt; sadd mysetkey 1 2 3 (integer) 3 添加Hash类型的模拟数据。192.168.10.10:6379&gt; hset mmtest username &quot;stephen&quot;(integer) 1 根据参数中的模式，获取当前数据库中符合该模式的所有key，从输出可以看出，该命令在执行时并不区分与Key关联的Value类型。192.168.10.10:6379&gt; keys my*1) &quot;mysetkey&quot;2) &quot;mykey&quot;3) &quot;mykey2&quot; 删除下面两个Keys192.168.10.10:6379&gt; del mykey mykey2(integer) 2 查看一下刚刚删除的Key是否还存在，从返回结果看，mykey确实已经删除了。192.168.10.10:6379&gt; exists mykey(integer) 0 查看一下没有删除的Key，以和上面的命令结果进行比较。192.168.10.10:6379&gt; exists mysetkey(integer) 1 将当前数据库中的mysetkey键移入到ID为1的数据库中，从结果可以看出已经移动成功。192.168.10.10:6379&gt; move mysetkey 1(integer) 1 打开ID为1的数据库。192.168.10.10:6379&gt; select 1OK 查看一下刚刚移动过来的Key是否存在，从返回结果看已经存在了。redis 127.0.0.1:6379[1]&gt; exists mysetkey(integer) 1 在重新打开ID为0的缺省数据库。redis 127.0.0.1:6379[1]&gt; select 0OK 查看一下刚刚移走的Key是否已经不存在，从返回结果看已经移走。192.168.10.10:6379&gt; exists mysetkey(integer) 0 准备新的测试数据。192.168.10.10:6379&gt; set mykey &quot;hello&quot;OK 将mykey改名为mykey1192.168.10.10:6379&gt; rename mykey mykey1OK 由于mykey已经被重新命名，再次获取将返回nil。192.168.10.10:6379&gt; get mykey(nil) 通过新的键名获取。192.168.10.10:6379&gt; get mykey1&quot;hello&quot; 由于mykey已经不存在了，所以返回错误信息。192.168.10.10:6379&gt; rename mykey mykey1(error) ERR no such key 为renamenx准备测试key192.168.10.10:6379&gt; set oldkey &quot;hello&quot;OK192.168.10.10:6379&gt; set newkey &quot;world&quot;OK 由于newkey已经存在，因此该命令未能成功执行。192.168.10.10:6379&gt; renamenx oldkey newkey(integer) 0 查看newkey的值，发现它也没有被renamenx覆盖。192.168.10.10:6379&gt; get newkey&quot;world&quot; persist/expire/expireat/ttl命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849为后面的示例准备的测试数据。192.168.10.10:6379&gt; set mykey &quot;hello&quot;OK 将该键的超时设置为100秒。192.168.10.10:6379&gt; expire mykey 100(integer) 1 通过ttl命令查看一下还剩下多少秒。192.168.10.10:6379&gt; ttl mykey(integer) 97 立刻执行persist命令，该存在超时的键变成持久化的键，即将该Key的超时去掉。192.168.10.10:6379&gt; persist mykey(integer) 1 ttl的返回值告诉我们，该键已经没有超时了。192.168.10.10:6379&gt; ttl mykey(integer) -1 为后面的expire命令准备数据。192.168.10.10:6379&gt; del mykey(integer) 1192.168.10.10:6379&gt; set mykey &quot;hello&quot;OK 设置该键的超时被100秒。192.168.10.10:6379&gt; expire mykey 100(integer) 1 用ttl命令看一下当前还剩下多少秒，从结果中可以看出还剩下96秒。192.168.10.10:6379&gt; ttl mykey(integer) 96 重新更新该键的超时时间为20秒，从返回值可以看出该命令执行成功。192.168.10.10:6379&gt; expire mykey 20(integer) 1 再用ttl确认一下，从结果中可以看出果然被更新了。192.168.10.10:6379&gt; ttl mykey(integer) 17 立刻更新该键的值，以使其超时无效。192.168.10.10:6379&gt; set mykey &quot;world&quot;OK 从ttl的结果可以看出，在上一条修改该键的命令执行后，该键的超时也无效了。192.168.10.10:6379&gt; ttl mykey(integer) -1 type/randomkey/sort命令123456789101112131415161718192021222324252627由于mm键在数据库中不存在，因此该命令返回none。192.168.10.10:6379&gt; type mmnone mykey的值是字符串类型，因此返回string。192.168.10.10:6379&gt; type mykeystring 准备一个值是set类型的键。192.168.10.10:6379&gt; sadd mysetkey 1 2(integer) 2 mysetkey的键是set，因此返回字符串set。192.168.10.10:6379&gt; type mysetkeyset 返回数据库中的任意键。192.168.10.10:6379&gt; randomkey&quot;oldkey&quot; 清空当前打开的数据库。192.168.10.10:6379&gt; flushdbOK 由于没有数据了，因此返回nil。192.168.10.10:6379&gt; randomkey(nil)]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FTomcat%20%E9%87%8D%E5%90%AF%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Tomcat的启动、停止、重启脚本，方便部署，不多说，上菜 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109cat /usr/local/tomcat-tk/start.sh#!/bin/bash#chkconfig 345 99 01JAVA_HOME=/usr/local/jdkRUNNING_USER=root TOMCAT_HOME=/usr/local/tomcat-tkTOMCAT_ID=tomcat-tkpsid=0 checkpid() &#123; javaps=`ps aux | grep $TOMCAT_HOME | grep -v grep | awk &apos;&#123;print $2&#125;&apos;` if [ -n &quot;$javaps&quot; ]; then psid=`echo $javaps` else psid=0 fi&#125; start() &#123; checkpid if [ $psid -ne 0 ]; then echo &quot;================================&quot; echo &quot;warn: $TOMCAT_ID already started! (线程ID数=$psid)&quot; echo &quot;================================&quot; else echo -n &quot;Starting $TOMCAT_ID ...&quot; $TOMCAT_HOME/bin/startup.sh checkpid if [ $psid -ne 0 ]; then echo &quot;(线程ID数=$psid) [OK]&quot; else echo &quot;[Failed]&quot; fi fi&#125; stop() &#123; checkpid if [ $psid -ne 0 ]; then echo -n &quot;Stopping $TOMCAT_ID ...(线程ID数=$psid) &quot; /usr/bin/kill -9 $psid if [ $? -eq 0 ]; then echo &quot;[OK]&quot; else echo &quot;[Failed]&quot; fi checkpid if [ $psid -ne 0 ]; then stop fi else echo &quot;================================&quot; echo &quot;warn: $TOMCAT_ID is not running&quot; echo &quot;================================&quot; fi&#125; status() &#123; checkpid if [ $psid -ne 0 ]; then echo &quot;$TOMCAT_ID is running! (线程ID数=$psid)&quot; else echo &quot;$TOMCAT_ID is not running,木有运行$TOMCAT_ID!&quot; fi&#125;info() &#123; echo &quot;Hello！System Information:&quot; echo &quot;****************************&quot; echo `head -n 1 /etc/issue` echo `uname -a` $TOMCAT_HOME/bin/version.sh echo &quot;****************************&quot;&#125; case &quot;$1&quot; in &apos;start&apos;) start ;; &apos;stop&apos;) stop ;; &apos;restart&apos;) stop sleep 2 start ;; &apos;status&apos;) status ;; &apos;info&apos;) info ;; *) echo &quot;`date &quot;+%Y%m%d %H:%M:%S&quot;`,温馨提示使用方法: $0 &#123;start|stop|restart|status|info&#125;&quot; exit 1esac]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FJetty%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%20%20%E5%A4%9A%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[1 安装jdk因为Tomcat的安装需要jdk里面的一些包的支持，所以先安装jdk。我们先到sun公司的jdk官网下载相应的版本到本地主机，再用xftp传输到虚拟机中的/usr/local/src目录。 12jdk-8u144-linux-x64.tar.gz官网下载地址 http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 准备123456[root@host ~]# cd /usr/local/src/[root@host src]# wget http://download.oracle.com/otn-pub/java/jdk/8u144-b01/jdk-8u144-linux-x64.tar[root@host src]# tar zxvf jdk-8u144-linux-x64.gz //解压……[root@host src]# mv jdk1.8.0_144 /usr/local/jdk1.8[root@host src]# cd /usr/local/jdk1.8/ 编辑关于jdk的环境变量12345678910[root@host jdk1.8]# vim /etc/profile……#把下面几行添加到文件的最后面JAVA_HOME=/usr/local/jdk1.8/JAVA_BIN=/usr/local/jdk1.8/binJRE_HOME=/usr/local/jdk1.8/jrePATH=$PATH:/usr/local/jdk1.8/bin:/usr/local/jdk1.8/jre/binCLASSPATH=/usr/local/jdk1.8/jre/lib:/usr/local/jdk1.8/lib:/usr/local/jdk1.8/jre/lib/charset.jar刷新下环境变量：[root@host jdk1.8]# source /etc/profile 检测JDK是否安装成功：123456[root@host jdk1.8]# java -versionjava version &quot;1.8.0_144&quot;Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)#若该命令执行成功，且执行结果和安装信息一致，说明配置成功。 #若反馈的不是该命令，则说明有问题，可以卸载（前提是空的主机，如果是工作中的服务器，系统里面有其他程序在运行，就需要注意了） 2 安装jetty下载jetty123cd /usr/local/srchttps://repo1.maven.org/maven2/org/eclipse/jetty/jetty-distribution/9.4.10.v20180503/jetty-distribution-9.4.10.v20180503.tar.gzhttp://www.eclipse.org/jetty/download.html 解压安装12tar -zxvf jetty-distribution-9.4.10.v20180503.tar.gzmv jetty-distribution-9.4.10.v20180503 /usr/local/jetty 启动jetty方法1： 12345cd /usr/local/jettyjava -jar start.jar 控制台打印日志,在控制台 Ctrl+ C 停止jetty或者nohup java -jar start.jar &amp; 日志输出都将附加到当前目录的 nohup.out 文件中tail -f nohup.out 查看日志 方法2： 1/usr/local//jetty/bin/jetty.sh start 停止jetty123456789# 1ps -aux |grep javaroot 23849 62.4 17.1 2568852 319816 pts/2 Sl 19:41 0:11 /usr/bin/java -Djetty.home=/opt/jetty -Djetty.base=/opt/jetty -Djava.io.tmpdir=/tmp -jar /opt/jetty/start.jar jetty.state=/opt/jetty/jetty.state jetty-started.xmlroot 23905 0.0 0.0 112648 960 pts/2 R+ 19:41 0:00 grep --color=auto java kill 23849 # 2/usr/local//jetty/bin/jetty.sh stop 3 部署war包默认是布置到webapps中就可以了。但是，实际使用中，经常要用到单机多实例部署，配置会有一些改变。 1. Jetty目录剖析12345678bin：可执行脚本文件demo- base：etc：Jetty模块定义的XML配置文件的目录lib：Jetty依赖的库文件logs：Jetty的日志目录modules：Jetty的模块resources：外部资源配置文件的目录webapps：项目WAR文件的目录还需要关心根目录下的一个文件：start.d（Wondows系统是start.ini文件），它定义了Jetty的活动模块。 2. 基本配置12345678910111213141516171819多实例，我们会把jetty的包直接copy几分并改名，接着修改一下相关配置。1. 修改环境变量vim /usr/local/jetty111/bin/jetty.sh最前面两行#!/usr/bin/env bashJETTY_HOME=/usr/local/jetty111JETTY_RUN=$JETTY_HOME/run2. 修改Jetty的端口Jetty默认使用8080端口，要让它使用其他端口（如7070），那么编辑start.ini文件，找到jetty.http.port行，修改为：## Connector port to listen onjetty.http.port=7070保存并退出，再重启Jetty。3. 修改webapps目录Jetty下的webapps是默认的Web项目的部署目录，如果想修改此目录，可修改配置文件start.ini，移除以下行的注释符号“#”# jetty.deploy.monitoredDir=wars并把内容修改到你指定的目录。保存并退出，再重启Jetty。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>jetty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql中kill掉所有锁表的进程]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2Fmysql%E4%B8%ADkill%E6%8E%89%E6%89%80%E6%9C%89%E9%94%81%E8%A1%A8%E7%9A%84%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[3点钟刚睡下, 4点多, 同事打电话告诉我用户数据库挂掉了. 我起床看一下进程列表. 1mysql&gt;show processlist; 出来哗啦啦好几屏幕的, 没有一千也有几百条, 查询语句把表锁住了, 赶紧找出第一个Locked的thread_id, 在MySQL的shell里面执行. 1mysql&gt;kill thread_id; kill掉第一个锁表的进程, 依然没有改善. 既然不改善, 咱们就想办法将所有锁表的进程kill掉吧, 简单的脚本如下. 1234567891011121314#!/bin/bashmysql -u root -e &quot;show processlist&quot; | grep -i &quot;Locked&quot; &gt;&gt; locked_log.txtfor line in `cat locked_log.txt | awk &apos;&#123;print $1&#125;&apos;`do echo &quot;kill $line;&quot; &gt;&gt; kill_thread_id.sqldone现在kill_thread_id.sql的内容像这个样子kill 66402982;kill 66402983;kill 66402986;kill 66402991;..... 好了, 我们在mysql的shell中执行, 就可以把所有锁表的进程杀死了. 1mysql&gt;source kill_thread_id.sql 当然了, 也可以一行搞定 1234for id in `mysqladmin processlist | grep -i locked | awk &apos;&#123;print $1&#125;&apos;`do mysqladmin kill $&#123;id&#125;done]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux自动部署jar包，注册系统服务（基于Centos7）]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2Flinux%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2jar%E5%8C%85%EF%BC%8C%E6%B3%A8%E5%86%8C%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%EF%BC%88%E5%9F%BA%E4%BA%8ECentos7%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言最近一直在搞服务器，现在要运行我们的程序，都是jar包的格式，但是每次输入运行命令都很麻烦，现在进行放入脚本启动或者注册服务启动，来简化启动，但是这个方法也有一定的缺陷，需要一定的标准规范才可以正确运行，比如jar包的打包名称一定要和脚本中的名称一样 更新时间2018年11月20日 - 初稿 扩展阅读无 1. 需求前提根据自己的需求修改相应的路径 123jar包路径 /usr/local/docpcjar包名称 doctor-pc-0.0.1-SNAPSHOT.jarjava路径 /usr/bin/java 2. 新建启动脚本脚本启动的日志会在jar包目录下生成 1234567891011121314151617181920212223242526272829303132333435# vim start.sh#脚本内容如下#启动命令所在目录HOME=&apos;/usr/local/docpc&apos;jar_name = doctor-pc-0.0.1-SNAPSHOT.jarstart()&#123; #进入命令所在目录 cd $HOME nohup sudo /usr/bin/java -jar $jar_name &gt; $jar_name.log 2&gt;&amp;1 &amp;&#125;stop()&#123; #kill 掉本程序 ps -ef | grep doctor-pc-0.0.1| grep -v grep |awk &apos;&#123;print $2&#125;&apos; | xargs sudo kill -9# 注意此处grep地段根据需要修改&#125;case $1 in start) start ;; stop) stop ;; restart) $0 stop sleep 2 $0 start ;; *) echo &quot;老周提醒脚本使用方法Usage: &#123;start|stop|restart&#125;&quot; ;;esacexit 至此脚本启动完成，在jar包的同等级目录下会生成日志 3. jar包的启动注册到系统服务并添加到开机自启123456789101112131415161718192021222324252627282930313233jar包路径是 /usr/local/docpc/1.进入 /lib/systemd/systemcd /lib/systemd/system2.新建 docpc.servicevim docpc.service#内容如下[Unit]Description=docpcAfter=network.target[Service]ExecStart=/usr/bin/java -jar /usr/local/docpc/doctor-pc-0.0.1-SNAPSHOT.jarExecReload=/bin/kill -s HUP $MAINPIDExecStop= ps -ef | grep doctor-pc-0.0.1| grep -v grep |awk &apos;&#123;print $2&#125;&apos; | xargs sudo kill -9[Install]WantedBy=multi-user.target3.给docpc.service加文件权限chmod 777 docpc.service4.加入开机自启systemctl enable docpc.service5.关闭开机自启命令是systemctl disable docpc.service到此，jar包的系统服务设置完成，脚本启动和注册系统是两个不同的启动方式，各位可以把启动脚本放入开机自动也可实现脚本的开机启动，这里就不说了，大家可以去Google一下。 4. 强烈推荐把启动脚本纳入/etc/rc.d/init.d目录下，统一管理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455561.复制脚本到/etc/rc.d/init.d目录cp /usr/local/docpc/start.sh /etc/rc.d/init.d/startjar2.编辑启动脚本，添加头部添加声明代码vim startjar#!/usr/bin/sh#chkconfig: 2345 80 90#description:auto_run#启动命令所在目录HOME=&apos;/usr/local/docpc&apos;#jar包名字jar_name = doctor-pc-0.0.1-SNAPSHOT.jarstart()&#123; #进入命令所在目录 cd $HOME nohup sudo /usr/bin/java -jar $jar_name &gt; $jar_name.log 2&gt;&amp;1 &amp;&#125;stop()&#123; #kill 掉本程序 ps -ef | grep doctor-pc-0.0.1| grep -v grep |awk &apos;&#123;print $2&#125;&apos; | xargs sudo kill -9# 注意此处grep地段根据需要修改&#125;case $1 in start) start ;; stop) stop ;; restart) $0 stop sleep 2 $0 start ;; *) echo &quot;老周提醒脚本使用方法Usage: &#123;start|stop|restart&#125;&quot; ;;esacexit 3. 服务添加到开机启动chkconfig --add startjar本步骤如果出现服务不支持chkconfig，一般就是没有添加头部文件。4.启动/关闭/重启/状态systemctl start startjarsystemctl stop startjarsystemctl restart startjarsystemctl status startjar5.脚本注册服务完成，本过程就是对上面两个过程的选择性整合，大家可根据实际情况选择使用最后附上删除服务chkconfig --del startjar]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible学习(2)-安装包和管理服务、playbook以及其变量、循环、条件判断、handlers]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FAnsible%E5%AD%A6%E4%B9%A0(2)-%E5%AE%89%E8%A3%85%E5%8C%85%E5%92%8C%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1%E3%80%81playbook%E4%BB%A5%E5%8F%8A%E5%85%B6%E5%8F%98%E9%87%8F%E3%80%81%E5%BE%AA%E7%8E%AF%E3%80%81%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E3%80%81handlers%2F</url>
    <content type="text"><![CDATA[ansible安装包和管理服务yum 安装包的用法12345678910[root@ansible ~]# ansible-doc -s yum- name: Manages packages with the `yum&apos; package manager yum:conf_file # yum的配置文件disable_gpg_check # 关闭gpg_checkdisablerepo # 不启用某个源enablerepo # 启用某个源list # Various (non-idempotent) commands for usage with `/usr/bin/ansible&apos; and `not&apos; playbooks. See examples.name # 要进行操作的软件包的名字，也可以传递一个url或者一个本地的rpm包的路径state # 状态（installted ,present&lt;安装&gt;，latest&lt;安装&gt;，absent&lt;删除&gt;） 实例 我们来给web组安装一个软件包 ntp：12345678910[root@ansible ~]# ansible web -m yum -a &apos;name=ntp state=latest&apos;其他略nginx | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;msg&quot;: &quot;&quot;, &quot;rc&quot;: 0, &quot;results&quot;: [ &quot;Loaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirrors.cn99.com\n * epel: ftp.cuhk.edu.hk\n * extras: mirrors.163.com\n * updates: mirrors.163.com\nResolving Dependencies\n--&gt; Running transaction check\n---&gt; Package ntp.x86_64 0:4.2.6p5-25.el7.centos.2 will be installed\n--&gt; Processing Dependency: ntpdate = 4.2.6p5-25.el7.centos.2 for package: ntp-4.2.6p5-25.el7.centos.2.x86_64\n--&gt; Processing Dependency: libopts.so.25()(64bit) for package: ntp-4.2.6p5-25.el7.centos.2.x86_64\n--&gt; Running transaction check\n---&gt; Package autogen-libopts.x86_64 0:5.18-5.el7 will be installed\n---&gt; Package ntpdate.x86_64 0:4.2.6p5-25.el7.centos.2 will be installed\n--&gt; Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package Arch Version Repository\n Size\n================================================================================\nInstalling:\n ntp x86_64 4.2.6p5-25.el7.centos.2 base 547 k\nInstalling for dependencies:\n autogen-libopts x86_64 5.18-5.el7 base 66 k\n ntpdate x86_64 4.2.6p5-25.el7.centos.2 base 86 k\n\nTransaction Summary\n================================================================================\nInstall 1 Package (+2 Dependent packages)\n\nTotal download size: 699 k\nInstalled size: 1.6 M\nDownloading packages:\n--------------------------------------------------------------------------------\nTotal 1.0 MB/s | 699 kB 00:00 \nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n Installing : autogen-libopts-5.18-5.el7.x86_64 1/3 \n Installing : ntpdate-4.2.6p5-25.el7.centos.2.x86_64 2/3 \n Installing : ntp-4.2.6p5-25.el7.centos.2.x86_64 3/3 \n Verifying : ntp-4.2.6p5-25.el7.centos.2.x86_64 1/3 \n Verifying : ntpdate-4.2.6p5-25.el7.centos.2.x86_64 2/3 \n Verifying : autogen-libopts-5.18-5.el7.x86_64 3/3 \n\nInstalled:\n ntp.x86_64 0:4.2.6p5-25.el7.centos.2 \n\nDependency Installed:\n autogen-libopts.x86_64 0:5.18-5.el7 ntpdate.x86_64 0:4.2.6p5-25.el7.centos.2 \n\nComplete!\n&quot; ]&#125; 然后利用该包对远程主机进行时间同步： 123456789[root@ansible ~]# ansible web -m shell -a &quot;ntpdate ntp.ubuntu.com&quot;nginx | SUCCESS | rc=0 &gt;&gt;13 Apr 16:40:16 ntpdate[1951]: adjust time server 91.189.94.4 offset 0.003532 secnfs | SUCCESS | rc=0 &gt;&gt;13 Apr 16:40:17 ntpdate[2031]: adjust time server 91.189.89.199 offset 0.011645 sectomcat | SUCCESS | rc=0 &gt;&gt;13 Apr 16:40:21 ntpdate[1952]: adjust time server 91.189.94.4 offset 0.004127 sec 卸载 12345678910[root@ansible ~]# ansible web -m yum -a &apos;name=ntp state=absent&apos;tomcat | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;msg&quot;: &quot;&quot;, &quot;rc&quot;: 0, &quot;results&quot;: [ &quot;已加载插件：fastestmirror\n正在解决依赖关系\n--&gt; 正在检查事务\n---&gt; 软件包 ntp.x86_64.0.4.2.6p5-25.el7.centos.2 将被 删除\n--&gt; 解决依赖关系完成\n\n依赖关系解决\n\n================================================================================\n Package 架构 版本 源 大小\n================================================================================\n正在删除:\n ntp x86_64 4.2.6p5-25.el7.centos.2 @base 1.4 M\n\n事务概要\n================================================================================\n移除 1 软件包\n\n安装大小：1.4 M\nDownloading packages:\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n 正在删除 : ntp-4.2.6p5-25.el7.centos.2.x86_64 1/1 \n 验证中 : ntp-4.2.6p5-25.el7.centos.2.x86_64 1/1 \n\n删除:\n ntp.x86_64 0:4.2.6p5-25.el7.centos.2 \n\n完毕！\n&quot; ]&#125;下略 service模块service 模块，作用于一些服务，比如对某些服务器的启动、重启、停止、重载等的管理。先来看下用法： 1234567891011[root@ansible ~]# ansible-doc -s service- name: Manage services.action: servicearguments # 给命令行提供一些选项enabled # 是否开机启动 yes|noname # 必选项，服务名称pattern # 定义一个模式，如果通过status指令来查看服务的状态时，没有响应，就会通过ps指令在进程中根据该模式进行查找，如果匹配到，则认为该服务依然在运行runlevel # 运行级别sleep # 如果执行了restarted，在则stop和start之间沉睡几秒钟state # 对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） 实例 启动lamp 上的apache 服务，并设置为随机启动：12345678[root@ansible ~]# ansible web -m service -a &apos;name=httpd state=started enabled=yes&apos;nginx | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;enabled&quot;: true, &quot;name&quot;: &quot;httpd&quot;, &quot;state&quot;: &quot;started&quot;, &quot;status&quot;: &#123;下略 远程验证启动： 123456789[root@ansible ~]# ansible web -m raw -a &apos;ps axu|grep httpd |grep -v grep&apos;tomcat | SUCCESS | rc=0 &gt;&gt;root 2445 0.0 0.2 226240 5160 ? Ss 16:53 0:00 /usr/sbin/httpd -DFOREGROUNDapache 2446 0.0 0.1 226240 3028 ? S 16:53 0:00 /usr/sbin/httpd -DFOREGROUNDapache 2447 0.0 0.1 226240 3028 ? S 16:53 0:00 /usr/sbin/httpd -DFOREGROUNDapache 2448 0.0 0.1 226240 3028 ? S 16:53 0:00 /usr/sbin/httpd -DFOREGROUNDapache 2449 0.0 0.1 226240 3028 ? S 16:53 0:00 /usr/sbin/httpd -DFOREGROUNDapache 2450 0.0 0.1 226240 3028 ? S 16:53 0:00 /usr/sbin/httpd -DFOREGROUNDShared connection to tomcat closed. 同时验证是否随机启动: 12345678910111213141516171819[root@ansible ~]# ansible web -m raw -a &apos;systemctl list-unit-files |grep httpd&apos;nginx | SUCCESS | rc=0 &gt;&gt;httpd.service enabledShared connection to nginx closed.或者[root@ansible ~]# ansible web -m raw -a &quot;chkconfig --list&quot;nfs | SUCCESS | rc=0 &gt;&gt;注：该输出结果只显示 SysV 服务，并不包含原生 systemd 服务。SysV 配置数据可能被原生 systemd 配置覆盖。 要列出 systemd 服务，请执行 &apos;systemctl list-unit-files&apos;。 查看在具体 target 启用的服务请执行 &apos;systemctl list-dependencies [target]&apos;。netconsole 0:关 1:关 2:关 3:关 4:关 5:关 6:关network 0:关 1:关 2:开 3:开 4:开 5:开 6:关Shared connection to nfs closed. 重启网络服务器，但只启动网卡eno16777736，并且重启时间间隔3s:1234567[root@ansible ~]# ansible web -m service -a &apos;name=network state=restarted sleep=3 arguments=ens33&apos;nginx | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;name&quot;: &quot;network&quot;, &quot;state&quot;: &quot;started&quot;, &quot;status&quot;: &#123;下略 使用ansible playbook Ansible的playbook相当于把模块写入到配置文件里面，方便管理。 例子： 12345678910111213141516171819[root@ansible ~]# vim /etc/ansible/test.yml注意格式--- // 三横杠- hosts: nfs //主机群 remote_user: root //用户 tasks: //任务组 - name: test_playbook //任务名称 shell: touch /tmp/yuntai.txt //shell模块[root@ansible ~]# ansible-playbook /etc/ansible/test.yml //执行playbookPLAY [nfs] **********************************************************************************************************************************************************************************TASK [Gathering Facts] **********************************************************************************************************************************************************************ok: [nfs]TASK [test_playbook] ************************************************************************************************************************************************************************ [WARNING]: Consider using the file module with state=touch rather than running touch. If you need to use command because file is insufficient you can add warn=False to this command taskor set command_warnings=False in ansible.cfg to get rid of this message.changed: [nfs]PLAY RECAP **********************************************************************************************************************************************************************************nfs : ok=2 changed=1 unreachable=0 failed=0 说明: 第一行需要有三个杠，hosts参数指定了对哪些主机进行参作，如果是多台机器可以用逗号作为分隔，也可以使用主机组，在/etc/ansible/hosts里定义； user参数指定了使用什么用户登录远程主机操作； tasks指定了一个任务，其下面的name参数同样是对任务的描述，在执行过程中会打印出来，shell是ansible模块名字 playbook里的变量实例： 1234567891011121314151617181920[root@ansible ~]# vim /etc/ansible/create_user.yml注意格式--- - name: create_user hosts: nfs user: root gather_facts: false vars: - user: &quot;test&quot; tasks: - name: create user user: name=&quot;&#123;&#123; user &#125;&#125;&quot;[root@ansible ~]# ansible-playbook /etc/ansible/create_user.yml //执行PLAY [create_user] **************************************************************************************************************************************************************************TASK [create user] **************************************************************************************************************************************************************************changed: [nfs]PLAY RECAP **********************************************************************************************************************************************************************************nfs : ok=1 changed=1 unreachable=0 failed=0 说明： name参数对该playbook实现的功能做一个概述，后面执行过程中，会打印 name变量的值 ，可以省略； gather_facts参数指定了在以下任务部分执行前，是否先执行setup模块获取主机相关信息，这在后面的task会使用到setup获取的信息时用到； vars参数，指定了变量，这里指字一个user变量，其值为test ，需要注意的是，变量值一定要用引号引住； user提定了调用user模块，name是user模块里的一个参数，而增加的用户名字调用了上面user变量的值。 playbook里的循环实例： 1234567891011121314151617181920212223242526[root@ansible ~]# vim /etc/ansible/while.yml--- - hosts: nfs user: root tasks: - name: change files&apos; mode file: path=/tmp/&#123;&#123; item &#125;&#125; state=touch mode=600 with_items: //注意item后面加s，这是变量的循环用法 - 1.txt //注意 - 后面要加空格 - 2.txt - 3.txt[root@ansible ~]# ansible-playbook /etc/ansible/while.yml //执行PLAY [nfs] **********************************************************************************************************************************************************************************TASK [Gathering Facts] **********************************************************************************************************************************************************************ok: [nfs] //Gathering Facts表示获取对应服务器的信息，当时控制多台服务器的时候，会变得很慢，我们可以使用 gather_facts: false 来关掉，可以参考上一例子。TASK [change files&apos; mode] *******************************************************************************************************************************************************************changed: [nfs] =&gt; (item=1.txt)changed: [nfs] =&gt; (item=2.txt)changed: [nfs] =&gt; (item=3.txt)PLAY RECAP **********************************************************************************************************************************************************************************nfs : ok=2 changed=1 unreachable=0 failed=0 playbook里的条件判断实例 123456789101112131415161718192021[root@ansible ~]# vim /etc/ansible/when.yml--- - hosts: nfs user: root gather_facts: True //获取nfs机器的信息，其实默认不写，也可以 tasks: - name: use when shell: touch /tmp/when.txt when: ansible_ens33.ipv4.address == &quot;192.168.122.133&quot;[root@ansible ~]# ansible-playbook /etc/ansible/when.ymlPLAY [nfs] **********************************************************************************************************************************************************************************TASK [Gathering Facts] **********************************************************************************************************************************************************************ok: [nfs]TASK [use when] ***************************************************************************************************************************************************************************** [WARNING]: Consider using the file module with state=touch rather than running touch. If you need to use command because file is insufficient you can add warn=False to this command taskor set command_warnings=False in ansible.cfg to get rid of this message.changed: [nfs]PLAY RECAP **********************************************************************************************************************************************************************************nfs : ok=2 changed=1 unreachable=0 failed=0 说明：ansible nfs -m setup 可以查看到所有的facter信息 playbook中的handlersplaybook中的handlers相当于shell中的 &amp;&amp;，上一个命令运行成功后，接着运行handlers。常用场景：执行task之后，服务器发生变化之后要执行的一些操作，比如我们修改了配置文件后，需要重启一下服务。 实例： 123456789101112131415161718192021222324[root@ansible ~]# vim /etc/ansible/handlers.yml--- - hosts: nfs user: root tasks: - name: use handlers copy: src=/tmp/test.txt dest=/tmp/110.txt notify: test handlers handlers: - name: test handlers shell: echo &quot;handlers tested OK&quot; &gt;&gt; test.txt[root@ansible ~]# ansible-playbook /etc/ansible/handlers.ymlPLAY [nfs] **********************************************************************************************************************************************************************************TASK [Gathering Facts] **********************************************************************************************************************************************************************ok: [nfs]TASK [use handlers] *************************************************************************************************************************************************************************changed: [nfs]RUNNING HANDLER [test handlers] *************************************************************************************************************************************************************changed: [nfs]PLAY RECAP **********************************************************************************************************************************************************************************nfs : ok=3 changed=2 unreachable=0 failed=0 说明： 只有copy模块真正执行后，才会去调用下面的handlers相关的操作。 也就是说如果1.txt和2.txt内容是一样的，并不会去执行handlers里面的shell相关命令。 这种比较适合配置文件发生更改后，重启服务的操作。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible学习(1)-介绍、安装、远程执行命令、远程执行脚本、管理任务计划]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2FAnsible%E5%AD%A6%E4%B9%A0(1)-%E4%BB%8B%E7%BB%8D%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E3%80%81%E8%BF%9C%E7%A8%8B%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC%E3%80%81%E7%AE%A1%E7%90%86%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[ansible介绍 不需要安装客户端，通过sshd去通信 基于模块工作，模块可以由任何语言开发 不仅支持命令行使用模块，也支持编写yaml格式的playbook，易于编写和阅读 安装十分简单，centos上可直接yum安装 有提供UI（浏览器图形化）www.ansible.com/tower，收费的 官方文档 http://docs.ansible.com/ansible/latest/index.html ansible已经被redhat公司收购，它在github上是一个非常受欢迎的开源软件，github地址https://github.com/ansible/ansible ansible安装系统环境: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162[root@ansible ~]# cat /etc/redhat-release &amp;&amp; uname -r &amp;&amp; ifconfig ens33 |grep inet |grep -v &apos;inet6&apos; &amp;&amp; hostnameCentOS Linux release 7.4.1708 (Core) 3.10.0-693.el7.x86_64 inet 192.168.122.136 netmask 255.255.255.0 broadcast 192.168.122.255ansible1. 安装centos 7扩展源（因为ansible 默认不被centos 收录，所以想要使用这个工具我们还得安装扩展源）[root@ansible ~]# yum -y install epel-release2. 安装ansible,同时建议安装上sshpass （ansible 安装方法有两种，推荐采用yum 安装）:[root@ansible ~]# yum -y install epel-release另一种是采用python 的模块pip 安装。3. 安装完成，查看下版本（验证下ansible 是否能正常工作）：[root@ansible ~]# ansible --versionansible 2.5.0 config file = /etc/ansible/ansible.cfg configured module search path = [u&apos;/root/.ansible/plugins/modules&apos;, u&apos;/usr/share/ansible/plugins/modules&apos;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Aug 4 2017, 00:39:18) [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)]ansible的可执行文件在 /usr/bin/ansible 下。主机群管理文件在/etc/ansible 目录下[root@ansible ~]# find / -name hosts/etc/hosts/etc/ansible/hosts //ansible主机群管理文件4. 配置Ansible管理节点和主机的连接，生成密钥对[root@ansible ~]# ssh-keygen -t rsa -P &apos;&apos;Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:JBkopXlNY0507b2FYatW2iX5H8Mrn08oZWK+WkEzeu8 root@ansibleThe key&apos;s randomart image is:+---[RSA 2048]----+| ..oB .. || .o.* = . o || o.. = .. o+= || . o .oBoo || S .==*+ || ++o*.= || . + o.=|| . = oo|| ... Eoo|+----[SHA256]-----+​[root@ansible ~]# cat /root/.ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWIGxEIw8HAXwL8v42Z6JkMM2ViNtO6yu3YIsRNjuzn47NkOyAo554xux+zXwqNAVkGGcN7LB4JVFsIXi6l/sLokCNaYDmDSGO47qeGGVvemPmdcP3X+pDmzVT4CNqXqKVSbJgTGkdks/f5NszYfEAEYKtAa8TckmuImnTVUClH7CLPuCNS61E4LZdigBGJAUkCuY88ewMs+DjQ0IOImCbGNOdsfCZF0zL1VTXvgKeXzYJdb3PUc9LA4+dQT0DY7YxEheVhouiwqKsrUoJA/Wih+mzAsIOm3fANnTAS4uWpGAGiLmcfsbgza0HeSvHM7ZWZFYV+sFMbVnY27TIDvhf root@ansible​5. 编辑ansible 主配置文件，配置要推送密钥的主机（下面以主机名为配置，是因为在/etc/hosts 里面有配置相应的解析）[root@ansible ~]# vim /etc/hosts ​192.168.122.133 nfs192.168.122.134 tomcat192.168.122.135 nginx​[root@ansible ~]# vim /etc/ansible/hosts //配置主机群​[root@ansible ~]# egrep -v &apos;^$|#&apos; /etc/ansible/hosts[web]nfs tomcat nginx6. 测试推送密钥[root@ansible ~]# ansible all -m authorized_key -a &quot;user=root key=&apos;&#123;&#123; lookup(&apos;file&apos;, &apos;/root/.ssh/id_rsa.pub&apos;)&#125;&#125;&apos; path=&apos;/root/.ssh/authorized_keys&apos; manage_dir=no&quot; --ask-pass -c paramikoSSH password: ​paramiko: The authenticity of host &apos;192.168.122.134&apos; can&apos;t be established.The ssh-rsa key fingerprint is 7f2734582f66765d3b560c8e79c932f2.Are you sure you want to continue connecting (yes/no)?192.168.122.133 | SUCCESS =&gt; &#123; &quot;changed&quot;: false, &quot;comment&quot;: null, &quot;exclusive&quot;: false, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;key&quot;: &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWIGxEIw8HAXwL8v42Z6JkMM2ViNtO6yu3YIsRNjuzn47NkOyAo554xux+zXwqNAVkGGcN7LB4JVFsIXi6l/sLokCNaYDmDSGO47qeGGVvemPmdcP3X+pDmzVT4CNqXqKVSbJgTGkdks/f5NszYfEAEYKtAa8TckmuImnTVUClH7CLPuCNS61E4LZdigBGJAUkCuY88ewMs+DjQ0IOImCbGNOdsfCZF0zL1VTXvgKeXzYJdb3PUc9LA4+dQT0DY7YxEheVhouiwqKsrUoJA/Wih+mzAsIOm3fANnTAS4uWpGAGiLmcfsbgza0HeSvHM7ZWZFYV+sFMbVnY27TIDvhf root@ansible&quot;, &quot;key_options&quot;: null, &quot;keyfile&quot;: &quot;/root/.ssh/authorized_keys&quot;, &quot;manage_dir&quot;: false, &quot;mode&quot;: &quot;0600&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;path&quot;: &quot;/root/.ssh/authorized_keys&quot;, &quot;size&quot;: 394, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0, &quot;unique&quot;: false, &quot;user&quot;: &quot;root&quot;, &quot;validate_certs&quot;: true&#125;​​paramiko: The authenticity of host &apos;192.168.122.135&apos; can&apos;t be established.The ssh-rsa key fingerprint is 7f2734582f66765d3b560c8e79c932f2.Are you sure you want to continue connecting (yes/no)?yes​192.168.122.134 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: null, &quot;exclusive&quot;: false, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;key&quot;: &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWIGxEIw8HAXwL8v42Z6JkMM2ViNtO6yu3YIsRNjuzn47NkOyAo554xux+zXwqNAVkGGcN7LB4JVFsIXi6l/sLokCNaYDmDSGO47qeGGVvemPmdcP3X+pDmzVT4CNqXqKVSbJgTGkdks/f5NszYfEAEYKtAa8TckmuImnTVUClH7CLPuCNS61E4LZdigBGJAUkCuY88ewMs+DjQ0IOImCbGNOdsfCZF0zL1VTXvgKeXzYJdb3PUc9LA4+dQT0DY7YxEheVhouiwqKsrUoJA/Wih+mzAsIOm3fANnTAS4uWpGAGiLmcfsbgza0HeSvHM7ZWZFYV+sFMbVnY27TIDvhf root@ansible&quot;, &quot;key_options&quot;: null, &quot;keyfile&quot;: &quot;/root/.ssh/authorized_keys&quot;, &quot;manage_dir&quot;: false, &quot;mode&quot;: &quot;0600&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;path&quot;: &quot;/root/.ssh/authorized_keys&quot;, &quot;size&quot;: 394, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0, &quot;unique&quot;: false, &quot;user&quot;: &quot;root&quot;, &quot;validate_certs&quot;: true&#125;​192.168.122.135 | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: null, &quot;exclusive&quot;: false, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;key&quot;: &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCWIGxEIw8HAXwL8v42Z6JkMM2ViNtO6yu3YIsRNjuzn47NkOyAo554xux+zXwqNAVkGGcN7LB4JVFsIXi6l/sLokCNaYDmDSGO47qeGGVvemPmdcP3X+pDmzVT4CNqXqKVSbJgTGkdks/f5NszYfEAEYKtAa8TckmuImnTVUClH7CLPuCNS61E4LZdigBGJAUkCuY88ewMs+DjQ0IOImCbGNOdsfCZF0zL1VTXvgKeXzYJdb3PUc9LA4+dQT0DY7YxEheVhouiwqKsrUoJA/Wih+mzAsIOm3fANnTAS4uWpGAGiLmcfsbgza0HeSvHM7ZWZFYV+sFMbVnY27TIDvhf root@ansible&quot;, &quot;key_options&quot;: null, &quot;keyfile&quot;: &quot;/root/.ssh/authorized_keys&quot;, &quot;manage_dir&quot;: false, &quot;mode&quot;: &quot;0600&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;path&quot;: &quot;/root/.ssh/authorized_keys&quot;, &quot;size&quot;: 394, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0, &quot;unique&quot;: false, &quot;user&quot;: &quot;root&quot;, &quot;validate_certs&quot;: true&#125;7. 测试免密登录[root@ansible ~]# ssh root@192.168.122.133Last login: Fri Apr 13 12:13:44 2018 from 192.168.122.136[root@nfs ~]# exit登出Connection to 192.168.122.133 closed.[root@ansible ~]# ssh root@192.168.122.134Last login: Fri Apr 13 12:13:48 2018 from 192.168.122.136[root@tomcat ~]# exit登出Connection to 192.168.122.134 closed.[root@ansible ~]# ssh root@192.168.122.135Last login: Fri Apr 13 12:13:52 2018 from 192.168.122.136[root@nginx ~]# exit登出Connection to 192.168.122.135 closed. ansible远程执行命令command模块12345678910111213141516171819202122232425262728293031323334353637383940414243[root@ansible ~]# ansible-doc -s command- name: Executes a command on a remote node command: chdir: # Change into this directory before running the command. 在执行命令前，先切换到指定的目录内 creates: # 判断一个文件是否存在，假如判断成立（即文件存在），则后面的命令不执行；判断不成立，后面的命令执行 free_form: # (required) The command module takes a free form command to run. There is no parameter actually named &apos;free form&apos;. See the examples! removes: # 判断一个文件是否存在，假如判断不成立（即该文件不存在），则该选项（后面的命令）不执行。该参数正好与creates 参数相反 stdin: # Set the stdin of the command directly to the specified value. warn: # If command_warnings are on in ansible.cfg, do not warn about this particular line if set to `no&apos;.报错信息解决错误： &quot;msg&quot;: &quot;Aborting, target uses selinux but python bindings (libselinux-python) aren&apos;t installed!&quot;解决： yum install -y libselinux-python简单命令测试语法：ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args]-f 启动多个个主机执行任务 -m 要使用的模块 -a 模块特有的参数[root@ansible ~]# ansible nfs -m command -a &apos;hostname&apos; //nfs一台机器nfs | SUCCESS | rc=0 &gt;&gt;nfs​[root@ansible ~]# ansible all -m command -a &apos;hostname&apos; //all所有机器nfs | SUCCESS | rc=0 &gt;&gt;nfs​nginx | SUCCESS | rc=0 &gt;&gt;nginx​tomcat | SUCCESS | rc=0 &gt;&gt;tomcat​[root@ansible ~]# ansible web -m command -a &apos;hostname&apos; //web，hosts中定义的组nginx | SUCCESS | rc=0 &gt;&gt;nginx​nfs | SUCCESS | rc=0 &gt;&gt;nfs​tomcat | SUCCESS | rc=0 &gt;&gt;tomcat​ 实例： 12345678910111213141516171819202122232425261. 使用 creates 参数，判断一个文件是否存在，存在的话，就跳过后面的执行命令：[root@ansible ~]# ansible nfs -m command -a &apos;creates=/tmp/linux.txt ls -l /etc/passwd&apos;nfs | SUCCESS | rc=0 &gt;&gt;skipped, since /tmp/linuser.txt exists如果存在的话，就执行后面命令：[root@ansible ~]# ansible nfs -m command -a &apos;creates=/tmp/linux.txt ls -l /etc/passwd&apos;nfs | SUCCESS | rc=0 &gt;&gt;-rw-r--r-- 1 root root 1074 4月 11 23:10 /etc/passwd2. 使用chdir 参数，压缩/tmp 目录下的某个文件[root@ansible ~]# ansible nfs -m command -a &apos;chdir=/tmp/ tar zcf tmp.tar.gz linux.txt&apos;​[root@ansible ~]# ansible nfs -m command -a &apos;ls -la /tmp/&apos;nfs | SUCCESS | rc=0 &gt;&gt;总用量 8-rw-r--r-- 1 root root 117 4月 13 14:41 tmp.tar.gz查看压缩的文件[root@ansible ~]# ansible nfs -m command -a &apos;chdir=/tmp/ tar tvf tmp.tar.gz&apos;​nfs | SUCCESS | rc=0 &gt;&gt;-rw-r--r-- root/root 0 2018-04-13 14:38 linux.txt3. 使用removes 参数，来判断一个不存在的文件，看看后面的命令是否执行（和creats参数相反）：[root@ansible ~]# ansible nfs -m command -a &apos;removes=/tmp/linux.com /sbin/reboot&apos;nfs | SUCCESS | rc=0 &gt;&gt;skipped, since /tmp/linux.com does not exist shell模块和raw模块shell 及raw 模块的用法基本同command 模块。只不过，command 模块不支持管道命令的执行而已。这里就不再去看shell 及 raw 模块的用法了。直接用实例说明： 实例： 1234567891011121314151617181. 使用shell 模块查看nfs中远程主机是否有这个用户：[root@ansible ~]# ansible nfs -m shell -a &apos;cat /etc/passwd|grep www&apos;nfs | SUCCESS | rc=0 &gt;&gt;www:x:666:1000::/home/www:/sbin/nologin2. 使用raw模块[root@ansible ~]# ansible nfs -m raw -a &apos;cat /etc/passwd|grep www&apos;nfs | SUCCESS | rc=0 &gt;&gt;www:x:666:1000::/home/www:/sbin/nologinShared connection to nfs closed.3. 使用command模块就报错[root@ansible ~]# ansible nfs -m command -a &apos;cat /etc/passwd|grep www&apos;nfs | FAILED | rc=1 &gt;&gt;cat: /etc/passwd|grep: 没有那个文件或目录cat: www: 没有那个文件或目录non-zero return code**注释：** raw很多地方和shell类似，更多的地方建议使用shell和command模块。但是如果是使用老版本python，需要用到raw，又或者是客户端是路由器，因为没有安装python模块，那就需要使用raw模块了 ansible拷贝文件或目录copy模块copy 模块的作用就是把本地文件复制到远程主机群，进行统一部署。先来看下基本用法： 123456789101112[root@Lib96 ~]# ansible-doc -s copy- name: Copies files to remote locations.action: copybackup # 用于复制时，是否备份远程主机上的目标文件content # 用于替代 ‘src’ ，可以直接设定指定文件的值dest # 必选项，要将源文件复制到远程主机的绝对路径，如果源文件是一个目录，那么远程路径也必须是一个目录directory_mode # 递归设定目录的权限，默认为系统默认权限force # 强制覆盖。如果目标主机包含该文件，但内容不同，如果设置为yes,则强制覆盖；如果设置为no，则只有当目录主机的目录位置不存在该文件时，才复制。默认为yesgroup # 定义文件/目录的所属组mode # 定义文件/目录的权限owner # 定义文件/目录的所属主src # 要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用 &apos;/&apos; 结尾，则只复制目录里的 内容，如果没有使用 &apos;/&apos; 来结尾，则包含目录在内的整个内容全部复制。 实例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566671. 现在本地新建一个文件：[root@ansible ~]# echo &quot;Just a test&quot; &gt; /tmp/test.txt将该文件复制到远程服务器上[root@ansible ~]# ansible web -m copy -a &quot;src=/tmp/test.txt dest=/tmp/ owner=root group=root mode=0744&quot;tomcat | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;e35f4016914f81d2221eb2363fd5045329e02302&quot;, &quot;dest&quot;: &quot;/tmp/test.txt&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;d22b51de9cf60e6abd3fa269946e8b77&quot;, &quot;mode&quot;: &quot;0744&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 12, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523603476.36-140086183660608/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;下略查看文件是否存在[root@ansible ~]# ansible web -m shell -a &apos;ls -lh /tmp/|grep test&apos;nfs | SUCCESS | rc=0 &gt;&gt;-rwxr--r-- 1 root root 12 4月 13 15:11 test.txt​nginx | SUCCESS | rc=0 &gt;&gt;-rwxr--r-- 1 root root 12 4月 13 15:11 test.txt​tomcat | SUCCESS | rc=0 &gt;&gt;-rwxr--r-- 1 root root 12 4月 13 15:11 test.txt2. 在该文件中增加一点内容[root@ansible ~]# echo &quot;add a word +1&quot; &gt;&gt; /tmp/test.txt [root@ansible ~]# cat !$cat /tmp/test.txtJust a testadd a word +1使用backup 参数复制到远程主机，同时修改其属性[root@ansible ~]# ansible nfs -m copy -a &apos;src=/tmp/test.txt dest=/tmp/test.txt owner=root group=root mode=700 backup=yes&apos;nfs | SUCCESS =&gt; &#123; &quot;backup_file&quot;: &quot;/tmp/test.txt.4430.2018-04-13@15:26:21~&quot;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;cd3c59bfb26e5e2ce10a2b05dad8fb6233aa2b8c&quot;, &quot;dest&quot;: &quot;/tmp/test.txt&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;6944c59411744cf901975e7604985a5a&quot;, &quot;mode&quot;: &quot;0700&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 26, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523604381.09-76462614226208/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;查看远程主机/tmp/ 下的文件，看是否多出了一个关于test.txt 的文件：[root@ansible ~]# ansible nfs -m shell -a &apos;ls -lh /tmp/test*&apos;nfs | SUCCESS | rc=0 &gt;&gt;-rwx------ 1 root root 26 4月 13 15:26 /tmp/test.txt-rwxr--r-- 1 root root 12 4月 13 15:11 /tmp/test.txt.4430.2018-04-13@15:26:21~查看备份文件的内容：[root@ansible ~]# ansible nfs -m shell -a &apos;cat /tmp/test.txt.4430.2018-04-13@15:26:21~&apos;nfs | SUCCESS | rc=0 &gt;&gt;Just a test查看后来复制过去的文件内容:[root@ansible ~]# ansible nfs -m shell -a &apos;cat /tmp/test.txt&apos;nfs | SUCCESS | rc=0 &gt;&gt;Just a testadd a word +1 ansible远程执行脚本写一个脚本 12345678910111213141516171819202122232425262728293031323334353637383940[root@ansible ~]# vim /tmp/1.sh#!/bin/bashecho `date` &gt; /tmp/test.txt把脚本分发到各机器上[root@ansible ~]# ansible web -m copy -a &quot;src=/tmp/1.sh dest=/tmp/1.sh mode=0755&quot;nginx | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;cd7875b47b8f0a7c6792d8608b2515555c08a11b&quot;, &quot;dest&quot;: &quot;/tmp/1.sh&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;f1fab3831917e274299249d13ce708e6&quot;, &quot;mode&quot;: &quot;0755&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 40, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1523605164.47-276652441982060/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;下略批量执行[root@ansible ~]# ansible web -m shell -a &quot;/tmp/1.sh&quot;nginx | SUCCESS | rc=0 &gt;&gt;​tomcat | SUCCESS | rc=0 &gt;&gt;​nfs | SUCCESS | rc=0 &gt;&gt;检查结果[root@ansible ~]# ansible web -m shell -a &quot;cat /tmp/test.txt&quot;tomcat | SUCCESS | rc=0 &gt;&gt;2017年 10月 13日 星期五 15:40:18 CST​nginx | SUCCESS | rc=0 &gt;&gt;2017年 10月 13日 星期五 15:40:18 CST​nfs | SUCCESS | rc=0 &gt;&gt;2017年 10月 13日 星期五 15:40:18 CST ansible管理任务计划##cron 模块cron 模块，其实就是调用了远程主机的cron 服务，来执行一些计划内的事情。先来看下该模块的用法： 123456789101112131415161718192021[root@ansible ~]# ansible-doc -s cron- name: Manage cron.d and crontab entries cron: backup: # 在对远程主机上的原计划任务修改之前做备份（也就是先备份再修改） cron_file: # 如果指定该选项，则用该文件替换远程主机上的cron.d目录下的用户的任务计划 day: # 天（1-31，*，*/2, ……） disabled: # If the job should be disabled (commented out) in the crontab. Only has effect if `state=present&apos;. env: # If set, manages a crontab&apos;s environment variable. New variables are added on top of crontab. &quot;name&quot; and &quot;value&quot; parameters are the name and the value of environment variable. hour: # 小时( 0-23, *, */2, ……） insertafter: # Used with `state=present&apos; and `env&apos;. If specified, the environment variable will be inserted after the declaration of specified environment variable. insertbefore: # Used with `state=present&apos; and `env&apos;. If specified, the environment variable will be inserted before the declaration of specified environment variable. job: # T要执行的任务，依赖于state=present minute: # 分钟（0-59，*，*/2，……） month: # 月（1-12，*，*/2，……） name: # 该任务的描述 reboot: # 用于需要重启后运行的任务 special_time: #指定什么时候执行，参数：reboot,yearly,annually,monthly,weekly,daily,hourly state: # 确认该任务计划是创建还是删除 user: # 用哪个身份执行 weekday: #周（0-7，*，……） 实例 ： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251. 给nfs主机创建一个计划任务，每天凌晨2点以root 身份重启下系统[root@ansible ~]# ansible nfs -m cron -a &quot;name=&apos;reboot system&apos; hour=2 user=root job=&apos;/sbin/reboot&apos;&quot;nfs | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;reboot system&quot; ]&#125;查看下生成的计划任务：[root@ansible ~]# ansible nfs -m shell -a &quot;crontab -l&quot;nfs | SUCCESS | rc=0 &gt;&gt;#Ansible: reboot system* 2 * * * /sbin/reboot2. 以系统用户root,每30分钟同步一次web 组中所有主机的时间:[root@ansible ~]# ansible web -m cron -a &quot;name=&apos;rsync system time&apos; minute=*/30 user=root job=&apos;/usr/sbin/ntpdate time-a.nist.gov&apos;&quot;nfs | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;reboot system&quot;, &quot;rsync system time&quot; ]&#125;nginx | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;rsync system time&quot; ]&#125;tomcat | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;rsync system time&quot; ]&#125;查看：[root@ansible ~]# ansible web -m shell -a &quot;crontab -l&quot;nfs | SUCCESS | rc=0 &gt;&gt;#Ansible: reboot system* 2 * * * /sbin/reboot#Ansible: rsync system time*/30 * * * * /usr/sbin/ntpdate time-a.nist.gov​tomcat | SUCCESS | rc=0 &gt;&gt;#Ansible: rsync system time*/30 * * * * /usr/sbin/ntpdate time-a.nist.gov​nginx | SUCCESS | rc=0 &gt;&gt;#Ansible: rsync system time*/30 * * * * /usr/sbin/ntpdate time-a.nist.gov3. 删除第一步在nfs上创建的重启系统的计划任务，之前加了name参数的，删除的时候要加上，不然删除会失败：[root@ansible ~]# ansible nfs -m cron -a &quot;name=&apos;reboot system&apos; hour=2 user=root job=&apos;/sbin/reboot&apos; state=absent&quot;nfs | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;rsync system time&quot; ]&#125;当然，也可以使用cron 的name删除，这样会少写很多[root@ansible ~]# ansible nfs -m cron -a &quot;name=&apos;reboot system&apos; state=absent&quot;nfs | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;rsync system time&quot; ]&#125;查看[root@ansible ~]# ansible nfs -m shell -a &quot;crontab -l&quot;nfs | SUCCESS | rc=0 &gt;&gt;#Ansible: rsync system time*/30 * * * * /usr/sbin/ntpdate time-a.nist.gov4. 每次重启系统的时候，输出一个reboot system:[root@ansible ~]# ansible web -m cron -a &quot;name=&apos;echo reboot after system reboot&apos; special_time=reboot job=&apos;echo reboot system&apos;&quot;nfs | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;rsync system time&quot;, &quot;echo reboot after system reboot&quot; ]&#125;tomcat | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;rsync system time&quot;, &quot;echo reboot after system reboot&quot; ]&#125;nginx | SUCCESS =&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;rsync system time&quot;, &quot;echo reboot after system reboot&quot; ]&#125;查看[root@ansible ~]# ansible web -m shell -a &quot;crontab -l&quot;tomcat | SUCCESS | rc=0 &gt;&gt;#Ansible: rsync system time*/30 * * * * /usr/sbin/ntpdate time-a.nist.gov#Ansible: echo reboot after system reboot@reboot echo reboot system​nginx | SUCCESS | rc=0 &gt;&gt;#Ansible: rsync system time*/30 * * * * /usr/sbin/ntpdate time-a.nist.gov#Ansible: echo reboot after system reboot@reboot echo reboot system​nfs | SUCCESS | rc=0 &gt;&gt;#Ansible: rsync system time*/30 * * * * /usr/sbin/ntpdate time-a.nist.gov#Ansible: echo reboot after system reboot@reboot echo reboot system]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建git服务器、安装gitlab、使用gitlab、gitlab备份和恢复]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F22.13-22.17%20%E6%90%AD%E5%BB%BAgit%E6%9C%8D%E5%8A%A1%E5%99%A8%E3%80%81%E5%AE%89%E8%A3%85gitlab%E3%80%81%E4%BD%BF%E7%94%A8gitlab%E3%80%81gitlab%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[22.13 搭建git服务器 github毕竟是公开的，而私有仓库又得花钱买。所以我们可以想办法搭建一个私有的，只自己公司使用的。Gitlab是个不错的选择。在介绍它之前，先讲述一下命令行的git服务器 服务端配置12345678910111213141516171819202122232425262728293031323334353637383940先准备一台服务器yum安装git服务[root@yt-02 ~]# yum install -y git 创建用户，并限定shell[root@yt-02 ~]# useradd -s /usr/bin/git-shell git #目的是不让git用户远程登录创建authorized_keys文件，并更改属主、数组权限，用来存放客户端机器上的公钥：[root@yt-02 ~]# cd /home/git/[root@yt-02 git]# ls[root@yt-02 git]# mkdir .ssh[root@yt-02 git]# touch .ssh/authorized_keys[root@yt-02 git]# chmod 600 .ssh/authorized_keys[root@yt-02 git]# chown -R git:git .ssh客户端生成密钥对，公钥粘贴到authorized_keys文件[root@yt-02 git]# ssh-keygen[root@yt-02 git]# cat /root/.ssh/id_rsa.pub[root@yt-02 git]# vim .ssh/authorized_keys测试（下面ssh表示可以登录）[root@yt-02 git]# ssh git@192.168.122.131fatal: Interactive git shell is not enabled.hint: ~/git-shell-commands should exist and have read and execute access.Connection to 192.168.122.131 closed.定好存储git仓库的目录[root@yt-02 git]# mkdir /data/gitroot/创建一个裸仓库，裸仓库没有工作区，因为服务器上的Git仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的Git仓库通常都以.git结尾[root@yt-02 gitroot]# git init --bare sample.git初始化空的 Git 版本库于 /data/gitroot/sample.git/[root@yt-02 gitroot]# lssample.git配置好权限[root@yt-02 gitroot]# chown -R git:git sample.git 客户端配置1234567891011121314151617181920212223242526272829303132333435安装git仓库[root@yt-01 ~]# yum install -y epel-release git克隆sample.git 库到本地[root@yt-01 gitroot]# git clone git@192.168.122.131:/data/gitroot/sample.git正克隆到 &apos;sample&apos;...warning: 您似乎克隆了一个空版本库。进入sample仓库的目录[root@yt-01 gitroot]# cd /data/gitroot/[root@yt-01 gitroot]# ls1.txt 2.txt sample[root@yt-01 gitroot]# cd sample/[root@yt-01 sample]# ls[root@yt-01 sample]# ls -la总用量 0drwxr-xr-x 3 root root 18 4月 3 19:10 .drwxr-xr-x 4 root root 58 4月 3 19:10 ..drwxr-xr-x 7 root root 119 4月 3 19:10 .git提交到本地[root@yt-01 sample]# git add 1.txt[root@yt-01 sample]# git commit -m &quot;add 1.txt&quot;[master（根提交） 48e10c5] add 1.txt 1 file changed, 2 insertions(+) create mode 100644 1.txt推送到服务器master分支[root@yt-01 sample]# git push -u origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 210 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@192.168.122.131:/data/gitroot/sample.git * [new branch] master -&gt; master分支 master 设置为跟踪来自 origin 的远程分支 master。 这样就搭建完成了。 22.14/22.15 安装gitlab 安装gitlab服务因为github在美国有点慢，连接和推送不方便。国内众多的代码管理平台也是非常的不错，例如：coding，码云，码市等。但是有些企业为了方便自己去搭建一个基于web界面的代码管理平台gitlab！建议后期搭建Gitlab平台，一定要让其服务独立运行在一台机器上，两方面： ①机器比较耗费硬件资源。 ②一旦出现问题维护起来困难比较大，为了不造成冲突！ gitlab官网 https://about.gitlab.com/gitlab-com/ 官方安装文档 https://about.gitlab.com/installation/?version=ce#centos-7 (ce/ee) 要求服务器内存不少于2g 12345678910[root@yt-01 sample]# vim /etc/yum.repos.d/gitlab.repo# 写入下面这一段[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1[root@yt-01 sample]# yum install -y gitlab-ce //yum安装 22.16 使用gitlabGitlab如果出现5xx错误可以先重启，再gitlab-ctl reconfigure 22.17 gitlab备份和恢复1234567891011121314151617181920# netstat -lnpt //查看监听端口# gitlab-ctl stop/restart/start/status# 浏览器访问gitlab，输入ip即可# 默认管理员root，无密码，它会让我们去定义一个密码# gitlab常用命令 https://www.cnyunwei.cc/archives/1204# gitlab备份 gitlab-rake gitlab:backup:create //在线备份# 备份目录在/var/opt/gitlab/backups[root@yt-01 /]# ll /var/opt/gitlab/backups总用量 72-rw------- 1 git git 71680 4月 3 20:00 1522756818_2018_04_03_10.6.2_gitlab_backup.tar# gitlab 恢复 先停服务 gitlab-ctl stop unicorn ; gitlab-ctl stop sidekiq[root@yt-01 /]# gitlab-ctl stop unicorn ; gitlab-ctl stop sidekiqok: down: unicorn: 0s, normally upok: down: sidekiq: 0s, normally up# gitlab-rake gitlab:backup:restore BACKUP=xxxxx （这里是一个编号，即备份文件的前缀）[root@yt-01 /]# gitlab-rake gitlab:backup:restore BACKUP=1522756818_2018_04_03_10.6.2# 再启动服务 gitlab-ctl start]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git分支管理、远程分支管理、标签管理、git别名]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F22.9-22.12%20git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86%E3%80%81%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86%E3%80%81%E6%A0%87%E7%AD%BE%E7%AE%A1%E7%90%86%E3%80%81git%E5%88%AB%E5%90%8D%2F</url>
    <content type="text"><![CDATA[22.9 分支管理1 查看分支12345[root@yt-01 LNMP]# cd /data/gitroot[root@yt-01 gitroot]# git branch* master[root@yt-01 gitroot]# ls1.txt 2 创建分支1234[root@yt-01 gitroot]# git branch yuntai[root@yt-01 gitroot]# git branch* master yuntai 3 分支管理12345678910111213141516171819202122232425# 切换到分支[root@yt-01 gitroot]# git checkout yuntai切换到分支 &apos;yuntai&apos;[root@yt-01 gitroot]# git branch //*号在yuntai分支前，表示目前的分支 master* yuntai[root@yt-01 gitroot]# ls //2个分支下文件相同1.txt# 新分支下创建新文件[root@yt-01 gitroot]# vim 2.txt[root@yt-01 gitroot]# git add 2.txt[root@yt-01 gitroot]# git commit -m &quot;jjjjjj&quot;[yuntai 98bf627] jjjjjj 1 file changed, 1 insertion(+) create mode 100644 2.txt[root@yt-01 gitroot]# cat 2.txt1234hghklal# 切换回master分支[root@yt-01 gitroot]# git checkout master切换到分支 &apos;master&apos;[root@yt-01 gitroot]# ls1.txt由此可见，在不同的分支可看到的文件的内容是不同的，在所有分支都能看到master分支的文件。 4 分支合并与冲突1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# 分支合并[root@yt-01 gitroot]# git merge yuntai //把yuntai分支合并到了master分支更新 5acf95f..98bf627Fast-forward 2.txt | 1 + 1 file changed, 1 insertion(+) create mode 100644 2.txt[root@yt-01 gitroot]# ls1.txt 2.txt# 分支合并的冲突问题[root@yt-01 gitroot]# vim 2.txt[root@yt-01 gitroot]# git add 2.txt[root@yt-01 gitroot]# git commit -m &quot;sdjjjjjj&quot;[master cf73e6e] sdjjjjjj 1 file changed, 1 insertion(+), 1 deletion(-)[root@yt-01 gitroot]# git branch* master yuntai[root@yt-01 gitroot]# git checkout yuntai切换到分支 &apos;yuntai&apos;[root@yt-01 gitroot]# vim 2.txt[root@yt-01 gitroot]# git add 2.txt[root@yt-01 gitroot]# git commit -m &quot;dddjjjj&quot;[yuntai ba7c380] dddjjjj 1 file changed, 1 insertion(+), 1 deletion(-)[root@yt-01 gitroot]# git merge master自动合并 2.txt冲突（内容）：合并冲突于 2.txt自动合并失败，修正冲突然后提交修正的结果。# 发生冲突！！！需要先修复冲突后才能合并# 解决冲突# 使用git diff或cat查看冲突在哪：[root@yt-01 gitroot]# git diffdiff --cc 2.txtindex 4311c21,4c236d2..0000000--- a/2.txt+++ b/2.txt@@@ -1,1 -1,1 +1,5 @@@++&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD +1234hghklal1234hghklal1234hghklal1234hghklal1234hghklal1234hghklal1234hghklal++=======+ doaiodwdndian++&gt;&gt;&gt;&gt;&gt;&gt;&gt; master# cat和vim命令中也会提醒冲突的地方[root@yt-01 gitroot]# cat 2.txt&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD1234hghklal1234hghklal1234hghklal1234hghklal1234hghklal1234hghklal1234hghklal=======doaiodwdndian&gt;&gt;&gt;&gt;&gt;&gt;&gt; master[root@yt-01 gitroot]# git checkout master //分支冲突的话，必须先解决冲突才能切换分支，所以分支冲突很麻烦，一定要注意2.txt: needs mergeerror: 您需要先解决当前索引的冲突[root@yt-01 gitroot]# git branch master* yuntai[root@yt-01 gitroot]# vim 2.txt[root@yt-01 gitroot]# git merge master //没有提交修改，所以报错error: &apos;merge&apos; is not possible because you have unmerged files.提示：请先在工作区改正文件，然后酌情使用提示：&apos;git add/rm &lt;file&gt;&apos; 标记解决方案，提示：或使用 &apos;git commit -a&apos;。fatal: Exiting because of an unresolved conflict.修改后提交[root@yt-01 gitroot]# git add 2.txt[root@yt-01 gitroot]# git commit -m &quot;修改冲突内容&quot;[yuntai 0ac22aa] 修改冲突内容合并分支[root@yt-01 gitroot]# git merge masterAlready up-to-date.[root@yt-01 gitroot]# ls1.txt 2.txt[root@yt-01 gitroot]# git checkout master切换到分支 &apos;master&apos;解决冲突的办法是更改目标分支下冲突文件和源分支中内容一致，然后在提交、合并。原则：只能将新分支合并到旧的分支，即merge后面跟内容最新的分支。 如果master分支和yuntai分支都对2.txt进行了编辑，当合并时会提示冲突，需要先解决冲突才可以继续合并。 解决冲突的方法是在master分支下，编辑2.txt，改为aming分支里面2.txt的内容。 然后提交2.txt，再合并yuntai分支。 但是这样有一个问题，万一master分支更改的内容是我们想要的呢？ 可以编辑2.txt内容，改为想要的，然后提交。切换到yuntai分支，然后合并master分支到yuntai分支即可（倒着合并）。合并分支有一个原则，那就是要把最新的分支合并到旧的分支。也就是说merge后面跟的分支名字一定是最新的分支。 5 删除分支如果我们确定不想要某个分支，我们可以删除分支 12345678[root@yt-01 gitroot]# git branch -d yuntai //如果分支没有合并，删除之前会提示，那就不合并，强制删除error: 分支 &apos;yuntai&apos; 没有完全合并。如果您确认要删除它，执行 &apos;git branch -D yuntai&apos;。[root@yt-01 gitroot]# git branch -D yuntai //强制删除已删除分支 yuntai（曾为 0ac22aa）。[root@yt-01 gitroot]# git branch* master 6 分支使用原则 master分支是非常重要的，线上发布代码用这个分支，平时开发代码不要在该分支操作； 创建dev分支，专门用作开发，只有到发布到线上之前再把dev合并到master上 开发人员应该在dev分支的基础上再分支成个人分支，自己的分支（在自己的pc上）里面开发代码，然后合并到dev分支。 在dev分支合并bob分支的命令：12# git checkout dev# git merge bob 22.10 远程分支管理1 我们现在远程创建2个分支2 在远程仓库克隆到本地123456789101112131415161718[root@yt-01~]# cd /data/[root@yt-01 data]# git clone git@github.com:zhouqunic/gittest.git正克隆到 &apos;gittest&apos;...remote: Counting objects: 6, done.remote: Compressing objects: 100% (3/3), done.remote: Total 6 (delta 0), reused 6 (delta 0), pack-reused 0接收对象中: 100% (6/6), done.[root@yt-01 data]# lsgitroot gittest mysql svnroot wwwroot[root@yt-01 data]# cd gittest/[root@yt-01 gittest]# ls123.txt README.md[root@yt-01 gittest]#[root@yt-01 gittest]# git branch* master# 克隆远程的时候只能把master克隆下来 查看远程分支，并克隆下来12345678910111213141516171819202122232425262728293031[root@yt-01 gittest]# git ls-remote origin //查看远程所有分支6007c36bb6151394b59c936deb0f67456fd8c639 HEAD6007c36bb6151394b59c936deb0f67456fd8c639 refs/heads/dev6007c36bb6151394b59c936deb0f67456fd8c639 refs/heads/master[root@yt-01 gittest]# git checkout -b dev origin/dev //克隆远程分支分支 dev 设置为跟踪来自 origin 的远程分支 dev。切换到一个新分支 &apos;dev&apos;[root@yt-01 gittest]# git branch //查看分支* dev master[root@yt-01 gittest]# ls123.txt README.md[root@yt-01 gittest]# vim 4.txt[root@yt-01 gittest]# vim 4.txt[root@yt-01 gittest]# git add 4.txt[root@yt-01 gittest]# git commit -m &quot;add 4.txt&quot;[dev 4585f09] add 4.txt 1 file changed, 2 insertions(+) create mode 100644 4.txt[root@yt-01 gittest]# git push //git push会把所有的分支变更推送到远程分支上Counting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 302 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:zhouqunic/gittest.git 6007c36..4585f09 dev -&gt; dev[root@yt-01 gittest]# git push origin dev //只推送选定的分支Everything up-to-date 本地分支比远程分支还多123456789101112131415161718192021222324252627282930313233343536root@yt-01 gittest]# git branch dev2 //新建本地分支dev2[root@yt-01 gittest]# git branch* dev dev2 master[root@yt-01 gittest]# git checkout dev2 //切换到新分支切换到分支 &apos;dev2&apos;[root@yt-01 gittest]# ls123.txt 4.txt README.md[root@yt-01 gittest]# echo -e &quot;5555&quot; &gt; 5.txt //新增新文件，并推送到本地[root@yt-01 gittest]# ls123.txt 4.txt 5.txt README.md[root@yt-01 gittest]# git add 5.txt[root@yt-01 gittest]# git commit -m &quot;add 5.txt&quot;[dev2 13cb704] add 5.txt 1 file changed, 1 insertion(+) create mode 100644 5.txt[root@yt-01 gittest]# git push //推送到远程，结果出现报错，提示用git push --set-upstream origin dev2命令推送fatal: 当前分支 dev2 没有对应的上游分支。为推送当前分支并建立与远程上游的跟踪，使用 git push --set-upstream origin dev2[root@yt-01 gittest]# git push --set-upstream origin dev2 //从本地推送远程没有的分支Counting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 324 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:zhouqunic/gittest.git * [new branch] dev2 -&gt; dev2分支 dev2 设置为跟踪来自 origin 的远程分支 dev2。[root@yt-01 gittest]# git ls-remote origin //查看远程分支，新分支dev2已经推送成功6007c36bb6151394b59c936deb0f67456fd8c639 HEAD4585f09ea5741cd9030c781a5e0a75629683fcef refs/heads/dev13cb704ff422999a9d0ec83f67f6e03f61dfaa94 refs/heads/dev26007c36bb6151394b59c936deb0f67456fd8c639 refs/heads/master 本地新建的分支如果不推送到远程，对其他人就是不可见的 查看远程分支 git ls-remote origin，可以看到所有分支 对于git push分支分两种情况 当本地分支和远程分支一致时,git push会把所有本地分支的变更一同推送到远程，如果想只推送一个分支，使用git push origin branch-name 当本地分支比远程分支多,默认git push 只推送本地和远程一致的分支，想要把多出来的本地分支推送到远程时，使用git push origin branch-name 如果推送失败，先用git pull抓取远程的新提交. git clone的时候默认只把master分支克隆下来，如果想把所有分支都克隆下来，需要手动创建，在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称要一致 22.11 标签管理 标签类似于快照功能，可以给版本库打一个标签，记录某个时刻库的状态。也可以随时恢复到该状态。12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@yt-01 gittest]# git checkout master //先切到master分支上[root@yt-01 gittest]# git tag v1.0 //给master打一个标签v1.0[root@yt-01 gittest]# git show v1.0 //查看标签信息commit 6007c36bb6151394b59c936deb0f67456fd8c639Author: yuntai &lt;zhouqunic@163.com&gt;Date: Tue Apr 3 16:01:02 2018 +0800 新建123.txt文件diff --git a/123.txt b/123.txtnew file mode 100644index 0000000..f3bed95--- /dev/null+++ b/123.txt@@ -0,0 +1,3 @@+123 123 123+123 123+123# tag是针对commit来打标签的，所以可以针对历史的commit来打tag# git tag 可以查看所有的标签[root@yt-01 gittest]# git log --pretty=oneline --abbrev-commit //先查看历史的commit6007c36 新建123.txt文件f7045bf 创建README.md[root@yt-01 gittest]# git tag v0.8 f7045bf //针对历史commit打标签[root@yt-01 gittest]# git tag -d v0.8 //删除标签已删除 tag &apos;v0.8&apos;（曾为 f7045bf）[root@yt-01 gittest]# git tag -a v0.8 -m &quot;tag just v1.1 and so on&quot; f7045bf //可以对标签进行描述[root@yt-01 gittest]# git push origin v1.0 //推送指定标签到远程Total 0 (delta 0), reused 0 (delta 0)To git@github.com:zhouqunic/gittest.git[root@yt-01 gittest]# git push --tag origin //推送所有标签Counting objects: 1, done.Writing objects: 100% (1/1), 166 bytes | 0 bytes/s, done.Total 1 (delta 0), reused 0 (delta 0)To git@github.com:zhouqunic/gittest.git * [new tag] v0.8 -&gt; v0.8 如果本地删除了一个标签，远程也想要删除需要这样操作：[root@yt-01 gittest]# git tag v1.0 -d //删除本地标签[root@yt-01 gittest]# git push origin :refs/tags/v1.0 //删除远程标签 实际上，tag和分支十分类似，只是概念上的不同。 22.12 git别名git设置别名123456789101112131415161718192021# 把ci设置为commit命令的别名[root@yt-01 gittest]# git config --global alias.ci commit# 把co设置为checkout命令的别名[root@yt-01 gittest]# git config --global alias.co checkout# 设置号的别名会保存在文件/root/.gitconfig中，所以可以通过编辑该文件来设置别名[root@yt-01 gittest]# cat /root/.gitconfig[user] email = zhouqunic@163.com name = yuntai[push] default = simple[alias] ci = commit co = checkout# 查看git别名使用命令[root@yt-01 gittest]# git config --list |grep aliasalias.ci=commitalias.co=checkout 查询log小技巧12345[root@yt-01 gittest]# git config --global alias.lg &quot;log --color --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit&quot; //把git lg彩色排列的历史记录[root@yt-01 gittest]# git lg* 6007c36 - (HEAD, tag: v1.0, origin/master, origin/HEAD, master) 新建123.txt文件 (2 小时之前) &lt;yuntai&gt;* f7045bf - (tag: v0.8) 创建README.md (3 小时之前) &lt;yuntai&gt; 取消别名12345678910[root@yt-01 gittest]# git config --global --unset alias.co //取消co的别名[root@yt-01 gittest]# vim vim /root/.gitconfig //或者直接去配置文件里面删除alias的配置[user] email = zhouqunic@163.com name = yuntai[push] default = simple[alias] ci = commit lg = log --color --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单机上使用git、建立远程仓库、克隆远程仓库]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F22.5-22.8%20%E5%8D%95%E6%9C%BA%E4%B8%8A%E4%BD%BF%E7%94%A8git%E3%80%81%E5%BB%BA%E7%AB%8B%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E3%80%81%E5%85%8B%E9%9A%86%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[22.5/22.6 单机上使用git1 准备1234567891011121314151617181920安装git[root@yt-01 /]# yum install -y git建立git版本库目录[root@yt-01 /]# mkdir /data/gitroot/初始化gi版本仓库[root@yt-01 /]# cd /data/gitroot/[root@yt-01 gitroot]# git init初始化空的 Git 版本库于 /data/gitroot/.git/配置用户名和邮箱[root@yt-01 gitroot]# git config --global user.email &quot;zhouqunic@163.com&quot;[root@yt-01 gitroot]# git config --global user.name &quot;yuntai&quot;配置文件[root@yt-01 gitroot]# cat /root/.gitconfig[user] email = zhouqunic@163.com name = yuntai 2. 上传，对比和查看状态12345678910111213141516171819202122232425262728293031323334353637383940414243创建新文件[root@yt-01 gitroot]# echo -e &quot;123/234/456/789&quot; &gt; 1.txt[root@yt-01 gitroot]# ll总用量 4-rw-r--r-- 1 root root 16 4月 3 14:39 1.txt把1.txt添加到git仓库[root@yt-01 gitroot]# git add 1.txt //打标记[root@yt-01 gitroot]# git commit -m &quot;creat new file 1.txt&quot; //上传[master（根提交） 44609a5] creat new file 1.txt 1 file changed, 1 insertion(+) create mode 100644 1.txt# 记住，上传文件到仓库，每次都要 git add filename 和 git commit -m &quot;注释&quot; 两句命令再次变更1.txt[root@yt-01 gitroot]# echo -e &quot;1 new added/END&quot; &gt;&gt; 1.txt[root@yt-01 gitroot]# cat 1.txt123/234/456/7891 new added/END查看当前仓库中的状态，比如是否有改动的文件[root@yt-01 gitroot]# git status# 位于分支 master# 尚未暂存以备提交的变更：# （使用 &quot;git add &lt;file&gt;...&quot; 更新要提交的内容）# （使用 &quot;git checkout -- &lt;file&gt;...&quot; 丢弃工作区的改动）## 修改： 1.txt#修改尚未加入提交（使用 &quot;git add&quot; 和/或 &quot;git commit -a&quot;）# 每部操作之后都可以使用“git status”查看当前状态，可以根据提示信息进行后续操作。不同版本文件对比[root@yt-01 gitroot]# git diff 1.txtdiff --git a/1.txt b/1.txtindex a53950c..49384d8 100644--- a/1.txt+++ b/1.txt@@ -1 +1,2 @@ 123/234/456/789+1 new added/END 3 版本变更12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576更新版本[root@yt-01 gitroot]# git add 1.txt[root@yt-01 gitroot]# git commit -m &quot;add 1.txt again&quot;[master 01803b5] add 1.txt again 1 file changed, 1 insertion(+)查看版本变更日志[root@yt-01 gitroot]# git logcommit 01803b54e07b9842da0c2c4558fdafd66b05ada6Author: yuntai &lt;zhouqunic@163.com&gt;Date: Tue Apr 3 15:04:36 2018 +0800 add 1.txt againcommit 2ab6b801dd207ef35d102c240173dc69d2ff3dc2Author: yuntai &lt;zhouqunic@163.com&gt;Date: Tue Apr 3 15:02:00 2018 +0800 add 1.txt againcommit 44609a553eef00abe45e45a3c1bd54cc8fe9a402Author: yuntai &lt;zhouqunic@163.com&gt;Date: Tue Apr 3 14:41:50 2018 +0800 creat new file 1.txt删除文件2行，并更新版本[root@yt-01 gitroot]# vim 1.txt[root@yt-01 gitroot]# git add 1.txt[root@yt-01 gitroot]# git commit -m &quot;删除最后2行 &quot;[master 5acf95f] 删除最后2行 1 file changed, 2 deletions(-)版本变更日志，一行显示[root@yt-01 gitroot]# git log --pretty=oneline //版本变更日志，一行显示5acf95fd5e06f1fc01acc0f28f5753610a292a07 删除最后2行01803b54e07b9842da0c2c4558fdafd66b05ada6 add 1.txt again2ab6b801dd207ef35d102c240173dc69d2ff3dc2 add 1.txt again44609a553eef00abe45e45a3c1bd54cc8fe9a402 creat new file 1.txt# 代码表示版本代码版本回退[root@yt-01 gitroot]# git reset --hard 2ab6b801dd207HEAD 现在位于 2ab6b80 add 1.txt again# hard后面跟的代码可以只填写一部分[root@yt-01 gitroot]# git log --pretty=oneline2ab6b801dd207ef35d102c240173dc69d2ff3dc2 add 1.txt again44609a553eef00abe45e45a3c1bd54cc8fe9a402 creat new file 1.txt撤销版本回退（假如忘了版本代码）[root@yt-01 gitroot]# git reflog //查看所有历史版本2ab6b80 HEAD@&#123;0&#125;: reset: moving to 2ab6b801dd2075acf95f HEAD@&#123;1&#125;: commit: 删除最后2行01803b5 HEAD@&#123;2&#125;: commit: add 1.txt again2ab6b80 HEAD@&#123;3&#125;: commit: add 1.txt again44609a5 HEAD@&#123;4&#125;: commit (initial): creat new file 1.txt# 版本回退[root@yt-01 gitroot]# git log --pretty=oneline5acf95fd5e06f1fc01acc0f28f5753610a292a07 删除最后2行01803b54e07b9842da0c2c4558fdafd66b05ada6 add 1.txt again2ab6b801dd207ef35d102c240173dc69d2ff3dc2 add 1.txt again44609a553eef00abe45e45a3c1bd54cc8fe9a402 creat new file 1.txt假如文件1.txt被删除了[root@yt-01 gitroot]# rm -rf 1.txt[root@yt-01 gitroot]# ls[root@yt-01 gitroot]# git checkout -- 1.txt //恢复原来文件[root@yt-01 gitroot]# ls1.txt假如更改了1.txt，然后git add了，但是没有git commit，不想更新了，想回退到当时版本[root@yt-01 gitroot]# echo -e &quot;xxxxxx&quot; &gt; 1.txt[root@yt-01 gitroot]# git add 1.txt[root@yt-01 gitroot]# git reset HEAD 1.txt //重置缓存重置后撤出暂存区的变更：M 1.txt[root@yt-01 gitroot]# cat 1.txtxxxxxx[root@yt-01 gitroot]# git checkout -- 1.txt //恢复原来文件[root@yt-01 gitroot]# cat 1.txt123/234/456/789 删除文件123456789101112131415161718192021222324252627[root@yt-01 gitroot]# git rm 1.txt //删除文件rm &apos;1.txt&apos;[root@yt-01 gitroot]# git commit -m &quot;删除1.txt文件&quot; //提交删除[master 7215021] 删除1.txt文件 1 file changed, 1 deletion(-) delete mode 100644 1.txt[root@yt-01 gitroot]# lsgit checkout已经不能恢复了[root@yt-01 gitroot]# git checkout -- 1.txterror: pathspec &apos;1.txt&apos; did not match any file(s) known to git.恢复git rm删除的文件[root@yt-01 gitroot]# git log --pretty=oneline //查看版本日志721502178db58654977d89635423afaa806e3c27 删除1.txt文件5acf95fd5e06f1fc01acc0f28f5753610a292a07 删除最后2行01803b54e07b9842da0c2c4558fdafd66b05ada6 add 1.txt again2ab6b801dd207ef35d102c240173dc69d2ff3dc2 add 1.txt again44609a553eef00abe45e45a3c1bd54cc8fe9a402 creat new file 1.txt[root@yt-01 gitroot]# git reset --hard 721502178d //最后的版本已经是删除掉的时候，恢复不了HEAD 现在位于 7215021 删除1.txt文件[root@yt-01 gitroot]# ls[root@yt-01 gitroot]# git reset --hard 5acf95fd5e06f1fc01acc0f28f5753610a292a07 //回退到对应版本才可以HEAD 现在位于 5acf95f 删除最后2行[root@yt-01 gitroot]# ls1.txt 22.7 建立远程仓库1 创建远程仓库GitHub官网：github.com注册账号并激活，然后开始创建主机的仓库！创建完成后，添加key：点击浏览器右上角头像——setting——SSH and GPG keys（选择SSH keys）——在服务器（虚拟机）执行ssh-keygen命令生成密钥对（/root/.ssh/id_rsa-私钥， /root/.ssh/id_rsa.pub-公钥）——将公钥复制到浏览器后点“添加”。 2 创建同名本地仓库，并连接12345678910111213141516171819创建本地版本仓库[root@yt-01 tmp]# mkdir /tmp/gittest/[root@yt-01 tmp]# cd gittest/[root@yt-01 tmp]# echo &quot;# gittest&quot; &gt;&gt; README.md[root@yt-01 gittest]# git add README.md [root@yt-01 gittest]# git commit -m &quot;创建README.md&quot;[master（根提交） f7045bf] 创建README.md 1 file changed, 1 insertion(+) create mode 100644 README.md远程连接[root@yt-01 gittest]# git remote add origin git@github.com:zhouqunic/gittest.git[root@yt-01 gittest]# git push -u origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 232 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:zhouqunic/gittest.git * [new branch] master -&gt; master分支 master 设置为跟踪来自 origin 的远程分支 master。 3 文件推送1234567891011121314151617181920212223242526272829303132333435新建文件[root@yt-01 gittest]# vim 123.txt[root@yt-01 gittest]# cat 123.txt123 123 123123 123123推送到本地仓库[root@yt-01 gittest]# git add 123.txt[root@yt-01 gittest]# git commit -m &quot;新建123.txt文件&quot;[master 6007c36] 新建123.txt文件 1 file changed, 3 insertions(+) create mode 100644 123.txt推送到远程仓库[root@yt-01 gittest]# git pushwarning: push.default 未设置，它的默认值将会在 Git 2.0 由 &apos;matching&apos;修改为 &apos;simple&apos;。若要不再显示本信息并在其默认值改变后维持当前使用习惯，进行如下设置： git config --global push.default matching若要不再显示本信息并从现在开始采用新的使用习惯，设置： git config --global push.default simple参见 &apos;git help config&apos; 并查找 &apos;push.default&apos; 以获取更多信息。（&apos;simple&apos; 模式由 Git 1.7.11 版本引入。如果您有时要使用老版本的 Git，为保持兼容，请用 &apos;current&apos; 代替 &apos;simple&apos; 模式）Counting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 300 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:zhouqunic/gittest.git f7045bf..6007c36 master -&gt; master# 上面有好多无用的提示信息，为了之后不显示这些信息，根据提示执行命令[root@yt-01 gittest]# git config --global push.default simple 22.8 克隆远程仓库克隆远程仓库12345678910111213141516创建一个本地文件夹，来放克隆的内容[root@yt-01 gittest]# cd /usr/local/sbin/[root@yt-01 sbin]# ls克隆远程仓库[root@yt-01 sbin]# git clone https://github.com/maicong/LNMP.git //克隆正克隆到 &apos;LNMP&apos;...remote: Counting objects: 420, done.remote: Total 420 (delta 0), reused 0 (delta 0), pack-reused 420接收对象中: 100% (420/420), 612.72 KiB | 95.00 KiB/s, done.处理 delta 中: 100% (224/224), done.[root@yt-01 sbin]# lsLNMP[root@yt-01 sbin]# cd LNMP/[root@yt-01 LNMP]# lsDBMGT etc home keys LICENSE lnmp.sh README.md source.sh svnserve svn.sh 编辑仓库要是自己的仓库，别人的仓库的话，必须fork到自己的仓库，克隆后才能编辑 123456789101112131415161718[root@yt-01 sbin]# git clone git@github.com:zhouqunic/LNMP.git正克隆到 &apos;LNMP&apos;...remote: Counting objects: 420, done.remote: Total 420 (delta 0), reused 0 (delta 0), pack-reused 420接收对象中: 100% (420/420), 612.72 KiB | 62.00 KiB/s, done.处理 delta 中: 100% (224/224), done.[root@yt-01 sbin]# lsLNMP[root@yt-01 sbin]# cd LNMP/[root@yt-01 LNMP]# lsDBMGT etc home keys LICENSE lnmp.sh README.md source.sh svnserve svn.sh[root@yt-01 LNMP]# echo &quot;^^^^&quot; &gt;&gt; lnmp.sh[root@yt-01 LNMP]# git add lnmp.sh[root@yt-01 LNMP]# git commit -m &quot;瞎改&quot;[master c67bc06] 瞎改 1 file changed, 1 insertion(+)# 此时只是提交到了本地仓库 推送到远程仓库123456789[root@yt-01 LNMP]# git pushWarning: Permanently added the RSA host key for IP address &apos;192.30.253.112&apos; to the list of known hosts.Counting objects: 5, done.Compressing objects: 100% (3/3), done.Writing objects: 100% (3/3), 293 bytes | 0 bytes/s, done.Total 3 (delta 2), reused 0 (delta 0)remote: Resolving deltas: 100% (2/2), completed with 2 local objects.To git@github.com:zhouqunic/LNMP.git 027e59a..c67bc06 master -&gt; master]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVN的安装和使用]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F22.1-22.4%20%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%E4%BB%8B%E7%BB%8D%E5%92%8Csvn%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[22.1 代码管理平台介绍1.关于代码管理平台的常识当大家谈论到代码管理平台的时候，会简单的把它认为就是一个放代码的地方，类似于FTP直接上传到指定位置就可以了。对于一个网站来说，这样理解没问题的。但是对于一个业务来说，每天都有很多代码需要不断的去更新，当然此过程不是想象的那么简单，上传即可，这个是需要开发组一点点去编辑（当然开发不是一个人去完成的是一个团队，不同的成员去编辑去修改，这个就是所谓的协同开发）。测试、（第一版，第二版，第三版……）合成，最后推送到指定的业务中去。 我们如果没有详细的工作日志，那么很难记得这些变更，代码管理平台就是一个帮助我们管理代码版本变更的一个工具。 版本控制，记录若干文件内容变化，以便将来查阅特定版本修订情况 版本管理工具发展简史，cvs -&gt; svn -&gt; git 参考 http://luckypoem14.github.io/test/2012/04/24/scm-history/ svn全称subversion，是一个开源版本控制系统，始于2000年 git是yt-01创始人linus发起的，2005年发布，最初目的是更好管理yt-01内核代码 git和svn不同在于git不需要依赖服务端就可以工作，即git是分布式的 github是基于git的在线web页面代码托管平台，可以选择付费服务 gitlab可以认为是一个开源的github，两者没有直接关系 2. svn和git的对比优点：1.对于某些项目的核心代码或者是一些重要的保密性要求较高的项目，svn比git更适合。2.svn支持空目录3.svn有更好的windows平台支持4.svn可以check out/clone一个子树（sub-tree）5.svn支持特权访问控制svn lock，在处理很难合并的文件时非常有用6.svn支持二进制文件，更容易处理大文件（不需要把老版本拷来拷去）7.学习简单、使用简单 缺点：1.无网的情况下：无法提交代码，无法查看代码的历史版本、无法同步代码2.代码要定期做备份（所有的代码数据及版本变更记录）3.分支切换缓慢4.由于每次提交都会保留一个原始副本，因此SVN的数据库容量会暴增。尤其是在开发人员非常多的情况下。 mark 22.2 安装svn服务端安装和配置SVN(yt-01)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273安装[root@yt-01 ~]# yum install -y subversion创建版本库[root@yt-01 ~]# mkdir -p /data/svnroot/myproject版本库初始化root@yt-01 ~]# svnadmin create /data/svnroot/myproject[root@yt-01 ~]# ll /data/svnroot/myproject/总用量 8drwxr-xr-x 2 root root 54 4月 3 11:43 confdrwxr-sr-x 6 root root 233 4月 3 11:43 db-r--r--r-- 1 root root 2 4月 3 11:43 formatdrwxr-xr-x 2 root root 231 4月 3 11:43 hooksdrwxr-xr-x 2 root root 41 4月 3 11:43 locks-rw-r--r-- 1 root root 229 4月 3 11:43 README.txt进入配置文件目录：[root@yt-01 ~]# cd /data/svnroot/myproject/conf/[root@yt-01 conf]# lsauthz passwd svnserve.conf#authz：控制权限#passwd：密码文件#svnserve.conf：仓库配置文件配置用户及权限：[root@yt-01 conf]# vim authz[groups]admins = yuntai,user1# admin:组名# yuntai，user1：两个用户[/] // [/]:指定目录，“/”代表仓库的根目录，即/data/svnroot/myproject/@admins = rw //指定admins组所对应的权限* = r //指定其他所有用户对应的权限[myproject:/] # myproject：项目名称，该方法适合SVN有多个项目（或有多个子项目）时使用user1 = rw配置用户密码：[root@yt-01 conf]# vim passwd[users]yuntai = 123456user1 = 123456#为了提高安全性，真是环境要设置复杂密码配置仓库文件：[root@yt-01 conf]# vim svnserve.conf[general]anon-access = none #指定匿名用户权限auth-access = write #指定认证用户权限password-db = passwd#指定用户密码文件authz-db = authz#指定用户权限文件realm = /data/svnroot/myproject#指定对用的仓库文件（绝对路径）启动SVN：[root@yt-01 conf]# svnserve -d -r /data/svnroot/# -d：表示后台运行# -r：=restrict（限制、约束）限制只输出指定路径下的版本库查看进程及端口：[root@yt-01 conf]# ps aux |grep svnroot 2543 0.0 0.1 162188 656 ? Ss 19:30 0:00 svnserve -d -r /data/svnroot/[root@yt-01 conf]# netstat -lntp |grep svntcp 0 0 0.0.0.0:3690 0.0.0.0:* LISTEN 2543/svnserve 22.3 客户端上使用svn（yt-02）12345678910111213141516171819202122232425262728293031安装：[root@yt-02 ~]# yum install -y subversion进入测试目录：[root@yt-02 ~]# mkdir -p /home/svntest/[root@yt-02 ~]# cd !$cd /home/svntest/取出代码（从客户端1）：[root@yt-02 svntest]# svn checkout svn://192.168.122.130/myproject --username=yuntai认证领域: &lt;svn://192.168.122.130:3690&gt; /data/svnroot/myproject“yuntai”的密码:-----------------------------------------------------------------------注意! 你的密码，对于认证域: &lt;svn://192.168.122.130:3690&gt; /data/svnroot/myproject只能明文保存在磁盘上! 如果可能的话，请考虑配置你的系统，让 Subversion可以保存加密后的密码。请参阅文档以获得详细信息。你可以通过在“/root/.subversion/servers”中设置选项“store-plaintext-passwords”为“yes”或“no”，来避免再次出现此警告。-----------------------------------------------------------------------保存未加密的密码(yes/no)?n取出版本 0。[root@yt-02 svntest]# lsmyproject[root@yt-02 svntest]# ls myproject/[root@yt-02 svntest]# ls -a. .. myproject[root@yt-02 svntest]# ls -a myproject/. .. .svn 测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677客户端1项目中增加一份文件[root@yt-02 svntest]# cd myproject/[root@yt-02 myproject]# ls[root@yt-02 myproject]# cp /etc/fstab ./ [root@yt-02 myproject]# lsfstab客户端1上传本地文件到服务端：[root@yt-02 myproject]# svn add ./fstab //打上标记A fstab[root@yt-02 myproject]# svn commit -m &quot;add fstab&quot; //正式上传，提交项目， -m：=mark，做标记正在增加 fstab传输文件数据.提交后的版本为 1。在服务端使用user1作为用户登录，作为客户端2，取出服务端项目文件[root@yt-01 myproject]# mkdir /home/svntest2/[root@yt-01 myprojec]# cd !$cd /home/svntest2/[root@yt-01 svntest2]# svn checkout svn://192.168.122.130/myproject --username=user1A myproject/fstab取出版本 1。[root@yt-01 svntest2]# lsmyproject[root@yt-01 svntest2]# cd myproject/[root@yt-01 myproject]# lsfstab# 此时，在客户端1中提交的文件被同步到客户端2中# 再次上传新文件后可以使用命令：svn update进行同步客户端1：[root@yt-02 myproject]# vim test.txt[root@yt-02 myproject]# lsfstab test.txt[root@yt-02 myproject]# svn add ./test.txtA test.txt[root@yt-02 myproject]# svn commit -m &quot;add test.txt&quot;正在增加 test.txt传输文件数据.提交后的版本为 2。客户端2：[root@yt-01 myproject]# lsfstab[root@yt-01 myproject]# svn update正在升级 &apos;.&apos;:已还原“test.txt”版本 2。[root@yt-01 myproject]# lsfstab test.txt#注：此处update可以简写为up客户端密码文件保存位置：[root@yt-02 myproject]# cd /root/.subversion/auth/svn.simple[root@yt-02 svn.simple]# ls60b825fc1cf60a306eb7e67ad30c922d[root@yt-02 svn.simple]# cat 60b825fc1cf60a306eb7e67ad30c922dK 8passtypeV 6simpleK 8passwordV 6123456K 15svn:realmstringV 52&lt;svn://192.168.122.130:3690&gt; /data/svnroot/myprojectK 8usernameV 6yuntaiEND# 如果在某客户端删除该文件，再次使用svn update进行同步时会提示输入root用户名和密码# 在此，直接回车，然后输入svn指定的用户和密码即可 SVN命令总结12345678910111213# svn delete filename //在本地删除# svn commit -m “delete filename” //在服务器上删除# svn update //把当前目录下的文件都更新到最新版# svn log //查看变更日志# svn add . //添加到版本控制中心# svn commit -m “add file” //把文件上传到服务器# svn checkout svn://192.168.133.130/myproject --username=yuntai 22.4 客户端上使用svn（windows） 官网 https://tortoisesvn.net/index.zh.html 下载TortoiseSVN 并安装 简明教程 http://www.jianshu.com/p/6b3b7b915332 扩展内容svn 多仓库管理 http://elim.iteye.com/blog/1171108svn+ssh http://www.linuxfly.org/post/450/svn清除保存的用户名和密码 http://holy2010.blog.51cto.com/1086044/645944svn命令详解 http://blog.sina.com.cn/s/blog_963453200101eiuq.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群介绍、搭建配置、操作]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F21.22-21.25%20redis%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D%E3%80%81%E6%90%AD%E5%BB%BA%E9%85%8D%E7%BD%AE%E3%80%81%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[21.22 redis集群介绍 集群概念应该不陌生了，多台机器组成，用来解决像存储空间，查询速度，负载等提供一个或多个服务支持！ Redis集群 是一个分布式的一种架构，支持横向扩展，也就是说之前咱们配置的LVS+keepalived需要配置好基础环境，然后加入到集群系统。现在的Redis分布式，是*只需要把Redis这个集群配置到当前配置内就可以自动的去工作了~ * Redis Cluster设计要点 redis cluster在设计的时候，就考虑到了去中心化，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。 那么redis 是如何合理分配这些节点和数据的呢？ Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽 (hash slot)的方式来分配的。redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。 注意的是：必须要3个以后的主节点，否则在创建集群时会失败，我们在后续会实践到。 所以，我们假设现在有3个节点已经组成了集群，分别是：A, B, C 三个节点，它们可以是一台机器上的三个端口，也可以是三台不同的服务器。那么，采用哈希槽 (hash slot)的方式来分配16384个slot 的话，它们三个节点分别承担的slot 区间是： 节点A覆盖0－5460; 节点B覆盖5461－10922; 节点C覆盖10923－16383. 如下图所示： 那么，现在我想设置一个key ,比如叫my_name: set my_name xyz 按照redis cluster的哈希槽算法：CRC16(‘my_name’)%16384 = 2412。 那么就会把这个key 的存储分配到 A 上了。 同样，当我连接(A,B,C)任何一个节点想获取my_name这个key时，也会这样的算法，然后内部跳转到B节点上获取数据。 这种哈希槽的分配方式有好也有坏，好处就是很清晰，比如我想新增一个节点D，redis cluster的这种做法是从各个节点的前面各拿取一部分slot到D上，我会在接下来的实践中实验。大致就会变成这样： 节点A覆盖1365-5460 节点B覆盖6827-10922 节点C覆盖12288-16383 节点D覆盖0-1364,5461-6826,10923-12287 同样删除一个节点也是类似，移动完成后就可以删除这个节点了。 所以redis cluster 就是这样的一个形状： Redis cluster是分布式集群，支持横向扩展，Redis从V3.0版本后才支持集群功能。Redis集群的工作原理类似于磁盘的raid5。 多个redis节点网络互联，数据共享。 所有的节点都是一主一从（可以是多个从），其中从不提供服务，仅作为备用（主一旦宕机，从马上顶替工作！）。 不支持同时处理多个键（如mset/mget），因为redis需要把键均匀分布在各个节点上，并发量很高的情况下同时创建键值会降低性能并导致不可预测的行为。 支持在线增加、删除节点。 客户端可以连任何一个主节点进行读写。 误区：好多人会认为Redis集群上的数据都是一致的，大错特错！Redis 上面的数据是共享式的，也就是A server有的B server不一定有。类似于Raid 5，写入数据可能是A磁盘 可能是B磁盘。你可以正常读取，但真正的存储位置你是不晓得在哪儿的！ 21.23/21.24 redis集群搭建配置1 场景设置 两台机器，分别开启三个Redis服务（端口） A机器上三个端口：7000、7002、7004，全部为主 B机器上三个端口：7001、7003、7005，全部为从 两台机器上都要编译安装Redis，然后编译并复制三个不同的Redis.conf，分别设置不同的端口号、dir等参数，还需要增加cluster相关参数，然后分别启动6个Redis服务 注意：一定需要关闭selinux，iptables放行对应端口 2 安装Ruby v2.2（master）Redis集群需要ruby的支持，需要先安装ruby（Ruby只需在一台机器上运行）。Redis4.0需要使用Ruby2.2，安装方法如下（因为本机自带的是2.0版本的ruby，所以需要使用如下方法把源码包包制作成yum安装包，然后借助yum工具安装ruby2.2——升级ruby版本） 12345678910111213141516171819202122232425安装yum开发工具组：[root@yt-01 ~]# yum -y groupinstall &quot;Development Tools&quot;升级库文件：[root@yt-01 ~]# yum -y install gdbm-devel libdb4-devel libffi-devel libyaml libyaml-devel ncurses-devel openssl-devel readline-devel tcl-devel[root@yt-01 ~]# cd /root/创建制作rpm包的目录：[root@yt-01 ~]# mkdir -p rpmbuild/&#123;BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS&#125;下载Ruby的源码包：[root@yt-01 ~]# wget http://cache.ruby-lang.org/pub/ruby/2.2/ruby-2.2.3.tar.gz -P rpmbuild/SOURCES下载specs文件，用于制作rpm包：[root@yt-01 ~]# wget https://raw.githubusercontent.com/tjinjin/automate-ruby-rpm/master/ruby22x.spec -P rpmbuild/SPECS制作rpm包：[root@yt-01 ~]# rpmbuild -bb rpmbuild/SPECS/ruby22x.spec#此处需要耐心等待，大约需要5分钟安装Ruby2.2：[root@yt-01 ~]# yum -y localinstall rpmbuild/RPMS/x86_64/ruby-2.2.3-1.el7.centos.x86_64.rpm[root@yt-01 ~]# ruby -vruby 2.2.3p173 (2015-08-18 revision 51636) [x86_64-linux] 注意： 除此方法之外，还可以编译安装ruby。好了，ruby 2.2已经安装完成。 3 准备机器master(ip:192.168.122.130)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@yt-01 ~]# vim /etc/redis_7000.confport 7000bind 192.168.122.130daemonize yespidfile /var/run/redis_7000.piddir /data/redis_data/7000cluster-enabled yes#开启cluster功能cluster-config-file nodes_7000.conf#该配置文件可以在dir目录下自动生成cluster-node-timeout 10100appendonly yes[root@yt-01 ~]# vim /etc/redis_7002.confport 7002bind 192.168.122.130daemonize yespidfile /var/run/redis_7002.piddir /data/redis_data/7002cluster-enabled yescluster-config-file nodes_7002.confcluster-node-timeout 10100appendonly yes[root@yt-01 ~]# vim /etc/redis_7004.confport 7004bind 192.168.122.130daemonize yespidfile /var/run/redis_7004.piddir /data/redis_data/7004cluster-enabled yescluster-config-file nodes_7004.confcluster-node-timeout 10100appendonly yes创建各配置文件对应的数据库目录：[root@yt-01 ~]# mkdir /data/redis_data[root@yt-01 ~]# mkdir /data/redis_data/&#123;7000,7002,7004&#125;依次启动Redis服务7000，7002，7004：[root@yt-01 ~]# redis-server /etc/redis_7000.conf33019:C 08 Apr 11:37:10.782 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo33019:C 08 Apr 11:37:10.782 # Redis version=4.0.9, bits=64, commit=00000000, modified=0, pid=33019, just started33019:C 08 Apr 11:37:10.782 # Configuration loaded[root@yt-01 ~]# redis-server /etc/redis_7002.conf[root@yt-01 ~]# redis-server /etc/redis_7004.conf启动完成后，结果如下：[root@yt-01 ~]# ps aux |grep redisroot 33020 0.0 0.1 145264 2632 ? Ssl 11:37 0:00 redis-server 192.168.122.130:7000 [cluster]root 33032 0.0 0.1 145264 2628 ? Ssl 11:37 0:00 redis-server 192.168.122.130:7002 [cluster]root 33054 0.0 0.1 145264 2644 ? Ssl 11:37 0:00 redis-server 192.168.122.130:7004 [cluster] 4 准备slave（IP:192168.122.131）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869安装redis先在yt-01上传redis到yt-02上[root@yt-01 ~]# cd /usr/local/src/[root@yt-01 src]# ll[root@yt-01 src]# scp -r redis-4.0.9 192.168.122.131:/usr/local/src/root@192.168.122.131&apos;s password:在yt-02上[root@yt-02 ~]# cd /usr/local/src[root@yt-02 src]# ll[root@yt-02 src]# cd redis-4.0.9/[root@yt-02 redis-4.0.9]# make install cd src &amp;&amp; make installmake[1]: 进入目录“/usr/local/src/redis-4.0.9/src”Hint: It&apos;s a good idea to run &apos;make test&apos; ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL installmake[1]: 离开目录“/usr/local/src/redis-4.0.9/src”# 因为之前在yt-01上编译过，这里只需要install就可以了[root@yt-02 ~]# vim /etc/redis_7001.confport 7001bind 192.168.122.131daemonize yespidfile /var/run/redis_7001.piddir /data/redis_data/7001cluster-enabled yescluster-config-file nodes_7001.confcluster-node-timeout 10100appendonly yes[root@yt-02 ~]# vim /etc/redis_7003.confport 7003bind 192.168.122.131daemonize yespidfile /var/run/redis_7003.piddir /data/redis_data/7003cluster-enabled yescluster-config-file nodes_7003.confcluster-node-timeout 10100appendonly yes[root@yt-02 ~]# vim /etc/redis_7005.confport 7005bind 192.168.122.131daemonize yespidfile /var/run/redis_7005.piddir /data/redis_data/7005cluster-enabled yescluster-config-file nodes_7005.confcluster-node-timeout 10100appendonly yes创建各配置文件对应的数据库目录：[root@yt-02 ~]# mkdir /data/redis_data[root@yt-02 ~]# mkdir /data/redis_data/&#123;7001,7003,7005&#125;依次启动Redis服务7001，7003，7005：[root@yt-02 ~]# redis-server /etc/redis_7001.conf[root@yt-02 ~]# redis-server /etc/redis_7003.conf[root@yt-02 ~]# redis-server /etc/redis_7005.conf启动完成后结果如下：[root@yt-02 ~]# ps aux |grep redisroot 25413 0.0 0.4 145264 7564 ? Ssl 11:50 0:00 redis-server 192.168.122.131:7001 [cluster]root 25418 0.0 0.4 145264 7564 ? Ssl 11:50 0:00 redis-server 192.168.122.131:7003 [cluster]root 25427 0.0 0.4 145264 7564 ? Ssl 11:50 0:00 redis-server 192.168.122.131:7005 [cluster] 5 配置redis集群12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758安装Redis配置集群的工具：[root@yt-01 ~]# gem install redis将命令redis-trib.rb加入环境变量目录下：[root@yt-01 ~]# cp /usr/local/src/redis-4.0.2/src/redis-trib.rb /usr/bin/[root@yt-01 ~]# redis-trib.rb create --replicas 1 192.168.122.130:7000 192.168.122.130:7002 192.168.122.130:7004 192.168.122.131:7001 192.168.122.131:7003 192.168.122.131:7005&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:192.168.122.130:7000192.168.122.131:7001192.168.122.130:7002Adding replica 192.168.122.131:7005 to 192.168.122.130:7000Adding replica 192.168.122.130:7004 to 192.168.122.131:7001Adding replica 192.168.122.131:7003 to 192.168.122.130:7002M: 8c76e2bcb05c8d911b57989b973376a1a4ae8d0e 192.168.122.130:7000 slots:0-5460 (5461 slots) masterM: 89b6e94a7c8c5b3660aa94b8492ebf2bb8684b5b 192.168.122.130:7002 slots:10923-16383 (5461 slots) masterS: 702d2db77c3a9a5e5b5a2fb3348e5a894479ad93 192.168.122.130:7004 replicates c097cca2ac912c6d867336683d31cf4dbdbb8818M: c097cca2ac912c6d867336683d31cf4dbdbb8818 192.168.122.131:7001 slots:5461-10922 (5462 slots) masterS: 3ef5d3b9a607259ff7b57f722c9eda9b38a1b083 192.168.122.131:7003 replicates 89b6e94a7c8c5b3660aa94b8492ebf2bb8684b5bS: 0e3946acca8ee2f093ea5951591b592a9bee4d45 192.168.122.131:7005 replicates 8c76e2bcb05c8d911b57989b973376a1a4ae8d0eCan I set the above configuration? (type &apos;yes&apos; to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join..&gt;&gt;&gt; Performing Cluster Check (using node 192.168.122.130:7000)M: 8c76e2bcb05c8d911b57989b973376a1a4ae8d0e 192.168.122.130:7000 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 89b6e94a7c8c5b3660aa94b8492ebf2bb8684b5b 192.168.122.130:7002 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 702d2db77c3a9a5e5b5a2fb3348e5a894479ad93 192.168.122.130:7004 slots: (0 slots) slave replicates c097cca2ac912c6d867336683d31cf4dbdbb8818S: 3ef5d3b9a607259ff7b57f722c9eda9b38a1b083 192.168.122.131:7003 slots: (0 slots) slave replicates 89b6e94a7c8c5b3660aa94b8492ebf2bb8684b5bS: 0e3946acca8ee2f093ea5951591b592a9bee4d45 192.168.122.131:7005 slots: (0 slots) slave replicates 8c76e2bcb05c8d911b57989b973376a1a4ae8d0eM: c097cca2ac912c6d867336683d31cf4dbdbb8818 192.168.122.131:7001 slots:5461-10922 (5462 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.# 注意：redis-trib.rb create --replicas 1 表示一个master对应几个slave，此处的参数“1”表示master和slave一一对应# 主从是redis-trib.rb自动分配的 Redis集群配置完成! 21.25 redis集群操作1 连接redis集群因为Redis集群是分布式结构，所以可以连接任何一个端口。 123456789101112131415161718192021222324252627282930313233343536连接：[root@yt-02 ~]# redis-cli -c -h 192.168.122.130 -p 7000#-c：=cluster，表示以集群方式连接创建数据：192.168.122.130:7000&gt; set key1 123-&gt; Redirected to slot [9189] located at 192.168.122.131:7001OK#该操作会被重定向到192.168.122.131:7001192.168.122.131:7001&gt; set key2 abc-&gt; Redirected to slot [4998] located at 192.168.122.130:7000OK192.168.122.130:7000&gt; set key3 cbdOK# 该操作会被重定向到本地192.168.122.130:7000&gt; set key5 test5-&gt; Redirected to slot [9057] located at 192.168.122.131:7001OK查看数据：192.168.122.130:7000&gt; get key1-&gt; Redirected to slot [9189] located at 192.168.122.131:7001&quot;123&quot;192.168.122.131:7001&gt; get key2-&gt; Redirected to slot [4998] located at 192.168.122.130:7000&quot;abc&quot;192.168.122.130:7000&gt; get key3&quot;cbd&quot;192.168.122.130:7000&gt; get key4-&gt; Redirected to slot [13120] located at 192.168.122.130:7002(nil)192.168.122.130:7002&gt; get key5-&gt; Redirected to slot [9057] located at 192.168.122.131:7001&quot;test5&quot; 2 集群的操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970查看集群的状态：[root@yt-01 ~]# redis-trib.rb check 192.168.122.130:7000&gt;&gt;&gt; Performing Cluster Check (using node 192.168.122.130:7000)M: 8c76e2bcb05c8d911b57989b973376a1a4ae8d0e 192.168.122.130:7000 slots:0-5460 (5461 slots) master 1 additional replica(s)M: 89b6e94a7c8c5b3660aa94b8492ebf2bb8684b5b 192.168.122.130:7002 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 702d2db77c3a9a5e5b5a2fb3348e5a894479ad93 192.168.122.130:7004 slots: (0 slots) slave replicates c097cca2ac912c6d867336683d31cf4dbdbb8818S: 3ef5d3b9a607259ff7b57f722c9eda9b38a1b083 192.168.122.131:7003 slots: (0 slots) slave replicates 89b6e94a7c8c5b3660aa94b8492ebf2bb8684b5bS: 0e3946acca8ee2f093ea5951591b592a9bee4d45 192.168.122.131:7005 slots: (0 slots) slave replicates 8c76e2bcb05c8d911b57989b973376a1a4ae8d0eM: c097cca2ac912c6d867336683d31cf4dbdbb8818 192.168.122.131:7001 slots:5461-10922 (5462 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.列出节点：[root@yt-01 ~]# redis-cli -c -h 192.168.122.130 -p 7000192.168.122.130:7000&gt; cluster nodes89b6e94a7c8c5b3660aa94b8492ebf2bb8684b5b 192.168.122.130:7002@17002 master - 0 1523160379000 2 connected 10923-16383702d2db77c3a9a5e5b5a2fb3348e5a894479ad93 192.168.122.130:7004@17004 slave c097cca2ac912c6d867336683d31cf4dbdbb8818 0 1523160380000 4 connected8c76e2bcb05c8d911b57989b973376a1a4ae8d0e 192.168.122.130:7000@17000 myself,master - 0 1523160380000 1 connected 0-54603ef5d3b9a607259ff7b57f722c9eda9b38a1b083 192.168.122.131:7003@17003 slave 89b6e94a7c8c5b3660aa94b8492ebf2bb8684b5b 0 1523160378767 5 connected0e3946acca8ee2f093ea5951591b592a9bee4d45 192.168.122.131:7005@17005 slave 8c76e2bcb05c8d911b57989b973376a1a4ae8d0e 0 1523160378000 6 connectedc097cca2ac912c6d867336683d31cf4dbdbb8818 192.168.122.131:7001@17001 master - 0 1523160377000 4 connected 5461-10922查看集群信息：192.168.122.130:7000&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:548cluster_stats_messages_pong_sent:581cluster_stats_messages_sent:1129cluster_stats_messages_ping_received:576cluster_stats_messages_pong_received:548cluster_stats_messages_meet_received:5cluster_stats_messages_received:1129添加节点（执行该操作前先在slave创建redis_7007.conf并启动）：192.168.122.130:7000&gt; cluster meet 192.168.122.131 7007OK192.168.122.130:7000&gt; cluster nodes84fa982c0a3314bb239eeba869238502752d2682 192.168.122.131:7007@17007 master - 0 1523160579000 0 connected##此时7007以master身份存在再添加一个节点：192.168.122.130:7000&gt; cluster meet 192.168.122.130 7006OK192.168.122.130:7000&gt; cluster nodes1daa74e086e82eee1dd091189f1a06547a149e26 192.168.122.130:7006@17006 master - 0 1523160976000 7 connected#也是以master身份存在#使用以上方式添加的新节点都是以master身份存在！ 将当前节点设置为指定节点的从 1234567891011121314151617181920212223242526272829303132先更换到要设置的节点：[root@yt-01 ~]# redis-cli -c -h 192.168.122.130 -p 7006设定为7007的从：192.168.122.130:7006&gt; cluster replicate 84fa982c0a3314bb239eeba869238502752d2682OK查看：192.168.122.130:7006&gt; cluster nodes1daa74e086e82eee1dd091189f1a06547a149e26 192.168.122.130:7006@17006 myself,slave 84fa982c0a3314bb239eeba869238502752d2682 0 1523161084000 7 connected84fa982c0a3314bb239eeba869238502752d2682 192.168.122.131:7007@17007 master - 0 1523161084000 0 connected#对比node号，即7006为7007的从。。移除某节点：192.168.122.130:7006&gt; cluster forget 84fa982c0a3314bb239eeba869238502752d2682(error) ERR Can&apos;t forget my master!192.168.122.130:7006&gt; 1daa74e086e82eee1dd091189f1a06547a149e26(error) ERR I tried hard but I can&apos;t forget myself...# 从节点不能移除master节点和也不能移除自己切换到一个主节点[root@yt-01 ~]# redis-cli -c -h 192.168.122.130 -p 7000192.168.122.130:7000&gt; cluster forget 677f27fb209ce45c823126fe38dbcf0b9fc43d93OK查看：192.168.122.130:7000&gt; cluster nodes#此时7006已经不存在了。保存当前配置：192.168.122.130:7000&gt; CLUSTER SAVECONFIGOK]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis常用操作、操作键值、安全设置]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F21.13-21.17%20redis%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E3%80%81%E6%93%8D%E4%BD%9C%E9%94%AE%E5%80%BC%E3%80%81%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[21.13/21.14/21.15 redis常用操作1 Redis常用操作 for String数据 SETNX 检测键值是否有value，如果有直接返回一个 0，如果没有直接返回一个 1 并且创建此 value。(string) 1234567891011121314151617181920如果一个key设置两个不同的值，第二个值会覆盖第一个值。# redis-cli 127.0.0.1:6379&gt; set key1 yunOK127.0.0.1:6379&gt; set key2 taiOK127.0.0.1:6379&gt; set key1 awkkOK127.0.0.1:6379&gt; get key1&quot;awkk&quot;使用setnx命令检测127.0.0.1:6379&gt; SETNX key1 aaa(integer) 0 127.0.0.1:6379&gt; SETNX key3 aaa(integer) 1 127.0.0.1:6379&gt; get key1&quot;awkk&quot;127.0.0.1:6379&gt; get key3&quot;aaa&quot; setex 针对某个key设置一个过期时间。(string) 1setex key3 10 1 //给key3设置过期时间为10s，值为1，若key已经存在，会覆盖新的值。 2 Redis常用操作 for List数据 LPUSH 插入值、LPOP 取（挤）出值、lrange 列出值（范围） 123456789101112131415127.0.0.1:6379&gt; LPUSH kk 222 //从左侧添加一个数据，相当于从瓶子上方往里面放饼干，先存的在里面，后存的在外边(integer) 1127.0.0.1:6379&gt; LPUSH kk 111(integer) 1127.0.0.1:6379&gt; LPUSH kk 2222 (integer) 3127.0.0.1:6379&gt; LRANGE kk 0 -1 1) &quot;2222&quot;2) &quot;111&quot;3) &quot;222&quot;127.0.0.1:6379&gt; LPOP kk //LPOP 取最上面的值&quot;2222&quot;127.0.0.1:6379&gt; RPOP kk //RPOP 取最下面的值&quot;222&quot;# 注意：RPOP 或者 LPOP只要把值取出来 其中的值就会被删除掉。 Linsert 插入一个值 before在前面/after在后面 123456789101112131415161718192021127.0.0.1:6379&gt; LRANGE kk1 0 -11) &quot;333&quot;2) &quot;asd&quot;3) &quot;111&quot;在之前插入一个数值：127.0.0.1:6379&gt; LINSERT kk1 before 333 zzz(integer) 4127.0.0.1:6379&gt; LRANGE kk1 0 -11) &quot;zzz&quot;2) &quot;333&quot;3) &quot;asd&quot;4) &quot;111&quot;在之后插入一个数值：127.0.0.1:6379&gt; LINSERT kk1 after asd sss(integer) 5127.0.0.1:6379&gt; LRANGE kk1 0 -11) &quot;zzz&quot;2) &quot;333&quot;3) &quot;asd&quot;4) &quot;sss&quot;5) &quot;111&quot; LSET 修改一个值 1234567891011121314127.0.0.1:6379&gt; LRANGE kk1 0 -11) &quot;zzz&quot;2) &quot;333&quot;3) &quot;asd&quot;4) &quot;sss&quot;5) &quot;111&quot;127.0.0.1:6379&gt; LSET kk1 1 555 //把第二个值 333 改为 555（首个数值是从0 开始的）OK127.0.0.1:6379&gt; LRANGE kk1 0 -11) &quot;zzz&quot;2) &quot;555&quot;3) &quot;asd&quot;4) &quot;sss&quot;5) &quot;111&quot; LINDEX 查看元素的值 12lindex kk1 0 //查看第1个元素lindex kk1 3 //查看第4个元素 LLEN 查看元素的长度 123127.0.0.1:6379&gt; LLEN kk1(integer) 5表示有5个元素 3 Redis常用操作 for Set（zset）数据123456789101112131415161718192021127.0.0.1:6379&gt; SADD pp 111 //向集合pp中放入元素(integer) 1127.0.0.1:6379&gt; SADD pp 222(integer) 1127.0.0.1:6379&gt; SADD pp 333(integer) 1127.0.0.1:6379&gt; SMEMBERS pp //查看集合中的所有元素1) &quot;111&quot;2) &quot;222&quot;3) &quot;333&quot;127.0.0.1:6379&gt; SPOP pp //随机取出一个元素，删除&quot;111&quot;127.0.0.1:6379&gt; SMEMBERS pp1) &quot;111&quot;2) &quot;222&quot;3) &quot;333&quot;127.0.0.1:6379&gt; SREM pp 111 //删除一个元素(integer) 1127.0.0.1:6379&gt; SMEMBERS pp1) &quot;222&quot;2) &quot;333&quot; SDIFF 求差集 12345678910111213141516171819127.0.0.1:6379&gt; SMEMBERS pp1) &quot;222&quot;2) &quot;333&quot;127.0.0.1:6379&gt; SMEMBERS mm1) &quot;221&quot;2) &quot;222&quot;3) &quot;233&quot;127.0.0.1:6379&gt; SDIFF pp mm1) &quot;333&quot;127.0.0.1:6379&gt; SDIFF mm pp1) &quot;221&quot;2) &quot;233&quot;第一个SDIFF pp在前 mm在后 意思是针对于pp 对照mm找出不同的值第一个SDIFF mm在前 pp在后 意思是针对于mm 对照pp找出不同的值127.0.0.1:6379&gt; SDIFFstore nn mm pp //求差集并且存储，存储到了nn里(integer) 2127.0.0.1:6379&gt; SMEMBERS nn1) &quot;221&quot;2) &quot;233&quot; SINTER 求交集 12345678910111213127.0.0.1:6379&gt; SMEMBERS pp1) &quot;222&quot;2) &quot;333&quot;127.0.0.1:6379&gt; SMEMBERS mm1) &quot;221&quot;2) &quot;222&quot;3) &quot;233&quot;127.0.0.1:6379&gt; SINTER mm pp1) &quot;222&quot;127.0.0.1:6379&gt; SINTERSTORE aa mm pp //求交集并且存储，存储到了aa里(integer) 1127.0.0.1:6379&gt; SMEMBERS aa1) &quot;222&quot; SISMEMBER 判断集合中是否有此值 12345678127.0.0.1:6379&gt; SMEMBERS mm1) &quot;221&quot;2) &quot;222&quot;3) &quot;233&quot;127.0.0.1:6379&gt; SISMEMBER mm 11(integer) 0127.0.0.1:6379&gt; SISMEMBER mm 233(integer) 1 ZADD 创建有序集合 123456789101112131415127.0.0.1:6379&gt; ZADD ss 1 123(integer) 1127.0.0.1:6379&gt; ZADD ss 2 234(integer) 1127.0.0.1:6379&gt; ZADD ss 3 asd(integer) 1127.0.0.1:6379&gt; ZRANGE ss 0 -1 //显示所有元素，按顺序显示1) &quot;123&quot;2) &quot;234&quot;3) &quot;asd&quot;127.0.0.1:6379&gt; ZREM ss 234 //删除指定元素(integer) 1127.0.0.1:6379&gt; ZRANGE ss 0 -11) &quot;123&quot;2) &quot;asd&quot; ZRANK 索引数据 1234567891011127.0.0.1:6379&gt; ZRANGE ss 0 -11) &quot;123&quot;2) &quot;asd&quot;3) &quot;asdaqwe&quot;4) &quot;asasdz&quot;127.0.0.1:6379&gt; ZRANK ss asd //返回元素的索引值，索引值从0开始，按score正向排序(integer) 1127.0.0.1:6379&gt; ZRANK ss asasdz(integer) 3127.0.0.1:6379&gt; ZREVRANK ss asd //按score反向排序，获取数据的值(integer) 2 ZCARD 统计集合元素中的个数 12127.0.0.1:6379&gt; ZCARD ss(integer) 4 ZCOUNT 统计范围内集合元素的个数 12127.0.0.1:6379&gt; ZCOUNT ss 1 10 //返回分值范围1-10的元素个数(integer) 2 ZRANGEBYSCORE 返回分值范围的元素 123127.0.0.1:6379&gt; ZRANGEBYSCORE ss 1 101) &quot;123&quot;2) &quot;asd&quot; ZREMRANGEBYSCORE 删除分值范围的元素 12345127.0.0.1:6379&gt; ZREMRANGEBYSCORE ss 1 10(integer) 2127.0.0.1:6379&gt; ZRANGE ss 0 -11) &quot;asdaqwe&quot;2) &quot;asasdz&quot; ZREMRANGEBYRANK 删除索引范围的元素，按score正向排序 1234567891011127.0.0.1:6379&gt; ZRANGE ss 0 -11) &quot;asdaqwe&quot;2) &quot;123&quot;3) &quot;234&quot;4) &quot;345&quot;5) &quot;asdaa&quot;6) &quot;asasdz&quot;127.0.0.1:6379&gt; ZREMRANGEBYRANK ss 1 10(integer) 5127.0.0.1:6379&gt; ZRANGE ss 0 -11) &quot;asdaqwe&quot; 4 Redis常用操作 for hash数据 HMSET 批量建立键值对 123456789127.0.0.1:6379&gt; HMSET yt name yuntai age 27 weight 77OK127.0.0.1:6379&gt; HGETALL yt1) &quot;name&quot;2) &quot;yuntai&quot;3) &quot;age&quot;4) &quot;27&quot;5) &quot;weight&quot;6) &quot;77&quot; HMGET 查询一个键值 12127.0.0.1:6379&gt; HMGET yt name1) &quot;yuntai&quot; HDEL 删除一个键值 1234567127.0.0.1:6379&gt; HDEL yt name(integer) 1127.0.0.1:6379&gt; HGETALL yt1) &quot;age&quot;2) &quot;27&quot;3) &quot;weight&quot;4) &quot;77&quot; HKEYS 打印所有的键值 HVALS 打印所有的values 123456127.0.0.1:6379&gt; HKEYS yt1) &quot;age&quot;2) &quot;weight&quot;127.0.0.1:6379&gt; HVALS yt1) &quot;27&quot;2) &quot;77&quot; hlen 查看有几个filed 12127.0.0.1:6379&gt; HLEN yt(integer) 2 21.16 redis操作键值123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137查看数据库内所有key：127.0.0.1:6379&gt; keys * 1) &quot;hseta&quot; 2) &quot;k3&quot; 3) &quot;setb&quot; 4) &quot;hash1&quot; 5) &quot;zseta&quot; 6) &quot;mykey&quot; 7) &quot;set3&quot; 8) &quot;key2&quot; 9) &quot;set2&quot;10) &quot;set4&quot;11) &quot;key1&quot;12) &quot;list2&quot;13) &quot;k1&quot;14) &quot;seta&quot;15) &quot;list1&quot;16) &quot;k2&quot;17) &quot;set1&quot;18) &quot;set5&quot;支持模糊匹配：127.0.0.1:6379&gt; keys set*1) &quot;setb&quot;2) &quot;set3&quot;3) &quot;set2&quot;4) &quot;set4&quot;5) &quot;seta&quot;6) &quot;set1&quot;7) &quot;set5&quot;查看某key是否存在：127.0.0.1:6379&gt; exists key1(integer) 1127.0.0.1:6379&gt; exists key11(integer) 0#0：表示不存在；1：表示存在删除key：127.0.0.1:6379&gt; del key1(integer) 1127.0.0.1:6379&gt; exists key1(integer) 0给已存在的key设置过期时间：127.0.0.1:6379&gt; EXPIRE key2 600查看某key还有多长时间过期：127.0.0.1:6379&gt; ttl key2(integer) 578#当key已经不存在时，返回-2#当key存在但是没有设置失效时间时，返回-1选择数据库：127.0.0.1:6379&gt; select 0OK#Redis有16个库，0表示当前所在的库将一个 key移动到另一个库：127.0.0.1:6379&gt; move set2 1(integer) 1127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; keys *1) &quot;set2&quot;取消某个key的过期时间（persist）：127.0.0.1:6379&gt; ttl key2(integer) 221127.0.0.1:6379&gt; persist key2(integer) 1127.0.0.1:6379&gt; ttl key2(integer) -1随机返回一个key：127.0.0.1:6379&gt; randomkey&quot;zseta&quot;127.0.0.1:6379&gt; randomkey&quot;mykey&quot;重命名：127.0.0.1:6379&gt; rename set2 set22OK127.0.0.1:6379&gt; smembers set2(empty list or set)127.0.0.1:6379&gt; smembers set221) &quot;d&quot;2) &quot;b&quot;3) &quot;eee&quot;查看key的类型：127.0.0.1:6379&gt; type key2string127.0.0.1:6379&gt; type set22set127.0.0.1:6379&gt; type zsetazset127.0.0.1:6379&gt; type list2list127.0.0.1:6379&gt; type hsetahash查看数据库找那个key的数目：127.0.0.1:6379&gt; DBSIZE(integer) 17查看数据库的状态信息：127.0.0.1:6379&gt; info清空当前数据库内所有key：127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; keys *1) &quot;set22&quot;127.0.0.1:6379[1]&gt; flushdbOK127.0.0.1:6379[1]&gt; keys *(empty list or set)清空所有数据库内所有的key：127.0.0.1:6379&gt; flushall保存数据到rdb文件中，在后台运行：127.0.0.1:6379&gt; bgsav同上，在前台运行：127.0.0.1:6379&gt; save获取所有配置参数：127.0.0.1:6379&gt; config get *查看指定参数：127.0.0.1:6379&gt; config get port1) &quot;port&quot;2) &quot;6379&quot;设置某参数：27.0.0.1:6379&gt; config set timeout 100 数据恢复首先定义或确定dir目录和dbfilename，然后把备份的rdb文件放到dir目录下面，重启Redis即可恢复数据。 21.17 redis安全设置谈到安全，先说一个真实的例子：前两年Redis比较火的时候，也就是攻击最严重的时候。见到了很多次由Redis被黑导致系统被黑的案例！怎么被黑的呢？ Redis 服务启动了，但是监听了一个全网IP，如果6379默认端口没有更改，并且iptables也处于关闭，公网IP 也开放着，Redis也没有设置任何密码，黑客就会扫描端口，然后就可以轻轻松松登录你的Redis服务器，并且是超级管理员的权限。然后黑客就可以设置dir dbname， dir 定义到/root/.ssh 且dbname定义为：.ssh/authorized_keys 再把这个值写上自己的公钥。 这些应该都不陌生吧，这不就活生生的把黑客的公钥上传到了咱们的服务器中，然后利用超级管理员做任何想做的事情了！！当然解决也很简单：1.设置密码 2.更改默认端口 3.监听内网IP 4.设定专用账户 5.修改configure命令 vim /etc/redis.conf 123456789101112131415设置监听ipbind 127.0.0.1 2.2.2.2//可以是多个ip，用空格分隔设置监听端口port 16000设置密码requirepass passwd123redis-cli -a &apos;passwd123&apos;将config命令改名rename-command CONFIG xxx禁掉config命令rename-command CONFIG “” 最后重启 redis 服务器 12# killall redis-server# redis-server /etc/redis.conf 再次登陆 redis server 我们发现需要密码 12345127.0.0.1:6379&gt; SADD asd 12(error) NOAUTH Authentication required.[root@zhdy-01 ~]# redis-cli -a &apos;asd9577&apos;127.0.0.1:6379&gt; SADD asd 12(integer) 1 我们还可以使用如上所讲的 更改config 为自定义名称，就算黑客登录了你的redis服务器也不晓得你们的config是什么命令。 12345678910111213141516[root@yt-01 ~]# vim /etc/redis.conf添加：rename-command CONFIG xxx[root@yt-01 ~]# killall redis-server[root@yt-01 ~]# redis-server /etc/redis.conf127.0.0.1:6379&gt; CONFIG GET *(error) ERR unknown command &apos;CONFIG&apos;127.0.0.1:6379&gt; xxx GET * 1) &quot;dbfilename&quot; 2) &quot;dump.rdb&quot; 3) &quot;requirepass&quot; 4) &quot;xxx9577&quot; 5) &quot;masterauth&quot; 6) &quot;&quot; 7) &quot;cluster-announce-ip&quot; 8) &quot;&quot; 9) &quot;unixsocket&quot; 最后一个就是禁掉 CONFIG 123vim /etc/redis.conf 把 # rename-commond CONFIG &quot; &quot;去掉前面的注释]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis慢查询日志、php安装redis扩展、存储session、主从配置]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F21.18-21.21%20redis%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%E3%80%81php%E5%AE%89%E8%A3%85redis%E6%89%A9%E5%B1%95%E3%80%81%E5%AD%98%E5%82%A8session%E3%80%81%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[21.18 redis慢查询日志针对慢查询日志可以设置两个参数，一个是执行时长，单位是微妙，另一个是慢查询日志的长度。当一个新的命令被写入日志时，最老的一条会从命令日志队列被移除。 1234567891011121314151617[root@yt-01 ~]# vim /etc/redis.confslowlog-log-slower-than 10000#单位：微秒slowlog-max-len 128#定义日志长度，表示最多存128条列出所有慢查询日志：[root@yt-01 ~]# redis-cli127.0.0.1:6379&gt; slowlog get(empty list or set)列出两条慢查询日志：127.0.0.1:6379&gt; slowlog get 2(empty list or set)查看慢查询日志条数：127.0.0.1:6379&gt; slowlog len(integer) 0 21.19-21.20 php安装redis扩展，redis存储php的sessionPHP和Redis通过模块相结合，使用前先查看PHP是否有Redis模块，如果没有，按如下方式安装并配置。 1 安装php-redis扩展模块1234567891011[root@yt-01 src]# wget https://coding.net/u/aminglinux/p/yuanke_centos7/git/raw/master/21NOSQL/phpredis.zip[root@yt-01 src]# unzip phpredis.zip[root@yt-01 src]# cd phpredis-develop/[root@yt-01 phpredis-develop]# /usr/local/php/bin/phpize[root@yt-01 phpredis-develop]# ./configure --with-php-config=/usr/local/php/bin/php-config[root@yt-01 phpredis-develop]# make &amp;&amp; make install增加如下配置：[root@yt-01 phpredis-develop]# vim /usr/local/php/etc/php.iniextension=redis.so[root@yt-01 phpredis-develop]# /usr/local/php/bin/php -mredis 2 Redis和PHP连接12345678方法1：编辑php.ini[root@yt-01 www]# vim /usr/local/php/etc/php.inisession.save_handler = redissession.save_path = &quot;tcp://127.0.0.1:6379&quot;方法2：编辑pool文件：[root@yt-01 ~]# vim /usr/local/php-fpm/etc/php-fpm.d/www.confphp_value[session.save_handler] = redisphp_value[session.save_path] = &quot;tcp://127.0.0.1:6379&quot; 3 测试1234567891011121314151617181920212223242526[root@yt-01 www]# pwd/data/wwwroot/111.com[root@yt-01 www]# lsindex.php#1.php为测试文件[root@yt-01 www]# vim 1.php&lt;?phpsession_start();if (!isset($_SESSION[&apos;TEST&apos;])) &#123;$_SESSION[&apos;TEST&apos;] = time();&#125;$_SESSION[&apos;TEST3&apos;] = time();print $_SESSION[&apos;TEST&apos;];print &quot;&lt;br&gt;&lt;br&gt;&quot;;print $_SESSION[&apos;TEST3&apos;];print &quot;&lt;br&gt;&lt;br&gt;&quot;;print session_id();?&gt;[root@yt-01 www]# curl localhost/1.php1523162689&lt;br&gt;&lt;br&gt;1523162689&lt;br&gt;&lt;br&gt;0fp6g1hi1q6ktdoogfplvlpo91[root@yt-01 www]# redis-cli127.0.0.1:6379&gt; keys *10) &quot;PHPREDIS_SESSION:6rtu66hia6rjq9rpadstnsqb61&quot;11) &quot;PHPREDIS_SESSION:hdi4f5r122gg1n9sj5lllbqf42&quot;12) &quot;PHPREDIS_SESSION:8tf4q887ti8m11sknl5oto82m4&quot;13) &quot;PHPREDIS_SESSION:hc1h18jtkrvk3secno4nmk7km2&quot; 这样就配置完成了。 注意： 注： 如果是在集群架构中，需要使用predis扩展模块，扩展地址 https://github.com/nrk/predis 。 21.21 redis主从配置为了节省资源，本实验在一台机器进行。即，在一台机器上启动两个端口，模拟两台机器。 1 redis主从搭建1234567891011121314151617181920212223242526272829303132准备还是之前的yt-01主机，环境是LAMP+redis复制redis配置文件[root@adailinux ~]# cp /etc/redis.conf /etc/redis2.conf配置redis从的配置文件[root@adailinux ~]# vim /etc/redis2.conf //需要修改port,dir,pidfile,logfileport 6380 //因为是同一台服务器，2个进程，所以需要换一个端口pidfile /var/run/redis_6380.pidlogfile &quot;/tmp/logs/redis2.log&quot;dir /data/redis2# slaveof &lt;masterip&gt; &lt;masterport&gt;slaveof 127.0.0.1 6379 //添加这一行###指定主服务器IP和端口# masterauth passwd123###如果主服务器设定了密码，需要在从服务器上添加该参数创建redis从的库文件夹[root@adailinux ~]# mkdir /data/redis2启动Redis[root@adailinux ~]# redis-server /etc/redis.conf[root@adailinux ~]# redis-server /etc/redis2.conf [root@adailinux ~]# ps aux |grep redisroot 2454 0.2 0.4 145244 2356 ? Ssl 17:18 0:00 redis-server 127.0.0.1:6379root 2459 0.3 0.4 145244 2332 ? Ssl 17:19 0:00 redis-server 127.0.0.1:6380[root@adailinux ~]# netstat -lntp |grep redistcp 0 0 127.0.0.1:6379 0.0.0.0:* LISTEN 2454/redis-server 1tcp 0 0 127.0.0.1:6380 0.0.0.0:* LISTEN 2459/redis-server 1启动成功，redis主从搭建完毕！ 2 查看slave上的数据123456789101112131415161718[root@adailinux ~]# redis-cli -p 6380127.0.0.1:6380&gt; keys * 1) &quot;list1&quot; 2) &quot;hseta&quot; 3) &quot;set1&quot; 4) &quot;set3&quot; 5) &quot;key2&quot; 6) &quot;k1&quot; 7) &quot;set4&quot; 8) &quot;seta&quot; 9) &quot;k2&quot;10) &quot;k3&quot;11) &quot;zseta&quot;12) &quot;setb&quot;13) &quot;hash1&quot;14) &quot;set5&quot;15) &quot;list2&quot;16) &quot;mykey&quot; 3 测试主从123456789101112131415在master上创建数据：[root@adailinux ~]# redis-cli -p 6379127.0.0.1:6379&gt; del key(integer) 1127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; set test 00001OK在slave上查看：[root@adailinux ~]# redis-cli -p 6380127.0.0.1:6380&gt; select 1127.0.0.1:6380[1]&gt; keys *1) &quot;test&quot;127.0.0.1:6380[1]&gt; get test&quot;00001&quot; 注意： Redis主从和mysql主从不一样，Redis主从不用事先同步数据，它会自动同步。因为master上设置有参数“slave-read-only yes”，即该slave为只读数据库！]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis介绍、安装、持久型、数据类型]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F21.9-21.12%20Redis%E4%BB%8B%E7%BB%8D%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E6%8C%81%E4%B9%85%E5%9E%8B%E3%80%81%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[21.9 redis介绍 Redis和Memcached类似，也属于k-v数据存储 ，但是功能和操作性要比Memcached好很多。 Redis官网 redis.io,当前最新稳定版4.0.9，支持更多value类型，除了和string外，还支持hash、lists（链表）、sets（集合）和sorted sets（有序集合） redis使用了两种文件格式：全量数据(RDB)和增量请求(aof)。 全量数据格式是把内存中的数据写入磁盘，便于下次读取文件进行加载。 增量请求文件则是把内存中的数据序列化为操作请求，用于读取文件进行replay得到数据，这种类似于mysql binlog。 为了节省资源，当我们手动保存一次全量数据，就可以删除当前的所有增量数据了，有些增量数据其实早就过期了，也可定期利用脚本做一些优化 。 redis的存储分为内存存储、磁盘存储和log文件三部分 21.10 redis安装1 下载123官网地址 redis.io[root@yt-01 ~]# cd /usr/local/src[root@yt-01 src]# wget http://download.redis.io/releases/redis-4.0.9.tar.gz 2 安装1234567891011[root@yt-01 src]# tar zxvf redis-4.0.9.tar.gz //解压[root@yt-01 src]# cd redis-4.0.9 //进入redis目录[root@yt-01 redis-4.0.9]# make &amp;&amp; make install //和其他软件不同，redis安装直接就可以编译[root@yt-01 redis-4.0.9]# echo $? //确认编译是否成功0[root@yt-01 redis-4.0.9]# redis- //用tab查看redis的命令，确认是否安装成功redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server[root@yt-01 redis-4.0.9]# which redis-cli //查看redis的启动文件地址/usr/local/bin/redis-cli[root@yt-01 redis-4.0.9]# ls //查看redis安装后的文件00-RELEASENOTES BUGS CONTRIBUTING COPYING deps INSTALL Makefile MANIFESTO README.md redis.conf runtest runtest-cluster runtest-sentinel sentinel.conf src tests utils 3 配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@yt-01 redis-4.0.9]# cp redis.conf /etc/redis.conf[root@yt-01 redis-4.0.9]# vim /etc/redis.conf //修改配置文件……daemonize yes #yes表示后台启动；no表示前台启动pidfile /var/run/redis_6379.pid #pid存放位置loglevel notice#指定日志级别：debug（调试，排错）、verbose（冗长的）、notice、warning#debug适合排查错误时使用，错误排查完毕后要换到notice，避免产生大量日志浪费系统空间logfile &quot;/var/log/redis.log&quot; #定义日志存放路径databases 16#Redis有库的概念，默认在0库dir /data/redis #定义rdb、aof文件的存放位置appendonly yes #开启aof日志，开启后会在dir定义的目录生成appendonly.aof文件appendfsync everysec #指定记录日志的规则：always（只要有变动就记录）、everysec（每秒记录一次）、no（不记录）创建rdb、aof文件的存放文件夹[root@yt-01 redis-4.0.9]# mkdir /data/redis启动redis[root@yt-01 redis-4.0.9]# redis-server /etc/redis.conf查看redis进程（因为虚拟机还运行着gitlab网站服务，所以进程会多几个）[root@yt-01 redis-4.0.9]# ps aux |grep redisroot 5526 0.0 0.0 4184 16 ? Ss 10:10 0:00 runsv redisroot 5527 0.0 0.0 4328 56 ? S 10:10 0:00 svlogd -tt /var/log/gitlab/redisgitlab-+ 5528 0.2 0.1 41484 3740 ? Ssl 10:10 0:36 /opt/gitlab/embedded/bin/redis-server 127.0.0.1:0root 6041 0.0 0.0 4184 0 ? Ss 10:11 0:00 runsv redis-exporterroot 6042 0.0 0.0 4328 36 ? S 10:11 0:00 svlogd -tt /var/log/gitlab/redis-exportergitlab-+ 6043 0.0 0.4 53424 7976 ? Ssl 10:11 0:04 /opt/gitlab/embedded/bin/redis_exporter -web.listen-address=localhost:9121 -redis.addr=unix:///var/opt/gitlab/redis/redis.socketroot 36317 0.0 0.1 145260 2184 ? Ssl 13:33 0:00 redis-server 127.0.0.1:6379 //默认监听端口是6379查看redis日志[root@yt-01 redis-4.0.9]# less /var/log/redis.log# 2条warning，提醒我们有2个内核参数需要调整……36317:M 06 Apr 13:33:51.922 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &apos;vm.overcommit_memory = 1&apos; to /etc/sysctl.conf and then reboot or run the command &apos;sysctl vm.overcommit_memory=1&apos; for this to take effect.36317:M 06 Apr 13:33:51.922 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command &apos;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&apos; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.36317:M 06 Apr 13:33:51.922 * Ready to accept connections/var/log/redis.log (END)配置内核参数[root@yt-01 redis-4.0.9]# sysctl vm.overcommit_memory=1[root@yt-01 redis-4.0.9]# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled加入开机启动[root@yt-01 redis-4.0.9]# vim /etc/rc.localsysctl vm.overcommit_memory=1echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled启动[root@yt-01 redis-4.0.9]# redis-server /etc/redis.conf 4 关闭redis服务的方法 方法1：查询到PID，kill -9 pid。该方式相当于断电，非正常关闭，一般不用，会造成数据丢失 方法2 1[root@yt-01 redis-4.0.9]# redis-cli shutdown 21.11 redis持久化 和Memcached服务一样，如果关闭RDB和aof数据就会存储在内存中，当重启服务或者重启机器 存储的数据就会丢失。如果数据很重要，我们就需要做持久化。 Redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File） RDB，简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上。 AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。 其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。 如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。 1 redis持久化相关的参数12345678910save 900 1 //表示每15分钟且至少有1个key改变，就触发一次持久化save 300 10 //表示每5分钟且至少有10个key改变，就触发一次持久化save 60 10000 //表示每60秒至少有10000个key改变，就触发一次持久save &quot; &quot; //这样可以禁用rdb持久化appendonly yes //如果是yes，则开启aof持久化appendfilename “appendonly.aof” //指定aof文件名字appendfsync everysec //每一秒写入aof文件，并完成磁盘同步。# 指定fsync()调用模式，有三种# no(不调用fsync),always(每次写都会调用fsync),everysec(每秒钟调用一次fsync)。# 第一种最快，第二种数据最安全，但会占用磁盘I/O会差一些，第三种为这种方案最恰当，默认选第三种。 2 开启和关闭持久化12345678910111213141516171819开启[root@yt-01 ~]# vim /etc/redis.conf……# save &quot; &quot;save 900 1save 300 10save 60 10000关闭[root@yt-01 ~]# vim /etc/redis.conf……save &quot; &quot;# save 900 1# save 300 10# save 60 10000设置完后，重启服务# redis-cli -p 127.0.0.1 shutdown # redis-server /etc/redis.conf 21.12 redis数据类型12345stringlistsetsort sethash 1 Redis数据类型-stringstring为最简单的类型，与Memcached一样的类型，一个key对应一个value，其支持的操作与Memcached的操作类似，它的功能更丰富。设置可以存二进制的对象。 123456789101112[root@yt-01 ~]# redis-cli127.0.0.1:6379&gt; set mykey 123OK127.0.0.1:6379&gt; get mykey&quot;123&quot;127.0.0.1:6379&gt; mset k1 a k2 b k3 cOK127.0.0.1:6379&gt; mget k1 k2 k31) &quot;a&quot;2) &quot;b&quot;3) &quot;c&quot;127.0.0.1:6379&gt; quit 2 Redis数据类型-list list是一个链表结构，主要功能是push、pop、获取一个范围的所有值等等。操作中key理解为链表的名字。 使用 list 结构，我们可以轻松地实现最新消息排行等功能（比如新浪微博的 TimeLine ）。list 的另一个应用就是消息队列，可以利用 list 的 push操作，将任务存在 list 中，然后工作线程再用pop操作将任务取出进行执行。 1234567891011121314151617181920212223[root@yt-01 redis-4.0.9]# redis-cli# 添加一条list数据127.0.0.1:6379&gt; lpush list1 &quot;yuntai&quot;(integer) 1127.0.0.1:6379&gt; lpush list1 &quot;yuntai1&quot;(integer) 2127.0.0.1:6379&gt; lpush list1 &quot;yuntai2&quot;(integer) 3# 查看指定list的数据127.0.0.1:6379&gt; lrange list1 0 -11) &quot;yuntai2&quot;2) &quot;yuntai1&quot;3) &quot;yuntai&quot;# 取出（pop挤出）一条数据，挤出就没有了127.0.0.1:6379&gt; lpop list1&quot;yuntai2&quot;# 取出数据list 从0到1127.0.0.1:6379&gt; lrange list1 0 -11) &quot;yuntai1&quot;2) &quot;yuntai&quot;127.0.0.1:6379&gt; quit 3 Redis数据类型-set set是集合，和我们数学中的集合概念相似，对集合的操作有添加删除元素，有对多个集合求交并差等操作。操作中key理解为集合的名字。比如在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。因为 Redis 非常人性化的为集合提供了求交集、并集、差集等操作，那么就可以非常方便的实现如共同关注、共同喜好、二度好友等功能，对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。 1234567891011121314151617181920212223242526272829303132[root@yt-01 redis-4.0.9]# redis-cli# 添加一条set数据127.0.0.1:6379&gt; SADD set1 a(integer) 1127.0.0.1:6379&gt; SADD set1 b(integer) 1127.0.0.1:6379&gt; SADD set1 c(integer) 1127.0.0.1:6379&gt; SADD set1 d(integer) 1# 查看set数据127.0.0.1:6379&gt; SMEMBERS set11) &quot;d&quot;2) &quot;c&quot;3) &quot;a&quot;4) &quot;b&quot;127.0.0.1:6379&gt; SREM set1 c(integer) 1127.0.0.1:6379&gt; SADD set2 a 2 b(integer) 3127.0.0.1:6379&gt; SINTER set1 set21) &quot;a&quot;2) &quot;b&quot;127.0.0.1:6379&gt; SUNION set1 set21) &quot;d&quot;2) &quot;a&quot;3) &quot;2&quot;4) &quot;b&quot;127.0.0.1:6379&gt; SDIFF set1 set21) &quot;d&quot;127.0.0.1:6379&gt; quit 4 Redis数据类型-sort set sorted set是有序集合，它比set多了一个权重参数score，使得集合中的元素能够按score进行有序排列，比如一个存储全班同学成绩的Sorted Sets，其集合value可以是同学的学号，而score就可以是其考试得分，这样在数据插入集合的时候，就已经进行了天然的排序。 1234567891011121314151617181920212223242526[root@yt-01 redis-4.0.9]# redis-cli# 添加sort set数据127.0.0.1:6379&gt; ZADD set3 12 abc(integer) 1127.0.0.1:6379&gt; ZADD set3 2 &quot;cde 123&quot;(integer) 1127.0.0.1:6379&gt; ZADD set3 24 &quot;123-aaa&quot;(integer) 1127.0.0.1:6379&gt; ZADD set3 4 &quot;a123a&quot;(integer) 1# 查看数据set3127.0.0.1:6379&gt; ZRANGE set3 0 -11) &quot;cde 123&quot;2) &quot;a123a&quot;3) &quot;abc&quot;4) &quot;123-aaa&quot;#数据的value根据score大小排序# 倒序查看数据set3127.0.0.1:6379&gt; ZREVRANGE set3 0 -11) &quot;123-aaa&quot;2) &quot;abc&quot;3) &quot;a123a&quot;4) &quot;cde 123&quot;127.0.0.1:6379&gt; quit 5 Redis数据类型- hash在 Memcached 中，我们经常将一些结构化的信息打包成hashmap，在客户端序列化后存储为一个字符串的值（一般是JSON格式），比如用户的昵称、年龄、性别、积分等。 123456789101112131415161718192021[root@yt-01 redis-4.0.9]# redis-cli# 添加一条hash数据hash1 k值为name，v值为yuntai127.0.0.1:6379&gt; hset hash1 name yuntai(integer) 1# 查询数据hash1 k值为name的v值127.0.0.1:6379&gt; hget hash1 name&quot;yuntai&quot;127.0.0.1:6379&gt; hset hash1 age 27(integer) 1127.0.0.1:6379&gt; hget hash1 age&quot;27&quot;# 查询hash1的所有值127.0.0.1:6379&gt; hgetall hash11) &quot;name&quot;2) &quot;yuntai&quot;3) &quot;age&quot;4) &quot;27&quot;127.0.0.1:6379&gt; quit]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcached命令行、数据导出和导入、存储sessions]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F21.5-21.8%20memcached%E5%91%BD%E4%BB%A4%E8%A1%8C%E3%80%81%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA%E5%92%8C%E5%AF%BC%E5%85%A5%E3%80%81%E5%AD%98%E5%82%A8sessions%2F</url>
    <content type="text"><![CDATA[21.5 memcached命令行Memcached类似于mysql一样，同样支持类似于mysql中创建一个库，创建一个表，插入一个表，查看表数据等。 1 登录 Memcached12345678910111213141516171819202122232425262728293031323334353637[root@yt-01 ~]# telnet 127.0.0.1 11211 //测试端口Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &apos;^]&apos;.# 进入memcached命令行stats 关于当前 memcached 实例的信息STAT pid 13412STAT uptime 1885STAT time 1522943511STAT version 1.4.24STAT libevent 2.0.21-stableSTAT pointer_size 64STAT rusage_user 0.017423STAT rusage_system 0.046463……set key2 0 30 2 //手动存储一个数据其中key2 代表着 key值0代表着 flags 标记30代表着 过期时间2代表着 2个字节---------------------------------------------set key2 0 30 2 //存储key2，标记为0，过期时间30s，2个字节的数据ab //输入数据，只能2个字节：abSTORED get key2 //获取key2数据（因为输入慢了，数据过期了）ENDset key2 0 30 2 //重新存abSTOREDget key2 //获取成功VALUE key2 0 2abEND 2 Memcached语法规则 &lt;command name&gt; &lt;key&gt; &lt;flags&gt; &lt;exptime&gt; &lt;bytes&gt;\r\n &lt;data block&gt;\r\n 注：\r\n在windows下是Enter键 &lt;command name&gt;可以是set, add, replace set表示按照相应的&lt;key&gt;存储该数据，没有的时候增加，有的时候覆盖 add表示按照相应的&lt;key&gt;添加该数据,但是如果该&lt;key&gt;已经存在则会操作失败 replace表示按照相应的&lt;key&gt;替换数据,但是如果该&lt;key&gt;不存在则操作失败。 &lt;key&gt;客户端需要保存数据的key &lt;flags&gt;是一个16位的无符号的整数(以十进制的方式表示)。 该标志将和需要存储的数据一起存储,并在客户端get数据时返回。 客户端可以将此标志用做特殊用途，此标志对服务器来说是不透明的。 &lt;exptime&gt; 为过期的时间。 若为0表示存储的数据永远不过期(但可被服务器算法：LRU 等替换)。 如果非0(unix时间或者距离此时的秒数),当过期后,服务器可以保证用户得不到该数据(以服务器时间为标准)。 &lt;bytes&gt; 需要存储的字节数，当用户希望存储空数据时&lt;bytes&gt;可以为0 &lt;data block&gt;需要存储的内容，输入完成后，最后客户端需要加上\r\n（直接点击Enter）作为结束标志。 3 Memcached数据示例1234567891011121314151617181920set key3 1 100 4 //存取一个4字节值abcdSTOREDget key3 //查询key3值VALUE key3 1 4abcdENDreplace key3 1 200 5 //替换key3的值abcdxSTOREDget key3 //查询替换后的值VALUE key3 1 5 abcdxENDdelete key3 //删除key3的值DELETEDget key3ENDquit //退出Connection closed by foreign host. 21.6 memcached数据导出和导入1 导出12345678910111213141516[root@yt-01 ~]# date -d &quot;+1 hour&quot; +%s //显示当前时间加一个小时时间戳1522948361[root@yt-01 ~]# memcached-tool 127.0.0.1:11211 dump &gt;data.txt //导出Dumping memcache contents Number of buckets: 1 Number of items : 4Dumping bucket 1 - 4 total items[root@yt-01 ~]# cat data.txtadd key1 1 1522948361 3asdadd name 1 1522948361 5justiadd sex 1 1522948361 3manadd age 1 1522948361 227 2 导入12[root@yt-01 ~]# nc 127.0.0.1 11211 &lt; data.txt若nc命令不存在，yum install nc 注意：导出的数据是带有一个时间戳的，这个时间戳就是该条数据过期的时间点，如果当前时间已经超过该时间戳，那么是导入不进去的。如果仅仅是为了测试，这样可以办到，因为memcached是缓存在内存中的，只要重启机器或者重启memcached服务缓存数据就会丢失，然后我们再次使用nc 导入就可以了 123456[root@yt-01 ~]# systemctl restart memcached[root@yt-01 ~]# nc 127.0.0.1 11211 &lt;data.txtSTOREDSTOREDSTOREDSTORED 21.7 php连接memcached1 先安装php的memcache扩展123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@yt-01 ~]# cd /usr/local/src/[root@yt-01 src]# wget http://www.apelearn.com/bbs/data/attachment/forum/memcache-2.2.3.tgz [root@yt-01 src]# tar zxf memcache-2.2.3.tgz[root@yt-01 src]# cd memcache-2.2.3[root@yt-01 memcache-2.2.3]# lsconfig9.m4 config.w32 example.php memcache_consistent_hash.c memcache_queue.c memcache_session.c php_memcache.hconfig.m4 CREDITS memcache.c memcache.dsp memcache_queue.h memcache_standard_hash.c README[root@yt-01 memcache-2.2.3]# /usr/local/php/bin/phpize //nginx的php目录是/usr/local/php-fpm/bin/phpizeConfiguring for:PHP Api Version: 20131106Zend Module Api No: 20131226Zend Extension Api No: 220131226[root@yt-01 memcache-2.2.3]# ./configure --with-php-config=/usr/local/php/bin/php-config[root@yt-01 memcache-2.2.3]# echo $?0[root@yt-01 src]# make &amp; make install# 报错/usr/local/src/memcache-2.2.3/memcache.c: 在函数‘php_mmc_connect&apos;中:/usr/local/src/memcache-2.2.3/memcache.c:1902: 错误：提供给函数‘zend_list_insert&apos;的实参太少/usr/local/src/memcache-2.2.3/memcache.c:1919: 错误：提供给函数‘zend_list_insert&apos;的实参太少/usr/local/src/memcache-2.2.3/memcache.c: 在函数‘zif_memcache_add_server&apos;中:/usr/local/src/memcache-2.2.3/memcache.c:1975: 错误：提供给函数‘zend_is_callable&apos;的实参太少/usr/local/src/memcache-2.2.3/memcache.c:2003: 错误：提供给函数‘zend_list_insert&apos;的实参太少/usr/local/src/memcache-2.2.3/memcache.c: 在函数‘zif_memcache_set_server_params&apos;中:/usr/local/src/memcache-2.2.3/memcache.c:2059: 错误：提供给函数‘zend_is_callable&apos;的实参太少/usr/local/src/memcache-2.2.3/memcache.c: 在函数‘mmc_find_persistent&apos;中:/usr/local/src/memcache-2.2.3/memcache.c:2159: 错误：提供给函数‘zend_list_insert&apos;的实参太少/usr/local/src/memcache-2.2.3/memcache.c:2177: 错误：提供给函数‘zend_list_insert&apos;的实参太少make: *** [memcache.lo] 错误 1# 解决方法# vim memcache.c将所有的：zend_list_insert(pool, le_memcache_pool);改为：zend_list_insert(pool, le_memcache_pool TSRMLS_CC);将所有的：zend_list_insert(mmc, le_pmemcache);改为：zend_list_insert(mmc, le_pmemcache TSRMLS_CC);讲所有的：if (!zend_is_callable(failure_callback, 0, NULL))改为：if (!zend_is_callable(failure_callback, 0, NULL, NULL))修改完成后，重新make编译；[root@yt-01 memcache-2.2.3]# make &amp; make installInstalling shared extensions: /usr/local/php/lib/php/extensions/no-debug-zts-20131226/[root@yt-01 memcache-2.2.3]# ls /usr/local/php/lib/php/extensions/no-debug-zts-20131226/memcache.so opcache.so[root@yt-01 memcache-2.2.3]# vim /usr/local/php/etc/php.ini搜索extension，在extension模块行的最后加上： extension=&quot;memcache.so&quot;[root@yt-01 memcache-2.2.3]# /usr/local/php/bin/php -m有memcache 模块就可以了 2 测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@yt-01 memcache-2.2.3]# vim 1.php //编辑测试脚本&lt;?php//连接Memcache Memcache$mem = new Memcache;$mem-&gt;connect(&quot;localhost&quot;, 11211);//保存数据$mem-&gt;set(&apos;key1&apos;, &apos;This is first value&apos;, 0, 60);$val = $mem-&gt;get(&apos;key1&apos;);echo &quot;Get key1 value: &quot; . $val .&quot;&lt;br&gt;&quot;;//替换数据$mem-&gt;replace(&apos;key1&apos;, &apos;This is replace value&apos;, 0, 60);$val = $mem-&gt;get(&apos;key1&apos;);echo &quot;Get key1 value: &quot; . $val . &quot;&lt;br&gt;&quot;;//保存数组数据$arr = array(&apos;aaa&apos;, &apos;bbb&apos;, &apos;ccc&apos;, &apos;ddd&apos;);$mem-&gt;set(&apos;key2&apos;, $arr, 0, 60);$val2 = $mem-&gt;get(&apos;key2&apos;);echo &quot;Get key2 value: &quot;;print_r($val2);echo &quot;&lt;br&gt;&quot;;//删除数据$mem-&gt;delete(&apos;key1&apos;);$val = $mem-&gt;get(&apos;key1&apos;);echo &quot;Get key1 value: &quot; . $val . &quot;&lt;br&gt;&quot;;//清除所有数据$mem-&gt;flush();$val2 = $mem-&gt;get(&apos;key2&apos;);echo &quot;Get key2 value: &quot;;print_r($val2);echo &quot;&lt;br&gt;&quot;;//关闭连接$mem-&gt;close();?&gt;# 脚本意为： 连接memcache set一个数据， 保存 替换删除 关闭 等。[root@yt-01 memcache-2.2.3]# /usr/local/php/bin/php 1.php //测试php脚本Get key1 value: This is first value&lt;br&gt;Get key1 value: This is replace value&lt;br&gt;Get key2 value: Array( [0] =&gt; aaa [1] =&gt; bbb [2] =&gt; ccc [3] =&gt; ddd)或者，将1.php放到某个虚拟主机的根目录下，在浏览器测试显示如上内容就表示没问题 21.8 memcached中存储sessions本节应用场景为LNMP架构下做的负载均衡。假如第一次登录是在A服务器上，第二次登录是在B服务器上，假如使用的是nginx代理upstream可以使用ip_hash；如果使用LVS呢？解决方法是：把session不存在服务器的磁盘上，而是存在memcached上去。memcached作为一个公共的服务器，任何web服务器都可以连接！ 12345678910本实例是在lamp/lnmp环境下实现编辑php.ini添加两行（待测试）session.save_handler = memcachesession.save_path = &quot;tcp://192.168.0.9:11211&quot;或者httpd.conf中对应的虚拟主机中添加php_value session.save_handler &quot;memcache&quot;php_value session.save_path &quot;tcp://192.168.0.9:11211&quot;或者php-fpm.conf对应的pool中添加php_value[session.save_handler] = memcachephp_value[session.save_path] = &quot;tcp://192.168.0.9:11211 &quot; 1 下载测试文件12345678910111213141516wget http://study.lishiming.net/.mem_se.txt将其移动到虚拟主机目录中：mv /root/.mem_se.txt /data/wwwroot/www.111.comcp .mem_se.txt 1.php在php-fpm.conf对应的pool中添加：vim /usr/local/php-fpm/etc/php-fpm.conf添加：php_value[session.save_handler] = memcachephp_value[session.save_path] = &quot;tcp://192.168.122.130:11211&quot;注：如上要是有专门的memcache服务器，这儿就需要配置独立memcache的地址。/etc/init.d/php-fpm restart 2 测试123456789101112131415161718[root@yt-01 www.111.com]# curl localhost/1.php1507648188&lt;br&gt;&lt;br&gt;1507648188&lt;br&gt;&lt;br&gt;41026no8snqjq81phrl7ukovc6[root@yt-01 www.111.com]# curl localhost/1.php1507648268&lt;br&gt;&lt;br&gt;1507648268&lt;br&gt;&lt;br&gt;e2apbv2kkibntt4r59llfj52r1[root@yt-01 www.111.com]# curl localhost/1.php1507648269&lt;br&gt;&lt;br&gt;1507648269&lt;br&gt;&lt;br&gt;4mjm7v7thjldh413kuebcbjbe0[root@yt-01 www.111.com]# curl localhost/1.php1507648270&lt;br&gt;&lt;br&gt;1507648270&lt;br&gt;&lt;br&gt;1if2vpeut27r1siebjlv87ik92登录 查看值：[root@yt-01 www.111.com]# telnet 127.0.0.1 11211Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &apos;^]&apos;.get i7vddchc2jdjpedsvck2tppra2VALUE i7vddchc2jdjpedsvck2tppra2 0 37TEST|i:1507648271;TEST3|i:1507648271;END如上使用get 去查看一个值！ 可以查询到相关的数据。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSQL和memcached介绍]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F21.1-21.4%20NoSQL%E5%92%8Cmemcached%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[21.1 nosql介绍1. 什么是NoSQL？ 非关系型数据库就是NoSQL，而关系型数据库代表MySQL 对于关系型数据库来说，是需要把数据存储到库、表、行、字段里，查询的时候根据条件一行一行地去匹配，当量非常大的时候就很耗费时间和资源，*尤其是数据是需要从磁盘里去检索 * NoSQL数据库存储原理非常简单（典型的数据类型为k-v），不存在繁杂的关系链，比如mysql查询的时候，需要找到对应的库、表（通常是多个表）以及字段。 NoSQL数据可以存储在内存里，查询速度非常快 NoSQL在性能表现上虽然能优于关系型数据库，但是它并不能完全替代关系型数据库 NoSQL因为没有复杂的数据结构，扩展非常容易，支持分布式 2. 常见NoSQL数据库 k-v形式的：memcached、redis 适合储存用户信息，比如会话、配置文件、参数、购物车等等。这些信息一般都和ID（键）挂钩，这种情景下键值数据库是个很好的选择。 文档数据库：mongodb 将数据以文档的形式储存。每个文档都是一系列数据项的集合。每个数据项都有一个名称与对应的值，值既可以是简单的数据类型，如字符串、数字和日期等；也可以是复杂的类型，如有序列表和关联对象。数据存储的最小单位是文档，同一个表中存储的文档属性可以是不同的，数据可以使用XML、JSON或者JSONB等多种形式存储。 列存储：Hbase 图：Neo4J、Infinite Graph、OrientDB 例如现实运维环境中，我们一台WEB安装了一个Discuz，随着访问量的增加，数据库扛不住那么大的压力；怎么办呢？我们设置一个NoSQL，当用户读取完毕后会直接放在NoSQL中，当用户再次读取的时候，会直接从缓存中读取，不需要再次从数据库中读取。帖子的ID就类似于Key，帖子的内容就类似于Value。 NoSQL因为没有复杂的数据结构，扩展非常容易，支持分布式。所以扩展也比较容易。如果你的A服务器受到瓶颈，增加服务器让让其继续缓存呗，因为不像关系型数据库需要互相关联，NoSQL直接横向扩展即可！ mysql的话只有前面说到的主主，主从，多主多从针对从进行负载均衡。要么就是分库分表，前提是关联的数据库不可以分开，不关联的数据库可以分开。 21.2 memrcached介绍 Memcached是国外社区网站LiveJournal团队开发，目的是为了通过缓存数据库查询结果，减少数据库访问次数，从而提高动态web站点性能。 官方站点 http://www.memcached.org/ 数据结构简单(k-v)，数据存放在内存里 多线程 基于c/s架构，协议简单 基于libevent的事件处理 自主内存存储处理（slab allowcation) 数据过期方式：Lazy Expiration 和 LRU 1. Memcached的数据流向一般使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态web应用的速度、提高可扩展性！ 正常的作业流程是： 用户发起请求给NGINX,然后再次调用PHP，PHP和mysql打交道，当用户PHP获取到请求转给NGINX，NGINX再次把请求数据交给用户。 如果并发量很大，请求mysql的队列比较多，这时候我们就需要增加一个缓存层Memcached。这样访问过的数据全部丢在缓存中，当再次请求这个数据的时候就直接从Memcached读取即可！ 2. Slab allocation的原理 将分配的内存分割成各种尺寸的块（chunk）， 并把尺寸相同的块分成组（chunk的集合），每个chunk集合被称为slab。 Memcached的内存分配以Page为单位，Page默认值为1M，可以在启动时通过-I参数来指定。 Slab是由多个Page组成的，Page按照指定大小切割成多个chunk。 3. Growth factor Memcached在启动时通过-f选项可以指定 Growth Factor因子。该值控制chunk大小的差异。默认值为1.25。 通过memcached-tool命令查看指定Memcached实例的不同slab状态，可以看到各Item所占大小（chunk大小）差距为1.25 命令1# memcached-tool 127.0.0.1:11211 display 4. Memcached的数据过期方式4.1 Lazy Expiration Memcached 内部不会监视记录是否过期，而是在get时查看记录的时间戳，检查记录是否过期。这种技术被称为lazy（惰性）expiration。因此，Memcached不会在过期监视上耗费CPU时间。 4.2 LRU * Memcached会优先使用已超时的记录的空间，但即使如此，也会发生追加新记录时空间不足的情况，此时就要使用名为Least Recently Used（LRU）机制来分配空间。顾名思义，这是删除“最近最少使用”的记录的机制。因此，当内存空间不足时（无法从slab class获取到新的空间时），就从最近未被使用的记录中搜索，并将其空间分配给新的记录。从缓存的实用角度来看，该模型十分理想。 21.3 安装memcached1234567891011121314151617181920yum install -y memcached libmemcached libeventsystemctl start memcached[root@yt-06 ~]# netstat -lntpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:11211 0.0.0.0:* LISTEN 2899/memcached [root@yt-06 ~]# ps aux | grep memcachedmemcach+ 2899 0.0 0.1 325556 1180 ? Ssl 22:02 0:00 /usr/bin/memcached -u memcached -p 11211 -m 64 -c 1024# /usr/bin/memcached -u memcached -p 11211 -m 64 -c 1024 //命令行启动+参数[root@yt-01 ~]# vim /etc/sysconfig/memcached //memcached配置文件PORT=&quot;11211&quot; //监听端口11211USER=&quot;memcached&quot; //启动用户MAXCONN=&quot;1024&quot; //最大并发数CACHESIZE=&quot;64&quot; //可用内存，默认单位 MOPTIONS=&quot;&quot; //可选选项，比如加上监听的ip，可以把OPTIONS=”” 改为OPTIONS=”127.0.0.1″ 21.4 查看memcached状态 memcached-tool 127.0.0.1:11211 stats 或者echo stats |nc 127.0.0.1 11211 需要安装nc工具 yum install -y nc 若安装libmemcached后，可以使用命令 memstat –servers=127.0.0.1:11211 查看memcached服务状态 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229[root@yt-01 ~]# memcached-tool 127.0.0.1:11211 stats#127.0.0.1:11211 Field Value accepting_conns 1 auth_cmds 0 auth_errors 0 bytes 0 bytes_read 7 bytes_written 0 cas_badval 0 cas_hits 0 cas_misses 0 cmd_flush 0 cmd_get 0 cmd_set 0 cmd_touch 0 conn_yields 0 connection_structures 11 crawler_items_checked 0 crawler_reclaimed 0 curr_connections 10 curr_items 0 decr_hits 0 decr_misses 0 delete_hits 0 delete_misses 0 evicted_unfetched 0 evictions 0 expired_unfetched 0 get_hits 0 get_misses 0 hash_bytes 524288 hash_is_expanding 0 hash_power_level 16 incr_hits 0 incr_misses 0 libevent 2.0.21-stable limit_maxbytes 67108864 listen_disabled_num 0 lrutail_reflocked 0 malloc_fails 0 pid 13412 pointer_size 64 reclaimed 0 reserved_fds 20 rusage_system 0.003162 rusage_user 0.000924 threads 4 time 1522941651 total_connections 11 total_items 0 touch_hits 0 touch_misses 0 uptime 25 version 1.4.24或者[root@yt-01 ~]# echo stats |nc 127.0.0.1 11211STAT pid 13412STAT uptime 169STAT time 1522941795STAT version 1.4.24STAT libevent 2.0.21-stableSTAT pointer_size 64STAT rusage_user 0.001480STAT rusage_system 0.006246STAT curr_connections 10STAT total_connections 12STAT connection_structures 11STAT reserved_fds 20STAT cmd_get 0STAT cmd_set 0STAT cmd_flush 0STAT cmd_touch 0STAT get_hits 0STAT get_misses 0STAT delete_misses 0STAT delete_hits 0STAT incr_misses 0STAT incr_hits 0STAT decr_misses 0STAT decr_hits 0STAT cas_misses 0STAT cas_hits 0STAT cas_badval 0STAT touch_hits 0STAT touch_misses 0STAT auth_cmds 0STAT auth_errors 0STAT bytes_read 13STAT bytes_written 1127STAT limit_maxbytes 67108864STAT accepting_conns 1STAT listen_disabled_num 0STAT threads 4STAT conn_yields 0STAT hash_power_level 16STAT hash_bytes 524288STAT hash_is_expanding 0STAT malloc_fails 0STAT bytes 0STAT curr_items 0STAT total_items 0STAT expired_unfetched 0STAT evicted_unfetched 0STAT evictions 0STAT reclaimed 0STAT crawler_reclaimed 0STAT crawler_items_checked 0STAT lrutail_reflocked 0END或者[root@yt-01 ~]# memstat --servers=127.0.0.1:11211Server: 127.0.0.1 (11211) pid: 13412 uptime: 193 time: 1522941819 version: 1.4.24 libevent: 2.0.21-stable pointer_size: 64 rusage_user: 0.001480 rusage_system: 0.007460 curr_connections: 10 total_connections: 13 connection_structures: 11 reserved_fds: 20 cmd_get: 0 cmd_set: 0 cmd_flush: 0 cmd_touch: 0 get_hits: 0 get_misses: 0 delete_misses: 0 delete_hits: 0 incr_misses: 0 incr_hits: 0 decr_misses: 0 decr_hits: 0 cas_misses: 0 cas_hits: 0 cas_badval: 0 touch_hits: 0 touch_misses: 0 auth_cmds: 0 auth_errors: 0 bytes_read: 30 bytes_written: 2275 limit_maxbytes: 67108864 accepting_conns: 1 listen_disabled_num: 0 threads: 4 conn_yields: 0 hash_power_level: 16 hash_bytes: 524288 hash_is_expanding: 0 malloc_fails: 0 bytes: 0 curr_items: 0 total_items: 0 expired_unfetched: 0 evicted_unfetched: 0 evictions: 0 reclaimed: 0 crawler_reclaimed: 0 crawler_items_checked: 0 lrutail_reflocked: 0或者[root@yt-01 ~]# telnet 127.0.0.1 11211Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &apos;^]&apos;.statsSTAT pid 22459 进程IDSTAT uptime 1027046 服务器运行秒数STAT time 1273043062 服务器当前unix时间戳STAT version 1.4.4 服务器版本STAT libevent 2.0.21-stableSTAT pointer_size 64 操作系统字大小(这台服务器是64位的)STAT rusage_user 0.040000 进程累计用户时间STAT rusage_system 0.260000 进程累计系统时间STAT curr_connections 10 当前打开连接数STAT total_connections 82 曾打开的连接总数STAT connection_structures 13 服务器分配的连接结构数STAT reserved_fds 20STAT cmd_get 54 执行get命令总数STAT cmd_set 34 执行set命令总数STAT cmd_flush 3 指向flush_all命令总数STAT get_hits 9 get命中次数STAT get_misses 45 get未命中次数STAT delete_misses 5 delete未命中次数STAT delete_hits 1 delete命中次数STAT incr_misses 0 incr未命中次数STAT incr_hits 0 incr命中次数STAT decr_misses 0 decr未命中次数STAT decr_hits 0 decr命中次数STAT cas_misses 0 cas未命中次数STAT cas_hits 0 cas命中次数STAT cas_badval 0 使用擦拭次数STAT touch_hits 0STAT touch_misses 0STAT auth_cmds 0STAT auth_errors 0STAT bytes_read 15785 读取字节总数STAT bytes_written 15222 写入字节总数STAT limit_maxbytes 67108864 分配的内存数（字节）STAT accepting_conns 1 目前接受的链接数STAT listen_disabled_num 0STAT time_in_listen_disabled_us 0STAT threads 4 线程数STAT conn_yields 0STAT hash_power_level 16STAT hash_bytes 524288STAT hash_is_expanding 0STAT malloc_fails 0STAT conn_yields 0STAT bytes 0 存储item字节数STAT curr_items 0 item个数STAT total_items 34 item总数STAT expired_unfetched 0STAT evicted_unfetched 0STAT evictions 0 为获取空间删除item的总数STAT reclaimed 0STAT crawler_reclaimed 0STAT crawler_items_checked 0STAT lrutail_reflocked 0END]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>nosql</tag>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[告警系统邮件引擎、运行告警系统]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F20.23-20.26%20%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9F%E9%82%AE%E4%BB%B6%E5%BC%95%E6%93%8E%E3%80%81%E8%BF%90%E8%A1%8C%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[20.23/20.24/20.25 告警系统邮件引擎创建发邮件的脚本——mail.pymail.sh内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@localhost mail]# pwd/usr/local/sbin/mon/mail[root@localhost mail]# vim mail.py#!/usr/bin/env python#-*- coding: UTF-8 -*-import os,sysreload(sys)sys.setdefaultencoding(&apos;utf8&apos;)import getoptimport smtplibfrom email.MIMEText import MIMETextfrom email.MIMEMultipart import MIMEMultipartfrom subprocess import *def sendqqmail(username,password,mailfrom,mailto,subject,content): gserver = &apos;smtp.163.com&apos; gport = 25 try: msg = MIMEText(unicode(content).encode(&apos;utf-8&apos;)) msg[&apos;from&apos;] = mailfrom msg[&apos;to&apos;] = mailto msg[&apos;Reply-To&apos;] = mailfrom msg[&apos;Subject&apos;] = subject smtp = smtplib.SMTP(gserver, gport) smtp.set_debuglevel(0) smtp.ehlo() smtp.login(username,password) smtp.sendmail(mailfrom, mailto, msg.as_string()) smtp.close() except Exception,err: print &quot;Send mail failed. Error: %s&quot; % errdef main(): to=sys.argv[1] subject=sys.argv[2] content=sys.argv[3]##定义QQ邮箱的账号和密码，你需要修改成你自己的账号和密码（请不要把真实的用户名和密码放到网上公开，否则你会死的很惨） sendqqmail(&apos;asdgsfsdl@163.com&apos;,&apos;sdfsd2.&apos;,&apos;asdgsfsdl@163.com&apos;,to,subject,content)if __name__ == &quot;__main__&quot;: main()#####脚本使用说明#######1. 首先定义好脚本中的邮箱账号和密码#2. 脚本执行命令为：python mail.py 目标邮箱 &quot;邮件主题&quot; &quot;邮件内容&quot; 创建邮件引擎的配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445#本脚本用于做告警收敛#Written by jokinglog=$1t_s=`date +%s`#时间戳1t_s2=`date -d &quot;2 hours ago&quot; +%s`#时间戳2（两个小时之前的时间）#定义该时间戳的目的是保证第一次执行该脚本时v大于一小时#保证第一次执行的时候能报警#因为只有发生故障的时候才会执行该脚本，所以第一次执行必须要报警if [ ! -f /tmp/$log ]then echo $t_s2 &gt; /tmp/$logfi#创建记录时间戳的日志文件t_s2=`tail -1 /tmp/$log|awk &apos;&#123;print $1&#125;&apos;`echo $t_s&gt;&gt;/tmp/$logv=$[$t_s-$t_s2]#两个时间戳的间隔时间echo $v#计时器：if [ $v -gt 3600 ]then#如果时间间隔大于1小时，则启动报警系统 ./mail.py $1 $2 $3 echo &quot;0&quot; &gt; /tmp/$log.txt#$log.txt为计数器文件：else if [ ! -f /tmp/$log.txt ] then echo &quot;0&quot; &gt; /tmp/$log.txt fi#查看计数器文件中的数字 nu=`cat /tmp/$log.txt` nu2=$[$nu+1] echo $nu2&gt;/tmp/$log.txt#重置$log.txt数值 if [ $nu2 -gt 10 ] then#告警收敛：该故障持续十分钟，开始报警 ./mail.py $1 &quot;trouble continue 10 min $2&quot; &quot;$3&quot; echo &quot;0&quot; &gt; /tmp/$log.txt#告警结束后重新开始计数 fifi 20.26 运行告警系统执行告警系统，将告警任务写入计划任务中，每分钟执行一次。 12[root@localhost mail]# crontab -e* * * * * cd /usr/local/sbin/mon/bin; bash main.sh]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>shell告警系统脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[告警系统需求分析、告警系统主脚本、配置文件、监控项目]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F20.19-20.22%20%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9F%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90%E3%80%81%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9F%E4%B8%BB%E8%84%9A%E6%9C%AC%E3%80%81%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E3%80%81%E7%9B%91%E6%8E%A7%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[20.19 告警系统需求分析 需求：使用shell定制各种个性化告警工具，但需要统一化管理、规范化管理。 思路：指定一个脚本包，包含主程序、子程序、配置文件、邮件引擎、输出日志等。 主程序：作为整个脚本的入口，是整个系统的命脉。 配置文件：是一个控制中心，用它来开关各个子程序，指定各个相关联的日志文件。 子程序：这个才是真正的监控脚本，用来监控各个指标。 邮件引擎：是由一个python程序来实现，它可以定义发邮件的服务器、发邮件人以及发件人密码 输出日志：整个监控系统要有日志输出。 要求：我们的机器角色多种多样，但是所有机器上都要部署同样的监控系统，也就说所有机器不管什么角色，整个程序框架都是一致的，不同的地方在于根据不同的角色，定制不同的配置文件。 程序架构： 12345bin下是主程序conf下是配置文件shares下是各个监控脚本mail下是邮件引擎log下是日志。 20.20 告警系统主脚本 主角本就是整个告警系统的入口，在使用中，我们直接执行它就可以了。 定义主角本的各个目录123456789101112以后工作中，我们就默认把脚本都放到/usr/local/sbin目录下，这样我们就可以轻松找到我们想要的脚本[root@localhost ~]# cd /usr/local/sbin 创建主目录和子目录[root@localhost sbin]# mkdir mon[root@localhost sbin]# cd mon[root@localhost mon]# mkdir mail log bin conf shares[root@localhost mon]# lsbin conf log mail shares把主脚本放大bin目录下[root@localhost mon]# cd bin 创建主脚本123456789101112131415161718192021222324[root@localhost bin]# vim main.sh#!/bin/bash# 是否发送邮件的开关export send=1# 过滤ip地址，关键词eth0可以根据主机网卡情况修改export addr=`/sbin/ifconfig |grep -A1 &quot;eth0: &quot;|awk &apos;/inet/ &#123;print $2&#125;&apos;`dir=`pwd`# 只需要最后一级目录名last_dir=`echo $dir|awk -F&apos;/&apos; &apos;&#123;print $NF&#125;&apos;`# 下面的判断目的是，保证执行脚本的时候，我们在bin目录里，不然监控脚本、邮件和日志很有可能找不到if [ $last_dir == &quot;bin&quot; ] || [ $last_dir == &quot;bin/&quot; ]; then conf_file=&quot;../conf/mon.conf&quot;else echo &quot;you shoud cd bin dir&quot; exitfiexec 1&gt;&gt;../log/mon.log 2&gt;&gt;../log/err.logecho &quot;`date +&quot;%F %T&quot;` load average&quot;/bin/bash ../shares/load.sh#先检查配置文件中是否需要监控502if grep -q &apos;to_mon_502=1&apos; $conf_file; then export log=`grep &apos;logfile=&apos; $conf_file |awk -F &apos;=&apos; &apos;&#123;print $2&#125;&apos; |sed &apos;s/ //g&apos;` /bin/bash ../shares/502.shfi 20.21 告警系统配置文件配置文件的意义主要是为了配合脚本的规范化，通过划分不同功能的文件，来方便查找、更改和控制脚本的各种参数。我们可以在配置文件中统一定义一些开关参数、日志路径、用户名、密码、IP、端口等信息，主要是脚本中需要调用到的一些资源信息。 创建配置文件1234567891011121314151617181920212223[root@localhost bin]# cd /usr/local/sbin/mon[root@localhost mon]# vim conf/mon.conf## to config the options if to monitor## 定义mysql的服务器地址、端口以及user、passwordto_mon_cdb=0 ##是否监控数据库，0 or 1, 默认是0，如果是1则监控，为0不监控db_ip=10.20.3.13db_port=3315db_user=usernamedb_pass=passwd## 监控httpd 如果是1则监控，为0不监控to_mon_httpd=0## 监控php 如果是1则监控，为0不监控to_mon_php_socket=0## 监控http_code_502 需要定义访问日志的路径to_mon_502=1logfile=/data/log/xxx.xxx.com/access.log#定义日子文件路径## 监控request_count 定义日志路径以及域名to_mon_request_count=0req_log=/data/log/www.discuz.net/access.logdomainname=www.discuz.net 20.22 告警系统监控项目监控系统负载1234567891011121314[root@localhost mon]# vim shares/load.sh#! /bin/bash##Writen by yuntai##load=`uptime |awk -F &apos;average:&apos; &apos;&#123;print $2&#125;&apos;|cut -d&apos;,&apos; -f1|sed &apos;s/ //g&apos; |cut -d. -f1`#获取负载值if [ $load -gt 10 ] &amp;&amp; [ $send -eq &quot;1&quot; ]#判断是否超负载，同时判断是否开启负载监控项then echo &quot;$addr `date +%T` load is $load&quot; &gt;../log/load.tmp /bin/bash ../mail/mail.sh yuntai_mail@163.com &quot;$addr\_load:$load&quot; `cat ../log/load.tmp`#超出设定的负载值后，发送邮件fiecho &quot;`date +%T` load is $load&quot;#日志文件（定义在系统配置脚本中） 监控web服务器502错误1234567891011[root@localhost mon]# cd shares/[root@localhost shares]# vim 502.sh#! /bin/bashd=`date -d &quot;-1 min&quot; +%H:%M`#因为监控主脚本一分钟执行一次，所以监控的内容为系统一分钟之前的状态c_502=`grep :$d: $log |grep &apos; 502 &apos;|wc -l`if [ $c_502 -gt 10 ] &amp;&amp; [ $send == 1 ]; then echo &quot;$addr $d 502 count is $c_502&quot;&gt;../log/502.tmp /bin/bash ../mail/mail.sh $addr\_502 $c_502 ../log/502.tmpfiecho &quot;`date +%T` 502 $c_502&quot; 监控磁盘使用率123456789101112131415161718192021[root@localhost shares]# vim disk.sh#! /bin/bash##Writen by yuntai##rm -f ../log/disk.tmpfor r in `df -h |awk -F &apos;[ %]+&apos; &apos;&#123;print $5&#125;&apos;|grep -v Use`##awk -F &apos;[ %]+&apos; 以一个或多个“[ %]”空格和百分号作为分隔符##即，awk可以一次指定多种分隔符（同时生效）do if [ $r -gt 90 ] &amp;&amp; [ $send -eq &quot;1&quot; ]then echo &quot;$addr `date +%T` disk useage is $r&quot; &gt;&gt;../log/disk.tmpfiif [ -f ../log/disk.tmp ]#判断该文件是否存在then df -h &gt;&gt; ../log/disk.tmp /bin/bash ../mail/mail.sh $addr\_disk $r ../log/disk.tmp echo &quot;`date +%T` disk useage is nook&quot;else echo &quot;`date +%T` disk useage is ok&quot;fi]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>shell告警系统脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中的函数、数组]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F20.16-20.18%20shell%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E3%80%81%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[20.16/20.17 shell中的函数、数组函数就是把一段代码整理到了一个小单元中，并给这个小单元起一个名字，当用到这段代码时直接调用这个小单元的名字即可。 格式:1234function f_name() ｛ command &#125;#单词“function”可以省略，直接写函数的名字；函数必须放在脚本的最前面；调用函数的方法，是直接写函数名。 示例112345678910111213141516171819[root@host ~]# cd /shell/#!/bin/bashinput() &#123; echo &quot;The first parameter is $1&quot; echo &quot;The second parameter is $2&quot; echo &quot;The third parameter is $3&quot; echo &quot;The number of parameter is $#&quot; echo &quot;The script&apos;s name is $0&quot;#定义函数&#125;input a b c asd sdg#引用函数[root@host shell]# sh func.shThe first parameter is aThe second parameter is bThe third parameter is cThe number of parameter is 5The script&apos;s name is func.sh 示例2123456789#!/bin/bashsum() &#123; s=$[$1+$2] echo $s&#125;sum 1 2[root@host shell]# sh func2.sh3 示例31234567891011121314151617181920212223242526272829303132#!/bin/baship() &#123; ifconfig|grep -A1 &quot;$e: &quot;|tail -1|awk &apos;&#123;print $2&#125;&apos;&#125;read -p &quot;Please input the eth name: &quot; emyip=`ip $e`echo &quot;$e address is $myip&quot;[root@host shell]# sh func3.sh Please input the eth name: eth0eth0 address is 172.18.192.237#知识点#grep -A1 keyword filename 找出filename中带有keyword的行，输出中除显示该行外，还显示之后的一行(After 1)#grep -B1 keyword filename 找出filename中带有keyword的行，输出中除显示该行外，还显示之前的一行(Before 1)#grep -1 keyword filename 找出filename中带有keyword的行，输出中除显示该行外，还显示之前的一行(After 1)和显示之后的一行(After 1）#awk &apos;&#123;pattern + action&#125;&apos; &#123;filenames&#125;#awk [-F field-separator] &apos;commands&apos; input-file(s)#cat /etc/passwd |awk -F &apos;:&apos; &apos;&#123;print $1&quot;\t&quot;$7&#125;&apos; #加-F &apos;.&apos; 是以.为分隔符，不加默认以空格或者tab为分隔符，$1为被分割的第一个域，$0为全部域，\t是tab键root /bin/bashdaemon /bin/shbin /bin/shsys /bin/sh#cat /etc/passwd |awk -F &apos;:&apos; &apos;BEGIN &#123;print &quot;name,shell&quot;&#125; &#123;print $1&quot;,&quot;$7&#125; END &#123;print &quot;blue,/bin/nosh&quot;&#125;&apos;name,shellroot,/bin/bashdaemon,/bin/shbin,/bin/shsys,/bin/sh....blue,/bin/nosh ###改进例子3加上2个判断，判定输入的是不是系统里面的网卡；判定如果输入的是系统里的网卡，那么到底有没有ip？ 123456789101112131415161718192021这个细节错了，需要重新改进#!/bin/bashwhile read -p &quot;Please input the eth name: &quot; e if [ -z ifconfig|grep -w &quot;$e&quot; ] then echo &quot;The eth you typed is none, please type a right one&quot; continue if [ -z ifconfig|grep -A1 &quot;$e: &quot;|tail -1|awk &apos;&#123;print $2&#125;&apos; ] then echo &quot;The eth has no ip&quot; fi else break fidoneip() &#123; ifconfig|grep -A1 &quot;$e: &quot;|tail -1|awk &apos;&#123;print $2&#125;&apos;&#125;myip=`ip $e`echo &quot;$e address is $myip&quot; 20.18 shell中的数组平时工作中，很少用到过数组，到那时这个概念还是要弄明白。 定义数组12345678910111213141516[root@host shell]# vim shuzu.sh#!/bin/basha=(1 2 3 4 5)echo $aecho $&#123;#a[@]&#125; #获取数组的元素个数 echo $&#123;a[2]&#125; #读取第三个元素，数组从0开始，a[0]是第一个元素echo $&#123;a[*]&#125; #等同于 $&#123;a[@]&#125; 显示整个数组的元素[root@host shell]# sh shuzu.sh 1531 2 3 4 5 数组赋值直接通过 数组名[下标] 就可以对其进行引用赋值，如果下标不存在，那么自动添加新一个数组元素进去。 123456789101112131415161718192021[root@host shell]# vim shuzu.sh#!/bin/basha=(1 2 3 4 5)echo $aecho $&#123;#a[@]&#125;echo $&#123;a[2]&#125;echo $&#123;a[*]&#125;a[1]=100echo $&#123;a[@]&#125;a[5]=100echo $&#123;a[@]&#125; [root@host shell]# sh shuzu.sh 1531 2 3 4 51 100 3 4 51 100 3 4 5 100 数组的删除uset a; unset a[1] 1234567891011121314[root@host shell]# vim shuzudelete.sh#!/bin/basha=(1 2 3 4 5)unset aecho $&#123;a[*]&#125; a=(1 2 3 4 5)unset a[1]echo $&#123;a[*]&#125; echo $&#123;#a[*]&#125; [root@host shell]# sh shuzudelete.sh 1 3 4 54 数组的分片.在某些特殊的复杂的情况下，会运用到 123456# a=(`seq 1 5`)# echo $&#123;a[@]:0:3&#125;1 2 3# echo $&#123;a[@]:1:4&#125;2 3 4 5 数组替换，可以echo替换，也可以直接赋值12345678910# a=(1 2 3 4 5)#echo $&#123;a[@/3/100]&#125;1 2 100 4 5#echo $&#123;a[@]&#125;1 2 3 4 5#a=($&#123;a[@]/3/100&#125;)#echo $&#123;a[@]&#125;1 2 100 4 5]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>函数</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本中的if逻辑判断、文件目录属性判断、if特殊用法、case判断]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F20.5%20-%2020.9%20shell%E8%84%9A%E6%9C%AC%E4%B8%AD%E7%9A%84if%E9%80%BB%E8%BE%91%E5%88%A4%E6%96%AD%E3%80%81%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E5%B1%9E%E6%80%A7%E5%88%A4%E6%96%AD%E3%80%81if%E7%89%B9%E6%AE%8A%E7%94%A8%E6%B3%95%E3%80%81case%E5%88%A4%E6%96%AD%2F</url>
    <content type="text"><![CDATA[20.5 shell脚本中的if逻辑判断Shell脚本中，充满着各种逻辑判断，是脚本中必备的。 逻辑判断表达式：123456789101112-gt (&gt;); 大于 great than-lt(&lt;); 小于 less than-ge(&gt;=); 大于或等于 -le(&lt;=); 小于或等于-eq(==); 等于 equal-ne(!=) 不等于 not equa- - -例如if [ $a -gt $b ]; if [ $a -lt 5 ]; if [ $b -eq 10 ]等 if逻辑判断格式12345678910格式1：if 条件 ; then 语句; fi格式2：if 条件; then 语句; else 语句; fi格式3：if …; then … ;elif …; then …; else …; fi- - -可以使用 &amp;&amp; || 结合多个条件条件A&amp;&amp;条件B：A并且B条件A||条件B：A或者Bif [ $a -gt 5 ] &amp;&amp; [ $a -lt 10 ]; thenif [ $b -gt 5 ] || [ $b -lt 3 ]; then if逻辑判断例子格式1：if 条件 ; then 语句; fi 1234567#!/bin/basha=5if [ $a -gt 3 ]#注意[]里面有大量空格then echo &quot;ok&quot;fi 格式2：if 条件; then 语句; else 语句; fi 12345678#!/bin/basha=5if [ $a -gt 3 ]then echo &quot;ok&quot;else echo &quot;nook&quot;fi 格式3：if …; then … ;elif …; then …; else …; fi 123456789101112#!/bin/basha=3if [ $a -gt 4 ]then echo &quot;&gt;1&quot;elif [ $a -gt 6 ]#注意elif可以嵌套多次的then echo &quot;&lt;6 &amp;&amp; &gt;1&quot;else echo &quot;nook&quot;fi 20.6 文件目录属性判断在shell中通常要和文件或者目录打交道，那么对于他们的属性判断十分重要。 文件目录属性判断123456[ -f file ]判断是否是普通文件，且存在 [ -f /usr/bin/grep ][ -d file ] 判断是否是目录，且存在 [ -d /tmp/mydir ][ -e file ] 判断文件或目录是否存在 [ -e /var/log/syslog ][ -r file ] 判断文件是否可读 [ -r /var/log/syslog ][ -w file ] 判断文件是否可写 [ -w /var/mytmp.txt ][ -x file ] 判断文件是否可执行 [ -x /usr/bin/grep ] 例子1234567#!/bin/bashf=&quot;/tmp/zhouquniclinux&quot;if [ -e $f ]then echo $f existelse touch $f 上例可以简化为 123456#!/bin/bash[ -e $f ] || touch $f[ ! -e $f ] || echo $f exist # || 当前面的执行成功后再执行后面的命令# 如果是&amp;&amp;，则不管前面的命令是否执行成功，都会执行后面的命令# ! 表示取反 20.7 if特殊用法if特殊用法123456if [ -z &quot;$a&quot; ] 这个表示当变量a的值为空时会怎么样if [ -n &quot;$a&quot; ] 表示当变量a的值不为空if grep -q &apos;123&apos; 1.txt; then 表示如果1.txt中含有&apos;123&apos;的行时会怎么样if [ ! -e file ]; then 表示文件不存在时会怎么样if (($a&lt;1)); then …等同于 if [ $a -lt 1 ]; then… [ ] 中不能使用&lt;,&gt;,==,!=,&gt;=,&lt;=这样的符号 例子if [ -z “$a” ] 这个表示当变量a的值为空时会怎么样 12345678910111213141516171819202122232425262728293031323334#!/bin/bashn=&apos;wc -l /tmp/lalala&apos;if [ $n -lt 100 ]then echo &quot;line num less than 100&quot;fi# 如果/tmp/lalala文件为空，或者被删除的话，脚本就会运行出错，出现bug应该加上一个判断条件#!/bin/bashn=&apos;wc -l /tmp/lalala&apos;if [ $n -z &quot;$n&quot; ]# [ $n -z &quot;$n&quot; ] = [ ! $n -n &quot;$n&quot; ]，-z 和 -n 是一对相反的条件then echo &quot;error&quot; exitelif [ $n -lt 100 ]then echo &quot;line num less than 100&quot;fi或者#!/bin/bashif [ ! -f /tmp/lalala ]then echo &quot;/tmp/lalala is not exist&quot; exitfin=&apos;wc -l /tmp/lalala&apos;if [ $n -lt 100 ]then echo &quot;line num less than 100&quot;fi if [ -n “$a” ] 表示当变量a的值不为空，也可以判断文件，判断文件时可以不加双引号 12345678910if [ -n 01.sh ]; then echo &quot;ok&quot;; fi另外#!/bin/bashif [ -n &quot;$b&quot; ]then echo $belse echo &quot;b is null&quot;fi 一条命令也可以作为判断条件。判断user1用户是否存在 12if grep -wq &apos;user1&apos; /etc/passwd; then echo &quot;user1 is exist&quot;; else echo &quot;user1 is not exist&quot;; fi#grep -w 显示过滤信息，加-q可以不显示过滤信息 20.8/20.9 case判断case判断格式12345678910111213case 变量名 in value1) commond1 ;; value2) commod2 ;; value3) commod3 ;;esac``` ### 在case中，可以在条件中使用“|”，表示或的意思，如： 2|3) commond ;; 1### 例子: 输入一个同学的分数，判断成绩是否及格，优秀。 [root@host shell]# vim case1.sh #!/bin/bashread -p “Please input a number: “ n read -p 是读取用户的输入数据，定义到变量里面if [ -z “$n” ]then echo “Please input a number.” exit 1 #“exit 1”表示非正常运行导致退出程序 #退出之后，echo $?会返回1值，表示程序退出是因为出错了fi n1=echo $n|sed &#39;s/[0-9]//g&#39; #判断用户输入的字符是否为纯数字 #如果是数字，则将其替换为空，赋值给$n1if [ -n “$n1” ]thenecho “Please input a number.”exit 1 #判断$n1不为空时（即$n不是纯数字）再次提示用户输入数字并退出fi #如果用户输入的是纯数字则执行以下命令：if [ $n -lt 60 ] &amp;&amp; [ $n -ge 0 ]then tag=1elif [ $n -ge 60 ] &amp;&amp; [ $n -lt 80 ]then tag=2elif [ $n -ge 80 ] &amp;&amp; [ $n -lt 90 ]then tag=3elif [ $n -ge 90 ] &amp;&amp; [ $n -le 100 ]then tag=4else tag=0fi #tag的作用是为判断条件设定标签，方便后面引用case $tag in 1) echo “not ok” ;; 2) echo “ok” ;; 3) echo “ook” ;; 4) echo “oook” ;; *) echo “The number range is 0-100.” ;;esac 12### 运行结果 [root@host shell]# sh case1.shPlease input a number: 45not ok[root@host shell]# sh case1.shPlease input a number: 66ok[root@host shell]# sh case1.shPlease input a number: 80ook[root@host shell]# sh case1.shPlease input a number: 99oook[root@host shell]# sh case1.shPlease input a number: xxxPlease input a number.[root@host shell]# echo $?1[root@host shell]# sh case1.shPlease input a number: 120The number range is 0-100.[root@host shell]# echo $?0```]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>if</tag>
        <tag>case</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[for循环、while循环、break跳出循环、continue结束本次循环、exit退出整个脚本]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F20.10-20.15%20for%E5%BE%AA%E7%8E%AF%E3%80%81while%E5%BE%AA%E7%8E%AF%E3%80%81break%E8%B7%B3%E5%87%BA%E5%BE%AA%E7%8E%AF%E3%80%81continue%E7%BB%93%E6%9D%9F%E6%9C%AC%E6%AC%A1%E5%BE%AA%E7%8E%AF%E3%80%81exit%E9%80%80%E5%87%BA%E6%95%B4%E4%B8%AA%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[20.10 for循环语法：1for 变量名 in 条件; do …; done 案例1计算1到100的和 1234567891011121314151617181920212223242526272829303132#!/bin/bashsum=0for i in `seq 1 100`do echo &quot;$sum+$i&quot; sum=$[$sum+$i]doneecho $sum[root@host shell]# sh -x for1.sh + sum=0++ seq 1 100+ for i in &apos;`seq 1 100`&apos;+ echo 0+10+1+ sum=1+ for i in &apos;`seq 1 100`&apos;+ echo 1+21+2+ sum=3... ...+ sum=4851+ for i in &apos;`seq 1 100`&apos;+ echo 4851+994851+99+ sum=4950+ for i in &apos;`seq 1 100`&apos;+ echo 4950+1004950+100+ sum=5050+ echo 50505050 案例2文件列表循环 123456789#!/bin/bashcd /etc/for a in `ls /etc/`do if [ -d $a ] then ls -d $a fidone for循环的分隔符for默认情况下会把空格或换行符（回车）作为分隔符 1234567891011121314[root@host /]# mkdir yuntai/[root@host /]# cd yuntai[root@host yuntai]# touch 1 2 3\ 4.txt[root@host yuntai]# ls -ltotal 0-rw-r--r-- 1 root root 0 Oct 19 09:14 1-rw-r--r-- 1 root root 0 Oct 19 09:14 2-rw-r--r-- 1 root root 0 Oct 19 09:14 3 4.txt #新建了一个名称中有空格的文件[root@host yuntai]# for i in `ls ./`; do echo $i ; done1234.txt 20.11/20.12 while循环语法1while 条件; do … ; done 案例1当系统负载大于10的时候，发送邮件，每隔30秒执行一次。 1234567891011#!/bin/bashwhile :#后面加冒号表示死循环的意思，也可以换成ture或者1do load=`w|head -1|awk -F &apos;load average: &apos; &apos;&#123;print $2&#125;&apos;|cut -d. -f1` if [ $load -gt 10 ] then top|mail -s &quot;load is high: $load&quot; xxxx@qq.com fi sleep 30done 案例2一种交互模式，当用户输入对应内容，检测该字符是否符合条件，如：空、非数字、数字。分别对字符做出判断，然后做出不同的回应。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/bin/bashwhile :do read -p &quot;Please input a number: &quot; n if [ -z &quot;$n&quot; ] then echo &quot;you need input sth.&quot; continue fi n1=`echo $n|sed &apos;s/[0-9]//g&apos;` if [ -n &quot;$n1&quot; ] then echo &quot;you just only input numbers.&quot; continue fi break#continue: 中断本次while循环后重新开始；#break: 表示跳出本层循环，即该while循环结束doneecho $n[root@host shell]# sh -x while2.sh + :+ read -p &apos;Please input a number: &apos; nPlease input a number: + &apos;[&apos; -z &apos;&apos; &apos;]&apos;+ echo &apos;you need input sth.&apos;you need input sth.+ continue+ :+ read -p &apos;Please input a number: &apos; nPlease input a number: z+ &apos;[&apos; -z z &apos;]&apos;++ sed &apos;s/[0-9]//g&apos;++ echo z+ n1=z+ &apos;[&apos; -n z &apos;]&apos;+ echo &apos;you just only input numbers.&apos;you just only input numbers.+ continue+ :+ read -p &apos;Please input a number: &apos; nPlease input a number: 3+ &apos;[&apos; -z 3 &apos;]&apos;++ sed &apos;s/[0-9]//g&apos;++ echo 3+ n1=+ &apos;[&apos; -n &apos;&apos; &apos;]&apos;+ break+ echo 33 20.13 break跳出循环用于跳出循环语句 12345678910111213141516171819202122232425262728293031323334#!/bin/bashfor i in `seq 1 5`do echo $i if [ $i == 3 ]# 数字最好用 -eq，如果是字符串，那么最好用 ==，这里用-eq更好 then break fi echo $idoneecho aaaaaaa[root@host shell]# sh -x break1.sh ++ seq 1 5+ for i in &apos;`seq 1 5`&apos;+ echo 11+ &apos;[&apos; 1 -eq 3 &apos;]&apos;+ echo 11+ for i in &apos;`seq 1 5`&apos;+ echo 22+ &apos;[&apos; 2 -eq 3 &apos;]&apos;+ echo 22+ for i in &apos;`seq 1 5`&apos;+ echo 33+ &apos;[&apos; 3 -eq 3 &apos;]&apos;+ break+ echo aaaaaaaaaaaaaa 20.14 continue结束本次循环用于结束本次循环，直接进入下次循环语句 1234567891011121314151617181920212223242526#!/bin/bashfor i in `seq 1 5`do echo $i if [ $i == 3 ] then continue#忽略continue之下的代码，直接进行下一次循环 fi echo $idoneecho $iecho aaaaaaa[root@host shell]# sh continue1.sh 11223 44555aaaaaaa 20.15 exit退出整个脚本直接退出整个脚本 123456789101112131415161718#!/bin/bashfor i in `seq 1 5`do echo $i if [ $i == 3 ] then exit fi echo $idoneecho aaaaaaa[root@host shell]# sh exit1.sh 11223 扩展 select用法select也是循环的一种，它比较适合用在用户选择的情况下。比如，我们有一个这样的需求，运行脚本后，让用户去选择数字，选择1，会运行w命令，选择2运行top命令，选择3运行free命令，选择4退出。脚本这样实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/bashecho &quot;Please chose a number, 1: run w, 2: run top, 3: run free, 4: quit&quot;echoselect command in w top free quitdo case $command in w) w ;; top) top ;; free) free ;; quit) exit ;; *) echo &quot;Please input a number:(1-4).&quot; ;; esacdone执行结果如下：sh select.shPlease chose a number, 1: run w, 2: run top, 3: run free, 4: quit1) w2) top3) free4) quit#? 116:03:40 up 32 days, 2:42, 1 user, load average: 0.01, 0.08, 0.08USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 61.135.172.68 15:33 0.00s 0.02s 0.00s sh select.sh#? 3 total used free shared buffers cachedMem: 1020328 943736 76592 0 86840 263624-/+ buffers/cache: 593272 427056Swap: 2097144 44196 2052948#? 我们发现，select会默认把序号对应的命令列出来，每次输入一个数字，则会执行相应的命令，命令执行完后并不会退出脚本。它还会继续让我们再次输如序号。序号前面的提示符，我们也是可以修改的，利用变量PS3即可，再次修改脚本如下： 1234567891011121314151617181920212223#!/bin/bashPS3=&quot;Please select a number: &quot;echo &quot;Please chose a number, 1: run w, 2: run top, 3: run free, 4: quit&quot;echoselect command in w top free quitdo case $command in w) w ;; top) top ;; free) free ;; quit) exit ;; *) echo &quot;Please input a number:(1-4).&quot; esacdone 如果想要脚本每次输入一个序号后就自动退出，则需要再次更改脚本如下： 1234567891011121314151617181920212223#!/bin/bashPS3=&quot;Please select a number: &quot;echo &quot;Please chose a number, 1: run w, 2: run top, 3: run free, 4: quit&quot;echoselect command in w top free quitdo case $command in w) w;exit ;; top) top;exit ;; free) free;exit ;; quit) exit ;; *) echo &quot;Please input a number:(1-4).&quot;;exit esacdone]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>for</tag>
        <tag>break</tag>
        <tag>continue</tag>
        <tag>exit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本结构和执行、变量、date命令]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F20.1%20-%2020.4%20shell%E8%84%9A%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E6%89%A7%E8%A1%8C%E3%80%81%E5%8F%98%E9%87%8F%E3%80%81date%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[#20.1 shell脚本介绍 shell是一种脚本语言 可以使用逻辑判断、循环等语法 可以自定义函数 shell是系统命令的集合 shell脚本可以实现自动化运维，能大大增加我们的运维效率 #20.2 shell脚本结构和执行 开头需要加#!/bin/bash，告诉系统该脚本是要以bin/bash文件解释器执行 以#开头的行作为解释说明 脚本的名字以.sh结尾，用于区分这是一个shell脚本 执行方法有两种 chmod +x 1.sh; ./1.sh bash 1.sh 查看脚本执行过程 bash -x 1.sh 查看脚本是否语法错误 bash -n 1.sh #20.3 date命令用法 很多shell脚本里面需要打印不同格式的时间或日期，以及要根据时间和日期执行操作。延时通常用于脚本执行过程中提供一段等待的时间。日期可以以多种格式去打印，也可以使用命令设置固定的格式。在类UNIX系统中，日期被存储为一个整数，其大小为自世界标准时间（UTC）1970年1月1日0时0分0秒起流逝的秒数。 date命令是显示或设置系统时间与日期。 12[root@host ~]# date //显示当前时区的当前时间Fri Sep 15 06:08:45 CST 2017 ##语法date(选项)(参数) ##选项-d&lt;字符串&gt;：显示字符串所指的日期与时间。字符串前后必须加上双引号；-s&lt;字符串&gt;：根据字符串来设置日期与时间。字符串前后必须加上双引号；-u：显示GMT；–help：在线帮助；–version：显示版本信息。 ##参数&lt;+时间日期格式&gt;：指定显示时使用的日期时间格式。 ##用法 123456789- date +%Y-%m-%d, date +%y-%m-%d 年月日- date +%H:%M:%S = date +%T 时间- date +%s 时间戳- date -d @1504620492- date -d &quot;+1day&quot; 一天后- date -d &quot;-1 day&quot; 一天前- date -d &quot;-1 month&quot; 一月前- date -d &quot;-1 min&quot; 一分钟前- date +%w, date +%W 星期 例子 查看系统日历 12345678[root@host ~]# cal September 2017 Su Mo Tu We Th Fr Sa 1 23 4 5 6 7 8 910 11 12 13 14 15 1617 18 19 20 21 22 2324 25 26 27 28 29 30 显示年份 1234[root@host ~]# date +%Y //以四位数显示年份2017[root@host ~]# date +%y //以两位数显示年份17 分别显示：年、月、日、时、分、秒、星期 12[root@host ~]# date &quot;+%Y-%m-%d %H:%M:%S %w&quot;2017-09-15 06:15:44 5 显示年月日 123456[root@host ~]# date +%D09/15/17[root@host ~]# date +%Y%m%d20170915[root@host ~]# date +%F2017-09-15 其他时间显示 1234567891011121314[root@host ~]# date +%h //显示现在的月份Sep[root@host ~]# date +%W //显示今年的第几周37[root@host ~]# date +%T //显示当前时间几点几分几秒06:21:34[root@host ~]# date +%s //显示时间戳，表示距离 从1970年1月1日00:00:00到现在 经历的秒数1505427580#时间戳换算[root@host ~]# date +%s -d &quot;2017-09-15 12:00:00&quot;1505448000[root@host ~]# date -d @1505448000Fri Sep 15 12:00:00 CST 2017 ##打印指定日期&amp;时间工作中，有时候需要使用N天前的日期或时间格式是date -d &quot;1 day&quot; +%d 12345678[root@host ~]# date +%F //今天的日期2017-09-15[root@host ~]# date -d &quot;-2 day&quot; +%d //两天前多少号13[root@host ~]# date -d &quot;1 day ago&quot; +&quot;%Y-%m-%d&quot; （=date -d &quot;1 day ago&quot; +%F） //1天前的日期2017-09-14[root@host ~]# date -d &quot;-1 year -1 month -1 day&quot; +%Y-%m-%d //前一年一个月一天的日期2016-08-14 #20.4 shell脚本中的变量 当脚本中使用某个字符串较频繁并且字符串长度很长时就应该使用变量代替 使用条件语句时，常使用变量 if [ $a -gt 1 ]; then … ; fi 引用某个命令的结果时，用变量替代 n=wc -l 1.txt 写和用户交互的脚本时，变量也是必不可少的 read -p “Input a number: “ n; echo $n 如果没写这个n，可以直接使用$REPLY 内置变量 $0, $1, $2… $0表示脚本本身，$1 第一个参数，$2 第二个 …. $#表示参数个数 数学运算a=1;b=2; c=$(($a+$b))或者$[$a+$b]]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>date</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix添加自定义监控项目、配置邮件告警、测试告警]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F19.12-19.16%20Zabbix%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E9%A1%B9%E7%9B%AE%E3%80%81%E9%85%8D%E7%BD%AE%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6%E3%80%81%E6%B5%8B%E8%AF%95%E5%91%8A%E8%AD%A6%E3%80%81%E4%B8%8D%E5%8F%91%E9%82%AE%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[19.12 添加自定义监控项目该配置的用途是监控模板中没有的监控项目。 1 需求监控某台web的80端口连接数，并出图。步骤：1） zabbix监控中心创建监控项目2） 针对该监控项目以图形展现 2 配置客户端80端口的监控脚本12345678[root@yt-02 ~]# vim /usr/local/sbin/estab.sh#!/bin/bash# 获取80端口并发连接数netstat -ant |grep &apos;:80 &apos; |grep -c ESTABLISHED# 注意：80后面跟一个空格，保证匹配更精确，如果不加空格，会把8080端口同时过滤出来。更改权限：[root@yt-02 ~]# chmod 755 /usr/local/sbin/estab.sh 3 打开zabbix客户端的自定义脚本开关：12345678910111213141516171819[root@yt-01 ~]# vim /etc/zabbix/zabbix_agentd.conf# 搜索 /UnsafeUserParameters和UserParameter……UnsafeUserParameters=1 #表示使用自定义脚本# 自定义监控项的key（监控web端“键值”）为my.estab.count，后面的[*]里面写的是脚本参数 UserParameter=my.estab.count[*],/usr/local/sbin/estab.sh# 如果没有参数则可以省略，脚本为/usr/local/sbin/estab.sh或者找到 # Include=/usr/local/etc/zabbix_agentd.conf.d/ 在下面添加读取用户参数的文件路径Include=/usr/local/zabbix/conf/zabbix_agentd/然后在/usr/local/zabbix/conf/zabbix_agentd/下创建userparameter.conf 文件，编辑此文件vi /usr/local/zabbix/conf/zabbix_agentd/tomcat.conf添加想要监控的项，比如UserParameter=tomcat,/home/zabbix/monitor/java.sh多个自定义监控项都可写在这个文件里重启zabbix-agent服务[root@z2 ~]# systemctl restart zabbix-agent 4 服务端使用zabbix自带命令测试该脚本1234567[root@yt-01 ~]# zabbix_get -s 192.168.122.131 -p 10050 -k &apos;my.estab.count&apos;0-s：源地址-p： 端口-k： 键值如上显示0即为没有任何连接。 出现的问题的话： 关闭iptables 关闭selinux 检查脚本权限 5 配置web端参数创建监控项配置 → 主机 → 监控项 → 创建监控项 创建图形“配置”→“主机” →“图形” → 创建图形” 添加该项目后，到“监测中” → “最新数据”查看刚添加的项目是否有数据出现 有了数据就可以添加图形了。 创建触发器19.13/19.14 配置邮件告警配置告警是目前绝大多数企业必须要有的一个状态，遇到问题第一时间获得警告大大提升了运维的高效性，如果没有配置任何告警，等待客户反应，这是一个非常不明智的选择。 1 选择邮箱建议配置一个163邮箱、移动139邮箱或者QQ邮箱，然后邮箱绑定微信，在遇到故障的第一时间就可以收到告警邮件。以163为例子，记得开启授权码和POP3/SMTP/IMAP服务。 2 编辑zabbix报警媒介管理 → 报警媒介类型 → 创建媒体类型（不建议用自带的脚本，不好用）脚本名称一定要用自己自定义的！！！ 脚本参数（不然不可以发邮件）： 123&#123;ALERT.SENDTO&#125; //发给谁&#123;ALERT.SUBJECT&#125; //主题&#123;ALERT.MESSAGE&#125; //邮件内容 3 写一个报警的邮件脚本服务端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253查看报警脚本保存路径：[root@yt-01 ~]# vim /etc/zabbix/zabbix_server.conf脚本位置 AlertScriptsPath=/usr/lib/zabbix/alertscripts创建报警脚本mail.py：[root@z1 ~]# cd /usr/lib/zabbix/alertscripts[root@z1 alertscripts]# vim mail.py#!/usr/bin/env python#-*- coding: UTF-8 -*-import os,sysreload(sys)sys.setdefaultencoding(&apos;utf8&apos;)import getoptimport smtplibfrom email.MIMEText import MIMETextfrom email.MIMEMultipart import MIMEMultipartfrom subprocess import *def sendqqmail(username,password,mailfrom,mailto,subject,content): gserver = &apos;smtp.163.com&apos; # smtp服务器 gport = 25 # 默认端口是25 try: msg = MIMEText(unicode(content).encode(&apos;utf-8&apos;)) msg[&apos;from&apos;] = mailfrom msg[&apos;to&apos;] = mailto msg[&apos;Reply-To&apos;] = mailfrom msg[&apos;Subject&apos;] = subject smtp = smtplib.SMTP(gserver, gport) smtp.set_debuglevel(0) smtp.ehlo() smtp.login(username,password) smtp.sendmail(mailfrom, mailto, msg.as_string()) smtp.close() except Exception,err: print &quot;Send mail failed. Error: %s&quot; % errdef main(): to=sys.argv[1] subject=sys.argv[2] content=sys.argv[3]##定义163或者qq邮箱的账号和授权码，你需要修改成你自己的账号和密码（请不要把真实的用户名和密码放到网上公开，否则你会死的很惨） sendqqmail(&apos;zhouqunic@163.com&apos;,&apos;zhouqun3&apos;,&apos;zhouqunic@163.com&apos;,to,subject,content)if __name__ == &quot;__main__&quot;: main()#####脚本使用说明#######1. 首先定义好脚本中的邮箱账号和密码#2. 脚本执行命令为：python mail.py 目标邮箱 &quot;邮件主题&quot; &quot;邮件内容&quot;更改脚本权限[root@yt-01 alertscripts]# chmod 755 /usr/lib/zabbix/alertscripts/mail.py测试能否发邮件[root@yt-01 alertscripts]# python mail.py zhouqunic@163.com &quot;zhuti&quot; &quot;neirong&quot;# 用邮箱自己给自己发送邮件，保证其不出其他故障 发送成功！ 4 配置用户创建一个接受告警邮件的用户，“管理”，“用户”，“创建用户”，“报警媒介”，类型选择“baojing”，注意用户的权限，如果没有需要到用户组去设置权限 5 配置报警媒介打开用户yuntai——报警媒介——添加报警媒介——更新 6 配置权限需要到用户所在的“用户群组”更改用户的权限 7 配置动作设置触发器被触发后所要执行的的操作！“配置”——“动作”——“创建动作” 19.15 测试告警配置 → 主机 → 触发器 → 创建触发器 条件改成，并发数小于5，咱们的虚拟机压根就没有任何人去访问，所以轻轻松松报警。 反应很快： 把触发器改回 “&gt;200”，很快就好了，收到恢复邮件 邮件乱码问题解决如上图，邮件中文都是方块的问题，有2个方案 触发器和监控项都改为英文 更新mail.py告警邮件脚本123456789101112131415161718192021222324252627#!/usr/bin/python#coding:utf-8import smtplibfrom email.mime.text import MIMETextimport sysmail_host = &apos;smtp.163.com&apos;mail_user = &apos;abcdefg@xx.com&apos;mail_pass = &apos;1111111&apos;mail_postfix = &apos;163.com&apos;def send_mail(to_list,subject,content): me = &quot;zabbix 监控告警平台&quot;+&quot;&lt;&quot;+mail_user+&quot;@&quot;+mail_postfix+&quot;&gt;&quot; msg = MIMEText(content, &apos;plain&apos;, &apos;utf-8&apos;) msg[&apos;Subject&apos;] = subject msg[&apos;From&apos;] = me msg[&apos;to&apos;] = to_list try: s = smtplib.SMTP() s.connect(mail_host) s.login(mail_user,mail_pass) s.sendmail(me,to_list,msg.as_string()) s.close() return True except Exception,e: print str(e) return Falseif __name__ == &quot;__main__&quot;: send_mail(sys.argv[1], sys.argv[2], sys.argv[3])]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix主动模式和被动模式、添加监控主机、添加自定义模板、处理图形中的乱码、自动发现]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F19.7-19.11%20Zabbix%E4%B8%BB%E5%8A%A8%E6%A8%A1%E5%BC%8F%E5%92%8C%E8%A2%AB%E5%8A%A8%E6%A8%A1%E5%BC%8F%E3%80%81%E6%B7%BB%E5%8A%A0%E7%9B%91%E6%8E%A7%E4%B8%BB%E6%9C%BA%E3%80%81%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E6%9D%BF%E3%80%81%E5%A4%84%E7%90%86%E5%9B%BE%E5%BD%A2%E4%B8%AD%E7%9A%84%E4%B9%B1%E7%A0%81%E3%80%81%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[19.7 主动模式和被动模式主动模式和被动模式所针对的对象是客户端。意思是客户端主动向服务端上报数据和由服务端到客户端采集数据。数据的提交时间在监控中心设置。 配置建议 当客户端数量非常多时，建议使用主动模式，这样可以降低服务端的压力。 当服务端有公网IP，客户端只有内网IP但是可以连接外网（使用iptables的nat表规则实现），这种场景适合使用主动模式 如果server量不是太多的话，两种模式都可。 19.8 添加监控主机 主机群组：在此先创建主机群组，然后再添加要监控的机器到已有群组中。这样做的好处是，在不同的主机群组设置不同监控规则，然后可以把想要使用同样规则的主机添加到指定群组进行管理，避免为每台主机去配置规则。 模板：预设的监控项目集合（监控规则末班） 主机：在监控中的所有机器 1 添加主机组1234567891011121314151617配置 → 主机群组 → 创建主机群组（添加主机前先要创建组）组名：yt-test → 添加即可。配置 → 主机 → 创建主机主机名称：yt-02（在被监控主机内有配置Hostname，此处填写这个）可见名称：yt-02（与上面保持一致即可）添加刚刚创建的组IP 地址：192.168.122.131（客户端的IP）DNS名称：目前用不到，不用写，如果该IP有对应的域名，则需要添加到“DNS名称”中端口：10050（默认，或填写自定义的）第二个选项 模板 稍后讲，其他不用管点击最后的 添加 即可！ 2 参数解析 应用集：监控项目的组集合 监控项：所有的监控项目 触发器：针对某一个监控项的监控规则（不填级别的规则颜色不同，会显示在首页主机状态中） 图形：根据监控历史数据绘制的图标 自动发现规则：zabbix自动监控系统文件，磁盘分区，网卡流量等，该部分自定义比较繁琐，所以使用自动发现规则 Web场景：在此可设置对主机上的某个站点进行监控，监控站点的任何非200页面的状态，并报警。 19.9 添加自定义模板在“模板”中自定义监控规则，然后应用到监控主机中，方便个性化管理。在模板里面我们可以增加很多自定义监控的项目，然后再次把模板链接到一个组内，当我们在组内增加了新的客户端就不需要我们再次去配置监控项目，直接加入组就ok了。 1 创建自定义模版1234配置 → 模板 → 创建模版模板名称：yuntai（自定义即可）群组：Templetes简单设置，添加即可。 2 快速的添加监控模板12341. 选择预设的一个模板（Template OS Linux）2. 点击“监控” → 选择一些我们需要的监控项 → 点击最下面的“复制” → 选择模板 → 找到刚刚创建的模板zhdy_monitor → 再次点击最下面的 “复制” 即可。3. 使用同样的方法，把其它的监控项完成。但是我们发现，其它选项都可以按照之前的步骤去操作，但是“自动发现”选项却没有“复制”这个选项。 3 复制其它模板的“自动发现”选项 方案1 12导出有“自动发现”选项,模版的配置文件xxx.xml。用编辑器打开，删除其他多余的选项代码，再导入到自定义的模版里面# 工作量比较大，也容易出错，不推荐 方案2 1把已有的模版链接到自定义模版上，然后 取消链接，更新规则后，删除 不需要的监控项，删除 多余的应用集，就可以保留“自动发现”选项 19.10 处理图形中的乱码 点击刚刚创建的主机 → 点击上面的选项“模板” → “链接指示器” → “添加” → “更新” → 然后我们就会看到模板的中的监控项全部复制到了新添加的主机中。 点击“图形” → 点击任意一个 → “预览” → 我们会发现其中出现了乱码： 这种情况是因为我们虚拟主机中没有能够解析这个字体的字体库。如何能够解决问题呢？这种情况其实很容易去处理，直接copy windows中的一个字体，放在linux中指定的路径即可。 1234567891011121314151617181920[root@yt-01 ~]# vim /usr/share/zabbix/include/defines.inc.php# 搜索ZBX_FONTPATH# 它定义的路径是“fonts”，它是一个相对路径# 绝对路径为/usr/share/zabbix/fonts# 而字体文件为“ZBX_GRAPH_FONT_NAME”所定义的“graphfont”# 它是一个文件，绝对路径为 /usr/share/zabbix/fonts/graphfont 先把windows下面的字体上传到服务器，然后再次mv到/usr/share/zabbix/fonts/lrwxrwxrwx 1 root root 33 4月 2 11:12 graphfont.ttf -&gt; /etc/alternatives/zabbix-web-font[root@yt-01 ~]# mv STLITI.TTF /usr/share/zabbix/fonts/然后把原有的字体改个名字，再次把我们上传的字体做个软链接即可。 [root@yt-01 ~]# cd /usr/share/zabbix/fonts/[root@yt-01 fonts]# lsgraphfont.ttf STLITI.TTF[root@yt-01 fonts]# mv graphfont.ttf graphfont.ttf.bak[root@yt-01 fonts]# ln -s STLITI.TTF graphfont.ttfzabbix web页刷新，就可以看不到乱码了 19.11 自动发现点击“自动发现规则” → 按理来说，我们已经配置了自动发现规则，为什么在图形中没有看到任何图表显示呢？ 其原因是 我们虽然配置了，但是自动发现规则是1小时候才可以显示，我们可以手动编辑调节“数据更新间隔”为10分钟或者为了让其快速显示，也可以临时设置1分钟，当出来图表再次把更新时间间隔调节为600秒即可。 点击“更新”即可。 至于说压力问题，只要不是监控太多的客户端，这个值还是可以的。 然后（重启服务器与客户端的zabbix服务 1234server端：# systemctl restart zabbix-serverclient端：# systemctl restart zabbix-agent 然后我们再次回到“图形”，我们就发现了被监控的网卡。如果需要修改模板内的状态显示风格或者颜色，可以进入“模板” → “自定义的模板” → “自动发现” → “点击监控的名称即可进去修改”。 扩展zabbix监控交换机（思科） http://tryrus.blog.51cto.com/10914693/1789847zabbix远程执行命令 http://www.ywnds.com/?p=6610zabbix分布式部署 http://sfzhang88.blog.51cto.com/4995876/1364399zabbix监控tomcat（版本有点老，大家只需要参考步骤，不能照搬） http://www.jianshu.com/p/e3825a885a1b http://www.fblinux.com/?p=616]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux监控平台介绍、zabbix监控介绍、安装、忘记密码怎么办]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F19.1-19.6%20Linux%E7%9B%91%E6%8E%A7%E5%B9%B3%E5%8F%B0%E4%BB%8B%E7%BB%8D%E3%80%81zabbix%E7%9B%91%E6%8E%A7%E4%BB%8B%E7%BB%8D%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E5%BF%98%E8%AE%B0%E5%AF%86%E7%A0%81%E6%80%8E%E4%B9%88%E5%8A%9E%2F</url>
    <content type="text"><![CDATA[19.1 Linux监控平台介绍常见的Linux监控平台有cacti、nagios、zabbix、smokeping、open-falcon等等 cacti、smokeping偏向于基础监控，成图非常漂亮 cacti、nagios、zabbix服务端监控中心，需要php环境支持，其中zabbix和cacti都需要mysql作为数据存储，nagios不用存储历史数据，注重服务或者监控项的状态，zabbix会获取服务或者监控项目的数据，会把数据记录到数据库里，从而可以成图 ，这几款软件都有web操作界面 open-falcon为小米公司开发，开源后受到诸多大公司和运维工程师的追捧，适合大企业，滴滴、360、新浪微博、京东等大公司在使用这款监控软件，值得研究 19.2 zabbix监控介绍C/S架构（被监控的server需要安装监控软件，既可以主动连接客户端，也可以被动的让客户端推送自己的状态），基于C++开发，监控中心支持web界面配置和管理。 单server节点可以支持上万台客户端（可支持同时上万台的server监控，并发量高，如果超过一定的量，性能可能会降低，但是我们可以增加Proxy代理点来充当监控服务器来减轻压力） 5个组件 zabbix-server 监控中心，接收客户端上报信息，负责配置、统计、操作数据。 数据存储 存放数据，比如mysql。 web界面 也叫web UI，在web界面下操作配置是zabbix简单易用的主要原因。 zabbix-proxy 可选组件，它可以代替zabbix-server的功能，减轻server的压力。 zabbix-agent 客户端软件，负责采集各个监控服务或项目的数据，并上报 zabbix监控流程图19.3/19.4 安装zabbix1. 准备工作因为Zabbix的特性，需要2至少2台服务器，1台监控服务端，1台客户端，还需要PHP和Mysql的环境支持，还有自带的web UI，还需要httpd支持。 | 主机名 | IP地址 | 角色 || — | ———— | —– | ————– || yt-01 | 192.168.2.130 | server || yt-02 | 192.168.2.131 | cilent | 官网下载地址，系统自带yum源的2.2版本很老了，在此使用zabbix官方提供的对应版本的yum源安装较新版本的。 123www.zabbix.com/downloadyum install make apr* autoconf automake curl-devel gcc gcc-c++ zlib-devel openssl openssl-devel pcre-devel gd kernel keyutils patch perl kernel-headers compat* mpfr cpp glibc libgomp libstdc++-devel ppl cloog-ppl keyutils-libs-devel libcom_err-devel libsepol-devel libselinux-devel krb5-devel zlib-devel libXpm* freetype libjpeg* libpng* php-common php-gd ncurses* libtool* libxml2 libxml2-devel patch cmake 我们先配置好服务端，再配置客户端。 2. server安装zabbix安装zabbix之前需要先安装其yum源仓库 123456789101112131415# 下载指定版本[root@yt-01 src]# wget repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm# 安装zabbix的yum扩展源[root@yt-01 src]# rpm -ivh zabbix-release-3.2-1.el7.noarch.rpm# 安装zabbix及其组件[root@yt-01 src]# yum install -y zabbix-agent zabbix-get zabbix-server-mysql zabbix-web zabbix-web-mysql# zabbix-agent是客户端程序# zabbix-get是服务端上命令行获取客户端检测项目的组件# zabbix-server-mysql是zabbix-server MySQL组件# zabbix-web是web界面组件# zabbix-web-mysql：web界面MySQL相关组件# 该过程会顺带安装上PHP和httpd服务。 3. 安装和配置MySQL安装MySQL安装mysql可以使用两种方法：1. yum安装 2.编译mysql安装，可参考之前LAMP安装的过程这里选择直接yum安装 123456789101112[root@yt-01 src]# yum install -y mysql mysql-server mysql-devel [root@yt-01 src]# wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpmwget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpmrpm -ivh mysql-community-release-el7-5.noarch.rpmls -1 /etc/yum.repos.d/mysql-community*yum install mysql-server[root@yt-01 src]# systemctl start mysqld[root@yt-01 src]# ps aux | grep mysql 配置MySQL12345678910111213141516171819[root@yt-01 src]# vim /etc/my.cnf # 需要增加配置。设置默认字符集的目的是让web UI可以正常的用中文显示。character_set_server = utf8# 重启mysqld服务[root@yt-01 src]# /etc/init.d/mysqld restart#进入mysql，创建zabbix库（类似安装wordpress，zabbix的web UI就是一个php写的监控网站）[root@yt-01 ~]# mysql -uroot -p123456mysql&gt; create database zabbix character set utf8;#创建库并指定其字符集 Query OK, 1 row affected (0.00 sec)mysql&gt; grant all on zabbix.* to &apos;zabbix&apos;@&apos;127.0.0.1&apos; identified by &apos;123456&apos;; # 允许账户zabbix能从本机连接到数据库zabbixQuery OK, 0 rows affected (0.00 sec)mysql&gt; quit 4. 导入zabbix自带的数据库12345678# 进入zabbix自带的数据库目录[root@yt-01 ~]# cd /usr/share/doc/zabbix-server-mysql-3.2.11/[root@yt-01 zabbix-server-mysql-3.2.11]# lsAUTHORS ChangeLog COPYING create.sql.gz NEWS README# 解压create.sql.gz包，导入到新建的zabbix库[root@zhdy-01 zabbix-server-mysql-3.2.11]# gzip -d create.sql.gz[root@z1 zabbix-server-mysql-3.2.11]# mysql -uroot -p123456 zabbix &lt; create.sql 5. 启动zabbix服务1234567891011121314# 启动zabbix服务[root@yt-01 zabbix-server-mysql-3.2.11]# systemctl start zabbix-server# 启动http服务（如果之前有配置nginx，或者tomcat（配置了80端口）服务一定要先停掉。不然启动httpd会报错）[root@yt-01 zabbix-server-mysql-3.2.11]# systemctl start httpd.service[root@yt-01 zabbix-server-mysql-3.2.11]# netstat -lntp |grep httpdtcp6 0 0 :::80 :::* LISTEN 2370/httpd # 把zabbix、http等服务设置开机启动 [root@yt-01 ~]# systemctl enable zabbix-serverCreated symlink from /etc/systemd/system/multi-user.target.wants/zabbix-server.service to /usr/lib/systemd/system/zabbix-server.service.[root@yt-01 ~]# systemctl enable httpdCreated symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. 6. 查看zabbix的日志1[root@yt-01 ~]# less /var/log/zabbix/zabbix_server.log 7. 配置zabbix1234567891011121314151617181920[root@yt-01 ~]# vim /etc/zabbix/zabbix_server.conf # 更改配置文件DBHost=127.0.0.1# 此处写的是本机MySQL的IP，实际生产环境中zabbix可能单独使用一台机器，则要填实际IP地址# 该IP应该和数据库授权时指定的IP一致DBname=zabbixDBUser=zabbixDBPassword=123456# 更改完成后，重启zabbix服务[root@z1 ~]# systemctl restart zabbix-server.service# 启动完成后查看其状态[root@z1 ~]# ps aux |grep zabbixnetstat -lntp |grep zabbixtcp 0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 2657/zabbix_servertcp6 0 0 :::10051 :::* LISTEN 2657/zabbix_server 服务端zabbix默认监听10051端口 8. 安装和配置zabbix web界面使用浏览器访问server机器上的IP：192.168.122.130/zabbix进入安装引导界面，进行该操作前保证server已关闭防火墙。 点击“Next step”进入检测界面 错误： 此处有错误提示，意识是PHP无法识别“data.timezone”（时区） 解决办法：编辑PHP配置文件，更改时区 123456# 修改时区[root@yt-01 ~]# vim /etc/php.ini date.timezone =Asia/Shanghai# 重启httpd服务[root@yt-02 ~]# systemctl restart httpd.service 浏览器刷新，问题解决！然后，继续点击“Next step”，配置数据库信息 点击“Next step”，设置服务器用户名（自定义） 继续点击“Next step”，至出现提示界面 已经安装完成！ 完成，进入管理界面： 1初始用户名Admin 密码zabbix 1234567# 切记：配置好了之后，第一件事情# 更改密码！更改密码！更改密码！# Administration→Users→Admin→Change password# 并且在修改密码下，可以更改web界面为中文。 19.6 zabbix客户端配置1. 安装Zabbix客户端1234567891011# 下载指定版本[root@yt-02 ~]# wget repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm# 安装zabbix的yum扩展源[root@yt-02 ~]# rpm -ivh zabbix-release-3.2-1.el7.noarch.rpm# client端仅仅只需要安装服务[root@yt-02 ~]# yum install -y zabbix-agent# 配置mysql（略） 2. 配置zabbix12345678910111213141516171819202122232425[root@yt-02 ~]# vim /etc/zabbix/zabbix_agentd.conf# 增加如下配置Server=192.168.2.130#定义监控服务端的ipServerActive=192.168.2.130#定义监控服务端的ip，不过该参数决定了监控的 主/被动模式#如果只有参数Server，则采用被动模式（只能等待服务端来采集信息）#设置此参数，则为主动模式（客户端主动向服务端发送信息）Hostname=yt-02 #定义客户端主机名字，只是便于服务端识别，不参与实际的控制# 启动zabbix服务[root@yt-02 ~]# systemctl start zabbix-agent.service # 查看进程是否运行[root@yt-02 ~]# ps aux | grep zabbix# 查看监控的端口，默认端口是10050[root@yt-02 src]# netstat -lntp|grep zabbixtcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 1897/zabbix_agentdtcp6 0 0 :::10050 :::* LISTEN 1897/zabbix_agentd# 设置为开机运行[root@yt-02 ~]# systemctl enable zabbix-agent 19.5 忘记Admin密码如何做修改zabbix的管理员密码（web界面）这个和修改wordpress以及修改mysql自身登录密码是类似的，直接在数据库内选中数据库选中user表进行修改。 123456789101112131415161718192021222324252627282930313233343536[root@yt-01 ~]# mysql -uroot -p# 切换到zabbix库&gt; show databases;&gt; use zabbix;&gt; show tabales;&gt; desc users;+----------------+---------------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------------+---------------------+------+-----+---------+-------+| userid | bigint(20) unsigned | NO | PRI | NULL | || alias | varchar(100) | NO | UNI | | || name | varchar(100) | NO | | | || surname | varchar(100) | NO | | | || passwd | char(32) | NO | | | || url | varchar(255) | NO | | | || autologin | int(11) | NO | | 0 | || autologout | int(11) | NO | | 900 | || lang | varchar(5) | NO | | en_GB | || refresh | int(11) | NO | | 30 | || type | int(11) | NO | | 1 | || theme | varchar(128) | NO | | default | || attempt_failed | int(11) | NO | | 0 | || attempt_ip | varchar(39) | NO | | | || attempt_clock | int(11) | NO | | 0 | || rows_per_page | int(11) | NO | | 50 | |+----------------+---------------------+------+-----+---------+-------+16 rows in set (0.00 sec)# 更改密码mysql&gt; update users set passwd=md5(&apos;123456&apos;) where alias=&apos;Admin&apos;;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; quit这样就成功修改了zabbix管理web的登录密码为123456！]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS DR模式搭建、keepalived + LV]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F18.11-18.12%20LVS%20DR%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA%E3%80%81keepalived%20%2B%20LVS%2F</url>
    <content type="text"><![CDATA[18.11 LVS DR模式搭建为什么不使用IP TUNNEL模式呢？ 在生产环境中用的比较多的情况就是DR模式，NAT模式用的也不是太多，因为我们也说到了NAT的瓶颈问题。 如果规模在10台以内访问量不是很大且硬件配置+网络环境都可以的话建议使用NAT模式，可以节省公网IP，因为公网IP的成本也比较高。 另外一种方案就是搭建内网的LVS，全部的server均使用内网IP，我们使用一个公网IP端口映射到内网VIP的80端口即可，从而达到节省IP资源。 1. 准备工作1.1 三台模拟服务器| 主机名 | IP地址 | 角色 || — | ———— | —– | ————– || yt-01 | 192.168.2.131 | Director || yt-02 | 192.168.2.132 | Real server 1 || yt-03 | 192.168.2.133 | Real server 2 || | 192.168.2.200 | VIP | 1.2 确保每台机器已经安装了ipvsadm服务123[root@yt-01 ~]# yum install -y ipvsadm[root@yt-02 ~]# yum install -y ipvsadm[root@yt-03 ~]# yum install -y ipvsadm 2. 在Director上面编写脚本1234567891011121314151617[root@yt-01 ~]# vim /usr/local/sbin/lvs_dr.sh#! /bin/bash echo 1 &gt; /proc/sys/net/ipv4/ip_forward ipv=/usr/sbin/ipvsadm vip=192.168.2.200 rs1=192.168.2.122 rs2=192.168.2.123#注意这里的网卡名字 ifdown ens33 ifup ens33 ifconfig ens33:2 $vip broadcast $vip netmask 255.255.255.255 up route add -host $vip dev ens33:2 $ipv -C $ipv -A -t $vip:80 -s wrr $ipv -a -t $vip:80 -r $rs1:80 -g -w 1 $ipv -a -t $vip:80 -r $rs2:80 -g -w 1 3. 运行DR上lvs_dr脚本123[root@yt-01 ~]# sh /usr/local/sbin/lvs_dr.sh成功断开设备 &apos;ens33&apos;。成功激活的连接（D-Bus 激活路径：/org/freedesktop/NetworkManager/ActiveConnection/3） 4. 每台Real Server上也编写脚本1234567891011121314[root@yt-02 ~]# vim /usr/local/sbin/lvs_rs.sh#! /bin/bashvip=192.168.2.200#把vip绑定在lo上，是为了实现rs直接把结果返回给客户端ifdown loifup loifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip lo:0#以下操作为更改arp内核参数，目的是为了让rs顺利发送mac地址给客户端echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_announce 5. 每台Real Server上运行脚本12345678910111213141516171819[root@yt-02 ~]# sh /usr/local/sbin/lvs_rs.sh[root@yt-03 ~]# sh /usr/local/sbin/lvs_rs.sh# 查看一下每台real server的router -n[root@zhdy-02 ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.2.2 0.0.0.0 UG 100 0 0 ens33192.168.2.0 0.0.0.0 255.255.255.0 U 100 0 0 ens33192.168.2.200 0.0.0.0 255.255.255.255 UH 0 0 0 lo# 查看IP是否已经绑在lo卡上[root@yt-02 ~]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet 192.168.2.200/32 brd 192.168.2.200 scope global lo:0 6. 测试6.1 测试前一定要全部关闭iptables12# systemctl stop firewalld# systemctl disable firewalld 6.2 修改2个RS的nginx主页内容，以便区分12[root@yt-02 ~]# echo &quot;rs1rs1&quot; &gt;/usr/share/nginx/html/index.html[root@yt-03 ~]# echo &quot;rs2rs2&quot; &gt;/usr/share/nginx/html/index.html 6.3 用浏览器测试VIP，多试几次1234567[root@zhdy-01 ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.2.200:80 wrr -&gt; 192.168.2.122:80 Route 1 1 9 -&gt; 192.168.2.123:80 Route 1 1 8 18.12 keepalived + LVSLVS有个关键的点，也是致命点。所有的请求都会通过Director去转发到Real server 如果Director宕机，我们的所有服务均会被停止掉。所以我们会把keepalived放在这儿，实现DR的高可用，这样就会完美的解决问题！ 完整架构需要两台服务器（角色为dir）分别安装keepalived软件，目的是实现高可用，但keepalived本身也有负载均衡的功能，所以本次实验可以只安装一台keepalived。 1. 准备工作| 主机名 | IP地址 | 角色 || — | ———— | —– | ————– || yt-01 | 192.168.2.131 | Director，安装keepalived || yt-02 | 192.168.2.132 | Real server 1 || yt-03 | 192.168.2.133 | Real server 2 || 无 | 192.168.2.300 | VIP | 2. 配置director12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879[root@yt-01 ~]# yum install -y keepalived# 自定义Keepalived配置文件[root@yt-01 ~]# vim /etc/keepalived/keepalived.confvrrp_instance VI_1 &#123; #备用服务器上为 BACKUP state MASTER #绑定vip的网卡为ens33，你的网卡和阿铭的可能不一样，这里需要你改一下 interface ens33 virtual_router_id 51 #备用服务器上为90 priority 100 #设置为不抢占，只在优先级高的机器上设置即可，优先级低的机器不设置，如果高的被down掉后，又起来，这样不会抢占，形成脑裂。 nopreempt advert_int 1 authentication &#123; auth_type PASS auth_pass 123456 &#125; virtual_ipaddress &#123; 192.168.2.300 &#125;&#125;virtual_server 192.168.2.300 80 &#123; #(每隔10秒查询realserver状态) delay_loop 10 #(lvs 算法) lb_algo wlc #算法(DR模式) lb_kind DR #(同一IP的连接60秒内被分配到同一台realserver) persistence_timeout 0 #(用TCP协议检查realserver状态) protocol TCP real_server 192.168.2.132 80 &#123; #(权重) weight 100 TCP_CHECK &#123; #(10秒无响应超时) connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.1682.133 80 &#123; weight 100 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; &#125; # 启动Keepalived服务[root@yt-01 ~]# systemctl start keepalived查看网卡信息：[root@yt-01 ~]# ip add2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:be:0e:17 brd ff:ff:ff:ff:ff:ff inet 192.168.2.131/24 brd 192.168.2.255 scope global ens33 valid_lft forever preferred_lft forever inet 192.168.2.300/32 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::592f:39cc:1b50:1d07/64 scope link valid_lft forever preferred_lft forever#虚拟IP（VIP）在ens33网卡上# 查看ipvsadm规则[root@director ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.2.300:80 wlc -&gt; 192.168.2.132:80 Route 100 0 0 -&gt; 192.168.2.133:80 Route 100 0 0 3. 配置Real Server12345678910111213141516171819# 编辑路由转发脚本[root@yt-02 ~]# vim /usr/local/sbin/lvs_rs.sh#/bin/bashvip=192.168.2.300#把vip绑定在lo上，是为了实现rs直接把结果返回给客户端ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip lo:0#以下操作为更改arp内核参数，目的是为了让rs顺利发送mac地址给客户端#参考文档www.cnblogs.com/lgfeng/archive/2012/10/16/2726308.htmlecho &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_announce# 运行脚本[root@yt-02 ~]# sh /usr/local/sbin/lvs_rs.shRS3上同上 配置完成 4. 测试在浏览器访问VIP：192.168.2.300，刷新网页，访问结果由RS1、RS2交替回复，停掉任意一台RS服务器，网页不会中断。 5. Keepalived+LVS作用 Keepalived搭建高可用保证LVS中director宕机后服务器不瘫痪（用多台Director） 如果只使用LVS，那么当LVS架构中某个real server宕机后，director仍然会继续向其发送请求，添加Keepalived后会自动将宕机的real server清除出rs列表。 扩展haproxy+keepalivedhttp://blog.csdn.net/xrt95050/article/details/40926255 nginx、lvs、haproxy比较http://www.csdn.net/article/2014-07-24/2820837 keepalived中自定义脚本vrrp_script http://my.oschina.net/hncscwc/blog/158746 lvs dr模式只使用一个公网ip的实现方法http://storysky.blog.51cto.com/628458/338726]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>LVR</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux负载均衡集群介绍、LVS和LVS NAT搭建]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F18.6-18.10%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D%E3%80%81LVS%E5%92%8CLVS%20NAT%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[18.6 负载均衡集群介绍 主流开源软件LVS、keepalived、haproxy、nginx等 其中LVS属于4层（网络OSI 7层模型），nginx属于7层，haproxy既可以认为是4层，也可以当做7层使用 keepalived的负载均衡功能其实就是lvs lvs这种4层的负载均衡是可以分发除80外的其他端口通信的，比如MySQL的，而nginx仅仅支持http，https，mail，haproxy也支持MySQL这种 相比较来说，LVS这种4层的更稳定，能承受更多的请求，而nginx这种7层的更加灵活，能实现更多的个性化需求 。 这里写图片描述 18.7 LVS介绍 LVS是由国人章文嵩开发 流行度不亚于apache的httpd，基于TCP/IP做的路由和转发，稳定性和效率很高 LVS最新版本基于Linux内核2.6，有好多年不更新了 LVS有三种常见的模式：NAT、DR、IP Tunnel LVS架构中有一个核心角色叫做分发器（Load balance），它用来分发用户的请求，还有诸多处理用户请求的服务器（Real Server，简称rs） 在调度器的实现技术中，IP负载均衡技术是效率最高的。 在已有的IP负载均衡技术中有通过网络地址转换（Network Address Translation）将一组服务器构成一个高性能的、高可用的虚拟服务器，我们称之为VS/NAT技术（Virtual Server via Network Address Translation），大多数商品化的IP负载均衡调度器产品都是使用此方法，如Cisco的LocalDirector、F5的Big/IP和 Alteon的ACEDirector。 在分析VS/NAT的缺点和网络服务的非对称性的基础上，我们提出通过IP隧道实现虚拟服务器的方法VS/TUN （Virtual Server via IP Tunneling），和通过直接路由实现虚拟服务器的方法VS/DR（Virtual Server via Direct Routing），它们可以极大地提高系统的伸缩性。 所以，IPVS软件实现了这三种IP负载均衡技术，它们的大致原理如下（我们将在其他章节对其工作原 理进行详细描述）： LVS有三种常见的模式：NAT、DR、IP Tunnel，其实企业中最常用的是 DR 实现方式，而 NAT 配置上比较简单和方便，后边实践中会总结 DR 和 NAT 具体使用配置过程。 LVS NAT模式工作原理：Virtual Server via Network Address Translation(VS/NAT) 网络地址转换调度器将请求的目标 ip 即 vip 地址改为 Real server 的 ip, 返回的数据包也经过调度器，调度器再把源地址修改为 vip 这种模式借助iptables的nat表来实现 用户的请求到分发器后，通过预设的iptables规则，把请求的数据包转发到后端的rs上去 rs需要设定网关为分发器的内网ip 用户请求的数据包和返回给用户的数据包全部经过分发器，所以分发器成为瓶颈 在nat模式中，只需要分发器有公网ip即可，所以比较节省公网ip资源 NAT模式优缺点： NAT技术将请求的报文和响应的报文都需要通过LB进行地址改写，因此网站访问量比较大的时候LB负载均衡调度器有比较大的瓶颈，一般要求最多之能10-20台节点 只需要在LB上配置一个公网IP地址就可以了。 每台内部的节点服务器的网关地址必须是调度器LB的内网地址。 NAT模式支持对IP地址和端口进行转换。即用户请求的端口和真实服务器的端口可以不一致。 LVS IP Tunnel模式工作原理：Virtual Server via IP Tunneling IP隧道封装调度器将请求来的数据包封装加密通过 ip 隧道转发到后端的 real server 上，而 real server 会直接把数据返回给客户端，而不再经过调度器 这种模式，需要有一个公共的IP配置在分发器和所有rs上，我们把它叫做vip 客户端请求的目标IP为vip，分发器接收到请求数据包后，会对数据包做一个加工，会把目标IP改为rs的IP，这样数据包就到了rs上 rs接收数据包后，会还原原始数据包，这样目标IP为vip，因为所有rs上配置了这个vip，所以它会认为是它自己 LVS DR模式工作原理：Virtual Server via Director Server 分发器封装分发器将请求来的数据包的MAC地址改为后端的 real server的MAC地址，然后直接原封不动地把数据包发到后端的 real server上，而 real server 会直接把数据返回给客户端，也不再经过调度器，客户端接受的IP信息还是显示的是分发器的IP 这种模式，也需要有一个公共的IP配置在分发器和所有rs上，也就是vip 和IP Tunnel不同的是，它会把数据包的MAC地址修改为rs的MAC地址 rs接收数据包后，会还原原始数据包，这样目标IP为vip，因为所有rs上配置了这个vip，所以它会认为是它自己 官方三种负载均衡技术比较总结表： 18.8 LVS调度算法在这8种算法中，rr、wrr、lc、wlc四种算法是最最常用的，需要记住。 轮询 Round-Robin rr这种算法是最简单的，就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是简单。轮询算法假设所有的服务器处理请求的能力都是一样的，调度器会将所有的请求平均分配给每个真实服务器，不管后端 RS 配置和处理能力，非常均衡地分发下去。 加权轮询 Weight Round-Robin wrr这种算法比 rr 的算法多了一个权重的概念，可以给 RS 设置权重，权重越高，那么分发的请求数越多，权重的取值范围 0 – 100。主要是对rr算法的一种优化和补充， LVS 会考虑每台服务器的性能，并给每台服务器添加要给权值，如果服务器A的权值为1，服务器B的权值为2，则调度到服务器B的请求会是服务器A的2倍。权值越高的服务器，处理的请求越多。 最小连接 Least-Connection lc这个算法会根据后端 RS 的连接数来决定把请求分发给谁，比如 RS1 连接数比 RS2 连接数少，那么请求就优先发给 RS1 加权最小连接 Weight Least-Connection wlc这个算法比 lc 多了一个权重的概念。 基于局部性的最小连接 Locality-Based Least Connections lblc这个算法是请求数据包的目标 IP 地址的一种调度算法，该算法先根据请求的目标 IP 地址寻找最近的该目标 IP 地址所有使用的服务器，如果这台服务器依然可用，并且有能力处理该请求，调度器会尽量选择相同的服务器，否则会继续选择其它可行的服务器 带复制的基于局部性最小连接 Locality-Based Least Connections with Replication lblcr记录的不是要给目标 IP 与一台服务器之间的连接记录，它会维护一个目标 IP 到一组服务器之间的映射关系，防止单点服务器负载过高。 目标地址散列调度 Destination Hashing dh该算法是根据目标 IP 地址通过散列函数将目标 IP 与服务器建立映射关系，出现服务器不可用或负载过高的情况下，发往该目标 IP 的请求会固定发给该服务器。 源地址散列调度 Source Hashing sh与目标地址散列调度算法类似，但它是根据源地址散列算法进行静态分配固定的服务器资源。 18.9/18.10 LVS NAT模式搭建NAT模式就是通过iptables模式实现的，我们配置一些规则在上面就可以实现了。 1.准备工作1.1 三台服务器 主机名 IP地址 角色 网关 yt-01 192.168.2.111 Director 公网IP （虚拟机的原因，公网IP同内网IP，生产环境中是不同的） yt-02 192.168.2.112 Real server A 192.168.2.111（即DR的内网IP地址） yt-03 192.168.2.113 Real server B 192.168.2.111（即DR的内网IP地址） 配置完成后，最好 route -n 再确认下。 1234[root@yt-02 ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.2.111 0.0.0.0 UG 0 0 0 ens33 1.2 三台机器上都关闭掉防火墙，重置iptables规则1234567891011121314151617181920212223[root@yt-01 ~]# systemctl stop firewalld[root@yt-01 ~]# systemctl disable firewalld[root@yt-01 ~]# systemctl start iptables-services; iptables -F; service iptables save [root@yt-01 ~]# getenforce Enforcing[root@yt-01 ~]# vim /etc/sysconfig/selinux # This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled[root@yt-01 ~]# yum install -y iptables-services [root@yt-01 ~]# systemctl start iptables[root@yt-01 ~]# systemctl enable iptablesCreated symlink from /etc/systemd/system/basic.target.wants/iptables.service to /usr/lib/systemd/system/iptables.service.[root@yt-01 ~]# iptables -F[root@yt-01 ~]# service iptables saveiptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ] 1.3 测试内外之间是否可以ping同Windows主机 1ping 192.168.2.111 yt-01 1ping www.qq.com 2.安装和配置2.1 在两个RS上面安装nginx12[root@yt-02 ~]# yum install -y nginx[root@yt-03 ~]# yum install -y nginx 2.2 在Director上安装ipvsadm1[root@yt-01 ~]# yum install -y ipvsadm 2.3 给Director编辑一个实现nat的脚本编写脚本 /usr/local/sbin/lvs_nat.sh，LVS架构几乎都是以脚本的形式 12345678910111213141516171819202122[root@yt-01 ~]# /usr/local/sbin/lvs_nat.sh#! /bin/bash# director 服务器上开启路由转发功能echo 1 &gt; /proc/sys/net/ipv4/ip_forward# 关闭icmp的重定向echo 0 &gt; /proc/sys/net/ipv4/conf/all/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/default/send_redirects# 注意区分网卡名字，两个网卡分别为ens33和ens37echo 0 &gt; /proc/sys/net/ipv4/conf/ens33/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/ens37/send_redirects# director 设置nat防火墙iptables -t nat -Fiptables -t nat -Xiptables -t nat -A POSTROUTING -s 192.168.2.0/24 -j MASQUERADE# director设置ipvsadmIPVSADM=&apos;/usr/sbin/ipvsadm&apos;$IPVSADM -C$IPVSADM -A -t 192.168.138.128:80 -s wlc -p 3# -s wlc -p 3 这就是IPVSADM算法，超时3s，Director服务器会自动分发到不同的Real Server服务器$IPVSADM -a -t 192.168.138.128:80 -r 192.168.2.112:80 -m -w 1$IPVSADM -a -t 192.168.138.128:80 -r 192.168.2.113:80 -m -w 1 2.4 执行DR上的lvs_nat.sh脚本保存后，运行脚本，LVS NAT模式就配置成功了。 1[root@yt-01 ~]# sh /usr/local/sbin/lvs_nat.sh 3.测试3.1 修改2个RS的nginx主页内容，以便区分12[root@yt-02 ~]# echo &quot;rs1rs1&quot; &gt;/usr/share/nginx/html/index.html[root@yt-03 ~]# echo &quot;rs2rs2&quot; &gt;/usr/share/nginx/html/index.html 3.2 用浏览器测试两台机器上的web内容扩展lvs 三种模式详解http://www.it165.net/admin/html/201401/2248.html lvs几种算法http://www.aminglinux.com/bbs/thread-7407-1-1.html 关于arp_ignore和 arp_announcehttp://www.cnblogs.com/lgfeng/archive/2012/10/16/2726308.html lvs原理相关的http://blog.csdn.net/pi9nc/article/details/23380589]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux集群介绍、keepalived介绍和配置高可用集群]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F18.1-18.5%20%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D%E3%80%81keepalived%E4%BB%8B%E7%BB%8D%E5%92%8C%E9%85%8D%E7%BD%AE%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[18.1 集群介绍Linux集群概述 根据功能划分为两大类：高可用和负载均衡 高可用集群通常为两台服务器，一台工作，另外一台作为冗余，当提供服务的机器宕机，冗余将接替继续提供服务 实现高可用的开源软件有：heartbeat(由于版本不再更新，在CentOS 6上面Bug比较多，不推荐使用了)、keepalived （既可以实现高可用，又可以实现负载均衡） 负载均衡集群，需要有一台服务器作为分发器，它负责把用户的请求分发给后端的服务器处理，在这个集群里，除了分发器外，就是给用户提供服务的服务器了，这些服务器数量至少为2 实现负载均衡的开源软件有LVS、keepalived、haproxy、nginx，商业的有F5、Netscaler 专用商业服务器，价格很高，从几万到几十万都有 18.2 keepalived介绍 在这里我们使用keepalived来实现高可用集群，因为heartbeat在centos6上有一些问题，影响实验效果（比如，切换不及时） keepalived通过 VRRP（Virtual Router Redundancy Protocl）虚拟路由冗余协议 来实现高可用。 在这个协议里会将多台功能相同的路由器组成一个小组，这个小组里会有1个master角色和N（N&gt;=1）个backup角色。 master会通过组播的形式向各个backup发送VRRP协议的数据包，当backup收不到master发来的VRRP数据包时，就会认为master宕机了。此时就需要根据各个backup的优先级来决定谁成为新的mater。 Keepalived要有三个模块，分别是core、check和vrrp。其中core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析，check模块负责健康检查，vrrp模块是来实现VRRP协议的。 18.3/18.4/18.5 用keepalived配置高可用集群准备 两台机器 192.168.2.180（Master/yt-01）、192..168.2.183（backupyt-02） keepalived的VIP设为192.168.2.100（在keepalived配置里面设置）。关于VIP，即Vitrual IP。当我们有主从两台机器，我们需要绑定域名到指定的IP，如果绑定在主上面。如果主宕机，我们就无法提供服务，所以Vitrual IP就起到了关键性作用。默认配置在主服务器上面，但是一旦宕机，从服务器就会立即启动，并且把这个IP绑定在从上面从而不会影响业务的状态！ 机器都要联网 两台机器都要安装keepalived 1# yum install -y keepalived 两台机器都安装nginx安装nginx作为实验对象，其中因为180上之前已经源码包安装过nginx，所以只需要181上安装就可以了 1# yum install -y nginx 两台机器都要关闭防火墙 1234# iptables -nvL# systemctl stop firewalld# getenforce# setenforce 0 配置主keepalived服务器更改配置文件 编辑180上keepalived配置文件12345678910111213141516171819202122232425262728293031323334# &gt; /etc/keepalived/keepalived.conf #清空原始配置文件# vim /etc/keepalived/keepalived.conf #复制下面代码，代替原配置文件# 全局定义参数global_defs &#123; notification_email &#123; #出现问题后接收提示的邮箱 test@test.com &#125; notification_email_from test@test.com #发件人邮箱 smtp_server 127.0.0.1 #邮件服务器 smtp_connect_timeout 30 #延时 router_id LVS_DEVEL #运行keepalived机器的一个标识&#125;vrrp_script chk_nginx &#123; #检测vrrp服务是否正常 script &quot;/usr/local/sbin/check_ng.sh&quot; #检测脚本的路径 interval 3 #检测间断是3s&#125;vrrp_instance VI_1 &#123; #定义相关Master的东西 state MASTER #设定角色 interface ens33 #指定ens33这块网卡，通过vrrp协议去发广播 virtual_router_id 51 #指定虚拟路由器的ID，一定要和从上的保持一致 priority 100 #指定权重，数字越大优先级越高 advert_int 1 authentication &#123; #认证的相关信息 auth_type PASS #定义认证数据类型为密码 auth_pass 123456 #密码暂定123456 &#125; virtual_ipaddress &#123; #定义VIP，VIP指的是高可用指定的固定IP地址，不论主从切换后IP都是这个 192.168.2.100 &#125; track_script &#123; chk_nginx #加载定义的chk_nginx脚本 &#125;&#125; 写监控脚本1234567891011121314151617181920[root@yt-01 ~]# vim /usr/local/sbin/check_ng.sh #keepalived的监控脚本，把下面代码粘贴进去#!/bin/bash#时间变量，用于记录日志d=`date --date today +%Y%m%d_%H:%M:%S`#计算nginx进程数量n=`ps -C nginx --no-heading|wc -l`#如果进程为0，则启动nginx，并且再次检测nginx进程数量，#如果还为0，说明nginx无法启动，此时需要关闭keepalivedif [ $n -eq &quot;0&quot; ]; then /etc/init.d/nginx start n2=`ps -C nginx --no-heading|wc -l` if [ $n2 -eq &quot;0&quot; ]; then echo &quot;$d nginx down,keepalived will stop&quot; &gt;&gt; /var/log/check_ng.log#杀掉keepalived，是为了防止脑裂。脑裂指的是高可用集群中，当主从切换时，主上的keepalived还在启动，会和从争抢VIP，导致后台链接服务器时，不知道连接哪台服务器好，导致出错。 systemctl stop keepalived fifi[root@yt-01 ~]# chmod 755 /usr/local/sbin/check_ng.sh ##给脚本755权限 脚本解读：如果进程里面没发现nginx那就代表着服务宕机了，然后脚本自动的再次启动nginx服务。 如果服务还是不可以启动，就把启动报错日志输入到指定的位置，然后把keepalived也关闭。 为什么需要关闭keepalived呢？ 行业里面有个名词叫做“脑裂”，如果主服务宕机，从服务势必会马上启动顶替主服务再次服务，如果主服务的keepalived没有关闭，一定会造成混乱，两台机器都争抢服务。 在高可用（HA）系统中，当联系2个节点的“心跳线”断开时，本来为一整体、动作协调的HA系统，就分裂成为2个独立的个体。由于相互失去了联系，都以为是对方出了故障。两个节点上的HA软件像“裂脑人”一样，争抢“共享资源”、争起“应用服务”，就会发生严重后果——或者共享资源被瓜分、2边服务都起不来了；或者2边服务都起来了，但同时读写“共享存储”，导致数据损坏。 高可用中，绝对不可以发生的脑裂问题！ 启动keepalived服务1234567891011[root@yt-01 ~]# systemctl start keepalived[root@yt-01 ~]# ps aux |grep keeproot 3887 0.0 0.1 120724 1400 ? Ss 15:57 0:00 /usr/sbin/keepalived -Droot 3888 0.0 0.2 120724 2748 ? S 15:57 0:00 /usr/sbin/keepalived -Droot 3889 0.0 0.2 124980 2744 ? S 15:57 0:00 /usr/sbin/keepalived -Droot 3914 0.0 0.0 112680 972 pts/1 R+ 15:57 0:00 grep --color=auto keep[root@yt-01 ~]# ps aux |grep nginxroot 3866 0.0 0.0 20500 628 ? Ss 15:54 0:00 nginx: master process /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confnobody 3867 0.0 0.3 22944 3216 ? S 15:54 0:00 nginx: worker processnobody 3868 0.0 0.3 22944 3216 ? S 15:54 0:00 nginx: worker processroot 3946 0.0 0.0 112680 972 pts/1 R+ 15:57 0:00 grep --color=auto nginx 停掉keepalived，测试是否会重新加载123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@yt-01 ~]# /etc/init.d/nginx stop[root@yt-01 ~]# ps aux |grep nginxroot 4093 0.0 0.0 20500 628 ? Ss 15:58 0:00 nginx: master process /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confnobody 4097 0.0 0.3 22944 3216 ? S 15:58 0:00 nginx: worker processnobody 4098 0.0 0.3 22944 3216 ? S 15:58 0:00 nginx: worker processroot 4106 0.0 0.0 112680 968 pts/1 R+ 15:58 0:00 grep --color=auto nginx还是会再加载#查看日志#[root@yt-01 ~]# tail /var/log/messages[root@yt-01 ~]# ifconfig -a ##这个命令查看不到VIPens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.2.180 netmask 255.255.255.0 broadcast 192.168.2.255 inet6 fe80::6b0e:c2eb:de7a:3662 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:14:f6:1b txqueuelen 1000 (Ethernet) RX packets 16608 bytes 11284525 (10.7 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 10439 bytes 3068832 (2.9 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1 (Local Loopback) RX packets 617885 bytes 308269731 (293.9 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 617885 bytes 308269731 (293.9 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@yt-01 ~]# ip add ##查看到的到VIP xxx/321: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:14:f6:1b brd ff:ff:ff:ff:ff:ff inet 192.168.2.180/24 brd 192.168.2.255 scope global ens33 valid_lft forever preferred_lft forever inet 192.168.2.100/32 scope global ens33 ##VIP为192.168.2.100/32## valid_lft forever preferred_lft forever inet6 fe80::6b0e:c2eb:de7a:3662/64 scope link valid_lft forever preferred_lft forever 配置keepalived从更改配置文件123456789101112131415161718192021222324252627282930313233[root@yt-02 ~]# &gt; /etc/keepalived/keepalived.conf ##清空原始配置文件[root@yt-02 ~]# vim /etc/keepalived/keepalived.conf ##复制下面代码，代替原配置文件global_defs &#123; notification_email &#123; test@test.com &#125; notification_email_from test@test.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_script chk_nginx &#123; script &quot;/usr/local/sbin/check_ng.sh&quot; interval 3&#125;vrrp_instance VI_1 &#123; state BACKUP #指定角色为从 interface ens33 virtual_router_id 51 priority 90 #指定权重为90，低于主 advert_int 1 authentication &#123; auth_type PASS auth_pass 123456 &#125; virtual_ipaddress &#123; 192.168.2.100 &#125; track_script &#123; chk_nginx &#125;&#125; 编辑监控脚本12345678910111213141516171819[root@yt-02 ~]# vim /usr/local/sbin/check_ng.sh ##keepalived监控脚本路径是在keepalived配置文件中指定的，把下面代码粘贴进去#!/bin/bash#时间变量，用于记录日志d=`date --date today +%Y%m%d_%H:%M:%S`#计算nginx进程数量n=`ps -C nginx --no-heading|wc -l`#如果进程为0，则启动nginx，并且再次检测nginx进程数量，#如果还为0，说明nginx无法启动，此时需要关闭keepalivedif [ $n -eq &quot;0&quot; ]; then systemctl start nginx ##因为是yum安装，启动有点不一样 n2=`ps -C nginx --no-heading|wc -l` if [ $n2 -eq &quot;0&quot; ]; then echo &quot;$d nginx down,keepalived will stop&quot; &gt;&gt; /var/log/check_ng.log systemctl stop keepalived fifi[root@yt-02 ~]# chmod 755 /usr/local/sbin/check_ng.sh ##给脚本755权限 启动keepalived12345678910[root@yt-02 ~]# systemctl start keepalived[root@yt-02 ~]# ps aux |grep keeproot 7174 0.0 0.1 120720 1404 ? Ss 20:46 0:00 /usr/sbin/keepalived -Droot 7175 0.0 0.2 120720 2752 ? S 20:46 0:00 /usr/sbin/keepalived -Droot 7176 0.0 0.2 124976 2740 ? S 20:46 0:00 /usr/sbin/keepalived -Droot 7218 0.0 0.0 112632 660 pts/0 D+ 20:46 0:00 grep --color=auto keep[root@yt-02 ~]# ps aux |grep nginxroot 7199 0.0 0.2 122904 2108 ? Ss 20:46 0:00 nginx: master process /usr/sbin/nginxnginx 7200 0.0 0.3 123368 3152 ? S 20:46 0:00 nginx: worker processroot 7232 0.0 0.0 112676 976 pts/0 S+ 20:47 0:00 grep --color=auto nginx 停掉keepalived，测试是否会重新加载1234567891011121314151617181920212223242526272829303132333435363738394041[root@yt-02 ~]# systemctl stop nginx[root@yt-02 ~]# ps aux |grep nginxroot 7413 0.0 0.2 122904 2108 ? Ss 20:48 0:00 nginx: master process /usr/sbin/nginxnginx 7414 0.0 0.3 123368 3152 ? S 20:48 0:00 nginx: worker processroot 7485 0.0 0.0 112676 972 pts/0 S+ 20:48 0:00 grep --color=auto nginx还是会再加载[root@yt-02 ~]# ifconfig -a ##查看不到VIPens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.2.183 netmask 255.255.255.0 broadcast 192.168.2.255 inet6 fe80::62d6:aa12:bb83:d01a prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:0d:54:47 txqueuelen 1000 (Ethernet) RX packets 16098 bytes 18728112 (17.8 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 4869 bytes 499007 (487.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1 (Local Loopback) RX packets 16 bytes 1360 (1.3 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 16 bytes 1360 (1.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@yt-02 ~]# ip add ##查看到的到VIP xxx/321: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:0d:54:47 brd ff:ff:ff:ff:ff:ff inet 192.168.2.183/24 brd 192.168.2.255 scope global ens33 valid_lft forever preferred_lft forever inet 192.168.2.100/32 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::62d6:aa12:bb83:d01a/64 scope link valid_lft forever preferred_lft forever 怎么区分主从上的nginx更改nginx默认主页的文件内容，比如：主上改成This is Master，从上改成This is backup。 1234nginx默认主页的文件地址主上：更改 /data/wwwroot/default/index.html 文件 （编译安装） 如果找不到，就去/usr/local/nginx/html/index.html从上：/usr/share/nginx/html/index.html 文件 （yum安装） 主： 从： VIP： 测试高可用先确定好两台机器上nginx差异，比如可以通过curl -I 来查看nginx版本，通过浏览器访问各个IP测试。 测试1：关闭master上的nginx服务chkng脚本可以再次启动nginx的，我们上面测试过，无法关闭的 测试2：在master上增加iptabls规则 iptables -I OUTPUT -p vrrp -j DROP用防火墙关闭vrrp协议，也不能让keepalived的主达到切换到从的目的。我们还是恢复过来，iptables -F 测试3：关闭master上的keepalived服务 1[root@yt-01 ~]# systemctl stop keepalived 访问VIP成功切换到从上。 测试4：启动master上的keepalived服务1[root@yt-01 ~]# systemctl start keepalived VIP马上有调到了主上面，这些过程，都可以在/var/log/messages日志里面看到。 扩展高可用开源方案 Keepalived VS Heartbeat对比出处：http://blog.csdn.net/yunhua_lee/article/details/9788433 DRBD工作原理和配置出处：http://502245466.blog.51cto.com/7559397/1298945 mysql+keepalived出处：http://lizhenliang.blog.51cto.com/7876557/1362313环境描述：OS：CentOS6.5_X64MASTER：192.168.0.202BACKUP：192.168.0.203VIP：192.168.0.2041、配置两台Mysql主主同步[root@master ~]# yum install mysql-server mysql -y[root@master ~]# service mysqld start[root@master ~]# mysqladmin -u root password 123.com[root@master ~]# vi /etc/my.cnf #开启二进制日志，设置id[mysqld]server-id = 1 #backup这台设置2log-bin = mysql-binbinlog-ignore-db = mysql,information_schema #忽略写入binlog日志的库auto-increment-increment = 2 #字段变化增量值auto-increment-offset = 1 #初始字段ID为1slave-skip-errors = all #忽略所有复制产生的错误[root@master ~]# service mysqld restart #先查看下log bin日志和pos值位置wKiom1MJYSngwysqAADkFn9zcK8686.jpgmaster配置如下：[root@ master ~]# mysql -u root -p123.commysql&gt; GRANT REPLICATION SLAVE ON . TO ‘replication’@’192.168.0.%’ IDENTIFIED BY ‘replication’;mysql&gt; flush privileges;mysql&gt; change master to -&gt; master_host=’192.168.0.203’, -&gt; master_user=’replication’, -&gt; master_password=’replication’, -&gt; master_log_file=’mysql-bin.000002’, -&gt; master_log_pos=106; #对端状态显示的值mysql&gt; start slave; #启动同步backup配置如下：[root@backup ~]# mysql -u root -p123.commysql&gt; GRANT REPLICATION SLAVE ON . TO ‘replication’@’192.168.0.%’ IDENTIFIED BY ‘replication’;mysql&gt; flush privileges;mysql&gt; change master to -&gt; master_host=’192.168.0.202’, -&gt; master_user=’replication’, -&gt; master_password=’replication’, -&gt; master_log_file=’mysql-bin.000002’, -&gt; master_log_pos=106;mysql&gt; start slave; #主主同步配置完毕，查看同步状态Slave_IO和Slave_SQL是YES说明主主同步成功。wKioL1MJYQ7QfZfXAAGQt0H1o1c742.jpg在master插入数据测试下：wKiom1MJYUCC0nlQAAEk4ruZ3ys652.jpg在backup查看是否同步成功：wKioL1MJYXyyChXUAADPZraUk3Y684.jpg可以看到已经成功同步过去，同样在backup插入到user表数据，一样同步过去，双主就做成功了。2、配置keepalived实现热备[root@backup ~]# yum install -y pcre-devel openssl-devel popt-devel #安装依赖包[root@master ~]# wget http://www.keepalived.org/software/keepalived-1.2.7.tar.gz[root@master ~]# tar zxvf keepalived-1.2.7.tar.gz[root@master ~]# cd keepalived-1.2.7[root@master ~]#./configure –prefix=/usr/local/keepalivedmake &amp;&amp; make install #将keepalived配置成系统服务[root@master ~]# cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/[root@master ~]# cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/[root@master ~]# mkdir /etc/keepalived/[root@master ~]# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/[root@master ~]# cp /usr/local/keepalived/sbin/keepalived /usr/sbin/[root@master ~]# vi /etc/keepalived/keepalived.conf! Configuration File forkeepalivedglobal_defs {notification_email {test@sina.com }notification_email_from admin@test.comsmtp_server 127.0.0.1smtp_connect_timeout 30router_id MYSQL_HA #标识，双主相同 }vrrp_instance VI_1 { state BACKUP #两台都设置BACKUP interface eth0 virtual_router_id 51 #主备相同 priority 100 #优先级，backup设置90 advert_int 1 nopreempt #不主动抢占资源，只在master这台优先级高的设置，backup不设置 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.0.204 }}virtual_server 192.168.0.204 3306 { delay_loop 2 #lb_algo rr #LVS算法，用不到，我们就关闭了 #lb_kind DR #LVS模式，如果不关闭，备用服务器不能通过VIP连接主MySQL persistence_timeout 50 #同一IP的连接60秒内被分配到同一台真实服务器 protocol TCP real_server 192.168.0.202 3306 { #检测本地mysql，backup也要写检测本地mysql weight 3 notify_down /usr/local/keepalived/mysql.sh #当mysq服down时，执行此脚本，杀死keepalived实现切换 TCP_CHECK { connect_timeout 3 #连接超时 nb_get_retry 3 #重试次数 delay_before_retry 3 #重试间隔时间 }}[root@master ~]# vi /usr/local/keepalived/mysql.sh #!/bin/bashpkill keepalived[root@master ~]# chmod +x /usr/local/keepalived/mysql.sh[root@master ~]# /etc/init.d/keepalived start #backup服务器只修改priority为90、nopreempt不设置、real_server设置本地IP。 #授权两台Mysql服务器允许root远程登录，用于在其他服务器登陆测试！mysql&gt; grant all on . to’root’@’192.168.0.%’ identified by ‘123.com’;mysql&gt; flush privileges;3、测试高可用性1、通过Mysql客户端通过VIP连接，看是否连接成功。2、停止master这台mysql服务，是否能正常切换过去，可通过ip addr命令来查看VIP在哪台服务器上。wKiom1MJYbCBORSGAAHChWpI93k009.jpg3、可通过查看/var/log/messges日志，看出主备切换过程4、master服务器故障恢复后，是否主动抢占资源，成为活动服务器。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL主从配置]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F17.1-17.5%20MySQL%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[17.1 MySQL主从介绍MySQL主从又叫做Replication、AB复制。简单讲就是A和B两台机器做主从后，在A上写数据，另外一台B也会跟着写数据，两者数据实时同步的。也就是说，当你在A机器写入一个表，再次查看B机器也会同步一个表。 MySQL主从是基于binlog的，主上须开启binlog才能进行主从。主从过程大致有3个步骤： 主将更改操作记录到binlog里。 从将主的binlog事件(sql语句)同步到从本机上并记录在relaylog里。 从根据relaylog里面的sql语句按顺序执行 主上有一个log dump线程，用来和从的I/O线程传递binlog 从上有两个线程，其中I/O线程用来同步主的binlog并生成relaylog，另外一个SQL线程用来把relaylog里面的sql语句落地。 Master：主mysqlSlave：备mysql 当有数据写进主mysql中的时候，就出自动生成一个log dump thread，记录到如上讲的binlog中，然后从数据库就会和主mysql有个线程进行交互，从服务器就会读取binlog日志到Slave，然后再次生成一个relay log（中继日志），然后再次和从服务器中的SQL thread线程进程交互执行。 简单的说，就是从服务器把主服务器上的binlog弄到自己服务器上去，然后根据这个binlog生成自己的relay日志，根据这个relay日志进行更改数据库，最终达到两边数据一致。 主从的作用;1.数据的备份； 假如A服务器（主）突然硬件问题，宕机了。但是线上跑了很多重要的数据，我们完全可以使用B服务器（从）直接顶上。 2. 负载均衡； 我们线上的所有数据均是从A上面读取，由于压力比较大，我们可以使用B服务器分享一部分用户到自己的服务器，但是只是可以读，不可以写入数据。看图可知，数据的读取是有方向性的，如果首先从B上读取那就混乱了，数据肯定不一致了。就会导致主从失败！ 17.2 准备工作因为是实验环境，直接准备了一台虚拟机，装好MYSQL后，再克隆一台虚拟机，避免其他变量影响。 17.3 配置主编辑配置文件添加如下参数： 123456[root@localhost ~]# vim /etc/my.cnf……server-id=180#自定义log_bin=yuntai01#自定义定log前缀 编辑完成后重启mysql服务： 123[root@localhost ~]# /etc/init.d/mysqld restartShutting down MySQL...... SUCCESS! Starting MySQL.................. SUCCESS! 查看mysql库文件： 1234567891011121314[root@localhost ~]# ls -lt /data/mysql/总用量 110684-rw-rw----. 1 mysql mysql 50331648 12月 14 15:30 ib_logfile0-rw-rw----. 1 mysql mysql 12582912 12月 14 15:30 ibdata1-rw-rw----. 1 mysql mysql 56288 12月 14 15:30 localhost.localdomain.err-rw-rw----. 1 mysql mysql 5 12月 14 15:30 localhost.localdomain.piddrwx------. 2 mysql mysql 4096 12月 12 18:13 zrlog-rw-rw----. 1 mysql mysql 143 12月 12 17:45 yuntai.000001 #重要-rw-rw----. 1 mysql mysql 16 12月 12 12:07 yuntai.index #重要-rw-rw----. 1 mysql mysql 56 11月 7 17:27 auto.cnfdrwx------. 2 mysql mysql 4096 11月 7 17:24 mysqldrwx------. 2 mysql mysql 4096 11月 7 17:24 performance_schema-rw-rw----. 1 mysql mysql 50331648 11月 7 17:24 ib_logfile1drwx------. 2 mysql mysql 6 11月 7 17:23 test 说明： 重启后生成两个前缀为yuntai01的二进制文件是实现主从的重要文件。 新建一个数据库为试验做准备： 12345678910111213141516备份一个数据库：[root@localhost ~]# mysqldump -uroot -p123456 zrlog &gt; /tmp/zrlog.sqlWarning: Using a password on the command line interface can be insecure.新建几个数据库：[root@localhost ~]# mysql -uroot -p123456mysql&gt; create database yuntai01;Query OK, 1 row affected (0.00 sec)mysql&gt; create database yuntai02;Query OK, 1 row affected (0.00 sec)mysql&gt; quitBye将备份的数据恢复到新建的数据库中：[root@localhost mysql]# mysql -uroot -p123456 yuntaitest &lt; /tmp/test.sql 创建一个用于同步数据的用户： 1234567891011121314151617181920[root@localhost mysql]# mysql -uroot -p123456Welcome to the MySQL monitor.mysql&gt; grant replication slave on *.* to &apos;repl&apos;@&apos;192.168.2.181&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected (0.01 sec)#IP 192.168.2.181 为“从”的IPmysql&gt; flush tables with read lock;Query OK, 0 rows affected (0.12 sec)#锁定数据表（目的是暂时使其不能继续写，保持现有状态用于同步）mysql&gt; show master status;+-----------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-----------------+----------+--------------+------------------+-------------------+| yuntai01.000001 | 542 | | | |+-----------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec)#记住file和position(设置主从同步时会使用)mysql&gt; quitBye 查看当前的数据库，准备备份 123456[root@localhost ~]# cd /data/mysql[root@localhost mysql]# lsauto.cnf ib_logfile0 localhost.localdomain.err mysql test yuntai01 yuntai01.index yuntai.indexibdata1 ib_logfile1 localhost.localdomain.pid performance_schema yuntai.000001 yuntai01.000001 yuntai02 zrlog#我们的数据库：yuntai01 yuntai02 zrlog，我们把这几个数据库全部备份并同步。 备份主库中所有数据库： 123[root@localhost mysql]# mysqldump -uroot -p123456 zrlog &gt; /tmp/zrlog.sql[root@localhost mysql]# mysqldump -uroot -p123456 yuntai01 &gt; /tmp/yuntai01.sql[root@localhost mysql]# mysqldump -uroot -p123456 yuntai02 &gt; /tmp/yuntai02.sql 数据对比 123456789101112[root@localhost mysql]# ls -lt /tmp/*.sql-rw-r--r--. 1 root root 1262 12月 14 15:54 /tmp/yuntai02.sql-rw-r--r--. 1 root root 1262 12月 14 15:54 /tmp/yuntai01.sql-rw-r--r--. 1 root root 10072 12月 14 15:53 /tmp/zrlog.sql[root@localhost mysql]# ls -lt总用量 110692......drwx------. 2 mysql mysql 4096 12月 14 15:50 zrlogdrwx------. 2 mysql mysql 20 12月 14 15:38 yuntai02drwx------. 2 mysql mysql 20 12月 14 15:38 yuntai01...... 17.4 配置从编辑从MySQL的配置文件添加如下参数：配置server-id=181，要求和主不一样。bin_log就不需要配置了，二进制文件只需要在主服务器上面配置即可。 123456789[root@localhost ~]# vim /etc/my.cnf……server-id=181#添加到最后重启配置文件[root@localhost ~]# /etc/init.d/mysqld restartShutting down MySQL...... SUCCESS! Starting MySQL.............................. SUCCESS! 将主中备份的数据发送到从中1234567891011[root@localhost ~]# scp 192.168.2.180:/tmp/*.sql /tmp/ ##此IP为MySQL主的IP地址The authenticity of host &apos;192.168.2.180 (192.168.2.180)&apos; can&apos;t be established.ECDSA key fingerprint is 17:2a:d4:3f:ff:02:39:05:e4:c2:02:44:73:5e:88:64.Are you sure you want to continue connecting (yes/no)? yes#输入yesWarning: Permanently added &apos;192.168.2.180&apos; (ECDSA) to the list of known hosts.root@192.168.2.180&apos;s password: #输入180机器的root密码yuntai01.sql 100% 1262 1.2KB/s 00:00 yuntai02.sql 100% 1262 1.2KB/s 00:00 zrlog.sql 100% 10KB 9.8KB/s 00:00 配置MySQL123456789101112配置MySQL环境[root@localhost ~]# export PATH=$PATH:/usr/local/mysql/bin/#这是将命令路径暂时加入环境变量，系但是统重启后该变量会失效，最好将其加入环境变量配置文件[root@localhost ~]# vim /etc/profile…… #添加export PATH=$PATH:/usr/local/mysql/bin/[root@localhost ~]# source /etc/profile //刷新刚刚的配置文件，否则不生效制定账户，设置密码[root@localhost ~]# mysqladmin -uroot password &apos;123456&apos; 创建对应的MySQL库12345678910111213141516171819202122232425[root@localhost ~]# mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 5Server version: 5.6.35 MySQL Community Server (GPL)Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; create database yuntai01;Query OK, 1 row affected (0.00 sec)mysql&gt; create database yuntai02;Query OK, 1 row affected (0.00 sec)mysql&gt; create database zrlog;Query OK, 1 row affected (0.00 sec)mysql&gt; quitBye 恢复数据库12345678910111213141516171819[root@localhost ~]# mysql -uroot -p123456 zrlog&lt; /tmp/zrlog.sql [root@localhost ~]# mysql -uroot -p123456 yuntai01&lt; /tmp/yuntai01.sql [root@localhost ~]# mysql -uroot -p123456 yuntai02&lt; /tmp/yuntai02.sql [root@localhost mysql]# mysql -uroot -p123456mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test || yuntai01 || yuntai02 || zrlog |+--------------------+7 rows in set (0.08 sec) 配置从服务器12345678mysql&gt; stop slave;Query OK, 0 rows affected, 1 warning (0.00 sec)重要步骤mysql&gt; change master to master_host=&apos;192.168.2.180&apos;, master_user=&apos;repl&apos;, master_password=&apos;123456&apos;, master_log_file=&apos;yuntai01.000001&apos;, master_log_pos=542;Query OK, 0 rows affected, 2 warnings (0.06 sec)# master_host：主MySQL IP、master_user：主MySQL上交互用的用户名# master_log_file：主服务器上面show master status的文件名、master_log_pos：show master status的position值 检测主从是否建立成功 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; show slave status\G #成功的话会显示如下内容*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.2.180 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: yuntai01.000002 Read_Master_Log_Pos: 120 Relay_Log_File: localhost-relay-bin.000005 Relay_Log_Pos: 282 Relay_Master_Log_File: yuntai01.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 120 Relay_Log_Space: 11178 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 180 Master_UUID: d14c4924-c39d-11e7-93c6-000c2914f61b Master_Info_File: /data/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 01 row in set (0.00 sec) 123456mysql&gt; show slave status\G 看是否有Slave_IO_Running: YesSlave_SQL_Running: Yes还需关注Seconds_Behind_Master: 0 //为主从延迟的时间Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it 配置中出现过的错误 12345678910111213141516171819 Slave_IO_Running: No Slave_SQL_Running: YesSeconds_Behind_Master: NULLMaster_SSL_Verify_Server_Cert: No Last_IO_Errno: 1593 Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server UUIDs; these UUIDs must be different for replication to work.#报错中也有显示主要原因是5.6中引入了UUID的概念，各个mysql service的uuid要保证不能一样。[root@localhost ~]# cd /data/mysql/[root@localhost mysql]# lsauto.cnf ib_logfile0 localhost.localdomain.err localhost-relay-bin.000002 master.info performance_schema test yuntai02ibdata1 ib_logfile1 localhost.localdomain.pid localhost-relay-bin.index mysql relay-log.info yuntai01 zrlog[root@localhost mysql]# vim auto.cnf [auto]server-uuid=d14c4924-c39d-11e7-93c6-000c2914f68b #随意改动2个字母或数字后保存[root@localhost mysql]# /etc/init.d/mysqld restart 到主服务器解开锁表123[root@localhost mysql]# mysql -uroot -p123456mysql&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) 到这里，MySQL的主从配置就完成了。 ##17.5 测试主从同步 参数介绍1234567891011121314主服务器:binlog-do-db= //仅同步指定的库binlog-ignore-db= //忽略指定的库从服务器：replicate_do_db= //同步指定的库replicate_ignore_db= //忽略指定的库replicate_do_table= //同步指定的表replicate_ignore_table= //忽略指定的表#建议只使用下面2个语句，使用参数“replicate_wild_”，使匹配更精确，提升使用性能。replicate_wild_do_table= 如yuntai.%，支持通配符 replicate_wild_ignore_table= #如果想定义的话，将上面语句写入Mysql的my.cnf配置文件中 假如在主服务器上面有很多数据库，但是我只想同步yuntai01这个库 1234# vim /etc/my.cnf......binlog-do-db=yuntai01要是多个的话就用英文状态下的逗号去分隔； 或者有时候数据库比较多，我就一个yuntai02库不需要同步 123# vim /etc/my.cnf......binlog-ignore-db=yuntai02 有时候我们需要在同步的时候忽略一些临时的表，这些表对我们的用处不大。我们可以在从服务器上编辑 123# vim /etc/my.cnf......replicate_wild_do_table=yuntai01.%,yuntai02.% 开始测试主操作123456789101112131415161718mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test || yuntai01 || yuntai02 || zrlog |+--------------------+7 rows in set (0.00 sec)mysql&gt; use yuntai01Database changedmysql&gt; show tables;Empty set (0.00 sec) 从操作，查看相同数据情况123456同上，略mysql&gt; use yuntai01Database changedmysql&gt; show tables;Empty set (0.00 sec) 主上，尝试往yuntai01库导入内容12345678910111213141516171819202122232425262728293031323334353637383940414243444546mysql&gt; quitBye[root@localhost mysql]# mysql -uroot -p123456 yuntai01 &lt; /tmp/zrlog.sqlWarning: Using a password on the command line interface can be insecure.[root@localhost mysql]# mysql -uroot -p123456Warning: Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 9398Server version: 5.6.35-log MySQL Community Server (GPL)Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; use yuntai01;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+--------------------+| Tables_in_yuntai01 |+--------------------+| comment || link || log || lognav || plugin || tag || type || user || website |+--------------------+9 rows in set (0.00 sec)mysql&gt; select count(*) plugin;+--------+| plugin |+--------+| 1 |+--------+1 row in set (0.00 sec) 再次去从上查看12345678同上，略mysql&gt; select count(*) plugin;+--------+| plugin |+--------+| 1 |+--------+1 row in set (0.01 sec) 主上删除表格plugin12mysql&gt; drop table plugin;Query OK, 0 rows affected (0.00 sec) 从上查看表格plugin12345678910111213141516mysql&gt; show tables;+--------------------+| Tables_in_yuntai01 |+--------------------+| comment || link || log || lognav || tag || type || user || website |+--------------------+8 rows in set (0.00 sec)plugin表格果然没有了！ 表示测试成功，mysql的确同步了。 千万别在从server上面删除任何数据，一旦删除也就意味着数据不是一致的，主从就失败了！如果主从这么失败了，如何再次恢复呢？ 先把主server上面的数据与从server上面的数据保持一致，刚刚从server删除了什么数据，现在也需要把主server上面的数据也删除，为的就是数据一致！ 首先主server上面操作 123456789mysql&gt; show master status;+-----------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-----------------+----------+--------------+------------------+-------------------+| yuntai01.000001 | 10863 | | | |+-----------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec)记住Position值 从server上操作使用新的Postion值 12mysql&gt; stop slave;mysql&gt; change master to master_host=&apos;192.168.2.180&apos;, master_user=&apos;repl&apos;, master_password=&apos;123456&apos;, master_log_file=&apos;yuntai01.000001&apos;, master_log_pos=10863; 再次启动从，查看状态 123mysql&gt; start slave;mysql&gt; show slave status\G 具体思路 保证数据一致性的前提下，如上操作，如果主表格还在写入导致的数据不符，在不影响业务的情况下，可以锁主表 实在是数据不一致的前提下，建议直接重新备份，然后再次导入，再次change master即可]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Tomcat监听80端口、配置Tomcat虚拟主机、Tomcat日志]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F16.4-16.8%20%E9%85%8D%E7%BD%AETomcat%E7%9B%91%E5%90%AC80%E7%AB%AF%E5%8F%A3%E3%80%81%E9%85%8D%E7%BD%AETomcat%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E3%80%81Tomcat%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[16.4 配置Tomcat监听80端口编辑Tomcat配置文件123456[root@localhost ~]# vim /usr/local/tomcat/conf/server.xml ……#搜索8080，修改下面的内容位80&lt;Connector port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;…… 重启服务123[root@localhost ~]# /usr/local/tomcat/bin/shutdown.sh[root@localhost ~]# /usr/local/tomcat/bin/startup.sh 查看服务123456789101112[root@localhost ~]# ps aux |grep tomcat[root@localhost ~]# netstat -lntp |grep javatcp6 0 0 127.0.0.1:8005 :::* LISTEN 2716/java tcp6 0 0 :::8009 :::* LISTEN 2716/java [root@localhost ~]# netstat -lntp |grep 80tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 1825/nginx: master tcp6 0 0 127.0.0.1:8005 :::* LISTEN 2716/java tcp6 0 0 :::8009 :::* LISTEN 2716/java # 这时的Tomcat服务正常运行，但是没有监听端口。因为监听80端口的是nginx服务，如果想让Tomcat监听80端口，需要关闭nginx服务，然后重启Tomcat服务。 关闭服务，重启12345678[root@localhost ~]# systemctl stop nginx.service [root@localhost ~]# /usr/local/tomcat/bin/shutdown.sh[root@localhost ~]# /usr/local/tomcat/bin/startup.sh 检查[root@localhost ~]# netstat -lntp |grep javatcp6 0 0 :::80 :::* LISTEN 2815/java tcp6 0 0 :::8009 :::* LISTEN 2815/java 16.5/16.6/16.7 配置Tomcat虚拟主机每一个虚拟主机相当于一个域名，一个主机可以配置多个域名，多个网站。1234567891011121314151617[root@localhost ~]# vim /usr/local/tomcat/conf/server.xml //Tomcat的配置文件格式是xml和Apache的不一样#搜索&lt;/Host&gt;,在&lt;/Host&gt;下面增加如下内容：... ...&lt;/Host&gt;&lt;Host name=&quot;www.123.cn&quot; appBase=&quot;&quot; unpackWARs= &quot;true&quot; autoDeploy=&quot;true&quot; xmlValidation=&quot;false&quot; xmlNamespaceAware=&quot;false&quot;&gt; &lt;Context path=&quot;&quot; docBase=&quot;/data/wwwroot/123.cn/&quot; debug=&quot;0&quot; reloadable=&quot;true&quot; crossContext=&quot;true&quot;/&gt;#appbase是指定Tomcat的应用项目的位置（war文件：JAVA的应用）#unpackWARs是否自动解压WAR包#如果未使用appbase参数指定，可以使用docbase来指定应用存放目录#当这两个参数同时存在时，需要将其中一个写为空，以免相互干扰&lt;/Host&gt;&lt;/engine&gt;…… 其中和之间的配置为虚拟主机配置部分，name定义域名，appBase定义应用的目录，Java的应用通常是一个war的压缩包，你只需要将war的压缩包放到appBase目录下面即可。刚刚阿铭访问的Tomcat默认页其实就是在appBase目录下面，不过是在它子目录ROOT里。 docBase，这个参数用来定义网站的文件存放路径，如果不定义，默认是在appBase/ROOT下面，定义了docBase就以该目录为主了，其中appBase和docBase可以一样。在这一步操作过程中很多同学遇到过访问404的问题，其实就是docBase没有定义对。 appBase为应用存放目录，通常是需要把war包直接放到该目录下面，它会自动解压成一个程序目录 部署java站点1.下载站点程序zrlog1[root@localhost src]# wget http://dl.zrlog.com/release/zrlog-1.7.1-baaecb9-release.war 2.创建站点目录1[root@localhost src]# mkdir -p /data/wwwroot/123.cn/ 3.解压war包，并复制到自定义的站点目录12345678910[root@localhost src]# cp zrlog-1.7.1-baaecb9-release.war /usr/local/tomcat/webapps/#appbase支持自动解压war包的，将zrlog包放到appbase的指定目录下[root@localhost src]# ls /usr/local/tomcat/webapps/docs host-manager ROOT zrlog-1.7.1-baaecb9-release.warexamples manager zrlog-1.7.1-baaecb9-release#拷贝过去后，zrlog包会自动被解压，解压后就可以直接访问该文件。 [root@localhost src]# cd /usr/local/tomcat/webapps/ [root@localhost webapps]# mv zrlog-1.7.1-baaecb9-release zrlog //重命名 注意：zrlog-1.7.1-baaecb9-release的名字太长，实际使用不方便，我们把它的名字改为zrlog。因为删除war包或者更改war包的名字，appbase的指定目录下的解压内容的名字也会随之删除和更改 1234[root@localhost webapps]# mv zrlog/* /data/wwwroot/123.cn/[root@localhost webapps]# cd /data/wwwroot/123.cn/[root@localhost 123.cn]# lsadmin assets error favicon.ico include install META-INF WEB-INF 4.重启Tomcat12345[root@localhost 123.cn]# /usr/local/tomcat/bin/shutdown.sh[root@localhost 123.cn]# /usr/local/tomcat/bin/startup.sh``` #### 5.配置外部电脑的hosts文件打开C:\Program Files\Git\etc\hosts，在最下面写入 192.168.2.180 www.123.cn 123.cn 12345### 6.电脑浏览器访问，进入类似wordpress安装界面在浏览器输入IP：192.168.2.180或者www.123.cn进入安装向导 ### 7.在MySQL中创建zrlog数据库 [root@localhost ~]# mysql -uroot -p123456Welcome to the MySQL monitor.mysql&gt; create database zrlog; //创建数据库zrlogQuery OK, 1 row affected (0.00 sec) mysql&gt; grant all on zrlog.* to ‘zrlog’@’127.0.0.1’ identified by ‘123456’; //给zrlog库授权Query OK, 0 rows affected (0.00 sec) 123456789101112131415161718192021222324### 8.安装向导界面配置填写Zrlog - 安装向导 1.数据库 --- 2.网站信息 --- 3.完成 填写网站信息 管理员帐号：admin 管理员密码：123456 管理员邮箱：zhouqunic@qq.com 网站标题：yuntai linux zrlog 网站子标题：Are you OK? 下一步：完成### 9.成功安装成功后，会显示网站主页面，有问题会报错，根据提示解决。# 16.8 Tomcat日志## 日志的位置和作用 [root@host webapps]# ls /usr/local/tomcat/logscatalina.2017-10-08.log catalina.out host-manager.2017-10-08.log localhost.2017-10-08.log localhost_access_log.2017-10-08.txt manager.2017-10-08.log 1234567- 其中catalina开头的日志为Tomcat的综合日志，它记录Tomcat服务相关信息，也会记录错误日志。- 其中catalina.2017-xx-xx.log和catalina.out内容相同，前者会每天生成一个新的日志。- host-manager和manager为管理相关的日志，其中host-manager为虚拟主机的管理日志。- localhost和localhost_access为虚拟主机相关日志，其中带access字样的日志为访问日志，不带access字样的为默认虚拟主机的错误日志。## 开启生成 访问日志访问日志默认不会生成，需要在server.xml中配置一下。 具体方法是在对应虚拟主机的里面加入下面的配置（假如域名为123.cn）： #prefix定义访问日志的前缀， #suffix定义日志的后缀， #pattern定义日志格式。 新增加的虚拟主机默认并不会生成类似默认虚拟主机的那个localhost.日期.log日志，错误日志会统一记录到catalina.out中。 ## 注意 关于Tomcat日志，最需要关注catalina.out，当出现问题时，我们应该第一想到去查看它。 # 扩展 ## JAR、WAR包区别 http://blog.csdn.net/lishehe/article/details/41607725 ## tomcat常见配置汇总 http://blog.sina.com.cn/s/blog_4ab26bdd0100gwpk.html ## resin安装 http://fangniuwa.blog.51cto.com/10209030/1763488/]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat介绍、安装jdk、安装Tomcat]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F16.1-16.3%20Tomcat%E4%BB%8B%E7%BB%8D%E3%80%81%E5%AE%89%E8%A3%85jdk%E3%80%81%E5%AE%89%E8%A3%85Tomcat%2F</url>
    <content type="text"><![CDATA[16.1 Tomcat介绍 Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun 和其他一些公司及个人共同开发而成。由于有了Sun 的参与和支持，最新的Servlet 和JSP 规范总是能在Tomcat 中得到体现，Tomcat 5 支持最新的Servlet 2.4 和JSP 2.0 规范。因为Tomcat 技术先进、性能稳定，而且免费，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。目前最新版本是8.0。 Tomcat是Apache软件基金会（Apache Software Foundation）的Jakarta项目中的一个核心项目，由Apache、Sun和其他一些公司及个人共同开发而成。 java程序写的网站用tomcat+jdk来运行 tomcat是一个中间件，真正起作用的，解析java脚本的是jdk jdk（java development kit）是整个java的核心，它包含了java运行环境和一堆java相关的工具以及java基础库。 最主流的jdk为sun公司发布的jdk，除此之外，其实IBM公司也有发布JDK，CentOS上也可以用yum安装openjdk，我们这次要安装的是sun公司的jdk。 16.2 安装jdk因为Tomcat的安装需要jdk里面的一些包的支持，所以先安装jdk。我们先到sun公司的jdk官网下载相应的版本到本地主机，再用xftp传输到虚拟机中的/usr/local/src目录。 123jdk版本1.6，1.7，1.8jdk-8u144-linux-x64.tar.gz官网下载地址 http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 准备123456[root@host ~]# cd /usr/local/src/[root@host src]# wget http://download.oracle.com/otn-pub/java/jdk/8u144-b01/jdk-8u144-linux-x64.tar[root@host src]# tar zxvf jdk-8u144-linux-x64.gz //解压……[root@host src]# mv jdk1.8.0_144 /usr/local/jdk1.8[root@host src]# cd /usr/local/jdk1.8/ 编辑关于jdk的环境变量12345678910[root@host jdk1.8]# vim /etc/profile……#把下面几行添加到文件的最后面JAVA_HOME=/usr/local/jdk1.8/JAVA_BIN=/usr/local/jdk1.8/binJRE_HOME=/usr/local/jdk1.8/jrePATH=$PATH:/usr/local/jdk1.8/bin:/usr/local/jdk1.8/jre/binCLASSPATH=/usr/local/jdk1.8/jre/lib:/usr/local/jdk1.8/lib:/usr/local/jdk1.8/jre/lib/charset.jar刷新下环境变量：[root@host jdk1.8]# source /etc/profile 检测JDK是否安装成功：123456[root@host jdk1.8]# java -versionjava version &quot;1.8.0_144&quot;Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)#若该命令执行成功，且执行结果和安装信息一致，说明配置成功。 #若反馈的不是该命令，则说明有问题，可以卸载（前提是空的主机，如果是工作中的服务器，系统里面有其他程序在运行，就需要注意了） 16.3 安装Tomcat准备1234567891011121314下载Tomcat二进制包[root@host src]# cd /usr/local/src/[root@host src]# wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.23/bin/apache-tomcat-8.5.23.tar.gz或者 wget http://archive.apache.org/dist/tomcat/tomcat-8/v8.5.23/bin/apache-tomcat-8.5.23.tar.gz解压[root@host src]# tar zxf apache-tomcat-8.5.23.tar.gz[root@host src]# mv apache-tomcat-8.5.23 /usr/local/tomcat //移动文件并改名关闭防火墙[root@localhost ~]# systemctl stop firewalld[root@localhost ~]# systemctl disable firewalldRemoved symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.Removed symlink /etc/systemd/system/basic.target.wants/firewalld.service. 启动Tomcat1234567[root@host src]# /usr/local/tomcat/bin/startup.sh Using CATALINA_BASE: /usr/local/tomcatUsing CATALINA_HOME: /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME: /usr/local/jdk1.8Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jarTomcat started. 关闭Tomcat123456789101112[root@host src]# /usr/local/tomcat/bin/shutdown.sh Using CATALINA_BASE: /usr/local/tomcatUsing CATALINA_HOME: /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME: /usr/local/jdk1.8Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar[root@host src]# ps aux|grep tomcat //确认是否开启root 2692 47.4 7.6 2266388 77132 pts/0 Sl 11:44 0:02 /usr/local/jdk1.8/bin/java -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -classpath /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/usr/local/tomcat -Dcatalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap startroot 2709 0.0 0.0 112680 976 pts/0 R+ 11:44 0:00 grep --color=auto tomcatTomcat服务不支持restart 查看是否有java进程启动123456789[root@host src]# netstat -lntp |grep javatcp6 0 0 :::8080 :::* LISTEN 2569/java tcp6 0 0 127.0.0.1:8005 :::* LISTEN 2569/java tcp6 0 0 :::8009 :::* LISTEN 2569/java #三个端口：8080；8005；8009#8080为提供web服务的端口#8005为管理端口#8009端口为第三方服务调用的端口（比如httpd和Tomcat结合时会用到） 扩展java容器比较http://my.oschina.net/diedai/blog/271367http://www.360doc.com/content/11/0618/21/16915_127901371.shtml j2ee、j2se、ejb、javabean、serverlet、jsp之间关系http://blog.csdn.net/ququhu/article/details/73470 tomcat server.xml配置详解http://blog.csdn.net/yuanxuegui2008/article/details/6056754 tomcat常用数据库连接的方法http://wjw7702.blog.51cto.com/5210820/1109263]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samba服务配置]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F15.3%20samba%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Samba介绍这套 SMB软件能够让同一局域网内的 Unix 与 window 互相的分享数据！ 安装Samba1234567yum install -y samba samba-client samba-common或 yum -y install samba*Samba-common：这个套件则主要提供了 SAMBA 的主要设定档(smb.conf) 、 smb.conf 语法检验的测试程序 ( testparm )等等。samba：这个套件主要包含了 SAMBA 的主要 daemon档案 ( smbd 及 nmbd )、 SAMBA 的文件档 ( document )、以及其它与 SAMBA 相关的logrotate 设定文件及开机预设选项档案等。samba-client：这个套件则提供了当 Linux 做为SAMBA Client 端时，所需要的工具指令，例如挂载 SAMBA 档案格式的执行档 smbmount等等。 ==标注：Samab服务开启之前需要关闭两个服务，iptables防火墙（如果你熟悉可以不关闭，放行smb的端口即可，SAMBA服务TCP端口139,445 UDP端口 137,138）；selinux服务。== samba软件结构123456789/etc/samba/smb.conf #samba服务的主要配置文件/etc/samba/lmhosts #samba服务的域名设定，主要设置IP地址对应的域名，类似linux系统的/etc/hosts/etc/samba/smbusers #samba服务设置samba虚拟用户的配置文件/var/log/samba #samab服务存放日志文件/var/lib/samba/private/&#123;passdb.tdb,secrets.tdb&#125; #存放samba的用户账号和密码数据库文档 不需要账号密码访问的共享(security = share ) smb.conf配置文件分为两大类，一个全局设置参数，一个是文件共享设置参数 查看共享文件权限 12[root@test src]# ls -ld /usr/local/srcdrwxr--r--. 3 root root 137 2月 4 17:03 /usr/local/src 分配共享文件最大权限(window用户可以创建或上传文件到共享目录) 123[root@test src]# chmod 777 /usr/local/src[root@test src]# ls -ld /usr/local/srcdrwxrwxrwx. 3 root root 122 2月 4 16:36 /usr/local/src 设置smb.conf配置文件 123456789101112131415161718[global]workgroup = WORKGROUP #设置主机工作组server string = Samba Server Version %v #samba服务注释log level = 1 #设置日志文件安全级别为1log file = /var/log/samba/%m #设置日志文件名称，%m以IP地址为名称max log size = 50 #设置日志文件最大容量50KB，0表示不限制security = share #以share验证方式访问passdb backend = tdbsam #定义用户后台类型load printers = no #关闭打印共享功能cups options = raw #打印机选项[usershare]comment = Home Directories #共享文件描述path = /usr/local/src #共享路径browseable = yes #共享文件可以浏览writable = yes #共享文件可写guest ok = yes #允许guest用户访问 检查smb.conf配置文件是否有语法错误 123456789101112131415161718[root@test src]# testparm //如果报以下错Load smb config files from /etc/samba/smb.confrlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)WARNING: Ignoring invalid value &apos;share&apos; for parameter &apos;security&apos;Error loading services.--------------------------------------------解决方法:smb.conf配置文件参数需要做调整原来：security = share替换成:security = usermap to guest = Bad User 启动samba服务 1[root@test src]# systemctl start smb 查看samba端口，TCP端口139,445 UDP端口 137,138 12345[root@test src]# netstat -tlnp | grep mbdtcp 0 0 0.0.0.0:139 0.0.0.0:* LISTEN 3030/smbd tcp 0 0 0.0.0.0:445 0.0.0.0:* LISTEN 3030/smbd tcp6 0 0 :::139 :::* LISTEN 3030/smbd tcp6 0 0 :::445 :::* LISTEN 3030/smbd 测试 Windows系统操作： 在win系统打开运行输入 \\[samba server IP] 直接访问，不需要输入任何用户和密码 在windows上访问，发现可以登陆到samba服务器并且能够看到共享文件夹，但是无法进入该文件夹123解决方法：# chcon -t samba_share_t /usr/local/src //执行一下该命令即可# systemctl restart smb 需要输入账号和密码访问的共享(security = user) 创建samba用户之前必须先创建系统用户，系统用户和samba用户名一样，但密码可以设置成不一样 创建系统用户test01 12[root@test ~]# useradd test01[root@test ~]# passwd test01 //系统用户密码:666 把系统用户test01添加为samba用户并设置samba用户登录密码,并且把用户信息写入smbpasswd文件中 123456[root@test ~]# pdbedit -a -u test01 //samba用户密码:123[root@test ~]# ll /etc/samba/smbpasswd -rw-------. 1 root root 103 2月 5 00:20 /etc/samba/smbpasswd[root@test ~]# cat !$cat /etc/samba/smbpasswdtest01:1000:XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX:F0873F3268072C7B1150B15670291137:[U ]:LCT-5C58665C: 列出Samba用户列表 12[root@test ~]# pdbedit -Ltest01:1001: 删除samba服务中的某个用户 1# smbpasswd -x 用户名 设置smb.conf配置文件 1234567891011121314151617181920212223# See smb.conf.example for a more detailed config file or# read the smb.conf manpage.# Run &apos;testparm&apos; to verify the config is correct after# you modified it.[global] workgroup = WORKGROUP security = user server string = Samba Server Version %v log level = 1 passdb backend = smbpasswd //改用smbpasswd方式认证 log file = /var/log/samba/%m max log size = 50 load printers = no cups options = raw encrypt passwords = yes smb passwd file = /etc/samba/smbpasswd //密码文件路径[worker] comment = test page path = /usr/local/src browseable = yes writable = yes valid users = test01 //允许test01用户登录,多个用户用逗号分隔 启动samba 1# systemctl start smb 测试 Windows系统操作： 在win系统打开运行输入 \\[samba server IP] 直接访问，需要输入用户和smb密码登录 linux客户端挂载samba共享目录 需要注意的是挂载端也需要安装cifs相关的文件系统包 1234567[root@test ~]# yum install cifs*[root@test ~]# mount -t cifs -o username=job01 //192.168.187.130/worker /mnt //因为samba只限job01用户登录,所以指定用户即可,密码:888Password for job01@//192.168.187.130/worker: ***[root@test ~]# ll /mnt总用量 960drwxrwxrwx. 9 test01 test01 0 1月 26 21:17 nginx-1.12.1-rwxrwxrwx. 1 root root 981093 1月 26 21:15 nginx-1.12.1.tar.gz Linux开机自动挂载samba共享 12345678910111213[root@test ~]# vim /etc/fstab## /etc/fstab# Created by anaconda on Sun Jan 27 04:33:03 2019## Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=1a362d06-090d-40af-9a33-25398fb4eee2 / xfs defaults 0 0UUID=1dfcee31-8661-4d6b-8913-24ecc2a810d4 /boot xfs defaults 0 0UUID=3438d7c6-f830-4b41-bbed-8f7d5bebb271 swap swap defaults 0 0//192.168.187.130/worker /mnt cifs credentials=/etc/samba/cred.passwd 0 0 //新增这一条规则 新增密码文件,重启验证一下 1234[root@test ~]# vim /etc/samba/cred.passwdusername=job01password=888chmod og=-- /etc/samba/cred.passwd 如果采用免密码登录的方式 123456然后客户端挂载的时候需要注意，比如：# mount -t cifs //192.168.187.130/usershare /mnt Password for root@//172.18.201.6/mysql_data:还是会出现让输入密码的交互模式，你一回车就会挂载上了。有没有办法去掉这个输出呢？再加一个password参数就ok了。# mount -t cifs -o password //192.168.187.130/usershare /mnt Linux挂载windows共享123456789101112131415161718192021[root@test ~]# mount -o username=administrator //192.168.1.3/linux /mntPassword for administrator@//192.168.1.3/linux: ******[root@test ~]# ls /mnt[300dpi高清版]Python基础教程(第2版)_HD.pdf mongo-1.6.16.tgzapache-tomcat-8.5.20.tar.gz mongodb-1.3.0.tgzapr-1.5.2.tar.gz mysql-5.6.35-linux-glibc2.5-x86_64.tar.gzapr-util-1.5.4.tar.gz nc-1.84-24.el6.x86_64.rpmbaidu-nolimit_v1.0.1.crx nginx-1.12.1.tar.gzCentOS-7-x86_64-DVD-1611.iso openfire_4_2_3.tar.gzcentos-7-x86_64-minimal.tar.gz oracle 11gR2部署DG文档extundelete-0.2.4.tar.bz2 php-5.6.30.tar.gzFileZilla3271 phpredis-develop.zipfriends-网络 redis-4.0.1.tar.gzhttpd-2.4.27.tar.gz ruby-2.2.3.tar.gzjdk-8u144-linux-x64.tar.gz shell+ABS.pdfkernel-debuginfo-3.10.0-514.el7.x86_64.rpm 帮助文档(群友提供)kernel-debuginfo-common-x86_64-3.10.0-514.el7.x86_64.rpm 黑客入门全程图解.pdfkernel-devel-3.10.0-514.el7.x86_64.rpm 计算机电子书Linux Shell编程艺术.pdf 课程PPTmariadb-10.2.6-linux-glibc_214-x86_64.tar.gz 压缩原理memcache-2.2.3.tgz]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS的exportfs命令和客户端问题、FTP介绍、使用vsftpd搭建ftp]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F14.4%20-%2015.2%20NFS%E7%9A%84exportfs%E5%91%BD%E4%BB%A4%E5%92%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%97%AE%E9%A2%98%E3%80%81FTP%E4%BB%8B%E7%BB%8D%E3%80%81%E4%BD%BF%E7%94%A8vsftpd%E6%90%AD%E5%BB%BAftp%2F</url>
    <content type="text"><![CDATA[14.4 exportfs命令 exportfs 命令用来管理当前NFS共享的文件系统列表。 常用参数-a 全部挂载或者全部卸载-r 重新挂载-u 卸载某一个目录-v 显示共享目录 1exportfs -arv //服务端更改配置文件后，不重启服务，直接执行该命令就可以使更改后的配置文件生效。 以下操作在服务端上12345[root@localhost ~]# vim /etc/exports //增加/tmp/ 192.168.2.0/24(rw,sync,no_root_squash)[root@localhost ~]# exportfs -arv //不用重启nfs服务，配置文件就会生效#在重启nfs服务之前，需要先把所有挂载点卸载，否则将发生严重的程序错误，甚至会拖垮系统。 14.5 NFS客户端问题##NFS4版本在centos6中应用存在如下问题：客户端挂载共享目录后，不管是root用户还是普通用户，创建的新文件的属主、数组都为nobody。 解决方案方法1：只在客户端进行挂载时加上选项-o nfsvers=3 1[root@host ~]# monunt -t nfs -o nfsvers=3 192.168.2.130:/tmp/ /mnt/ 方法2：修改客户端和服务端的配置文件 12vim /etc/idmapd.conf#把配置文件中的“Domain = local.domain.com”改为“Domain = xxx.com”（此处xxx.com是自己随意定义），然后重启rpcidmapd服务（在centos7中直接重启rpcbind服务） 15.1 FTP介绍 FTP 是File Transfer Protocol（文件传输协议）的英文简称，而中文简称为“文传协议”。用于Internet上的控制文件的双向传输。同时，它也是一个应用程序（Application）。基于不同的操作系统有不同的FTP应用程序，而所有这些应用程序都遵守同一种协议以传输文件。在FTP的使用当中，用户经常遇到两个概念：”下载”（Download）和”上传”（Upload）。”下载”文件就是从远程主机拷贝文件至自己的计算机上；”上传”文件就是将文件从自己的计算机中拷贝至远程主机上。用Internet语言来说，用户可通过客户机程序向（从）远程主机上传（下载）文件。 FTP是File Transfer Protocol（文件传输协议，简称文传协议）的英文简称，用于在Internet上控制文件的双向传输。 FTP的主要作用就是让用户连接一个远程计算机（这些计算机上运行着FTP服务器程序），并查看远程计算机中的文件，然后把文件从远程计算机复制到本地计算机，或把本地计算机的文件传送到远程计算机。 小公司用的多，大企业不用FTP，因为不安全 15.2/15.3 使用vsftpd搭建ftp安装vsftpd工具centos上自带vsftpd 1[root@host ~]# yum install -y vsftpd 创建用户12[root@host ~]# useradd -s /sbin/nologin virftp#创建一个vsftpd服务的普通用户进行传输数据，避免使用root用户导致安全问题。 配置虚拟用户密码文件12345[root@host ~]# vim /etc/vsftpd/vsftpd_login //内容如下,奇数行为用户名，偶数行为密码，多个用户就写多行testuser1123456[root@host ~]# chmod 600 /etc/vsftpd/vsftpd_login //更改文件的权限 密码转换将密码转换成二进制文件，使电脑可以识别 1[root@host ~]# db_load -T -t hash -f /etc/vsftpd/vsftpd_login /etc/vsftpd/vsftpd_login.db 配置1234567891011121314151617181920212223[root@host ~]# mkdir /etc/vsftpd/vsftpd_user_conf //创建存放目录[root@host ~]# cd /etc/vsftpd/vsftpd_user_conf [root@host vsftpd_user_conf]# vim testuser1 //指定虚拟用户的 配置文件，虚拟用户配置文件和虚拟用户名称需要保持一致。local_root=/home/virftp/testuser1#定义虚拟用户家目录anonymous_enable=NO#是否允许匿名用户登录write_enable=YES#是否可写local_umask=022#定义创建新文件时的默认权限anon_upload_enable=NO#是否允许匿名用户上传文件anon_mkdir_write_enable=NO#是否允许匿名用户创建目录文件idle_session_timeout=600#空闲用户保留时间data_connection_timeout=120#数据传输超时时间max_client=10#客户端最大连接数量 创建虚拟用户家目录12345[root@host vsftpd_user_conf]# mkdir /home/virftp/testuser1创建一个文件：[root@host vsftpd_user_conf]# touch /home/virftp/testuser1/123.txt[root@host vsftpd_user_conf]# chown -R virftp:virftp /home/virftp 虚拟用户密码匹配1234[root@host vsftpd_user_conf]# vim /etc/pam.d/vsftpd //添加这两行内容，用于指定用户的密码文件位置#%PAM-1.0auth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd_loginaccount sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login 编辑vsftpd主配置文件12345678910111213141516[root@host vsftpd_user_conf]# vim /etc/vsftpd/vsftpd.conf……anonymous_enable=NOanon_upload_enable=NOanon_mkdir_write_enable=NO……在文件内容最后添加如下内容： chroot_local_user=YESguest_enable=YESguest_username=virftp#开启虚拟用户和系统用户的映射virtual_use_local_privs=YES#使用虚拟用户user_config_dir=/etc/vsftpd_user_confallow_writeable_chroot=YES 启动FTP服务12345678[root@host vsftpd_user_conf]# systemctl start vsftpd[root@host vsftpd_user_conf]# ps aux |grep vsftpdroot 3671 0.0 0.0 52708 564 ? Ss 18:40 0:00 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf[root@host vsftpd_user_conf]# netstat -lntpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp6 0 0 :::21 :::* LISTEN 3671/vsftpd 测试 在Windows系统进行测试，需要安装filezilla软件。 在Linux中测试，安装lftp工具。 1[root@host ~]# yum install -y lftp 用法 12345678910111213[root@host ~]# lftp testuser1@127.0.0.1口令: #登录lftp testuser1@127.0.0.1:~&gt; ls drwxr-xr-x 2 1002 1002 22 Aug 24 10:19 testuser1lftp testuser1@127.0.0.1:/&gt; ?#查询在lftp中可执行的命令#常用命令：put、getlftp testuser1@127.0.0.1:/&gt; get testuser1/123.txtlftp testuser1@127.0.0.1:/&gt; quit[root@host ~]# ls123.txt anaconda-ks.cfg //下载文件成功]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>NFS</tag>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS的介绍、服务端安装配置、配置选项]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F14.1%20-%2014.3%20NFS%E7%9A%84%E4%BB%8B%E7%BB%8D%E3%80%81%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E3%80%81%E9%85%8D%E7%BD%AE%E9%80%89%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[14.1 NFS介绍 NFS（Network File System）即网络文件系统，是FreeBSD支持的文件系统中的一种，它允许网络中的计算机之间通过TCP/IP网络共享资源。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样。 NFS是Network File System的缩写 NFS最早由Sun公司开发，分2,3,4三个版本，2和3由Sun起草开发，4.0开始Netapp公司参与并主导开发，最新为4.1版本 NFS数据传输基于RPC协议，RPC为Remote Procedure Call的简写。 NFS应用场景是：A,B,C三台机器上需要保证被访问到的文件是一样的，A共享数据出来，B和C分别去挂载A共享的数据目录，从而B和C访问到的数据和A上的一致 14.2 NFS服务端安装配置准备两台虚拟机，一台作为服务端，一台作为客户端。 服务端(IP：192.168.2.130)安装NFS工具1[root@localhost ~]# yum install -y nfs-utils rpcbind 配置1234567[root@localhost ~]# vim /etc/exports/home/nfstestdir 192.168.2.0/24(rw,sync,all_squash,anonuid=1000,anongid=1000)#指定要进行分享的目录；指定要共享该目录的机器创建要分享的目录并设置好权限：[root@localhost ~]# mkdir /home/nfstestdir[root@localhost ~]# chmod 777 /home/nfstestdir 启动NFS服务1234[root@localhost ~]# systemctl start nfs[root@localhost ~]# systemctl enable nfs //把NFS服务加入开机启动项#NFS服务的后台服务进程为rpcbind服务（在服务端进程名称为systemd），默认的监听端口是111 客户端（IP：192.168.2.131）安装NFS工具1[root@host ~]# yum install -y nfs-utils 检查检查客户端是否有权限访问服务端文件 123456789101112[root@host ~]# showmount -e 192.168.2.130clnt_create: RPC: Port mapper failure - Unable to receive: errno 113 (No route to host) //报错，无法连接到服务器解决办法1. 检查服务端rpcbind服务是否开启，111端口是否在监视2. 如果服务端rpcbind服务已经开启，那么一般都是防火墙的原因，关闭服务端和客户端firewalld和SELinux防火墙关闭防火墙后，再次检查[root@host ~]# showmount -e 192.168.2.130Export list for 192.168.2.130:/home/nfstestdir 192.168.2.0/24#检查链接OK，通过 挂载客户端12345[root@host ~]# mount -t nfs 192.168.2.130:/home/nfstestdir /mnt/[root@host ~]# df -h文件系统 容量 已用 可用 已用% 挂载点192.168.2.130:/home/nfstestdir 18G 7.5G 11G 42% /mnt 测试在客户端挂载目录，创建一个文件 1234[root@host ~]# cd /mnt/[root@host mnt]# ll总用量 0-rw-r--r-- 1 mysql mysql 0 9月 18 22:50 test000 查看服务端的共享目录，是否同步了该文件 123[root@localhost ~]# ll /home/nfstestdir/总用量 0-rw-r--r-- 1 mysql mysql 0 9月 18 22:50 test000 表示同步成功，实现了跨服务器的共享。 14.3 NFS配置选项服务端12345678910[root[@localhost ~]# vim /etc/exports/home/nfstestdir 192.168.2.0/24(rw,sync,all_squash,anonuid=1000,anongid=1000)#&#123;rw 读写ro 只读sync 同步模式，内存数据实时写入磁盘async 非同步模式no_root_squash 客户端挂载NFS共享目录后，root用户不受约束，权限很大root_squash 与上面选项相对，客户端上的root用户收到约束，被限定成某个普通用户all_squash 客户端上所有用户在使用NFS共享目录时都被限定为一个普通用户anonuid/anongid 和上面几个选项搭配使用，定义被限定用户的uid和gid&#125; 固定NFS启动端口，便于iptables设置NFS 的防火墙特别难设定规则，为什么呢？因为除了固定的port 111, 2049 之外， 还有很多不固定的端口是由rpc.mountd, rpc.rquotad 等服务所开启的。因此我们需要在/etc/sysconfig/nfs 指定特定的端口，这样每次启动nfs 时，相关服务启动的端口就会固定，如此一来， 我们就能够设定正确的防火墙了！ 12345678910111213141516171819202122232425262728[root@nfs-01 ~]# rpcinfo -p localhost program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100024 1 udp 43265 status 100024 1 tcp 50310 status 100005 1 udp 20048 mountd 100005 1 tcp 20048 mountd 100005 2 udp 20048 mountd 100005 2 tcp 20048 mountd 100005 3 udp 20048 mountd 100005 3 tcp 20048 mountd 100003 3 tcp 2049 nfs 100003 4 tcp 2049 nfs 100227 3 tcp 2049 nfs_acl 100003 3 udp 2049 nfs 100003 4 udp 2049 nfs 100227 3 udp 2049 nfs_acl 100021 1 udp 46936 nlockmgr 100021 3 udp 46936 nlockmgr 100021 4 udp 46936 nlockmgr 100021 1 tcp 43528 nlockmgr 100021 3 tcp 43528 nlockmgr 100021 4 tcp 43528 nlockmgr 只有固定端口nfs 2049、portmapper111 ，另外3个服务端口可设置为mountd 892、rpc.statd 662、 nlockmgr 32803、32769。我们为了好设置iptables规则，把它们设为10001 - 10005。 1.vim /etc/sysconfig/nfs文件，将下列内容的注释去掉，如果没有则添加： 12345678910# Port rpc.mountd should listen on.MOUNTD_PORT=10001## Optional arguments passed to rpc.statd. See rpc.statd(8)STATDARG=&quot;&quot;# Port rpc.statd should listen on.STATD_PORT=10002# Outgoing port statd should used. The default is port# is randomSTATD_OUTGOING_PORT=10003 vim /etc/modprobe.d/lockd.conf，去掉 # 1234567# Set the TCP port that the NFS lock manager should use.# port must be a valid TCP port value (1-65535).options lockd nlm_tcpport=10004## Set the UDP port that the NFS lock manager should use.# port must be a valid UDP port value (1-65535).options lockd nlm_udpport=10005 设置完成以后，重启服务器才可以重置端口。 设置iptables 123456iptables -A INPUT -p tcp --dport 111 -j ACCEPTiptables -A INPUT -p udp --dport 111 -j ACCEPTiptables -A INPUT -p tcp --dport 2049 -j ACCEPTiptables -A INPUT -p udp --dport 2049 -j ACCEPTiptables -A INPUT -p tcp --dport 10001:10005 -j ACCEPTiptables -A INPUT -p udp --dport 10001:10005 -j ACCEPT NFS iptables规则https://stackoverflow.com/questions/26187345/iptables-rules-for-nfs-server-and-nfs-client]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>NFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql用户管理、常用sql语句、mysql数据库备份恢复]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F13.4%20-%2013.6%20mysql%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%E3%80%81%E5%B8%B8%E7%94%A8sql%E8%AF%AD%E5%8F%A5%E3%80%81mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[13.4 mysql用户管理因为日常使用中，需要给人员的权限进行限制，所以需要对用户进行管理。 创建用户并授权 指定登录IP 1234567891011[root@host ~]# mysql -uroot -pEnter password: Welcome to the MySQL monitor.mysql&gt; grant all on *.* to &apos;user1&apos;@&apos;127.0.0.1&apos; identified by &apos;123456&apos;;#创建user1用户并授予其所有权限“*.*”（通配符）#第一个*表示db_name；第二个*表示tb_name#同时指定其来源IP127.0.0.1（即，只可通过此IP登录）#此处可以使用通配符%，代表所有IP（一般不使用）#设定密码：identified bymysql&gt; quitBye 指定登录socket 1234567[root@host ~]# mysql -uroot -pEnter password: Welcome to the MySQL monitor.mysql&gt; grant all on *.* to &apos;user2&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected (0.01 sec)mysql&gt; quitBye 用户登录 指定的IP用户登录 1234[root@host ~]# mysql -uuser1 -p123456 -h127.0.0.1Welcome to the MySQL monitor.mysql&gt; quitBye 指定的socket登录 1234[root@host ~]# mysql -uuser2 -p&apos;123456&apos;Welcome to the MySQL monitor. mysql&gt; exitBye 因为指定登录主机为localhost，所以该用户默认使用（监听）本地mysql.socket文件，不需要指定IP即可登录。 针对具体的权限进行授权123456789[root@host ~]# mysql -uroot -p&apos;123456&apos;Welcome to the MySQL monitor.mysql&gt; create database db1;Query OK, 1 row affected (0.04 sec)mysql&gt; grant SELECT,UPDATE,INSERT on db1.* to &apos;user2&apos;@&apos;113.83.64.114&apos; identified by &apos;123456&apos;;#创建user2用户，并授予其针对db1库SELECT,UPDATE,INSERT权限mysql&gt; grant all on db1.* to &apos;user3&apos;@&apos;%&apos; identified by &apos;123456&apos;;#创建user3，并针对所有IP授予其db1库所有权限 查看授权1234567[root@host ~]# mysql -uroot -p&apos;123456&apos;Welcome to the MySQL monitor.mysql&gt; show grants;#查看当前用户的权限mysql&gt; show grants for user2@113.83.64.114;#查看指定用户的权限 更改权限123456789101112131415161718[root@host ~]# mysql -uroot -p&apos;123456&apos;Welcome to the MySQL monitor.mysql&gt; GRANT USAGE ON *.* TO &apos;user2&apos;@&apos;127.0.0.1&apos; IDENTIFIED BY PASSWORD &apos;*6BB4837EB743291105EE4568DDA7DC67ED2CA2AD9&apos;;Query OK, 0 rows affected (0.03 sec)mysql&gt; GRANT SELECT, INSERT, UPDATE ON `db1`.* TO &apos;user2&apos;@&apos;127.0.0.1&apos;;Query OK, 0 rows affected (0.00 sec)mysql&gt; show grants for user2@127.0.0.1;+--------------------------------------------------------------------------------------------------------------+| Grants for user2@127.0.0.1 |+--------------------------------------------------------------------------------------------------------------+| GRANT USAGE ON *.* TO &apos;user2&apos;@&apos;127.0.0.1&apos; IDENTIFIED BY PASSWORD &apos;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9&apos; || GRANT SELECT, INSERT, UPDATE ON `db1`.* TO &apos;user2&apos;@&apos;127.0.0.1&apos; |+--------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec)mysql&gt; quitBye 13.5 常用sql语句12345678910select count(*) from mysql.user; //查看指定库的内容的行数select * from mysql.db\G; //查看库的所有内容select db from mysql.db; //查看库指定内容select db,user from mysql.db; //select * from mysql.db where host like &apos;192.168.%&apos;\G; //查看某些IP对应的库内容，like表示匹配 (模糊查询)insert into db1.t1 values (1, &apos;abc&apos;); //在db1库t1表里插入内容（1,abc）update db1.t1 set name=&apos;aaa&apos; where id=1; //更新表格里所有id为1的表，把name内容更改为aaatruncate table db1.t1; //清空一个表，留下表的格子drop table db1.t1; //删除一个表drop database db1; //删除一个库 13.6 mysql数据库备份恢复123456备份库 mysqldump -uroot -p123456 db1&gt; /tmp/db1.sql恢复库 mysql -uroot -p123456 db1 &lt; /tmp/db1.sql备份表 mysqldump -uroot -p123456 db1 t1 &gt; /tmp/user.sql恢复表 mysql -uroot -p123456 db1 &lt; /tmp/t1.sql备份所有库 mysqldump -uroot -p -A &gt;/tmp/123.sql只备份表结构 mysqldump -uroot -p123456 -d mysql &gt; /tmp/mysql.sql 扩展SQL语句教程http://blog.51cto.com/zt/206 什么是事务？事务的特性有哪些？概念事务(Transaction)是访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。事务通常由高级数据库操纵语言或编程语言（如SQL，C++或Java）书写的用户程序的执行所引起，并用形如begin transaction和end transaction语句（或函数调用）来界定。事务由事务开始(begin transaction)和事务结束(end transaction)之间执行的全体操作组成。例如：在关系数据库中，一个事务可以是一条SQL语句，一组SQL语句或整个程序。 特性 事务是恢复和并发控制的基本单位。 事务应该具有4个属性：原子性、一致性、隔离性、持续性。这四个属性通常称为ACID特性。 原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的操作要么都做，要么都不做。 一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。 根据binlog恢复指定时间段的数据如果不小心对数据库进行误操作，而又没有及时备份怎么办？这恐怕是广大的coder经常遇到的一类问题。我今天就因为不小心删除了某个数据库，但最后的备份是1个礼拜前的，唯一能解决的办法就是通过mysqlbinlog来恢复了。解决方案如下： 如果MySQL服务器启用了二进制日志，你可以使用mysqlbinlog工具来恢复从指定的时间点开始(例如，从你最后一次备份)直到现在或另一个指定的时间点的数据。关于启用二进制日志的信息，参见5.11.3节，“二进制日志”。对于mysqlbinlog的详细信息，参见mysql手册8.6节，“mysqlbinlog：用于处理二进制日志文件的实用工具”。要想从二进制日志恢复数据，你需要知道当前二进制日志文件的路径和文件名。一般可以从配置文件(一般情况，Linux下为my.cnf ，windows系统下为my.ini，取决于你的系统)中找到路径。如果未包含在选项文件中，当服务器启动时，可以在命令行中以选项的形式给出。启用二进制日志的选项为–log-bin。要想确定当前的二进制日志文件的文件名，输入下面的MySQL语句： 1SHOW BINLOG EVENTS \G; 或者还可以从命令行输入下面的内容： 1mysql –user=root -pmypasswd -e ‘SHOW BINLOG EVENTS \G’ 将密码mypasswd替换为你的MySQL服务器的root密码。 比如得到的日志文件名为： 1mysql-bin.000001 1. 指定恢复时间 对于MySQL5.1.54，可以在mysqlbinlog语句中通过–start-date和–stop-date选项指定DATETIME格式的起止时间。 举例说明，比如在今天下午14:02(今天是2012年3月15日)，不小心执行SQL语句删除了一个数据表，但发现没有最新的备份（当然，这只是开发环境，并不是正式的生产环境，正式环境还得定时做数据备份）。要想恢复表和数据，可以通过mysqlbinlog恢复指定时间的备份，输入： 1mysqlbinlog –stop-date=”2012-03-15 14:02:00″ /data1/log/mysql/mysql-bin.000001 | mysql -u root -pmypasswd 该命令将恢复截止到在–stop-date选项中以DATETIME格式给出的日期和时间的所有数据。 如果你没有检测到输入的错误的SQL语句，可能你想要恢复后面发生的数据库活动。根据这些，你可以用起使日期和时间再次运行mysqlbinlog： 1mysqlbinlog –start-date=”2012-03-15 00:01:00″ /data1/log/mysql/mysql-bin.000001 | mysql -u root -pmypasswd 在该行中，从今天凌晨0:01登录的SQL语句将运行，组合执行前夜的转储文件和mysqlbinlog的两行可以将所有数据恢复到今天凌晨0:01前一秒钟。你应检查日志以确保时间确切。 指定时间段恢复 通过mysqlbinlog –start-date 和–stop-date恢复指定时间段的数据库活动记录，如下：1mysqlbinlog –start-date=”2012-03-09 02:00:00″ –stop-date=”2012-03-15 14:00:00″ /data1/log/mysql/mysql-bin.000001 &gt; /tmp/mysql_restore_030915.sql 通过这种方式，就能获取最后一个备份的文件时间2012-03-09 02:00:00到今天删除数据库之前2012-03-15 14:02这段时间的数据库活动事务操作 mysql字符集调整http://xjsunjie.blog.51cto.com/999372/1355013 使用xtrabackup备份innodb引擎的数据库innodb引擎的数据库可以使用mysqldump备份，如果表很大几十个G甚至上百G，显示用mysqldump备份会非常慢。然后使用xtrabackup 可以很快的在线备份innodb数据库。InnoDB 有个商业的InnoDB Hotbackup，可以对InnoDB引擎的表实现在线热备。而 percona出品的Xtrabackup，是InnoDB Hotbackup的一个开源替代品，可以在线对InnoDB/XtraDB引擎的表进行物理备份。 innobackupex是参考了InnoDB Hotbackup的innoback脚本修改而来的，主要是为了方便的同时备份InnoDB和MyISAM引擎的表，并且加入了一些使用的选项，如 –slave-info可以记录备份恢复后，作为slave需要的一些信息，根据这些信息，可以很方便的利用备份来重做slave。最新下载地址如下：http://www.percona.com/mysql/xtrabackup/0.7/安装如下： 1234tar zxf xtrabackup-0.7.tar.gz cd xtrabackup-0.7 ./configure make 千万不要make install 而是要接着下面的步骤操作。 123cd innobase/xtrabackup/ make make install 然后，就会在你的/usr/bin目录里安装上两个工具：xtrabackup，innobackupex-1.5.1 xtrabackup可以在不加锁的情况下备份innodb数据表，不过此工具不能操作myisam。innobackupex-1.5.1是一个脚本封装，能同时处理innodb和myisam，但在处理myisam时需要加一个读锁。 1/usr/bin/xtrabackup --backup --target-dir=/backup/mysqlbackup 这里的target-dir 就是要备份到的目录，这个工具不用指定数据库名的，默认会把所有innodb引擎的数据库全部备份。等备份完了，你会看到 target-dir 下会有所有innodb引擎的库，但是奇怪的是并没有备份 .frm 的文件，这个没有关系，需要你手动拷贝一份即可。 至于恢复，拷贝回去就ok啦。 innobackupex 备份 Xtrabackup 增量备份Mysql增量备份Xtrabackup中包含两个工具：• xtrabackup - 用于热备份innodb, xtradb表的工具，不能备份其他表(MYISAM表)。• innobackupex - 对xtrabackup封装的perl脚本，提供了myisam表备份的能力。（能进行整库和数据表备份）。*注：备份恢复之前请做好全库备份安装Xtrabackup官网网址http://www.percona.com/doc/percona-xtrabackup/index.html安装配置文件中需要添加 datadir = /usr/local/mysql/datadir //MYSQL数据文件目录 1、自动安装 YUM 源后，用YUM安装 123yum install -y gnupgrpm -Uhv http://www.percona.com/downloads/percona-release/percona-release-0.0-1.x86_64.rpm yum install -y percona-xtrabackup 2、手动写入YUM源新建文件 /etc/yum.repos.d/Percona.repo 123456[percona]name = CentOS $releasever - Perconabaseurl=http://repo.percona.com/centos/$releasever/os/$basearch/enabled = 1gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-perconagpgcheck = 1 之后YUM安装 ，安装后可执行xtrabackup -v 查看之后可以用xtrabackup 备份 一、innobackupex 备份全库备份主程序为 /usr/bin/innobackupex-1.5.1，其需要从 mysql 配置文件中读取相关信息，Mysql缺省配置文件 my.cnf 中未配置 datadir 选项，必须显性添加，否则备份程序会报错： innobackupex:: Warning: Ignored unrecognized line 2 in options : ‘xtrabackup: Error: Please set parameter ‘datadir’在论坛Mysql 配置文件 /etc/my.cnf 配置文件添加 datadir 内容： 在[mysqld]段加入 1datadir = /usr/local/mysql/var 1、备份 1#/usr/bin/innobackupex-1.5.1 --user=root --password=password --defaults-file=/etc/my.cnf /usr/local/bbsBackup 2、恢复 1234#/usr/bin/innobackupex-1.5.1 --apply-log /usr/local/bbsBackup/2011-09-26_02-00-01/#/usr/bin/innobackupex-1.5.1 --copy-back /usr/local/bbsBackup/2011-09-26_02-00-01/#chown -R mysql:mysql /usr/local/mysql/#/etc/init.d/mysqld start 二、全量备份及恢复备份注：使用xtrabackup，仅限InnoDB和xtradb表，且注意mysql配置文件my.cnf中需设置“default_table_type = InnoDB”否则不成功 1#/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --backup --target-dir=/usr/local/bbsBackup/base/ 恢复时执行两次：1、 12#/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --prepare --target-dir=/usr/local/bbsBackup/base#/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --prepare --target-dir=/usr/local/bbsBackup/base 2、 1234567//将数据库停掉#/etc/init.d/mysqld stop//删除数据库目录下的ib*（ib开头的所有）文件。#rm /usr/local/mysql/var/ib*//将/usr/local/bbsBackup/base目录下的ib*文件拷贝到数据库目录。#cd /usr/local/mysql/var/#cp /usr/local/bbsBackup/base/ib* ./ 3、设置权限： 1#chown mysql:mysql ib* 重启数据库后测试，是否成功。 三、增量备份及恢复注：做增量前当然要先进行全量备份，在全量的基础上来进行增量。首先进行全量备份。 1#/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --backup --target-dir=/usr/local/bbsBackup/base/ 在全量备份的基础上进行增量。 1#/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --backup --target-dir=/usr/local/bbsBackup/1 --incremental-basedir=/usr/local/bbsBackup/base/ 注：/usr/local/bbsBackup/1是每次都需修改的。比如第二次增量就改成/usr/local/bbsBackup/2增量恢复。（步骤同全量恢复，只是在执行恢复命令的时候中间多一步）1、 123#/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --prepare --target-dir=/usr/local/bbsBackup/base#/usr/bin/xtrabackup --target-dir=/usr/local/bbsBackup/base --prepare --incremental-dir=/usr/local/bbsBackup/1#/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --prepare --target-dir=/usr/local/bbsBackup/base 2、 1234567//将数据库停掉#/etc/init.d/mysqld stop//删除数据库目录下的ib*（ib开头的所有）文件。#rm /usr/local/mysql/var/ib*//将/usr/local/bbsBackup/base目录下的ib*文件拷贝到数据库目录。#cd /usr/local/mysql/var/#cp /usr/local/bbsBackup/base/ib* ./ 3、设置权限： 1#chown mysql:mysql ib* 重启数据库后测试，是否成功。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql设置更改root密码、连接mysql、mysql常用命令]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F13.1%20-%2013.3%20%E8%AE%BE%E7%BD%AE%E6%9B%B4%E6%94%B9root%E5%AF%86%E7%A0%81%E3%80%81%E8%BF%9E%E6%8E%A5mysql%E3%80%81mysql%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[13.1 设置更改root密码MySQL的root和Linux的root是不一样的，默认是没有密码的，需要设置。 配置MySQL环境变量首次直接使用mysql会提示‘未找到命令’，这是因为将该命令没有加入环境变量。如果要使用命令，需要使用它的绝对路径：/usr/local/mysql/bin/mysql。为了方便，建议将其加入系统的环境变量。 12345678[root@host ~]# export PATH=$PATH:/usr/local/mysql/bin/#这是将命令路径暂时加入环境变量，系但是统重启后该变量会失效，最好将其加入环境变量配置文件[root@host ~]# vim /etc/profile…… #添加export PATH=$PATH:/usr/local/mysql/bin/[root@host ~]# source /etc/profile //刷新刚刚的配置文件，否则不生效 首次登陆mysql，root用户是没有密码的，可以直接登录1234[root@host ~]# mysql -uroot //指定用户名Welcome to the MySQL monitor. Commands end with ; or \g.……mysql&gt; quit //输入quit可以退出 设置密码1234567891011[root@host ~]# mysqladmin -uroot password &apos;123456&apos; [root@host ~]# mysql -uroot //设置好密码的话，再次登陆要加-p，不然报错ERROR 1045 (28000): Access denied for user &apos;root&apos;@&apos;localhost&apos; (using password: NO)[root@host ~]# mysql -uroot -pEnter password: Welcome to the MySQL monitor.mysql&gt;注意： -p后面可以直接带密码，不用加空格，例如 -p&apos;123456&apos;，引号可以不加，但是密码如果是带有特殊符号的，就必须加引号，所以最好习惯加引号也可以在Enter后再输入密码，这样会不容易泄漏密码，更安全。 更改密码 知道原密码的情况下 12345[root@host ~]# mysqladmin -uroot -p&apos;123456&apos; password &apos;1234567&apos;[root@host ~]# mysql -uroot -p&apos;1234567&apos;Welcome to the MySQL monitor.mysql&gt; 不知道原密码的情况下 编辑mysql配置文件，添加skip-grant 1234567[root@host ~]# vim /etc/my.cnf[mysqld]skip-grant //添加这一行，表示忽略授权datadir=/data/mysqlsocket=/tmp/mysql.sock…… 重启mysql服务 1234[root@host ~]# /etc/init.d/mysqld restartShutting down MySQL... SUCCESS! Starting MySQL..................... SUCCESS! #重启之后，登陆MySQL就不需要密码了 直接登陆MySQL，设置密码 1234567891011121314[root@host ~]# mysql -urootWelcome to the MySQL monitor. mysql&gt; use mysql; //切换到mysql库Database changedmysql&gt; select * from user\G; //查看用户的表信息（密码，授权等等）(/G: 使输出信息有序显示，不然显示内容会很乱 )mysql&gt; select password from user; //查看用户密码，显示结果Wie加密字符串！ mysql&gt; update user set password=password(&apos;123456&apos;) where user=&apos;root&apos;; //用123456代替原密码（将密码设置为123456）Query OK, 4 rows affected (0.11 sec)Rows matched: 4 Changed: 4 Warnings: 0mysql&gt; quitBye 13.2 连接mysql远程连接：使用IP&amp;port1234[root@host ~]# mysql -uroot -p123456 -h127.0.0.1 -P3306 //-p=password -h=host -P=portWelcome to the MySQL monitor.mysql&gt; quitBye 本机连接：使用socket12345[root@host ~]# mysql -uroot -p123456 -S/tmp/mysql.sock //-S 制定socket#只适用于本机连接，等同于“mysql -uroot -p123456”Welcome to the MySQL monitor.mysql&gt; quitBye 显示数据库信息，一般用于脚本中12345678910[root@host ~]# mysql -uroot -p&apos;123456&apos; -e &quot;show databases&quot; //-e 可以执行一些命令Warning: Using a password on the command line interface can be insecure.+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+ 13.3 mysql常用命令查看库的信息1234mysql&gt;查询库 show databases;切换库 use mysql; 这些命令需要在切换库之后执行#mysql&gt; use mysql 12345查看库里的表 show tables;查看表里的字段 desc tb_name;查看建表语句 show create table tb_name\G;查看当前用户 select user();查看当前使用的数据库 select databsase(); 扩展mysql5.7 root密码更改http://www.apelearn.com/bbs/thread-7289-1-1.html myisam 和innodb引擎对比http://www.pureweber.com/article/myisam-vs-innodb/ mysql 配置详解http://blog.linuxeye.com/379.html mysql调优http://www.aminglinux.com/bbs/thread-5758-1-1.html 亲身mysql调优经历http://www.apelearn.com/bbs/thread-11281-1-1.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php-fpm的pool、php-fpm慢执行日志、open_basedir、php-fpm进程管理]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F12.21%20-%2012.24%20php-fpm%E7%9A%84pool%E3%80%81php-fpm%E6%85%A2%E6%89%A7%E8%A1%8C%E6%97%A5%E5%BF%97%E3%80%81open_basedir%E3%80%81php-fpm%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[12.21 php-fpm的pool为了避免因多站点使用同一个pool时，因为一个站点故障导致pool出问题，进而影响使用同一个pool的其他站点的正常运行，我们有必要对每一个站点设置一个单独的pool。 为php-fpm配置多个pool编辑php-fpm配置文件：12345678910111213141516171819202122232425262728[root@host etc]# vim /usr/local/php-fpm/etc/php-fpm.conf [www]listen = /tmp/php-fcgi.sock#listen = 127.0.0.1:9000listen.mode = 666user = php-fpmgroup = php-fpmpm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024……[zhouqun.com] //添加新的poollisten = /tmp/zhouqun.socklisten.mode = 666user = php-fpmgroup = php-fpmpm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024 语法检测：12[root@host etc]# /usr/local/php-fpm/sbin/php-fpm -t[12-Sep-2017 23:26:57] NOTICE: configuration file /usr/local/php-fpm/etc/php-fpm.conf test is successful 重新加载配置文件：12[root@host etc]# /etc/init.d/php-fpm reloadReload service php-fpm done 查看进程：1234[root@host etc]# ps aux |grep php-fpmphp-fpm 6222 0.0 0.4 226640 4716 ? S 16:10 0:00 php-fpm: pool wwwphp-fpm 6223 0.0 0.4 226640 4712 ? S 16:10 0:00 php-fpm: pool zhouqun.com 为站点设置pool123456789[root@host vhost]# vim /usr/local/nginx/conf/vhost/aaa.com.conflocation ~ \.php$ &#123; include fastcgi_params; fastcgi_pass unix:/tmp/zhouqun.sock; //把fastcgi_pass地址改为和php-fpm.conf中一样的地址就可以 fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/wwwroot/default$fastcgi_script_name; &#125; 添加php-fpm.conf子配置文件为了便于管理，可以将php-fpm中的每个pool单独进行管理。进行如下操作，添加php-fpm子配置文件： 1234567[root@host vhost]# vim /usr/local/php-fpm/etc/php-fpm.conf[global]pid = /usr/local/php-fpm/var/run/php-fpm.piderror_log = /usr/local/php-fpm/var/log/php-fpm.loginclude = etc/php-fpm.d/*.conf //添加#在全局变量版块添加参数“include = etc/php-fpm.d/*.conf”。然后可以清除php-fpm配置文件中其他参数，再到php-fpm.d目录下进行单独设置。 创建指定目录1234[root@host vhost]# cd /usr/local/php-fpm/etc/[root@host etc]# mkdir php-fpm.d[root@host etc]# cd php-fpm.d/ 创建php-fpm子配置文件123456789101112131415161718192021222324252627[root@host php-fpm.d]# vim www.conf[www]listen = /tmp/php-fcgi.socklisten.mode = 666user = php-fpmgroup = php-fpmpm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024[root@host php-fpm.d]# vim zhouqun.conf[zhouqun.com]listen = /tmp/zhouqun.socklisten.mode = 666user = php-fpmgroup = php-fpmpm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024 检查语法错误并重启：12345[root@host php-fpm.d]# /usr/local/php-fpm/sbin/php-fpm -t[16-Aug-2017 16:49:17] NOTICE: configuration file /usr/local/php-fpm/etc/php-fpm.conf test is successful[root@host php-fpm.d]# /etc/init.d/php-fpm reloadReload service php-fpm done 查看php-fpm进程信息还是使用ps命令。 12.22 php-fpm慢执行日志php网站莫名的访问很慢，可以通过慢执行日志找到症结所在，所以满日志非常重要，php网站强烈推荐使用LNMP架构搭建。 开启慢执行日志：1234567[root@host php-fpm.d]# vim /usr/local/php-fpm/etc/php-fpm.d/www.conf……request_slowlog_timeout = 1 //当请求超过1秒开始记录日志slowlog = /usr/local/php-fpm/var/log/www-slow.log //日志存放地址检测并重加载[root@host php-fpm.d]# /usr/local/php-fpm/sbin/php-fpm -t[root@host php-fpm.d]# /etc/init.d/php-fpm reload 试验在使用www pool的站点添加文件： 123456[root@host php-fpm.d]# vim /data/wwwroot/test.com/sleep.php //创建一个.php文件，故意让它休眠2秒，让它运行缓慢&lt;?phpecho &quot;test slow log&quot;;sleep(2); echo &quot;done&quot;;?&gt; 检测：12[root@host php-fpm.d]# curl -x127.0.0.1:80 test.com/sleep.php test slow log done 查看慢日志：12345[root@host php-fpm.d]# tail /usr/local/php-fpm/var/log/www-slow.log [12-Sep-2017 23:42:23] [pool www] pid 4236script_filename = /data/wwwroot/test.com/sleep.php[0x00007fe027r0e2f5] sleep() /data/wwwroot/test.com/sleep.php:3 //显示文件的第三行导致的访问慢，因为第三行就是sleep命令 12.23 php-fpm定义open_basedir在php-fpm服务中，当一台服务器跑多个网站时，用open_basedir限定各个站点所能访问的服务器上的目录的范围，可以针对每个pool设定open _ basedir。 核心配置参数：123[root@host ~]# vim /usr/local/php-fpm/etc/php-fpm.d/www.conf ……php_admin_value[open_basedir]=/data/wwwroot/test.com:/tmp/ //修改 创建测试PHP脚本：123[root@host php-fpm.d]# vim /data/wwwroot/test.com/1.php&lt;?phpecho &quot;This is a test php of open_basedir&quot;; 测试：12[root@host php-fpm.d]# curl -x127.0.0.1:80 test.com/1.phpThis is a test php of open_basedir 12.24 php-fpm进程管理php-fpm中pool配置参数解析： 123456789101112131415161718[root@host php-fpm.d]# vim www.conf[www]listen = /tmp/php-fcgi.socklisten.mode = 666user = php-fpmgroup = php-fpmpm = dynamic#设置进程启动方式（dynamic表示动态，static表示静态）#只有此处设置为dynamic，下面的配置才生效pm.max_children = 50 //最多可启动的子进程数量pm.start_servers = 20 //设定初始启动的进程数量pm.min_spare_servers = 5 //表示php-fpm空闲时最少要有几个子进程pm.max_spare_servers = 35 //表示php-fpm空闲时最多要有几个子进程pm.max_requests = 500 //表示一个子进程最多可接受多少个请求rlimit_files = 1024 //表示每个子进程打开的多少个文件句柄request_slowlog_timeout = 1 //当请求超过1秒开始记录日志slowlog = /usr/local/php-fpm/var/log/www-slow.log //日志存放地址php_admin_value[open_basedir]=/data/wwwroot/test.com:/tmp/]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx负载均衡、ssl原理、生成ssl密钥对、Nginx配置ssl]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F12.17%20-%2012.20%20Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81ssl%E5%8E%9F%E7%90%86%E3%80%81%E7%94%9F%E6%88%90ssl%E5%AF%86%E9%92%A5%E5%AF%B9%E3%80%81Nginx%E9%85%8D%E7%BD%AEssl%2F</url>
    <content type="text"><![CDATA[12.17 Nginx负载均衡Nginx负载均衡就是指 当代理服务器将自定义的域名解析到多个指定IP时，通过upstream模块来保证用户可以通过代理服务器正常访问各个IP（反向代理多台服务器就是负载均衡）。 负载均衡配置配置参数1234567891011121314151617181920212223[root@host ~]# vim /usr/local/nginx/conf/vhost/load.confupstream qq#自定义域名&#123; ip_hash;#目的是为了保证同一个用户始终保持在同一台机器上#还有就是为了当域名指向多个IP时，保证每个用户始终解析到同一IP server 61.135.157.156:80; server 125.39.240.113:80;#指定web服务器的IP&#125;server&#123; listen 80; server_name www.qq.com; location / &#123; proxy_pass http://qq; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 检测代理前 1234[root@host ~]# curl -x127.0.0.1:80 www.qq.com This is the default directory.#没使用代理时，会直接解析到默认的虚拟主机。 代理后 1234567[root@host ~]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@host ~]# /usr/local/nginx/sbin/nginx -s reload[root@host ~]# curl -x127.0.0.1:80 www.qq.com……#使用代理后，会解析到代理服务器所指向的IP的网页代码 dig命令dig命令是常用域名的解析工具，可以寻找域名的全部IP。 如果服务器中没有安装命令 1[root@host ~]# yum install -y bind-utils 解析qq网站的全部IP 12345678910[root@host ~]# dig www.qq.com;; ANSWER SECTION:www.qq.com. 138 IN A 61.135.157.156www.qq.com. 138 IN A 125.39.240.113;; Query time: 12 msec;; SERVER: 119.29.29.29#53(119.29.29.29);; WHEN: 二 9月 12 22:44:23 CST 2017;; MSG SIZE rcvd: 61 12.18 ssl原理 SSL(Secure Sockets Layer 安全套接层)协议,及其继任者TLS（Transport Layer Security传输层安全）协议，是为网络通信提供安全及数据完整性的一种安全协议。 http、https、tcp HTTP超文本传输协议（HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。 HTTPS(全称:Hyper Text Transfer Protocol over Secure Socket Layer)，简单讲是HTTP的安全加密版。 HTTP默认的端口号为80，HTTPS的端口号为443。 TCP(Transmission Control Protocol 传输控制协议)是一种面向连接的、可靠的、基于字节流的传输层通信协议。默认监听80端口。 http是应用层协议， tcp是传输层。 http使用tcp传输文本数据； http只是定义了tcp数据的解析方式 SSL工作流程 浏览器发送一个https的请求给服务器； 服务器要有一套数字证书，可以自己制作（后面的操作就是阿铭自己制作的证书），也可以向组织申请，区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出&gt;提示页面，这套证书其实就是一对公钥和私钥； 服务器会把公钥传输给客户端； 客户端（浏览器）收到公钥后，会验证其是否合法有效，无效会有警告提醒，有效则会生成一串随机数，并用收到的公钥加密； 客户端把加密后的随机字符串传输给服务器； 服务器收到加密随机字符串后，先用私钥解密（公钥加密，私钥解密），获取到这一串随机数后，再用这串随机字符串加密传输的数据（该加密为对称加密，所谓对称加密，就是将数据和私钥也就是这个随机字符串&gt;通过某种算法混合在一起，这样除非知道私钥，否则无法获取数据内容）； 服务器把加密后的数据传输给客户端； 客户端收到数据后，再用自己的私钥也就是那个随机字符串解密； 12.19 生成ssl密钥对SSL工作流程如果虚拟机中没有此工具，手动安装： 1[root@host ~]# yum install -y openssl SSL证书就是一对公钥和私钥。创建私钥12345678910111213141516[root@host ~]# cd /usr/local/nginx/conf/[root@host conf]# openssl genrsa -des3 -out tmp.key 2048 //生成SSL密钥Generating RSA private key, 2048 bit long modulus....................................................................................+++...............................................................+++e is 65537 (0x10001)Enter pass phrase for tmp.key:Verifying - Enter pass phrase for tmp.key: //密钥需要我们设置密码，一般我们都不需要再设置密码，所以要转换一下key，取消密码[root@host conf]# openssl rsa -in tmp.key -out host.key //转换一下key，将tmp.key 转换为没密码的host.keyEnter pass phrase for tmp.key:writing RSA key[root@host conf]# rm -f tmp.key //删除tmp.key 自己生成证书123456789101112131415161718192021[root@host conf]# openssl req -new -key host.key -out host.csr //自己生成证书请求文件，需要拿这个私钥一起生成证书You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [XX]:11State or Province Name (full name) []:BeiJingLocality Name (eg, city) [Default City]:BeiJingOrganization Name (eg, company) [Default Company Ltd]:BeiJingOrganizational Unit Name (eg, section) []:BeiJingCommon Name (eg, your name or your server&apos;s hostname) []:hostEmail Address []:zhouqunic@qq.com#以上是配置证书信息，因为是自己颁发给自己的证书，就随意瞎填或者干脆Enter跳过，如果是正式应用在自己的网站上，最好规范填写。Please enter the following &apos;extra&apos; attributesto be sent with your certificate requestA challenge password []:123456An optional company name []:123456 创建公钥：12345[root@host conf]# openssl x509 -req -days 365 -in host.csr -signkey host.key -out host.crt //这里的aminglinux.crt为公钥Signature oksubject=/C=11/ST=BeiJing/L=BeiJing/O=BeiJing/OU=BeiJing/CN=host/emailAddress=zhouqunic@qq.comGetting Private key 12.20 Nginx配置ssl12345678910111213141516[root@host conf]# cd vhost/[root@host vhost]# vim ssl.confserver&#123; listen 443; server_name zhouqun.com; index index.html index.php; root /data/wwwroot/zhouquncom; ssl on; //开启ssl ssl_certificate host.crt; //配置公钥 ssl_certificate_key host.key; //配置私钥 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ///配置协议&#125;[root@host vhost]# mkdir /data/wwwroot/zhouqun.com 检测 123[root@host conf]# /usr/local/nginx/sbin/nginx -tnginx: [emerg] unknown directive &quot;ssl&quot; in /usr/local/nginx/conf/vhost/ssl.conf:7 //报错了nginx: configuration file /usr/local/nginx/conf/nginx.conf test failed 报错 unknown directive “ssl” 未识别ssl配置，需要重新编译nginx，加上–with-http_ssl_module 123456789101112131415161718192021222324[root@host conf]# cd /usr/local/src/nginx-1.12.1/[root@host nginx-1.12.1]# ./configure --prefix=/usr/local/nginx --with-http_ssl_module [root@host conf]# make[root@host conf]# make install[root@host nginx-1.12.1]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@host nginx-1.12.1]# /etc/init.d/nginx restartRestarting nginx (via systemctl): [ OK ][root@host nginx-1.12.1]# netstat -lntpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 5991/nginx: master tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1735/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 2040/master tcp 0 0 0.0.0.0:443 0.0.0.0:* LISTEN 5991/nginx: master tcp6 0 0 :::3306 :::* LISTEN 1990/mysqld tcp6 0 0 :::22 :::* LISTEN 1735/sshd tcp6 0 0 ::1:25 :::* LISTEN 2040/master nginx监听80和443端口。 测试 12345[root@host nginx-1.12.1]# cd /data/wwwroot/zhouqun.com/[root@host adai.com]# vim index.htmlThis is ssl. 添加本地域名： 1234567891011121314151617[root@host adai.com]# vim /etc/hosts127.0.0.1 zhouqun.com[root@host vhost]# curl https://zhouqun.com/curl: (60) Peer&apos;s certificate issuer has been marked as not trusted by the user.More details here: http://curl.haxx.se/docs/sslcerts.htmlcurl performs SSL certificate verification by default, using a &quot;bundle&quot;of Certificate Authority (CA) public keys (CA certs). If the defaultbundle file isn&apos;t adequate, you can specify an alternate fileusing the --cacert option.If this HTTPS server uses a certificate signed by a CA represented inthe bundle, the certificate verification probably failed due to aproblem with the certificate (it might be expired, or the name mightnot match the domain name in the URL).If you&apos;d like to turn off curl&apos;s verification of the certificate, usethe -k (or --insecure) option. 因为该证书是自己创建的，没有符合https组织的规范，不能被正确识别，如果换上正规的证书，就没问题了。 所以，如果要使用浏览器检测，那么进行该测试之前，需要更改Windows的hosts文件，不然就会证书出错的。 扩展针对请求的uri来代理http://ask.apelearn.com/question/1049 根据访问的目录来区分后端的webhttp://ask.apelearn.com/question/920]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>ssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx的防盗链、访问控制、解析php相关配置、代理]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F12.13%20-%2012.16%20Nginx%E7%9A%84%E9%98%B2%E7%9B%97%E9%93%BE%E3%80%81%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E3%80%81%E8%A7%A3%E6%9E%90php%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E3%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[12.13 Nginx防盗链Nginx防盗链可结合日志管理一起配置，因为该配置也要使用location板块 1234567891011121314151617181920212223242526272829[root@host ~]# vim /usr/local/nginx/conf/vhost/test.com.conf……location ~* ^.+\.(gif|jpg|png|swf|flv|rar|zip|doc|pdf|gz|bz2|jpeg|bmp|xls)$&#123; expires 7d; valid_referers none blocked server_names *.test.com ; #定义referer白名单 if ($invalid_referer) &#123; return 403; #if函数的意思是：如果不是白名单内的域名，返回值：403 &#125; access_log off;&#125;……[root@host ~]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@host ~]# /usr/local/nginx/sbin/nginx -s reload检查[root@host ~]# curl -e &quot;http://www.baidu.com/1.txt&quot; -x127.0.0.1:80 -I test.com/baidu.pngHTTP/1.1 403 ForbiddenServer: nginx/1.12.1Date: Mon, 11 Sep 2017 11:25:47 GMTContent-Type: text/htmlContent-Length: 169Connection: keep-alive访问被拒绝，防盗链生效 12.14 Nginx访问控制只允许几个指定IP通过访问/admin/目录的请求 12345678910111213141516[root@host ~]# vim /usr/local/nginx/conf/vhost/test.com.conf ……location /admin/ &#123;#设置IP白名单 allow 192.168.8.132; allow 127.0.0.1; deny all; &#125;[root@host ~]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@host ~]# /usr/local/nginx/sbin/nginx -s reload 创建目录 12[root@host ~]# mkdir /data/wwwroot/test.com/admin[root@host ~]# echo “test,test”&gt;/data/wwwroot/test.com/admin/1.html 测试 1234[root@host ~]# curl -x127.0.0.1:80 test.com/admin/1.html“test,test”[root@host ~]# curl -x192.168.2.107:80 test.com/admin/1.html“test,test” 访问控制 1234567891011121314#正则匹配location ~ .*(abc|image)/.*\.php$&#123; deny all;&#125;#user_agent限制if ($http_user_agent ~ &apos;Spider/3.0|YoudaoBot|Tomato&apos;)&#123; return 403;&#125;#deny all和return 403效果一样 12.15 Nginx解析php相关配置核心配置文件 123456789101112[root@host ~]# vim /usr/local/nginx/conf/vhost/test.com.conf……location ~ \.php$ &#123; include fastcgi_params;#fastcgi_pass 127.0.0.1:9000 fastcgi_pass unix:/tmp/php-fcgi.sock;#fastcgi_pass 有两种监听格式，要保证Nginx和php-fpm中格式是一致的，否则会报502错误 fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/wwwroot/test.com$fastcgi_script_name;#fastcgi _param SCRIPT _FILENAME所在行的路径要和root路径一致 &#125; 12.16 Nginx代理 在计算机网络中，反向代理是代理服务器的一种。它根据客户端的请求，从后端的服务器上获取资源，然后再将这些资源返回给客户端。与前向代理不同，前向代理作为一个媒介将互联网上获取的资源返回给相关联的客户端，而反向代理是在服务器端作为代理使用，而不是客户端。 Nginx作为反向代理的特点 接收用户请求是异步的，即先将用户请求全部接收下来，再一次性发送后后端web服务器，极大的减轻后端web服务器的压力； nginx代理和后端web服务器间无需长连接； 发送响应报文时，是边接收来自后端web服务器的数据，边发送给客户端的； 调度灵活。NGINX工作在网络协议栈的第七层，能够对HTTP应用请求进行解析和分流，支持比较复杂的正则规则，具有更优化的负载均衡效果。 网络依赖型低。NGINX对网络的依赖程度非常低，理论上讲，只要能够ping通就可以实施负载均衡，而且可以有效区分内网和外网流量。 支持服务器检测。NGINX能够根据应用服务器处理页面返回的状态码、超时信息等检测服务器是否出现故障，并及时返回错误的请求重新提交到其它节点上。 工作原理Nginx代理是在一台代理服务器中自定义一个域名，该域名指向一个IP，然后将用户的请求通过这台代理服务器访问指定的IP所对应的web服务器。 进入虚拟主机目录1[root@host ~]# cd /usr/local/nginx/conf/vhost/ 创建代理服务器1234567891011121314151617[root@host vhost]# vim proxy.confserver&#123; listen 80; server_name ask.apelearn.com;#定义域名 location / &#123; proxy_pass http://121.201.9.155/;#指定被代理（被访问）的IP（web服务器IP） proxy_set_header Host $host;#$host指的是代理服务器的servername（也是被代理IP的域名） proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125;设置好以后，就可以访问aminglinux论坛了 检测验证123456789101112131415161718192021222324252627282930#之前[root@host vhost]# curl -x127.0.0.1:80 ask.apelearn.com/robots.txt&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.12.1&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;#之后[root@host vhost]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@host vhost]# /usr/local/nginx/sbin/nginx -s reload[root@host vhost]# curl -x127.0.0.1:80 ask.apelearn.com/robots.txt## robots.txt for MiWen#User-agent: *Disallow: /?/admin/Disallow: /?/people/Disallow: /?/question/Disallow: /account/Disallow: /app/Disallow: /cache/ 扩展502问题汇总http://ask.apelearn.com/question/9109 location优先级http://blog.lishiming.net/?p=100]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx访问日志、Nginx日志切割、静态文件不记录日志和过期时间]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F12.10%20-%2012.12%20Nginx%E8%AE%BF%E9%97%AE%E6%97%A5%E5%BF%97%E3%80%81Nginx%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E3%80%81%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E4%B8%8D%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%E5%92%8C%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[12.10 Nginx访问日志日志格式1234567[root@host ~]# vim /usr/local/nginx/conf/nginx.conf //搜索log_format... ...log_format combined_realip &apos;$remote_addr $http_x_forwarded_for [$time_local]&apos; &apos; $host &quot;$request_uri&quot; $status&apos; &apos; &quot;$http_referer&quot; &quot;$http_user_agent&quot;&apos;;#combined_realip是日志名称 # 后面带引号和$的是日志内容 日志格式参数注释 名称 含义 $remote_addr 客户端IP（公网IP） $http_x_forwarded_for 代理服务器的IP $time_local 服务器本地时间 $host 访问主机名（域名） $request_uri 访问的URL地址 $status 状态码 $http_referer referer $http_user_agent user_agent 定义虚拟主机日志格式（一定要先定义nginx.conf中的日志格式，才能在这里调用和再定义）12345678910111213[root@host ~]# cd /usr/local/nginx/conf/vhost/[root@host vhost]# lsaaa.com.conf test.com.conf[root@host vhost]# vim aaa.com.conf //定义aaa.com.conf日志格式 ……access_log /tmp/aaa.com.log combined_realip;#指定日志位置和格式检查错误：[root@host vhost]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 检查1234[root@host vhost]# curl -x127.0.0.1:80 aaacom This is aaa.com[root@host vhost]# cat /tmp/aaa.com.log 127.0.0.1 - [8/Sep/2017:22:39:68 +0800] aaa.com &quot;/&quot; 200 &quot;-&quot; &quot;curl/7.29.0&quot; 12.11 Nginx日志切割因为Nginx没有自带的日志切割工具，所以需要借助系统日志切割命令或自己编写日志切割脚本。 日志切割脚本以后把所有哦的shell脚本统一保存位置：/usr/local/sbin/ 12345678910111213141516171819[root@host vhost]# vim /usr/local/sbin/nginx_log_rotate.sh#! /bin/bashd=`date -d &quot;-1 day&quot; +%Y%m%d` #定义切割时间（切割一天前的日志）logdir=&quot;/tmp/&quot;#此处指定要切割的日志路径（该路径来自虚拟主机配置文件）nginx_pid=&quot;/usr/local/nginx/logs/nginx.pid&quot;#调用pid的目的是为了执行命令：/bin/kill -HUP `cat $nginx_pid`#该命令相当于命令：nginx -s reload（重新加载文件），确保与虚拟主机配置文件变更保持同步#该地址来自nginx配置文件cd $logdirfor log in `ls *.log`do mv $log $log-$ddone#这里使用通配进行循环，对所有符合条件的日志文件进行切割/bin/kill -HUP `cat $nginx_pid`#执行此命令进行重新加载生成新的日志文件来记录新的日志 执行该脚本12345678910111213[root@host vhost]# sh -x /usr/local/sbin/nginx_log_rotate.sh++ date -d &apos;-1 day&apos; +%Y%m%d+ d=20170909+ logdir=/tmp/+ nginx_pid=/usr/local/nginx/logs/nginx.pid+ cd /tmp/++ ls test.com.log yum.log+ for log in &apos;`ls *.log`&apos;+ mv test.com.log test.com.log-20170909+ for log in &apos;`ls *.log`&apos;+ mv yum.log yum.log-20170909++ cat /usr/local/nginx/logs/nginx.pid+ /bin/kill -HUP 59154 添加到系统任务计划123456789101112131415161718[root@host vhost]# vim /etc/crontabSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed0 3 * * * /bin/bash/ /usr/local/sbin/nginx_log_rotate.sh#每天凌晨3点切割一次前一天日志[root@host vhost]# chmod +x /usr/local/sbin/nginx_log_rotate.sh //加上可执行权限 12.12 静态文件不记录日志和过期时间核心配置参数123456789101112131415161718[root@host vhost]# vim test.com.conflocation ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ #匹配文件类型 &#123; expires 7d; #过期时间为7天 access_log off; #不记录该类型文件的访问日志 &#125;location ~ .*\.(js|css)$ &#123; expires 12h; #过期时间为12小时 access_log off; #不记录该类型文件的访问日志 &#125; access_log /tmp/test.com.log combined_realip; #指定日志位置及格式 检测123456789101112131415161718192021222324252627282930313233[root@host vhost]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@host vhost]# /usr/local/nginx/sbin/nginx -s reload访问index.html文件[root@host vhost]# !curlcurl -x127.0.0.1:80 test.comThis is test.com[root@host vhost]# !catcat /tmp/test.com.log 127.0.0.1 - [9/Sep/2017:00:12:26 +0800] test.com &quot;/&quot; 200 &quot;-&quot; &quot;curl/7.29.0&quot;#有日志访问baidu.png文件[root@host test.com]# curl -x127.0.0.1:80 test.com/baidu.png -IHTTP/1.1 200 OKServer: nginx/1.12.1Date: Sat, 9 Aug 2017 09:47:57 GMTContent-Type: image/pngContent-Length: 3706Last-Modified: Sat, 09 Sep 2017 01:13:35 GMTConnection: keep-aliveETag: &quot;59805459-e7a&quot;Expires: Sat, 09 Sep 2017 00:47:46 GMTCache-Control: max-age=604800Accept-Ranges: bytes#max-age=604800s=7天，即该文件缓存的过期时间为7天！[root@host test.com]# cat /tmp/test.com.log 127.0.0.1 - [9/Sep/2017:00:13:39+0800] test.com &quot;/&quot; 200 &quot;-&quot; &quot;curl/7.29.0&quot;#无该文件的访问日志！！！]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx安装、默认虚拟主机、Nginx用户认证、Nginx域名重定向]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F12.6%20-%2012.9%20Nginx%E5%AE%89%E8%A3%85%E3%80%81%E9%BB%98%E8%AE%A4%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E3%80%81Nginx%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%E3%80%81Nginx%E5%9F%9F%E5%90%8D%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[12.6 Nginx安装准备12345[root@host ~]# cd /usr/local/src/[root@host src]# wget http://nginx.org/download/nginx-1.12.1.tar.gz[root@host src]# tar zxvf nginx-1.12.1.tar.gz 安装12345678910[root@host src]# cd nginx-1.12.1/[root@host nginx-1.12.1]# ./configure --prefix=/usr/local/nginx //如果需要支持某模块，可以在此添加，如HTTPS、SSL等，我们这里就先不安装，后面再编译进去[root@host nginx-1.12.1]# make &amp;&amp; make install //编译[root@host nginx-1.12.1]# echo $? //检查0[root@host nginx-1.12.1]# cd /usr/local/nginx/[root@host nginx]# lsconf html logs sbin 配置添加nginx到启动服务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283[root@host nginx]# vim /etc/init.d/nginx //创建启动脚本，写入以下代码#!/bin/bash# chkconfig: - 30 21# description: http service.# Source Function Library. /etc/init.d/functions# Nginx SettingsNGINX_SBIN=&quot;/usr/local/nginx/sbin/nginx&quot;NGINX_CONF=&quot;/usr/local/nginx/conf/nginx.conf&quot;NGINX_PID=&quot;/usr/local/nginx/logs/nginx.pid&quot;RETVAL=0prog=&quot;Nginx&quot;start() &#123; echo -n $&quot;Starting $prog: &quot; mkdir -p /dev/shm/nginx_temp daemon $NGINX_SBIN -c $NGINX_CONF RETVAL=$? echo return $RETVAL&#125;stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc -p $NGINX_PID $NGINX_SBIN -TERM rm -rf /dev/shm/nginx_temp RETVAL=$? echo return $RETVAL&#125;reload()&#123; echo -n $&quot;Reloading $prog: &quot; killproc -p $NGINX_PID $NGINX_SBIN -HUP RETVAL=$? echo return $RETVAL&#125;restart()&#123; stop start&#125;configtest()&#123; $NGINX_SBIN -c $NGINX_CONF -t return 0&#125;case &quot;$1&quot; in start) start ;; stop) stop ;; reload) reload ;; restart) restart ;; configtest) configtest ;; *) echo $&quot;Usage: $0 &#123;start|stop|reload|restart|configtest&#125;&quot; RETVAL=1esacexit $RETVAL检查语法[root@host nginx]# /usr/local/nginx/sbin/nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful更改权限[root@host nginx]# chmod 755 /etc/init.d/nginx添加到系统服务[root@host nginx]# chkconfig --add nginx[root@host nginx]# chkconfig nginx on 更改Nginx的配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091[root@host nginx]# cd /usr/local/nginx/conf/ [root@host conf]# mv nginx.conf nginx.conf.bak //把Nginx自带脚本存做备份，创建自己的脚本[root@host conf]# vim nginx.conf //写入以下内容user nobody nobody;#定义启动Nginx服务的用户worker_processes 2;#定义子进程数error_log /usr/local/nginx/logs/nginx_error.log crit;pid /usr/local/nginx/logs/nginx.pid;worker_rlimit_nofile 51200;#指定Nginx最多可打开的文件数events&#123; use epoll; worker_connections 6000;#进程最大连接数&#125;http&#123; include mime.types; default_type application/octet-stream; server_names_hash_bucket_size 3526; server_names_hash_max_size 4096; log_format combined_realip &apos;$remote_addr $http_x_forwarded_for [$time_local]&apos; &apos; $host &quot;$request_uri&quot; $status&apos; &apos; &quot;$http_referer&quot; &quot;$http_user_agent&quot;&apos;; sendfile on; tcp_nopush on; keepalive_timeout 30; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; connection_pool_size 256; client_header_buffer_size 1k; large_client_header_buffers 8 4k; request_pool_size 4k; output_buffers 4 32k; postpone_output 1460; client_max_body_size 10m; client_body_buffer_size 256k; client_body_temp_path /usr/local/nginx/client_body_temp; proxy_temp_path /usr/local/nginx/proxy_temp; fastcgi_temp_path /usr/local/nginx/fastcgi_temp; fastcgi_intercept_errors on; tcp_nodelay on; gzip on; gzip_min_length 1k; gzip_buffers 4 8k; gzip_comp_level 5; gzip_http_version 1.1; gzip_types text/plain application/x-javascript text/css text/htm application/xml; server &#123; listen 80; server_name localhost; index index.html index.htm index.php; root /usr/local/nginx/html; location ~ \.php$#虚拟主机配置 &#123; include fastcgi_params; fastcgi_pass unix:/tmp/php-fcgi.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name;#PHP解析配置 &#125; &#125;&#125;检测语法：[root@host conf]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful启动Nginx服务：[root@host conf]# /etc/init.d/nginx startStarting nginx (via systemctl): [ 确定 ]查看链接情况[root@host conf]# ps aux|grep nginx root 17603 0.0 0.0 20500 624 ? Ss 22:57 0:00 nginx: master process /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confnobody 17604 0.0 0.1 22944 3212 ? S 22:57 0:00 nginx: worker processnobody 17605 0.0 0.1 22944 3212 ? S 22:57 0:00 nginx: worker processroot 17607 0.0 0.0 112680 972 pts/1 R+ 22:57 0:00 grep --color=auto nginx[root@host conf]# ps aux|grep php-fpmroot 17609 0.0 0.0 112680 968 pts/1 R+ 22:58 0:00 grep --color=auto php-fpm 检查123456789101112131415161718192021222324252627[root@host conf]# curl localhost //curl测试，结果如下，表示正常&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 检测PHP解析 1234567[root@host conf]# vim /usr/local/nginx/html/1.php&lt;?phpecho &quot;test php scripts.&quot;;?&gt;[root@host conf]# curl localhost/1.phptest php scripts. 12.7 默认虚拟主机编辑Nginx配置文件,删除原有server内容，添加如下内容：12345678[root@host ~]# cd /usr/local/nginx/conf[root@host conf]# vim /usr/local/nginx/conf/nginx.conf……include vhost/*.conf; //创建一个虚拟主机配置文件子目录（相当于增加子虚拟主机）[root@host conf]# mkdir vhost //创建配置文件中的目录文件#nginx配置文件也支持include语法 增加一台虚拟主机：12345678910111213[root@host conf]# cd vhost[root@host vhost]# vim aaa.com.conf //添加下面这一段server&#123; listen 80 default_server; //有&apos;default_server&apos;标记的就是默认虚拟主机 server_name aaa.com; index index.html index.htm index.php; root /data/wwwroot/default;&#125;[root@host vhost]# mkdir -p /data/wwwroot/default //创建配置文件中指定的root目录 为虚拟主机添加内容1234567891011121314进入目录，添加索引页：[root@host vhost]# cd /data/wwwroot/default[root@host default]# vim index.html //编辑一段话This is the default directory.[root@host default]# /usr/local/nginx/sbin/nginx -t //测试语法nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 重启动或重加载（两个命令选一个）：[root@host default]# /usr/local/nginx/sbin/nginx -s reload //重加载[root@host default]# /usr/local/nginx/sbin/nginx restart //重启动 检测1234[root@host default]# curl localhostThis is the default directory[root@host default]# curl -x127.0.0.1:80 123.comThis is the default directory 12.8 Nginx用户认证创建一个虚拟主机1234567891011121314151617181920[root@host default]# cd /usr/local/nginx/conf/vhost/[root@host vhost]# vim test.com.conf //写入如下内容server&#123; listen 80; server_name test.com; index index.html index.htm index.php; root /data/wwwroot/test.com; location / # / 表示根目录，如果你改成 /admin/，那就是针对目录认证；/admin/test.php，针对php文件认证。# 指定设置用户认证的目录（还可以设置对目录或者PHP的用户认证） &#123; auth_basic &quot;Auth&quot;;#指定用户名 auth_basic_user_file /usr/local/nginx/conf/htpasswd;#指定用户的密码文件 &#125;&#125; 生成密码文件123456[root@host vhost]# yum install -y httpd //需要使用Apache的/usr/local/apache/bin/htpasswd命令，如果已经安装了Apache，可以直接使用，如果没有，需要yum安装[root@host vhost]# htpasswd -c /usr/local/nginx/conf/htpasswd zhouqunNew password: Re-type new password: Adding password for user zhouqun# htpasswd -c创建该密码文件，如果是第二次添加用户，不用加该 -c 选项，所添加的用户名和密码会保存到该文件下。 重新加载 12345[root@host vhost]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@host vhost]# /usr/local/nginx/sbin/nginx -s reload# 使用reload的好处是能避免因配置文件中存在错误而无法正常启动, reload不会破坏原有运行环境，所以不适用restart。 添加配置文件1234[root@host vhost]# mkdir /data/wwwroot/test.com //添加配置文件指定的根目录[root@host vhost]# echo &quot;This is test.com&quot; &gt;/data/wwwroot/test.com/index.html //添加索引页 检查123456[root@host vhost]# curl -x127.0.0.1:80 test.com -uzhouqun:123456This is test.com#如果不指定用户名和密码，会报错401，原因是：需要用户认证；#如果为创建虚拟主机根目录会报错404，原因是：找不到指定目录；#如果指定目录中没有添加索引页（.html或.php文件），会报错404，原因是：文件存在错误。 12.9 Nginx域名重定向编辑虚拟主机配置文件123456789101112131415161718192021[root@host vhost]# vim test.com.confserver&#123; listen 80; server_name test.com test2.com test3.com;#为一个IP配置多个域名，此时权重会改变，如果需要全部跳转到第一个域名，可以使用rewrite模块实现 index index.html index.htm index.php; root /data/wwwroot/test.com; if ($host != &apos;test.com&apos; ) &#123; rewrite ^/(.*)$ http://test.com/$1 permanent; &#125;#使用rewrite模块编写跳转代码# 实际上，rewrite ^/(.*)$ http://test.com/$1 = rewrite http://$host/(.*)$ http://test.com/$1# ^代替了$host&#125;[root@host vhost]# /usr/local/nginx/sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful[root@host vhost]# /usr/local/nginx/sbin/nginx -s reload 检测12345678910[root@host vhost]# curl -x127.0.0.1:80 test2.com -IHTTP/1.1 301 Moved PermanentlyServer: nginx/1.12.1Date: Fri, 8 Sep 2017 1:20:24 GMTContent-Type: text/htmlContent-Length: 185Connection: keep-aliveLocation: http://test.com/# 301, 域名跳转，跳转后的地址为 http://test.com/ 扩展nginx.conf 配置详解PS：Nginx使用有两三年了，现在经常碰到有新用户问一些很基本的问题，我也没时间一一回答，今天下午花了点时间，结合自己的使用经验，把Nginx的主要配置参数说明分享一下，也参考了一些网络的内容，这篇是目前最完整的Nginx配置参数中文说明了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144#定义Nginx运行的用户和用户组user www www;#nginx进程数，建议设置为等于CPU总核心数。worker_processes 8;#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /var/log/nginx/error.log info;#进程文件pid /var/run/nginx.pid;#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 65535;#工作模式与连接数上限events&#123;#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。use epoll;#单个进程最大连接数（最大连接数=连接数*进程数）worker_connections 65535;&#125;#设定http服务器http&#123;include mime.types; #文件扩展名与文件类型映射表default_type application/octet-stream; #默认文件类型#charset utf-8; #默认编码server_names_hash_bucket_size 128; #服务器名字的hash表大小client_header_buffer_size 32k; #上传文件大小限制large_client_header_buffers 4 64k; #设定请求缓client_max_body_size 8m; #设定请求缓sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。tcp_nopush on; #防止网络阻塞tcp_nodelay on; #防止网络阻塞keepalive_timeout 120; #长连接超时时间，单位是秒#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;#gzip模块设置gzip on; #开启gzip压缩输出gzip_min_length 1k; #最小压缩文件大小gzip_buffers 4 16k; #压缩缓冲区gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）gzip_comp_level 2; #压缩等级gzip_types text/plain application/x-javascript text/css application/xml;#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。gzip_vary on;#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用upstream blog.ha97.com &#123;#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。server 192.168.80.121:80 weight=3;server 192.168.80.122:80 weight=2;server 192.168.80.123:80 weight=3;&#125;#虚拟主机的配置server&#123;#监听端口listen 80;#域名可以有多个，用空格隔开server_name www.ha97.com ha97.com;index index.html index.htm index.php;root /data/www/ha97;location ~ .*\.(php|php5)?$&#123;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;include fastcgi.conf;&#125;#图片缓存时间设置location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$&#123;expires 10d;&#125;#JS和CSS缓存时间设置location ~ .*\.(js|css)?$&#123;expires 1h;&#125;#日志格式设定log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;&apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;&apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;;#定义本虚拟主机的访问日志access_log /var/log/nginx/ha97access.log access;#对 &quot;/&quot; 启用反向代理location / &#123;proxy_pass http://127.0.0.1:88;proxy_redirect off;proxy_set_header X-Real-IP $remote_addr;#后端的Web服务器可以通过X-Forwarded-For获取用户真实IPproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#以下是一些反向代理的配置，可选。proxy_set_header Host $host;client_max_body_size 10m; #允许客户端请求的最大单文件字节数client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）proxy_temp_file_write_size 64k;#设定缓存文件夹大小，大于这个值，将从upstream服务器传&#125;#设定查看Nginx状态的地址location /NginxStatus &#123;stub_status on;access_log on;auth_basic &quot;NginxStatus&quot;;auth_basic_user_file conf/htpasswd;#htpasswd文件的内容可以用apache提供的htpasswd工具来产生。&#125;#本地动静分离反向代理配置#所有jsp的页面均交由tomcat或resin处理location ~ .(jsp|jspx|do)?$ &#123;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://127.0.0.1:8080;&#125;#所有静态文件由nginx直接读取不经过tomcat或resinlocation ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$&#123; expires 15d; &#125;location ~ .*.(js|css)?$&#123; expires 1h; &#125;&#125;&#125; 更详细的模块参数请参考：http://wiki.nginx.org/Main]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LNMP架构介绍、MySQL安装、PHP安装、Nginx介绍]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F12.1%20-%2012.5%20LNMP%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D%E3%80%81MySQL%E5%AE%89%E8%A3%85%E3%80%81PHP%E5%AE%89%E8%A3%85%E3%80%81Nginx%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[12.1 LNMP架构介绍 LNMP代表的就是：Linux系统下Nginx+MySQL+PHP这种网站服务器架构。 和LAMP不同的是，提供web服务的是Nginx 并且php是作为一个独立服务存在的，这个服务叫做php-fpm Nginx直接处理静态请求，动态请求会转发给php-fpm。 12.2 MySQL安装卸载二进制包安装的MySQL确认MySQL服务运行状态，并停止 123[root@host ~]# ps -ef | grep mysql[root@host ~]# /etc/init.d/mysql.server status[root@host ~]# /etc/init.d/mysql.server stop 删除MySQL安装时的相关文件 123[root@host ~]# rm -rf /usr/local/mysql [root@host ~]# rm -rf /etc/init.d/mysqld [root@host ~]# rm -rf /data/mysql 安装MySQL和之前LAMP环境安装MySQL的方法一样11.1 LAMP架构介绍+11.2 MySQL_MariaDB介绍+11.3-11. 5MySQL安装.md 12.3/12.4 PHP安装和LAMP安装PHP有区别，需要开启php-fpm服务。 准备PHP的包和用户1234[root@host ~]# cd /usr/local/src/[root@host src]# wget http://cn2.php.net/distributions/php-5.6.30.tar.gz //下载php二进制包[root@host src]# tar zxvf php-5.6.30.tar.gz //解压缩[root@host src]# useradd -s /sbin/nologin php-fpm //创建专门账号用来运行php-fpm服务，因为在LNMP环境中，PHP是以一种服务的形式独立存在的 卸载之前编译安装的PHP（如果之前有安装的话）12345[root@host ~]# cd /usr/local/src[root@host src]# ls[root@host src]# cd php-5.6.30[root@host php-5.6.30]# ls[root@host php-5.6.30]# make clean 安装PHP123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@host php-5.6.30]# cd php-5.6.30[root@host php-5.6.30]# ./configure --prefix=/usr/local/php-fpm --with-config-file-path=/usr/local/php-fpm/etc --enable-fpm --with-fpm-user=php-fpm --with-fpm-group=php-fpm --with-mysql=/usr/local/mysql --with-mysqli=/usr/local/mysql/bin/mysql_config --with-pdo-mysql=/usr/local/mysql --with-mysql-sock=/tmp/mysql.sock --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-ftp --enable-mbstring --enable-exif --with-pear --with-curl --with-openssl //初始化另外，附php7.1的./configure ，从lnmp.org的脚本copy来的。 [root@localhost php-7.1.6]# ./configure --prefix=/usr/local/php-fpm --with-config-file-path=/usr/local/php-fpm/etc --enable-fpm --with-fpm-user=php-fpm --with-fpm-group=php-fpm --enable-mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-mysql-sock=/tmp/mysql.sock --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-ftp --enable-mbstring --enable-exif --with-pear --with-curl --with-openssl附php7.2的./configure[root@localhost php-7.2.10]# ./configure \--prefix=/usr/local/php \--with-config-file-path=/usr/local/php/etc \--with-config-file-scan-dir=/usr/local/php/conf.d \--enable-fpm \--with-fpm-user=www \--with-fpm-group=www \--enable-mysqlnd \--with-mysqli=mysqlnd \--with-pdo-mysql=mysqlnd \--with-iconv-dir \--with-freetype-dir \--with-jpeg-dir \--with-png-dir \--with-zlib \--with-libxml-dir \--enable-xml \--disable-rpath \--enable-bcmath \--enable-shmop \--enable-sysvsem \--enable-inline-optimization \--with-curl \--enable-mbregex \--enable-mbstring \--enable-intl \--enable-pcntl \--enable-ftp \--with-gd \--with-openssl \--with-mhash \--enable-pcntl \--enable-sockets \--with-xmlrpc \--enable-zip \--enable-soap \--with-gettext \--disable-fileinfo \--enable-opcache \--with-xsl 编译过程中的出错排查12汇总yum install -y libxml2 libxml2-devel openssl openssl-devel libcurl libcurl-devel libjpeg libjpeg-turbo-devel libpng libpng-devel freetype freetype-devel libmcrypt libmcrypt-devel php-mcrypt libmcrypt libmcrypt-devel 错误1： 1onfigure: error: xml2-config not found. Please check your libxml2 installation. 解决办法1： 12345678910[root@host php-5.6.30]# yum list |grep libxml2libxml2.x86_64 2.9.1-6.el7_2.3 @anacondalibxml2.i686 2.9.1-6.el7_2.3 base libxml2-devel.i686 2.9.1-6.el7_2.3 base libxml2-devel.x86_64 2.9.1-6.el7_2.3 base libxml2-python.x86_64 2.9.1-6.el7_2.3 base libxml2-static.i686 2.9.1-6.el7_2.3 base libxml2-static.x86_64 2.9.1-6.el7_2.3 base [root@host php-5.6.30]# yum install -y libxml2 libxml2-devel //一般只需要安裝devel的庫文件就好了 错误2： 1configure: error: Cannot find OpenSSL&apos;s &lt;evp.h&gt; 解决办法2： 1[root@host php-5.6.30]# yum install -y openssl openssl-devel 错误3： 12configure: error: Please reinstall the libcurl distribution - easy.h should be in &lt;curl-dir&gt;/include/curl/ 解决办法3： 1[root@host php-5.6.30]# yum install -y libcurl libcurl-devel 错误4： 1configure: error: jpeglib.h not found. 解决办法4： 1[root@host php-5.6.30]# yum install -y libjpeg libjpeg-turbo-devel 错误5： 1configure: error: png.h not found. 解决办法5： 1[root@host php-5.6.30]# yum install -y libpng libpng-devel 错误6： 1configure: error: freetype-config not found. 解决办法6： 1[root@host php-5.6.30]# yum install -y freetype freetype-devel 错误7： 1configure: error: mcrypt.h not found. Please reinstall libmcrypt. 解决办法7： 1[root@host php-5.6.30]# yum install -y libmcrypt libmcrypt-devel 错误8： 12configure: error: mcrypt.h not found. Please reinstall libmcrypt.(centos源不能安装libmcrypt-devel，由于版权的原因没有自带mcrypt的包rpm -qa|grep limcrypt limcrypt-devel,此源为rethot社区版的源) 解决办法8：安装第三方yum源 1234wget http://www.atomicorp.com/installers/atomicsh ./atomicyum install php-mcrypt libmcrypt libmcrypt-devel 检测、编译和安装 123456[root@host php-5.6.30]# echo $?0[root@host php-5.6.30]# make [root@host php-5.6.30]# make install 配置PHP添加配置文件 1[root@host php-5.6.30]# cp php.ini-production /usr/local/php-fpm/etc/php.ini 配置文件编辑 1234567891011121314151617181920212223[root@host php-5.6.30]# vi /usr/local/php-fpm/etc/php-fpm.conf //写入如下内容[global]#定义全局参数pid = /usr/local/php-fpm/var/run/php-fpm.piderror_log = /usr/local/php-fpm/var/log/php-fpm.log[www]listen = /tmp/php-fcgi.sock#监听地址，也可以写：listen = 127.0.0.1：:9000，本地监听，也可以监听其他IP：port#此处格式会影响配置Nginx和PHP结合时Nginx寻址PHP的路径listen.mode = 666#当监听的为socket文件时该部分才生效，用于指定.sock文件的权限user = php-fpmgroup = php-fpm#定义php-fpm服务的用户pm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024#以上部分为进程相关信息 配置启动脚本 1234567891011121314[root@host etc]# cd /usr/local/src/php-5.6.30 //进入源码目录下来[root@host php-5.6.30]# cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm //把启动脚本放到到系统配置[root@host php-5.6.30]# chmod 755 /etc/init.d/php-fpm //修改权限[root@host php-5.6.30]# chkconfig --add php-fpm //添加到开机启动项[root@host php-5.6.30]# chkconfig php-fpm on //设置开机启动[root@host php-5.6.30]# service php-fpm start //启动php-fpm服务Starting php-fpm done[root@host php-5.6.30]# ps aux |grep php-fpm //查看后台www的pool是否启动 12.5 Nginx介绍 Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。 Nginx官网 nginx.org，最新版1.13，最新稳定版1.12 Nginx应用场景：web服务、反向代理、负载均衡 Nginx著名分支，淘宝基于Nginx开发的Tengine，使用上和Nginx一致，服务名，配置文件名都一样，和Nginx的最大区别在于Tenging增加了一些定制化模块，在安全限速方面表现突出，另外它支持对js，css合并 Nginx核心+lua相关的组件和模块组成了一个支持lua的高性能web容器openresty。 1、Nginx优点Nginx设计为一个主进程多个工作进程的工作模式，每个进程是单线程来处理多个连接，而且每个工作进程采用了非阻塞I/O来处理多个连接，从而减少了线程上下文切换，从而实现了公认的高性能、高并发；因此在生成环境中会通过把CPU绑定给Nginx工作进程从而提升其性能；另外因为单线程工作模式的特点，内存占用就非常少了。Nginx更改配置重启速度非常快，可以毫秒级，而且支持不停止Nginx进行升级Nginx版本、动态重载Nginx配置。Nginx模块也是非常多，功能也很强劲，不仅可以作为http负载均衡，Nginx发布1.9.0版本还支持TCP负载均衡，还可以很容易的实现内容缓存、web服务器、反向代理、访问控制等功能。 2、Lua的优点Lua是一种轻量级、可嵌入式的脚本语言，这样可以非常容易的嵌入到其他语言中使用。另外Lua提供了协程并发，即以同步调用的方式进行异步执行，从而实现并发，比起回调机制的并发来说代码更容易编写和理解，排查问题也会容易。Lua还提供了闭包机制，函数可以作为First Class Value 进行参数传递，另外其实现了标记清除垃圾收集。因为Lua的小巧轻量级，可以在Nginx中嵌入Lua VM，请求的时候创建一个VM，请求结束的时候回收VM。 3、什么是ngx_luangx_lua是Nginx的一个模块，将Lua嵌入到Nginx中，从而可以使用Lua来编写脚本，这样就可以使用Lua编写应用脚本，部署到Nginx中运行，即Nginx变成了一个Web容器；这样开发人员就可以使用Lua语言开发高性能Web应用了。ngx_lua提供了与Nginx交互的很多的API，对于开发人员来说只需要学习这些API就可以进行功能开发，而对于开发web应用来说，如果接触过Servlet的话，其开发和Servlet类似，无外乎就是知道接收请求、参数解析、功能处理、返回响应这几步的API是什么样子的。 4、开发环境我们可以使用OpenResty来搭建开发环境，OpenResty将Nginx核心、LuaJIT、许多有用的Lua库和Nginx第三方模块打包在一起；这样开发人员只需要安装OpenResty，不需要了解Nginx核心和写复杂的C/C++模块就可以，只需要使用Lua语言进行Web应用开发了。 参考http://jinnianshilongnian.iteye.com/blog/2280928 扩展Nginx为什么比Apache Httpd高效：原理篇http://www.toxingwang.com/linux-unix/linux-basic/1712.html apache和nginx工作原理比较http://www.server110.com/nginx/201402/6543.html mod_php 和 mod_fastcgi以及php-fpm的比较http://dwz.cn/1lwMSd 概念了解：CGI，FastCGI，PHP-CGI与PHP-FPMhttp://www.nowamagic.net/librarys/veda/detail/1319/]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构-php扩展模块安装]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.32%20LAMP%E6%9E%B6%E6%9E%84-php%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9D%97%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[11.32 php扩展模块安装有时候，编译好PHP后，发现还有其他模块需要添加进去，那么就需要安装php扩展模块安装。 1/usr/local/php/bin/php -m //查看模块 下面安装一个redis的模块，当做php中的缓存来用 1. 下载redis的安装包到src目录12cd /usr/local/src/wget https://codeload.github.com/phpredis/phpredis/zip/develop 2. 把包改名字并解压12mv develop phpredis-develop.zipunzip phpredis-develop.zip 3. 编译并安装12345cd phpredis-develop/usr/local/php/bin/phpize //为了生成configure文件 ./configure --with-php-config=/usr/local/php/bin/php-configmake make install 4. 加载redis模块现在php还是不支持redis的，需要编辑php的配置文件 123/usr/local/php/bin/php -i |grep extension_dir //查看扩展模块存放目录，我们可以在php.ini中去自定义该路径 vim /usr/local/php/etc/php.ini //增加一行配置（可以放到文件最后一行）extension = redis.so //添加进去 5. 关于扩展模块除了像redis这种第三方模块，在php的源码包里的ext目录下，有很多这种本地已经存在的模块，我们可以直接编译安装。 12345678910cd /usr/local/src/php-7.1.6/extlscd zip/lscd /usr/local/src/phpize./configure --with-php-config=/usr/local/php/bin/php-configmake make installvim /usr/local/php/etc/php.ini //增加一行配置（可以放到文件最后一行）extension = zip.so //添加进去 扩展apache rewrite教程http://coffeelet.blog.163.com/blog/static/13515745320115842755199/ http://www.cnblogs.com/top5/archive/2009/08/12/1544098.html apache rewrite 出现死循环http://ask.apelearn.com/question/1043 php错误日志级别参考http://ask.apelearn.com/question/6973 php开启短标签http://ask.apelearn.com/question/120 php.ini详解http://legolas.blog.51cto.com/2682485/493917]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构-apache限定某个目录禁止解析php、限制user_agent、php相关配置]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.28%20-%2011.30%20LAMP%E6%9E%B6%E6%9E%84-apache%E9%99%90%E5%AE%9A%E6%9F%90%E4%B8%AA%E7%9B%AE%E5%BD%95%E7%A6%81%E6%AD%A2%E8%A7%A3%E6%9E%90php%E3%80%81%E9%99%90%E5%88%B6user_agent%E3%80%81php%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[11.28 限定某个目录禁止解析php如果有一个目录是允许上传图片的，保不准有些人通过手段上传了php文件，那么就有可能被运行，造成安全隐患，被拿到root权限。 1. 编辑虚拟主机配置文件1234[root@host 111.com]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf &lt;Directory /data/wwwroot/111.com/upload&gt; php_admin_flag engine off &lt;/Directory&gt; 2. 创建相应的目录1234[root@host 111.com]# mkdir upload……[root@host 111.com]# ls upload/123.php qq.png 3. 测试12345[root@host 111.com]# curl -x127.0.0.1:80 111.com/upload/123.php -IHTTP/1.1 403 ForbiddenDate: Mon, 04 Sep 2017 22:31:52 GMTServer: Apache/2.4.27 (Unix) PHP/5.6.30Content-Type: text/html; charset=iso-8859-1 11.29 限制user_agent User Agent中文名为用户代理，简称 UA，它是一个特殊字符串头，使得服务器能够识别客户使用的操作系统及版本、CPU 类型、浏览器及版本、浏览器渲染引擎、浏览器语言、浏览器插件等。user_agent可以理解为浏览器标识。 CC攻击（Challenge Collapsar）是DDOS（分布式拒绝服务）的一种，攻击者通过代理服务器或者肉鸡向向受害主机不停地发大量数据包，造成对方服务器资源耗尽，一直到宕机崩溃，我们可以通过限制攻击者useragent的方法来阻断其攻击（这只是初级的防御方法）。 核心配置文件内容 123456&lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_USER_AGENT&#125; .*curl.* [NC,OR] RewriteCond %&#123;HTTP_USER_AGENT&#125; .*baidu.com.* [NC] RewriteRule .* - [F] &lt;/IfModule&gt; curl -A “123123” 指定user_agent 11.30/11.31 php相关配置查看php配置文件位置1/usr/local/php/bin/php -i | grep -i &quot;loaded configuration file&quot; 参数设置1234567891011121314151617date.timezone=Asia/Shanghai #设定时区,设定到上海或者重庆都可以disable_functions # 限制安全函数disable_functions=eval,assert,popen,passthru,escapeshellarg,escapeshellcmd,passthru,exec,system,chroot,scandir,chgrp,chown,escapeshellcmd,escapeshellarg,shell_exec,proc_get_status,ini_alter,ini_restore,dl,pfsockopen,openlog,syslog,readlink,symlink,leak,popepassthru,stream_socket_server,popen,proc_open,proc_close #某些生产环境有时会禁掉phpinfoeval,assert,popen,passthru,escapeshellarg,escapeshellcmd,passthru,exec,system,chroot,scandir,chgrp,chown,escapeshellcmd,escapeshellarg,shell_exec,proc_get_status,ini_alter,ini_restore,dl,pfsockopen,openlog,syslog,readlink,symlink,leak,popepassthru,stream_socket_server,popen,proc_open,proc_close #这些都是比较危险的函数，这样设置 error_log, log_errors, display_errors, error_reporting # 日志相关display_errors=On/Off #设定是否显示错误原因，一般关掉，防止用户看到。但是配置Off后，必须设置错误日志的的路径和错误日志的级别，否则后面无法查找出错的原因。log_errors=On/Off 开启/关闭错误日志error_log=/tmp/php_errors.log #设定错误日志的保存路径。如果定义好路径后无法生产日志，此时需要检查日志文件所在目录是否有写（w）权限error_reporting = E_ ALL &amp; ~E_ NOTICE #设定错误日志级别，级别有：E_ ALL 、~E_ NOTICE 、~E_ STRICT 、~E_DEPRECATED（可以自由组合）。生产环境使用：E_ ALL &amp; ~E_ NOTICE就可以。open_basedir = /data/wwwroot/111.com:/tmp/ #安全参数选项，设置了open_basedir选项，将会把所有关于文件的操作限制在指定目录及其子目录# 一台服务器运行着不止一台虚拟主机，所以在该文件下设置该选项并不合适。那么，该如何设定该配置呢？答案是分别在每个虚拟主机的配置文件进行相关设置php_admin_value open_basedir &quot;/data/wwwroot/111.com:/tmp/&quot; # “php_admin_value”可以定义php.ini中的参数。分别在每个虚拟主机设定相关的“open_basedir”即可。 扩展apache开启压缩http://www.aminglinux.com/bbs/thread-5528-1-1.html apache2.2到2.4配置文件变更http://www.aminglinux.com/bbs/thread-7292-1-1.html apache options参数http://www.aminglinux.com/bbs/thread-1051-1-1.html apache禁止trace或track防止xsshttp://www.aminglinux.com/bbs/thread-1045-1-1.html apache 配置https 支持sslhttp://www.aminglinux.com/bbs/thread-1029-1-1.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>apache</tag>
        <tag>httpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构-apache配置防盗链，访问控制Directory，访问控制FilesMatch]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.25%20-%2011.27%20LAMP%E6%9E%B6%E6%9E%84-apache%E9%85%8D%E7%BD%AE%E9%98%B2%E7%9B%97%E9%93%BE%EF%BC%8C%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6Directory%EF%BC%8C%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6FilesMatch%2F</url>
    <content type="text"><![CDATA[11.25 配置防盗链编辑虚拟主机配置文件： 1234567891011121314151617181920212223242526272829303132333435363738[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf &lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/123.com&quot; ServerName 123.com ServerAlias www.example.com &lt;Directory /data/wwwroot/123.com&gt; SetEnvIfNoCase Referer &quot;http://123.com&quot; local_ref SetEnvIfNoCase Referer &quot;http://ask.apelearn.com&quot; local_ref SetEnvIfNoCase Referer &quot;^$&quot; local_ref #定义referer白名单 &lt;FilesMatch &quot;\.(txt|doc|mp3|zip|rar|jpg|gif|png)&quot;&gt; Order Allow,Deny Allow from env=local_ref #定义规则：允许变量local_ref指定的referer访问，拒绝其他所有访问。 &lt;/FilesMatch&gt; &lt;/Directory&gt; ErrorLog &quot;logs/123.com-error_log&quot; SetEnvIf Request_URI &quot;.*\.gif$&quot; img SetEnvIf Request_URI &quot;.*\.jpg$&quot; img SetEnvIf Request_URI &quot;.*\.png$&quot; img SetEnvIf Request_URI &quot;.*\.bmp$&quot; img SetEnvIf Request_URI &quot;.*\.swf$&quot; img SetEnvIf Request_URI &quot;.*\.js$&quot; img SetEnvIf Request_URI &quot;.*\.css$&quot; img CustomLog &quot;|/usr/local/apache2.4/bin/rotatelogs -l logs/123.com-access_%Y%m%d.log 86400&quot; combined env=!img #CustomLog &quot;logs/123.com-access_log&quot; combined env=!img&lt;/VirtualHost&gt; 检测语法错误并重加载：[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful注： 如果在referer白名单中不加“^$”（空值），那么直接访问指定内容将会被拒绝。curl命令curl -e 指定referer[root@host ~]# curl -e &quot;http://www.aminglinux.com/123.html&quot; -x192.168.2.130:80 123.com/baidu.png -I 11.26 访问控制Directory编辑虚拟主机配置文件： 在配置文件加入如下参数：这是用于设定指定IP访问指定目录的权限 1234567891011121314151617181920212223[root@host admin]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf...... &lt;Directory /data/wwwroot/123.com/admin/&gt; Order deny,allow Deny from all Allow from 127.0.0.1 #只允许IP--127.0.0.1访问“/data/wwwroot/123.com/admin/”目录中的内容 &lt;/Directory&gt;[root@host admin]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host admin]# /usr/local/apache2.4/bin/apachectl graceful测试：[root@host admin]# curl -x127.0.0.1:80 123.com/admin/index.php121212更换IP访问：[root@host admin]# curl -x192.168.2.130:80 123.com/admin/index.php -IHTTP/1.1 403 ForbiddenDate: Fri, 25 Aug 2017 23:55:38 GMTServer: Apache/2.4.27 (Unix) PHP/5.6.30Content-Type: text/html; charset=iso-8859-1 #因为只有指定IP：127.0.0.1可以访问该目录，所以才会报错：403 11.27 访问控制FilesMatch使用FilesMatch参数： 这里是应用于对某些请求设定权限。 1234567891011121314151617181920[root@host admin]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf...... &lt;Directory /data/wwwroot/123.com&gt; &lt;FilesMatch admin.php(.*)&gt; Order deny,allow Deny from all Allow from 127.0.0.1 &lt;/FilesMatch&gt; &lt;/Directory&gt;[root@host admin]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host admin]# /usr/local/apache2.4/bin/apachectl graceful[root@host admin]# curl -x127.0.0.1:80 123.com/admin.php -IHTTP/1.1 404 Not FoundDate: Fri, 25 Aug 2017 23:43:14 GMTServer: Apache/2.4.27 (Unix) PHP/5.6.30Content-Type: text/html; charset=iso-8859-1 #访问的文件不存在，所以才会报错：404 扩展几种限制ip的方法http://www.lishiming.net/thread-6519-1-1.html apache 自定义headerhttp://www.aminglinux.com/bbs/thread-830-1-1.html apache的keepalive和keepalivetimeouthttp://www.aminglinux.com/bbs/thread-556-1-1.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>apache</tag>
        <tag>httpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构-访问日志不记录静态文件，访问日志切割，静态元素过期时间]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.22%20-%2011.24%20LAMP%E6%9E%B6%E6%9E%84-%E8%AE%BF%E9%97%AE%E6%97%A5%E5%BF%97%E4%B8%8D%E8%AE%B0%E5%BD%95%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%EF%BC%8C%E8%AE%BF%E9%97%AE%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%EF%BC%8C%E9%9D%99%E6%80%81%E5%85%83%E7%B4%A0%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[11.22 访问日志不记录静态文件网站大多元素为静态文件，如图片、css、js等，这些元素可以不用记录，没有意义。限制访问日志，让系统不记录静态文件，可以有效的减少无用的日志的空间占用。把虚拟主机配置文件 “httpd-vhosts.conf” 改成如下： 1234567891011121314151617181920212223242526[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf......&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/www.123.com&quot; ServerName www.123.com ServerAlias 123.com SetEnvIf Request_URI &quot;.*\.gif$&quot; img SetEnvIf Request_URI &quot;.*\.jpg$&quot; img SetEnvIf Request_URI &quot;.*\.png$&quot; img SetEnvIf Request_URI &quot;.*\.bmp$&quot; img SetEnvIf Request_URI &quot;.*\.swf$&quot; img SetEnvIf Request_URI &quot;.*\.js$&quot; img SetEnvIf Request_URI &quot;.*\.css$&quot; img #以上为定义变量：将所有关于图片的请求定义为变量img CustomLog &quot;logs/123.com-access_log&quot; combined env=!img# “env=!img”表示非img变量。本行命令的含义是：不记录关于变量img的请求日志。&lt;/VirtualHost&gt;配置完成后重新检测和加载[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful[root@host ~]# mkdir /data/wwwroot/www.123.com/images #创建目录，并在这目录下上传一个图片[root@host ~]# curl -x127.0.0.1:80 -I 123.com/images/123.jpg [root@host ~]#tail /usr/local/apache2.4/logs/123.com-access_log # 日志没有静态文件的记录了 11.23 访问日志切割日志一直记录总有一天会把整个磁盘占满，所以有必要让它自动切割，并删除老的日志文件把虚拟主机配置文件改成如下： 123456789101112131415161718192021222324[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf......&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/www.123.com&quot; ServerName www.123.com ServerAlias 123.com SetEnvIf Request_URI &quot;.*\.gif$&quot; img SetEnvIf Request_URI &quot;.*\.jpg$&quot; img SetEnvIf Request_URI &quot;.*\.png$&quot; img SetEnvIf Request_URI &quot;.*\.bmp$&quot; img SetEnvIf Request_URI &quot;.*\.swf$&quot; img SetEnvIf Request_URI &quot;.*\.js$&quot; img SetEnvIf Request_URI &quot;.*\.css$&quot; img CustomLog &quot;|/usr/local/apache2.4/bin/rotatelogs -l logs/123.com-access_%Y%m%d.log 86400&quot; combined env=!img# 使用rotatelogs工具，以系统时间为基准，每天切割一次日志，并且日志名字格式为“123.com-access_%Y%m%d.log”&lt;/VirtualHost&gt;配置完成后重新检测和加载[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl gracefulls /usr/local/apache2.4/logs 注： rotatelogs是Apache切割日志的工具，语法如下：Rotatelogs的用法：rotatelogs [ -l ] logfile [ rotationtime [ offset ]] | [ filesizeM ]选项： -l 使用本地时间代替GMT时间作为时间基准。注意：在一个改变GMT偏移量(比如夏令时)的环境中使用-l会导致不可预料的结果。 logfile 它加上基准名就是日志文件名。如果logfile中包含”%”，则它会被视为用于strftime()的格式字符串；否则它会被自动加上以秒为单位的”.nnnnnnnnnn”后缀。这两种格式都表示新的日志开始使用的时间。 rotationtime 日志文件滚动的以秒为单位的间隔时间。 offset 相对于UTC的时差的分钟数。如果省略，则假定为”0”并使用UTC时间。比如，要指定UTC时差为”-5小时”的地区的当地时间，则此参数应为”-300”。 filesizeM 指定以filesizeM文件大小滚动，而不是按照时间或时差滚动。 每小时切割一次日志CustomLog &quot;|/usr/local/apache2.4/bin/rotatelogs logs/access_%Y%m%d%H.log 3600&quot; combined 11.24 静态元素过期时间浏览器访问网站的图片时会把静态的文件缓存在本地电脑里，这样下次再访问时就不用去远程下载了，增加配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf……&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/111.com&quot; ServerName 111.com ServerAlias www.example.com &lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_HOST&#125; !^111.com$ RewriteRule ^/(.*)$ http://111.com/$1 [R=301,L] &lt;/IfModule&gt;&lt;IfModule mod_expires.c&gt; ExpiresActive on #打开该功能的开关 ExpiresByType image/gif &quot;access plus 1 days&quot; ExpiresByType image/jpeg &quot;access plus 24 hours&quot; ExpiresByType image/png &quot;access plus 24 hours&quot; ExpiresByType text/css &quot;now plus 2 hour&quot; ExpiresByType application/x-javascript &quot;now plus 2 hours&quot; ExpiresByType application/javascript &quot;now plus 2 hours&quot; ExpiresByType application/x-shockwave-flash &quot;now plus 2 hours&quot; ExpiresDefault &quot;now plus 0 min&quot; #以上是定义不同类型的文件缓存的时间&lt;/IfModule&gt; ErrorLog &quot;logs/111.com-error_log&quot; SetEnvIf Request_URI &quot;.*\.gif$&quot; img SetEnvIf Request_URI &quot;.*\.jpg$&quot; img SetEnvIf Request_URI &quot;.*\.png$&quot; img SetEnvIf Request_URI &quot;.*\.bmp$&quot; img SetEnvIf Request_URI &quot;.*\.swf$&quot; img SetEnvIf Request_URI &quot;.*\.js$&quot; img SetEnvIf Request_URI &quot;.*\.css$&quot; img CustomLog &quot;|usr/local/apache2.4/bin/rotatelogs -l logs/111.com-access_%Y%m%d.log 86400&quot; combined env=!img#使用rotatelogs工具，以系统时间为基准，每天切割一次日志，并且日志名字格式为“111.com-access_%Y%m%d.log”。配置完成后重新检测和加载[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK检测Apache配置文件是否开启expire模块： [root@host ~]# /usr/local/apache2.4/bin/apachectl -M |grep expires未检测到expires模块，所以需要编辑Apache配置文件，加载expires模块配置Apache，加载expires模块[root@host ~]# vim /usr/local/apache2.4/conf/httpd.confLoadModule expires_module modules/mod_expires.so加载配置文件：[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful检查模块是否开启：[root@host ~]# /usr/local/apache2.4/bin/apachectl -M |grep expiresexpires_module (shared)# 查找expires模块，并开启加载该模块的命令行（去掉#即可）。 再次检测[root@host ~]# curl -x192.168.2.130:80 111.com/baidu.png -I 在配置文件添加mod_expires.c模块内容，其余不变。 扩展apache日志记录代理IP以及真实客户端IP12345默认情况下log日志格式为：LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined其中%h 是记录访问者的IP，如果在web的前端有一层代理，那么这个%h其实就是代理机器的IP，这不是我们想要的。在这种情况下，%&#123;X-FORWARDED-FOR&#125;i 字段会记录客户端真实的IP。所以log日志改为：LogFormat &quot;%h %&#123;X-FORWARDED-FOR&#125;i %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined apache只记录指定URI的日志需求是，把类似请求 www.aaa.com/aaa/… 这样的请求才记录日志。在httpd.conf 或者 相关的虚拟主机配置文件中添加 123SetEnvIf Request_URI &quot;^/aaa/.*&quot; aaa-requestCustomLog &quot;|/usr/local/apache/bin/rotatelogs -l /usr/local/apache/logs/aaa-access_%Y%m%d.log 86400&quot; combined env=aaa-request这样就可以了。这个原理和不记录图片等静态访问的日志是一样的。 ##apache日志记录客户端请求的域名 正常情况下，根本就没有必要记录这一项，毕竟咱们大都根据虚拟主机来设置相应的访问日志，但也有个别的情况，比如ServerName *.abc.com这样泛解析的形式，所以有必要记录一下用户请求的域名到底是哪个。而apache的LogFormat 中正好有一项值满足了这个需求。即 %V 这里是大写的V ,小写的v 记录的是咱们在虚拟主机中设置的ServerName ，这个的确是没有必要记录的。 apache 日志切割问题apache的日志是可以自动切割的。方法一： 使用 cronolog 为每一天建立一个新的日志 1CustomLog &quot;|bin/cronolog logs/access_%Y%m%d.log&quot; combined 也可以按小时 1CustomLog &quot;|bin/cronolog logs/access_%Y%m%d%h.log&quot; combined 方法二：使用 rotatelogs 每一天记录一个日志 1CustomLog &quot;|bin/rotatelogs -l logs/access_%Y%m%d.log 86400&quot; combined 每小时 1CustomLog &quot;|bin/rotatelogs -l logs/access_%Y%m%d%H.log 3600&quot; combined 再看apache rotatelogs语法 12345678910111213rotatelogs [ -l ] logfile [ rotationtime [ offset ]] | [ filesizeM ]选项-l 使用本地时间代替GMT时间作为时间基准。注意：在一个改变GMT偏移量(比如夏令时)的环境中使用-l会导致不可预料的结果。所以一定要加上-l 否则出现的日志时间和实际时间是相差8小时的。 logfile它加上基准名就是日志文件名。如果logfile中包含”%”，则它会被视为用于strftime()的格式字符串；否则它会被自动加上以秒为单位的”.nnnnnnnnnn”后缀。这两种格式都表示新的日志开始使用的时间。 rotationtime日志文件滚动的以秒为单位的间隔时间。 offset相对于UTC的时差的分钟数。如果省略，则假定为”0″并使用UTC时间。比如，要指定UTC时差为”-5小时”的地区的当地时间，则此参数应为”-300″。 filesizeM指定以filesizeM文件大小滚动，而不是按照时间或时差滚动。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>apache</tag>
        <tag>httpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构-Apache用户认证，域名跳转，Apache访问日志]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.18%20-%2011.21%20LAMP%E6%9E%B6%E6%9E%84-Apache%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%EF%BC%8C%E5%9F%9F%E5%90%8D%E8%B7%B3%E8%BD%AC%EF%BC%8CApache%E8%AE%BF%E9%97%AE%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[11.18 Apache用户认证 经常上网的读者会遇到这种情况：访问一些网站的某些资源时，浏览器弹出一个对话框，要求输入用户名和密码来获取对资源的访问。这就是用户认证的一种技术。用户认证是保护网络系统资源的第一道防线，它控制着所有登录并检查访问用户的合法性，其目标是仅让合法用户以合法的权限访问网络系统的资源。基本的用户认证技术是“用户名＋密码”。 注意： 本章使用浏览器进行检测的前提是在物理机hosts文件添加虚拟机IP和虚拟主机域名。 1. 配置整个网站的用户认证1.1 编辑虚拟主机配置文件“httpd-vhosts.conf”1234567891011121314151617[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf……&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/111.com&quot; ServerName 111.com ServerAlias www.example.com &lt;Directory /data/wwwroot/111.com&gt; #指定认证的目录 Allowoverride AuthConfig #该行相当于打开用户认证的开关 AuthName &quot;111.com user auth&quot; #自定义认证的名字，作用不大 AuthType Basic #认证类型，一般为basic AuthUserFile /data/.htpasswd #指定密码文件所在位置（需要手动添加） require valid-user #设定需要认证的用户为“AuthUserFile”中定义的所有可用用户 &lt;/Directory&gt; ErrorLog &quot;logs/111.com-error_log&quot; CustomLog &quot;logs/111.com-access_log&quot; common&lt;/VirtualHost&gt; 1.2 创建“httpd-vhosts.conf”中指定的密码文件12345678[root@host ~]# /usr/local/apache2.4/bin/htpasswd -c -m /data/.htpasswd zhouqun# 在“/data/.htpasswd”为用户zhouqun创建一个使用MD5算法加密的密码文件New password: Re-type new password: Adding password for user zhouqun[root@adailinux ~]# cat /data/.htpasswdzhouqun:$apr1$F7lSqIT0$ksTH0NhusdaJK.7sgj/ -c：为了创建文件以及第一个用户，文件存在或创建第二个用户时不需要使用-m：表示密码使用MD5加密 1.3 配置完成后重新加载123[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful 1.4 测试12345678910111213141516[root@host ~]# curl -x192.168.2.130:80 111.com -IHTTP/1.1 401 UnauthorizedDate: Wed, 23 Aug 2017 00:32:50 GMTServer: Apache/2.4.27 (Unix) PHP/5.6.30WWW-Authenticate: Basic realm=&quot;111.com user auth&quot;Content-Type: text/html; charset=iso-8859-1- 此时提示状态码为“401”，说明当前所访问的内容需要进行用户认证。- 使用 用户名和密码 访问[root@host ~]# curl -x192.168.2.130:80 -uzhouqun:123456 111.com -IHTTP/1.1 200 OKDate: Wed, 23 Aug 2017 00:34:26 GMTServer: Apache/2.4.27 (Unix) PHP/5.6.30X-Powered-By: PHP/5.6.30Content-Type: text/html; charset=UTF-8- 状态码“200”，即访问成功。 用浏览器测试 2. 配置单个文件的用户认证2.1 编辑虚拟主机配置文件“httpd-vhosts.conf”123456789101112131415161718[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/111.com&quot; ServerName 111.com ServerAlias www.example.com #&lt;Directory /data/wwwroot/111.com&gt; # 注释掉&lt; Directory &gt;，取消对目录设定的用户认证，更改为&lt; FilesMatch&gt;，即对文件设定用户认证&lt;FilesMatch admin.php&gt; #因为是针对文件，所以使用&lt;FilesMatch&gt;，后面跟文件 AllowOverride AuthConfig #表示开启认证 AuthName &quot;111.com user&quot; #提示信息，可自定义 AuthType Basic #认证类型，使用Basic即可 AuthUserFile /data/wwwroot/.htpasswd #认证密码文件位置 require valid-user #指定需要认证的用户为全部可用用户&lt;/FilesMatch&gt; #&lt;/Directory&gt; ErrorLog &quot;logs/111.com-error_log&quot; CustomLog &quot;logs/111.com-access_log&quot; common&lt;/VirtualHost&gt; 2.2 创建“httpd-vhosts.conf”中指定的密码文件1[root@host ~]# /usr/local/apache2.4/bin/htpasswd -m /data/wwwroot/.htpasswd zhouqun 2.3 配置完成后重新加载123[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful 2.4 测试1234567891011[root@host ~]# curl -x192.168.8.131:80 111.com welcome to 111.com [root@host ~]# curl -x192.168.8.131:80 111.com/123.php -IHTTP/1.1 401 UnauthorizedDate: Wed, 23 Aug 2017 00:38:12 GMTServer: Apache/2.4.27 (Unix) PHP/5.6.30WWW-Authenticate: Basic realm=&quot;111.com user auth&quot;Content-Type: text/html; charset=iso-8859-1- 此时可以自由访问“111.com”指定的目录，但是当访问目录下的“123.php”文件时会报错：401，即，需要进行用户认证。 使用 用户名和密码 访问 123[root@host ~]# curl -x192.168.2.130:80 -uadai:123456 111.com/123.php welcom to 123file 成功！ 使用浏览器 访问 11.19/11.20 域名跳转1. 域名跳转分类及区别1.1 种类：301表示永久跳转；302表示临时跳转。 1.2 区别： 使用效果不同 302跳转是暂时的跳转，搜索引擎会抓取新的内容而保留旧的网址。因为服务器返回302代码，搜索引擎认为新的网址只是暂时的。 301重定向是永久的重定向，搜索引擎在抓取新内容的同时也将旧的网址替换为重定向之后的网址。 SEO使用方式不同在搜索引擎优化中302跳转被众多黑帽SEO优化人员追求，对网站进行恶意302跳转至非用户目标访问网站，因此搜索引擎对于网站的302跳转通常是比较不友好，所以要慎用302跳转！ SEO是什么？SEO（Search Engine Optimization）搜索引擎优化，在了解搜索引擎自然排名机制的基础上，对网站进行内部及外部的调整优化，改进网站在搜索引擎中的关键词自然排名，获得更多流量，从而达成网站销售及品牌建设的预期目标。 2. 域名跳转的作用 一个站点有多个域名会对SEO有影响，说白了就是百度搜索关键词的排名会收到影响，如果把多个域名全部跳转到指定的一个域名，这样以这个域名为中心，就可以吧权重集中在这个域名上，这样搜索关键词的排名也就靠前。 如果之前的某个域名不再使用了，但是搜索引擎还保留着之前老域名的连接，这以为着用户可能会搜到我们的网站并且点击老域名，固需要把老域名做个跳转跳到新域名。 3. 域名跳转配置3.1 配置虚拟主机配置文件：httpd-vhosts.conf1234567891011121314[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf……&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/111.com&quot; ServerName 111.com ServerAlias www.example.com &lt;IfModule mod_rewrite.c&gt; #需要mod_rewrite的支持 RewriteEngine on #开启rewrite功能 RewriteCond %&#123;HTTP_HOST&#125; !^111.com$ #Cond=condition，定义rewrite条件：所有非111.com的主机名（域名） RewriteRule ^/(.*)$ http://111.com/$1 [R=301,L] #定义rewrite规则：当满足上面条件时才执行当前规则，即跳转到111.com。 &lt;/IfModule&gt; ErrorLog &quot;logs/111.com-error_log&quot; CustomLog &quot;logs/111.com-access_log&quot; common&lt;/VirtualHost&gt; 3.2 检查系统配置并重新加载123456789101112131415161718[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful[root@host ~]# /usr/local/apache2.4/bin/apachectl -M #检查Apache是否加载了虚拟主机配置中调用的rewrite模块- 如果没有调用到，需要编辑Apache配置文件 “httpd.conf”[root@host ~]# vim /usr/local/apache2.4/conf/httpd.conf ……LoadModule rewrite_module modules/mod_rewrite.so #去掉注释符号“#”，加载rewrite模块。LoadModule php5_module modules/libphp5.so#LoadModule php7_module modules/libphp7.so- 检测[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful[root@host ~]# /usr/local/apache2.4/bin/apachectl -M |grep rewriterewrite_module (shared) 3.3 使用curl检测123456789[root@host ~]# curl -x192.168.2.130:80 www.example.com -IHTTP/1.1 301 Moved PermanentlyDate: Wed, 23 Aug 2017 00:44:37 GMTServer: Apache/2.4.27 (Unix) PHP/5.6.30Location: http://111.com/Content-Type: text/html; charset=iso-8859-1状态码为301，即设定了域名永久跳转!在浏览器进行检测时，访问“www.example.com”会直接跳转到“111.com”。 11.21 Apache访问日志访问日志记录用户的每一个请求 1. 设置Apache访问日志格式1.1 Apache访问日志位置123[root@host ~]# ls /usr/local/apache2.4/logs111.com-access_log abc.com-access_log access_log httpd.pid111.com-error_log abc.com-error_log error_log 1.2 系统自带日志格式123456[root@host ~]# vim /usr/local/apache2.4/conf/httpd.conf # 搜索LogFormat LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b&quot; common# h表示host来源IP，l表示login用户，u表示user用户密码，t表示time时间，r表示request（行为），s表示status状态码，b表示byte大小# user-agent：用户代理# referer：跳转到当前位置的上一个网址（即：提供当前IP的网站） combinedio是combined的升级，一般我们使用combined格式就足够了。 1.3 设置访问日志格式123456789101112131415161718192021[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/data/wwwroot/111.com&quot; ServerName 111.com ServerAlias www.example.com &lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_HOST&#125; !^111.com$ RewriteRule ^/(.*)$ http://111.com/$1 [R=301,L] &lt;/IfModule&gt; ErrorLog &quot;logs/111.com-error_log&quot; CustomLog &quot;logs/111.com-access_log&quot; combined # 将comom修改为combined即可&lt;/VirtualHost&gt;- 重新加载：[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful- 样式：[root@host ~]# cat /usr/local/apache2.4/logs/111.com-access_log 扩展apache虚拟主机开启php的短标签12[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.confphp_admin_flag short_open_tag on #这一行变为on就好了，默认是off的]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>apache</tag>
        <tag>httpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构-Apache和PHP结合、Apache默认虚拟主机]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.14%20-%2011.17%20LAMP%E6%9E%B6%E6%9E%84-Apache%E5%92%8CPHP%E7%BB%93%E5%90%88%E3%80%81Apache%E9%BB%98%E8%AE%A4%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[11.14/11.15 Apache和PHP结合1. 配置ApacheApache(httpd) 的主配置文件： /usr/local/apache2.4/conf/httpd.conf需要修改以下4个地方 ServerName localhost:80 Require all denied 修改为 Require all granted AddType application/x-httpd-php .php DirectoryIndex index.html index.php 1.1 选择要调用的PHP因为本来安装了PHP5 和PHP7 两个版本的PHP，需要配置一下，一次只加载一个PHP模块（我们选择PHP5），而不是2个一起调用，否则，会出现错误。 1234[root@host ~]# vim /usr/local/apache2.4/conf/httpd.conf……LoadModule php5_module modules/libphp5.so#LoadModule php7_module modules/libphp7.so #加上 “#” 注释掉php7，只加载PHP5 模块 1.2 物理机启用win7中telnet命令1开始 --&gt; 控制面板 --&gt; 程序 --&gt; 打开或关闭Windows功能 --&gt; 选择telnet客户端 (注意不要勾选 telnet服务端) 1.3 配置Apache12345678910111213141516- 更改配置文件：将配置中 “Require all denied” 改为 “Require all granted”[root@host ~]# vim /usr/local/apache2.4/conf/httpd.conf……&lt;Directory /&gt; AllowOverride none Require all granted&lt;/Directory&gt;……- 检测配置是否存在语法错误：[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK- 重新加载服务：[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful注：该命令不会使服务重启，只是加载配置文件的内容。 1.4 添加监听80端口的规则1[root@host ~]# iptables -I INPUT -p tcp --dport 80 -j ACCEPT 说明： 至此，物理机可以使用浏览器直接访问本地虚拟机IP了。 1.5 添加PHP服务1234567891011121314151617181920212223- 授权PHP服务解析本机服务器：添加 “AddType application/x-httpd-php .php”[root@host ~]# vim /usr/local/apache2.4/conf/httpd.conf…… # AddType application/x-compress .Z AddType application/x-gzip .gz .tgz AddType application/x-httpd-php .php # 添加 “AddType application/x-httpd-php .php” #……- 增加索引页：添加 “index.php” 变为 “DirectoryIndex index.html index.php”[root@host ~]# vim /usr/local/apache2.4/conf/httpd.conf……&lt;IfModule dir_module&gt; DirectoryIndex index.html index.php # 添加“index.php”&lt;/IfModule&gt;……- 检测语法：[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK- 重新加载[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful 1.6 检测服务器是否支持PHP解析12345678910111213141516171819[root@host ~]# vim /usr/local/apache2.4/htdocs/1.php&lt;?phpphpinfo(); #该参数的含义是PHP的信息?&gt; #该命令的含义是：在访问该地址时，直接打印PHP的相关信息- 在物理机浏览器输入 虚拟机ip+1.php ：192.168.2.130/1.php 1. 返回下面结果，表示已经支持PHP解析2. 返回下面结果，表示还不支持PHP解析，需要查找原因[root@host ~]# /usr/local/apache2.4/bin/apachectl -M检查有没有加载 php5_module 模块,如果没找到ls /usr/local/apache2.4/modules/libphp5.so 看有没有这个文件如果有文件，检查配置文件[root@host ~]# vim /usr/local/apache2.4/conf/httpd.conf/libphp5.so #看配置文件里有没有加载这个配置文件/Addtype #检查是否有 AddType application/x-httpd-php .php 这一行（注意中间有个空格）/index.php #检查是否有 DirectoryIndex index.html index.php 1.7 切换使用PHP7.0123456789[root@host~]# vim /usr/local/apache2.4/conf/httpd.conf……#LoadModule php5_module modules/libphp5.soLoadModule php7_module modules/libphp7.so # 注释掉5，去掉7前面的 #检测、加载：[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful 11.16/11.17 Apache默认虚拟主机一台服务器可以访问多个网站，每个网站都是一个虚拟主机概念：域名（主机名）、DNS、解析域名、hosts任何一个域名解析到这台机器，都可以访问的虚拟主机就是默认虚拟主机 1. Windows的hosts文件hosts文件路径：C:\Windows\System32\drivers\etc\hosts 在该文件中可添加DNS解析192.168.2.130 www.abc.com www.123.com修改之后，当我们访问www.abc.com和www.123.com时就会解析到我们的Linux服务器（192.168.2.130），访问该域名时会自动解析到本地默认虚拟主机“ServerName www.example.com:80” 2. Linux的虚拟主机在物理机访问的域名“www.abc.com”并未在虚拟机Apache配置文件中定义，虚拟机中只定义了“ServerName www.example.com:80”一个域名，该域名即为Apache的默认主机，此时通过任何一个绑定该虚拟机IP的域名进行访问都会跳转到该主机。因为一台服务器可以跑多个域名，为了方便管理，需要对虚拟主机配置文件进行配置： 2.1 启用虚拟主机配置文件12345678910[root@host ~]# vim /usr/local/apache2.4/conf/httpd.conf……# Virtual hostsInclude conf/extra/httpd-vhosts.conf #去掉前面的#，就可以启用了……- 检测，加载[root@host ~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful注意： 重新加载配置文件后，之前定义的默认虚拟主机www.example.com:80将失效。 2.2 编辑虚拟主机配置文件，配置如下：123456789101112131415161718[root@host ~]# vim /usr/local/apache2.4/conf/extra/httpd-vhosts.conf... ... #每一个&lt;VirtualHost *:80&gt;代表一个虚拟主机，一个主机就是一个网站&lt;VirtualHost *:80&gt; ServerAdmin zhouqunic@qq.com DocumentRoot&quot;/data/wwwroot/abc.com&quot; #指定网站根目录 ServerName abc.com #定义网站域名 ServerAlias www.abc.com www.123.com #设置别名（可设置多个） ErrorLog &quot;logs/abc.com-error_log&quot; CustomLog &quot;logs/abc.com-error_log&quot; common #指定错误日志和访问日志文件&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; DocumentRoot&quot;/data/wwwroot/111.com&quot; ServerName 111.com ServerAlias www.example.com ErrorLog &quot;logs/111.com-error_log&quot; CustomLog &quot;logs/111.com-access_log&quot; common&lt;/VirtualHost&gt; 2.3 添加虚拟主机相应目录123[root@host ~]# mkdir /data/wwwroot/[root@host ~]# mkdir /data/wwwroot/abc.com[root@host ~]# mkdir /data/wwwroot/111.com 3. 添加测试文件123456789101112131415- 在相应目录创建PHP文件[root@host ~]# vim /data/wwwroot/abc.com/index.php&lt;?phpecho &quot;welcome to aaa.com&quot;?&gt;[root@host ~]# vim /data/wwwroot/111.com/index.php&lt;?phpecho &quot;welcome to 111.com&quot;?&gt;- 检测、重加载Apache配置文件[root@host~]# /usr/local/apache2.4/bin/apachectl -tSyntax OK[root@host ~]# /usr/local/apache2.4/bin/apachectl graceful 4. 测试在此使用物理机的浏览器和虚拟机的curl命令分别进行测试 虚拟机上测试如果不在虚拟机中进行本地域名配置（hosts），在进行ping命令测试虚拟主机域名时会访问到外网。如果想在访问“abc.com”时指向到本地虚拟机IP，可以在/etc/hosts文件中指定域名，或者使用curl命令进行访问，如下： 12345678[root@host ~]# curl -x 192.168.2.130:80 abc.comwelcome to aaa.com[root@host ~]# curl -x 192.168.2.130:80 111.comwelcome to 111.com[root@host ~]# curl -x 192.168.2.130:80 123.comwelcome to aaa.com[root@host ~]# curl -x 192.168.2.130:80 www.example.comwelcome to 111.com 使用物理机浏览器访问使用浏览器访问，可以直接输入 192.168.2.130，或者修改hosts： 192.168.2.130 abc.com 111.com abcde.com www.example.com，然后输入 域名访问。如果不改hosts文件的话，输入域名，会默认使用DNS解析到外网网址去。 扩展apache所有的主机都指向第一个虚拟主机http://www.aminglinux.com/bbs/thread-491-1-1.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构-安装PHP5、PHP7]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.10%20-%2011.13%20LAMP%E6%9E%B6%E6%9E%84-%E5%AE%89%E8%A3%85PHP5%E3%80%81PHP7%2F</url>
    <content type="text"><![CDATA[PHP官网www.php.net当前主流版本为5.6/7.1 1. 编译安装PHP5.6123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@host apache2.4]# cd /usr/local/src/ [root@host src]# wget http://cn2.php.net/distributions/php-5.6.30.tar.bz2 #下载PHP5.6源码包[root@host src]# tar jxf php-5.6.30.tar.bz2tar (child): bzip2: Cannot exec: No such file or directorytar (child): Error is not recoverable: exiting nowtar: Child returned status 2tar: Error is not recoverable: exiting now //说明没有安装bzip2这个软件包。解决方法：安装bzip2软件包[root@host src]# yum -y install bzip2[root@host src]# tar jxf php-5.6.30.tar.bz2[root@host src]# cd php-5.6.30 #[root@host php-5.6.30]# ./configure --prefix=/usr/local/php --with-apxs2=/usr/local/apache2.4/bin/apxs --with-config-file-path=/usr/local/php/etc --with-mysql=/usr/local/mariadb --with-pdo-mysql=/usr/local/mariadb --with-mysqli=/usr/local/mariadb/bin/mysql_config --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-bz2 --with-openssl --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-mbstring --enable-sockets --enable-exif [root@host php-5.6.30]# ./configure --prefix=/usr/local/php --with-apxs2=/usr/local/apache2.4/bin/apxs --with-config-file-path=/usr/local/php/etc --with-mysql=/usr/local/mysql --with-pdo-mysql=/usr/local/mysql --with-mysqli=/usr/local/mysql/bin/mysql_config --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-bz2 --with-openssl --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-mbstring --enable-sockets --enable-exif# 解释# --prefix 安装目录#--with-apxs2 apache的工具，能让我们不用人工干涉它，帮忙把扩展模块放到apache的modules目录里，并且在它的配置文件里加上一行mod-modules，自动的给你配置上这个模块，一般可以给你加上so文件，但是不会自动加载配置模块，这就是为什么要后安装PHP#--with-mysql --with-pdo-mysql --with-mysqli 定义给mysql通信的相关函数或者驱动，让php能和mysql交换数据#--with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-bz2 --with-openssl --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-mbstring --enable-sockets --enable-exif 这些都是一些必要的参数#在编译的过程中，会出现一些错误，往往是因为缺少相关的库文件1. configure: error: xml2-config not found. Please check your libxml2 installation.yum install libxml2-devel -y2. configure: error: Cannot find OpenSSL&apos;s &lt;evp.h&gt;yum install -y openssl openssl-devel3. configure: error: Please reinstall the BZip2 distributionyum install -y bzip2 bzip2-devel4. configure: error: jpeglib.h not found.yum install -y libjpeg-devel5. configure: error: png.h not found.yum install -y libpng-devel6. configure: error: freetype-config not found.yum install -y freetype-devel7. configure: error: mcrypt.h not found. Please reinstall libmcrypt.(centos源不能安装libmcrypt-devel，由于版权的原因没有自带mcrypt的包rpm -qa|grep limcrypt limcrypt-devel,此源为rethot社区版的源)安装第三方yum源wget http://www.atomicorp.com/installers/atomicsh ./atomicyum install php-mcrypt libmcrypt libmcrypt-devel---make &amp;&amp; make installecho $?0cp php.ini-production /usr/local/php/etc/php.ini #把参考配置文件拷贝到定义的路径#也可以自己找一下， /usr/local/php/bin/php -i | less 查看一些php的参数# php.ini-production 使用于生产环境的配置文件，还有适用于开发和实验环境的配置文件php.ini-development 2. 查看PHP的目录123456789ls /usr/local/php/ls /usr/local/php/bin/ #php核心的二进制文件在这个文件夹里面du -sh /usr/local/php/bin/php36M /usr/local/php/bin/phpdu -sh /usr/local/apache2.4/modules/libphp.so #PHP和Apache结合的模块37M /usr/local/apache2.4/modules/libphp.so/usr/local/php/bin/php -m #查看php加载的模块（静态）/usr/local/apache2.4/bin/httpd -M #查看apache加载的模块vi /usr/local/apache2.4/conf/httpd.conf #apache配置文件 3. 安装PHP712345678cd /usr/local/src/ wget http://cn2.php.net/distributions/php-7.1.6.tar.bz2tar zxf php-7.1.6.tar.bz2cd php-7.1.6./configure --prefix=/usr/local/php7 --with-apxs2=/usr/local/apache2.4/bin/apxs --with-config-file-path=/usr/local/php7/etc --with-pdo-mysql=/usr/local/mysql --with-mysqli=/usr/local/mysql/bin/mysql_config --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-bz2 --with-openssl --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-mbstring --enable-sockets --enable-exifmake &amp;&amp; make installls /usr/local/apache2.4/modules/libphp7.socp php.ini-production /usr/local/php7/etc/php.ini 4. php中mysql,mysqli,mysqlnd,pdo到底是什么http://blog.csdn.net/u013785951/article/details/60876816 5. 查看编译参数http://ask.apelearn.com/question/1295]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构-mariadb、apache httpd安装]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.6%20-%2011.9%20LAMP%E6%9E%B6%E6%9E%84-mariadb%E3%80%81apache%20httpd%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[[toc] 11.6 MariaDB安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960cd /usr/local/src #进入制定目录wget https://downloads.mariadb.com/MariaDB/mariadb-10.2.6/bintar-linux-glibc_214-x86_64/mariadb-10.2.6-linux-glibc_214-x86_64.tar.gz #到官网下载mariaDB二进制包tar zxvf mariadb-10.2.6-linux-glibc_214-x86_64.tar.gz #将包解压到当前目录mv mariadb-10.2.6-linux-glibc_214-x86_64 /usr/local/mariadb #将mariaDB的glibc文件移动到/usr/local/mariadb目录cd /usr/local/mariadb #进入目录mkdir /data/useradd mysql #添加mysql用户./scripts/mysql_install_db --user=mysql --basedir=/usr/local/mariadb --datadir=/data/mariadb #执行mysql初始化命令/usr/local/mariadb//bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory #报错，缺少文件libaioyum list | grep libaio #寻找libaio包，如下，一般我们缺少的包，安装devel或者deb的包就好libaio.i686 0.3.109-13.el7 base libaio.x86_64 0.3.109-13.el7 base libaio-devel.i686 0.3.109-13.el7 base libaio-devel.x86_64 0.3.109-13.el7 baseyum install libaio-devel.x86_64 #安装./scripts/mysql_install_db --user=mysql --basedir=/usr/local/mariadb --datadir=/data/mariadb #再次执行mysql初始化命令echo $?0cp support-files/my-small.cnf /usr/local/mariadb/my.cnf #复制源配置文件到mariadb下面，在 [mysqld]里定义basedir和datadir，如果系统同时有mysql的话，可能或调用mysql的basedir和datadirvim /usr/local/mariadb/my.cnf basedir=/usr/local/mariadb datadir=/data/mariadbcp support-files/mysql.server /etc/init.d/mariadb #复制mysql服务配置文件到mariadb下面，需要修改参数vim /etc/init.d/mariadb //定义basedir、datadir、conf以及启动参数 basedir=/usr/local/mariadb datadir=/data/mariadb conf=$basedir/my.cnf... ...case &quot;$mode&quot; in &apos;start&apos;) # Start daemon # Safeguard (relative paths, core dumps..) cd $basedir echo $echo_n &quot;Starting MySQL&quot; if test -x $bindir/mysqld_safe then # Give extra arguments to mysqld with the my.cnf file. This script # may be overwritten at next upgrade. $bindir/mysqld_safe --defaults-file=&quot;$conf&quot; --datadir=&quot;$datadir&quot; --pid-file=&quot;$mysqld_pid_file_path&quot; &quot;$@&quot; &amp; wait_for_ready; return_value=$?/etc/init.d/mariadb start #启动ps aux | grep mariadb #确认下是否正常启动，YESroot 11492 0.0 0.6 115388 3308 ? S 12:45 0:00 /bin/sh /usr/local/mariadb/bin/mysqld_safe --defaults-file=/usr/local/mariadb/my.cnf --datadir=/data/mariadb --pid-file=/data/mariadb/joking.pidmysql 11611 0.0 10.8 1125112 56148 ? Sl 12:45 0:00 /usr/local/mariadb/bin/mysqld --defaults-file=/usr/local/mariadb/my.cnf --basedir=/usr/local/mariadb --datadir=/data/mariadb --plugin-dir=/usr/local/mariadb/lib/plugin --user=mysql --log-error=/data/mariadb/joking.err --pid-file=/data/mariadb/joking.pid --socket=/tmp/mysql.sock --port=3306root 11770 0.0 0.4 112656 2260 pts/0 S+ 12:54 0:00 grep --color=auto mariadbnetstat -ltnpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1895/master tcp 0 0 0.0.0.0:28206 0.0.0.0:* LISTEN 1083/sshd tcp6 0 0 ::1:25 :::* LISTEN 1895/master tcp6 0 0 :::3306 :::* LISTEN 11611/mysqld tcp6 0 0 :::28206 :::* LISTEN 1083/sshd 11.7/11.8/11.9 Apache安装Apache是一个基金会的名字，httpd才是我们要安装的软件包，早期它的名字就叫apache，现在主流版本是2.42.2和2.4的安装方法不同，涉及到依赖的APR通用函数库版本不同，我们的CentOS7自带的APR包是2.2的，而2.4的需要下载自己编译Apache官网www.apache.org 1. 先下载下列这些包到 /usr/local/src/12345cd /usr/local/src/wget http://mirrors.cnnic.cn/apache/httpd/httpd-2.4.27.tar.gz #httpd的二进制包wget http://mirrors.hust.edu.cn/apache/apr/apr-1.6.2.tar.gz # APR库源码包wget http://mirrors.hust.edu.cn/apache/apr/apr-util-1.6.0.tar.gz # APR-util库源码包# apr和apr-util是一个通用的函数库，它让httpd可以不关心底层的操作系统平台，可以很方便地移植（从linux移植到windows） 2. 解压这些包123tar zxvf httpd-2.4.27.tar.gz tar zxvf apr-1.6.2.tar.gz tar zxvf apr-util-1.6.0.tar.gz 3.安装APR1234567891011cd /usr/local/src/apr-1.6.2./configure --prefix=/usr/local/aprecho $? #检查安装是否成功0 # 0表示OKmake &amp;&amp; make install报错rm: cannot remove &apos;libtoolT&apos;: No such file or directory解决：编辑 configure文件，查找 $RM &quot;$cfgfile&quot; 这个地方，用#注释掉vim configure /$RM &quot;$cfgfile //查找这个，并用#注释掉 4. 安装APR-util12345678cd /usr/local/src/apr-util-1.6.0./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr # 这个需要制定依赖aprmake &amp;&amp; make install报错xml/apr_xml.c:35:19: fatal error: expat.h: No such file or directory解决：安装expat库yum install expat-devel 5. 安装httpd 2.4123456789101112131415161718cd /usr/local/src/httpd-2.4.27./configure \ #这里的反斜杠是脱义字符，加上它我们可以把一行命令写成多行--prefix=/usr/local/apache2.4 \--with-apr=/usr/local/apr \--with-apr-util=/usr/local/apr-util \--enable-so \ #表示开启支持动态扩展模块，PHP还有Appache都支持以模块的形式存在--enable-mods-shared=most #表示开启大多数模块#如果输出错误，说缺少pcre包的话yum list | grep pcreyum install -y pcre-devel.x86_64./configure \ --prefix=/usr/local/apache2.4 --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --enable-so --enable-mods-shared=most 这句是错了./configure --prefix=/usr/local/apache2.4 --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --enable-so --enable-mods-shared=mostecho $? #确认上条命令是都OK0make &amp;&amp; make install 6. Apache相关文件和模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@joking httpd-2.4.27]# cd /usr/local/apache2.4/[root@joking apache2.4]# lsbin build cgi-bin conf error htdocs icons include logs man manual modules[root@joking apache2.4]# ls bin/httpdbin/httpd[root@joking apache2.4]# du -sh !$du -sh bin/httpd2.3M bin/httpd[root@joking apache2.4]# ls conf/extra httpd.conf magic mime.types original[root@joking apache2.4]# ls htdocs/index.html[root@joking apache2.4]# ls logs/[root@joking apache2.4]# ls modules/httpd.exp mod_authn_dbd.so mod_authz_user.so mod_deflate.so mod_info.so mod_negotiation.so mod_proxy_scgi.so mod_session_dbd.so mod_substitute.somod_access_compat.so mod_authn_dbm.so mod_autoindex.so mod_dir.so mod_lbmethod_bybusyness.so mod_proxy_ajp.so mod_proxy.so mod_session.so mod_unique_id.somod_actions.so mod_authn_file.so mod_buffer.so mod_dumpio.so mod_lbmethod_byrequests.so mod_proxy_balancer.so mod_proxy_wstunnel.so mod_setenvif.so mod_unixd.somod_alias.so mod_authn_socache.so mod_cache_disk.so mod_env.so mod_lbmethod_bytraffic.so mod_proxy_connect.so mod_ratelimit.so mod_slotmem_shm.so mod_userdir.somod_allowmethods.so mod_authz_core.so mod_cache.so mod_expires.so mod_lbmethod_heartbeat.so mod_proxy_express.so mod_remoteip.so mod_socache_dbm.so mod_version.somod_auth_basic.so mod_authz_dbd.so mod_cache_socache.so mod_ext_filter.so mod_log_config.so mod_proxy_fcgi.so mod_reqtimeout.so mod_socache_memcache.so mod_vhost_alias.somod_auth_digest.so mod_authz_dbm.so mod_cgid.so mod_file_cache.so mod_log_debug.so mod_proxy_fdpass.so mod_request.so mod_socache_shmcb.so mod_watchdog.somod_auth_form.so mod_authz_groupfile.so mod_dav_fs.so mod_filter.so mod_logio.so mod_proxy_ftp.so mod_rewrite.so mod_speling.somod_authn_anon.so mod_authz_host.so mod_dav.so mod_headers.so mod_macro.so mod_proxy_hcheck.so mod_sed.so mod_ssl.somod_authn_core.so mod_authz_owner.so mod_dbd.so mod_include.so mod_mime.so mod_proxy_http.so mod_session_cookie.so mod_status.so[root@joking apache2.4]# du -sh modules/7.3M modules/[root@joking apache2.4]# [root@joking apache2.4]# ls /usr/local/apache2.4/moduleshttpd.exp mod_authn_dbd.so mod_authz_user.so mod_deflate.so mod_info.so mod_negotiation.so mod_proxy_scgi.so mod_session_dbd.so mod_substitute.somod_access_compat.so mod_authn_dbm.so mod_autoindex.so mod_dir.so mod_lbmethod_bybusyness.so mod_proxy_ajp.so mod_proxy.so mod_session.so mod_unique_id.somod_actions.so mod_authn_file.so mod_buffer.so mod_dumpio.so mod_lbmethod_byrequests.so mod_proxy_balancer.so mod_proxy_wstunnel.so mod_setenvif.so mod_unixd.somod_alias.so mod_authn_socache.so mod_cache_disk.so mod_env.so mod_lbmethod_bytraffic.so mod_proxy_connect.so mod_ratelimit.so mod_slotmem_shm.so mod_userdir.somod_allowmethods.so mod_authz_core.so mod_cache.so mod_expires.so mod_lbmethod_heartbeat.so mod_proxy_express.so mod_remoteip.so mod_socache_dbm.so mod_version.somod_auth_basic.so mod_authz_dbd.so mod_cache_socache.so mod_ext_filter.so mod_log_config.so mod_proxy_fcgi.so mod_reqtimeout.so mod_socache_memcache.so mod_vhost_alias.somod_auth_digest.so mod_authz_dbm.so mod_cgid.so mod_file_cache.so mod_log_debug.so mod_proxy_fdpass.so mod_request.so mod_socache_shmcb.so mod_watchdog.somod_auth_form.so mod_authz_groupfile.so mod_dav_fs.so mod_filter.so mod_logio.so mod_proxy_ftp.so mod_rewrite.so mod_speling.somod_authn_anon.so mod_authz_host.so mod_dav.so mod_headers.so mod_macro.so mod_proxy_hcheck.so mod_sed.so mod_ssl.somod_authn_core.so mod_authz_owner.so mod_dbd.so mod_include.so mod_mime.so mod_proxy_http.so mod_session_cookie.so mod_status.so[root@joking apache2.4]# /usr/local/apache2.4/bin/httpd -M #查看加载的模块# /usr/local/apache2.4/bin/apachectl -M #同上，利用shell调用httpdAH00558: httpd: Could not reliably determine the server&apos;s fully qualified domain name, using 127.0.1.1. Set the &apos;ServerName&apos; directive globally to suppress this messageLoaded Modules:core_module (static)so_module (static)http_module (static)mpm_event_module (static)authn_file_module (shared)authn_core_module (shared)authz_host_module (shared)authz_groupfile_module (shared)authz_user_module (shared)authz_core_module (shared)access_compat_module (shared)auth_basic_module (shared)reqtimeout_module (shared)filter_module (shared)mime_module (shared)log_config_module (shared)env_module (shared)headers_module (shared)setenvif_module (shared)version_module (shared)unixd_module (shared)status_module (shared)autoindex_module (shared)dir_module (shared)alias_module (shared)(static) --原封模块(shared) --扩展模块 7. 启动apache1234567891011121314151617[root@joking apache2.4]# /usr/local/apache2.4/bin/apachectl start #有提示，但并不是错误的AH00558: httpd: Could not reliably determine the server&apos;s fully qualified domain name, using host.localdomain. Set the &apos;ServerName&apos; directive globally to suppress this message[root@joking apache2.4]# ps aux | grep httpdroot 27772 0.0 0.8 95520 4364 ? Ss 10:15 0:00 /usr/local/apache2.4/bin/httpd -k startdaemon 27773 0.0 0.8 382348 4416 ? Sl 10:15 0:00 /usr/local/apache2.4/bin/httpd -k startdaemon 27774 0.0 0.8 382348 4416 ? Sl 10:15 0:00 /usr/local/apache2.4/bin/httpd -k startdaemon 27775 0.0 0.8 382348 4416 ? Sl 10:15 0:00 /usr/local/apache2.4/bin/httpd -k startroot 27858 0.0 0.4 112656 2312 pts/0 R+ 10:16 0:00 grep --color=auto httpd[root@joking apache2.4]# netstat -lntp #查看端口Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1506/master tcp 0 0 0.0.0.0:28206 0.0.0.0:* LISTEN 1059/sshd tcp6 0 0 ::1:25 :::* LISTEN 1506/master tcp6 0 0 :::3306 :::* LISTEN 2866/mysqld tcp6 0 0 :::28206 :::* LISTEN 1059/sshd tcp6 0 0 :::80 :::* LISTEN 27772/httpd 扩展1. apache dsohttps://yq.aliyun.com/articles/6298 2. apache apxshttp://man.chinaunix.net/newsoft/ApacheMenual_CN_2.2new/programs/apxs.html 3. apache工作模式http://www.cnblogs.com/fnng/archive/2012/11/20/2779977.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>mariadb</tag>
        <tag>apache</tag>
        <tag>httpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP架构介绍、MySQL_MariaDB介绍、MySQL安装]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F11.1-11.5%20LAMP%E6%9E%B6%E6%9E%84-%E4%BB%8B%E7%BB%8D%E3%80%81MySQL_MariaDB%E4%BB%8B%E7%BB%8D%E3%80%81MySQL%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[11.1 LAMP架构介绍 LAMP 是Linux Apache MySQL PHP的简写，其实就是把Apache, MySQL以及PHP安装在Linux系统上，组成一个环境来运行php的脚本语言。至于什么是php脚本语言，阿铭不介绍，请自己查资料吧。Apache是最常用的WEB服务软件，而MySQL是比较小型的数据库软件，这两个软件以及PHP都可以安装到windows的机器上。下面阿铭就教你如何构建这个LAMP环境。 1. LAMP=Linux+Apache(httpd–web服务)+MySQL(数据存储库)+PHP（脚本语言） PHP网站：Google、淘宝、百度、51CTO博客、猿课论坛 三个角色可以在一台机器，也可以分开（但是httpd和PHP要在一起） 这2年流行的语言是python、JAVA、GO 2. LAMP架构图httpd、PHP、MySQL三者如何工作 11.2 MySQL、MariaDB介绍 MySQL是一个关系型数据库，由mysql ab公司开发，mysql在2008年被sun公司收购（10亿刀），2009年sun公司被oracle公司收购（74亿刀） MySQL官网https://www.mysql.com 最新版本5.7GA/8.0DMR 从MySQL5.6开始变化比较大，5.7性能上有很大提升 Mariadb为MySQL的一个分支，官网https://mariadb.com/最新版本10.2 MariaDB主要由SkySQL公司(现更名为MariaDB公司)维护,SkySQL公司由MySQL原作者带领大部分原班人马创立. Mariadb5.5版本对应MySQL的5.5，10.0对应MySQL5.6 Community 社区版本，Enterprise 企业版，GA（Generally Available)指通用版本，在生产环境中用的，DMR（Development Milestone Release)开发里程碑发布版，RC（Release Candidate)发行候选版本，Beta开放测试版本，Alpha内部测试版本 11.3/11.4/11.5 MySQL安装 MySQL的几个常用安装包：rpm、源码、二进制免编译 rpm包不能定制，不推荐；源码要编译，很慢，但是可以提高性能，暂时不学；先学别人编译好的免编译包 12345678910111213141516171819202122232425262728293031323334353637383940- cd /usr/local/src 进入目录下- wget http://mirrors.sohu.com/mysql/MySQL-5.6/mysql-5.6.35-linux-glibc2.5-x86_64.tar.gz 下载包到该目录下- tar zxvf mysql-5.6.35-linux-glibc2.5-x86_64.tar.gz 解压免编译包确认/usr/local/mysql没有创建，不然下面的命令会变成移动，而不是重命名- mv mysql-5.6.35-linux-glibc2.5-x86_64 /usr/local/mysql 移动目录/usr/local/并重命名为MySQL- cd /usr/local/mysql- useradd mysql 创建MySQL用户- mkdir /data/ 创建MySQL的数据存放目录- ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql 格式化mysql文件- cp support-files/my-default.cnf /etc/my.cnf 将默认配置文件复制到/etc/目录，并改名- cp support-files/mysql.server /etc/init.d/mysqld 将默认启动文件复制到/etc/目录并改名- chmod 755 /etc/init.d/mysqld将服务配置文件复制到/etc/目录，并改名- vi /etc/init.d/mysqld 编辑服务配置文件- 定义其中的basedir和datadirbasedir=/usr/local/mysqldatadir=/data/mysql- chkconfig --add mysqld 将mysqld服务加入开机服务- chkconfig --list 查看是否加入开机服务成功- /etc/init.d/mysqld start# 命令启动mysql服务service mysqld startps aux | grep mysqlnetstat -lntp mysql默认端口3306# 假如没办法将脚本放入到开机服务，或者没有启动脚本模板拷贝，要启动mysql服务,用命令行/usr/local/mysql/bin/mysqld_safe --defaults-file=/etc/my.cnf --user=mysql --datadir=/data/mysql &amp;ps# 用服务命令启动mysql，可以用`/etc/init.d/mysqld stop`命令关闭，但是用上面命令行的方式开启的，就不行了。那该怎么停止呢？只能用`killall mysql`关闭，不能用`kill mysql`关闭，因为kill会直接终止进程，而killall会等正在读写的数据完成后再结束，如果后面工作遇到killall没反应，是因为数据量很大，那就一直等，不要急。# killall命令centos7默认没安装，安装命令如下yum install psmisc 错误1 12345678910[root@localhost mysql]# /etc/init.d/mysqld startStarting MySQL ERROR! Couldn&apos;t find MySQL server (/data/mysql/bin/mysqld_safe)[root@localhost mysql]# [root@localhost mysql]# Starting MySQL ERROR! Couldn&apos;t find MySQL server (/data/mysql/bin/mysqld_safe)原因：vi /etc/init.d/mysqld- 定义basedir和datadir 出现错误，正确的是basedir=/usr/local/mysqldatadir=/data/mysql 1cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/data/mysql -DMYSQL_UNIX_ADDR=/tmp/mysql.sock -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DENABLED_LOCAL_INFILE=1 -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DEXTRA_CHARSETS=all -DMYSQL_TCP_PORT=3306 扩展1. mysql5.5源码编译安装http://www.aminglinux.com/bbs/thread-1059-1-1.html 2. mysql5.7二进制包安装（变化较大）http://www.apelearn.com/bbs/thread-10105-1-1.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>lamp</tag>
        <tag>mysql</tag>
        <tag>mariadb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsync同步工具02-rsync服务配置、系统日志和screen工具]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F10.32%20-%2010.35%20Rsync%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B702-rsync%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%E3%80%81%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E5%92%8Cscreen%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[10.32/10.33 rsync通过服务同步rsync 有2种同步数据的方式：一种是通过ssh，另外一种是通过服务的方式通过。 通过ssh同步 12rsync -av test1/ 192.168.133.132:/tmp/test2/rsync -av -e &quot;ssh -p 22&quot; test1/ 192.168.133.132:/tmp/test2/ 通过服务的方式同步首先要开启一个服务，架构是cs架构，客户端 to 服务端，服务端开启一个rsync服务,而且要监听一个端口，默认的是873，这个端口也可以自定义；开启服务后，客户端可以通过873端口和服务端通信，传输数据。 1. rsyncd.conf配置文件详解123456789101112131415161718192021222324252627282930port：指定在哪个端口启动rsyncd服务，默认是873端口。log file：指定日志文件。pid file：指定pid文件，这个文件的作用涉及服务的启动、停止等进程管理操作。address：指定启动rsyncd服务的IP。假如你的机器有多个IP，就可以指定由其中一个启动rsyncd服务，如果不指定该参数，默认是在全部IP上启动。[]：指定模块名，里面内容自定义。path：指定数据存放的路径。use chroot true|false：表示在传输文件前首先chroot到path参数所指定的目录下。这样做的原因是实现额外的安全防护，但缺点是需要以roots权限，并且不能备份指向外部的符号连接所指向的目录文件。默认情况下chroot值为true，如果你的数据当中有软连接文件，阿铭建议你设置成false。max connections：指定最大的连接数，默认是0，即没有限制。read only ture|false：如果为true，则不能上传到该模块指定的路径下。list：表示当用户查询该服务器上的可用模块时，该模块是否被列出，设定为true则列出，false则隐藏。uid/gid：指定传输文件时以哪个用户/组的身份传输。auth users：指定传输时要使用的用户名。secrets file：指定密码文件，该参数连同上面的参数如果不指定，则不使用密码验证。注意该密码文件的权限一定要是600。格式：用户名:密码hosts allow：表示被允许连接该模块的主机，可以是IP或者网段，如果是多个，中间用空格隔开。 123456当设置了auth users和secrets file后，客户端连服务端也需要用用户名密码了，若想在命令行中带上密码，可以设定一个密码文件rsync -avL test@192.168.133.130::test/test1/ /tmp/test8/ --password-file=/etc/pass 其中/etc/pass内容就是一个密码，权限要改为600chmod 600 /etc/rsyncd.passwd 2. 实例1234567891011121314151617181920212223242526272829303132333435363738[root@host ~]# vi /etc/rsyncd.conf 配置文件# /etc/rsyncd: configuration file for rsync daemon mode# See rsyncd.conf man page for more options.# configuration example:# uid = nobody# gid = nobody# use chroot = yes# max connections = 4# pid file = /var/run/rsyncd.pid# exclude = lost+found/# transfer logging = yes# timeout = 900# ignore nonreadable = yes# dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2# [ftp]# path = /home/ftp# comment = ftp export area换成port=873log file=/var/log/rsync.logpid file=/var/run/rsyncd.pidaddress=172.16.137.128[test]path=/root/rsyncuse chroot=truemax connections=4read only=nolist=trueuid=rootgid=root#auth users=test 指定传输时要使用的用户名#secrets file=/etc/rsyncd.passwd 指定密码文件，该参数连同上面的参数如果不指定，则不使用密码验证。注意该密码文件的权限一定要是600。格式：用户名:密码hosts allow=172.16.137.129 1实例后面复习再添加 10.34 linux系统日志123456789101112131415161718192021221./var/log/messages linux系统总的日志，一般的日志都在这里，少数特殊服务的例外/etc/logrotate.conf 日志切割配置文件2. dmesg命令dmesg 硬件相关日志,保存在内存中(硬盘或者网卡有问题，会记录在这里)dmesg -c 清空日志3. /var/log/dmesg 这是系统启动的日志文件4.last命令用于显示用户最近登录信息。单独执行last命令，它会读取/var/log/wtmp的文件，并把该给文件的内容记录的登入系统的用户名单全部显示出来。lastb命令用于显示用户错误的登录列表，此指令可以发现系统的登录异常。单独执行lastb命令，它会读取/var/log/btmp文件，并把该文件内容记录的登入失败的用户名单，全部显示出来。（使用ssh的登录失败不会记录在btmp文件中）/var/log/secure 包含验证和授权方面信息。例如，sshd会将所有信息记录（其中包括失败登录）在这里。 10.35 screen工具虚拟的一个终端，一般为了不让一个任务意外中断。 12为了不让一个任务意外中断的一般思路nohup command &amp; 把任务放到后台，并把结果输出到日志里 Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换。GNU Screen可以看作是窗口管理器的命令行界面版本。它提供了统一的管理多个会话的界面和相应的功能。 1. 会话恢复 只要Screen本身没有终止，在其内部运行的会话都可以恢复。这一点对于远程登录的用户特别有用——即使网络连接中断，用户也不会失去对已经打开的命令行会话的控制。只要再次登录到主机上执行screen -r就可以恢复会话的运行。同样在暂时离开的时候，也可以执行分离命令detach，在保证里面的程序正常运行的情况下让Screen挂起（切换到后台）。这一点和图形界面下的VNC很相似。 2. 多窗口 在Screen环境下，所有的会话都独立的运行，并拥有各自的编号、输入、输出和窗口缓存。用户可以通过快捷键在不同的窗口下切换，并可以自由的重定向各个窗口的输入和输出。Screen实现了基本的文本操作，如复制粘贴等；还提供了类似滚动条的功能，可以查看窗口状况的历史记录。窗口还可以被分区和命名，还可以监视后台窗口的活动。 会话共享 Screen可以让一个或多个用户从不同终端多次登录一个会话，并共享会话的所有特性（比如可以看到完全相同的输出）。它同时提供了窗口访问权限的机制，可以对窗口进行密码保护。 12345678910yum install -y screenscreen(完成以后就进入了虚拟窗口)ctrl+a再按d退出虚拟终端，但并没有结束screen -ls 查看虚拟终端列表screen -r id号 进入指定的任务screen -S aming 自定义一个任务的名字screen -r aming 后面可以用名字进来 扩展 Linux日志文件总管logrotatehttp://linux.cn/article-4126-1.html xargs用法详解 http://blog.csdn.net/zhangfn2011/article/details/6776925]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>rsync</tag>
        <tag>screen</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsync同步工具01-常用选项和简单使用]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F10.28%20-10.31%20Rsync%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B701-%E5%B8%B8%E7%94%A8%E9%80%89%E9%A1%B9%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[10.28 rsync工具介绍 rsync命令是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。rsync使用所谓的“rsync算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 rsync是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明。 1234567语法:rsync [OPTION]... SRC DEST (SRC:源目录or文件 DEST:目标目录or文件)rsync [OPTION]... SRC [USER@]host:DEST rsync [OPTION]... [USER@]HOST:SRC DEST rsync [OPTION]... [USER@]HOST::SRC DEST rsync [OPTION]... SRC [USER@]HOST::DEST rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] 对应于以上六种命令格式，rsync有六种不同的工作模式： 拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号”:”分隔符时就启动这种工作模式。如：rsync -a /data /backup 使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号”:”分隔符时启动该模式。如：rsync -avz *.c foo:src 使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号”:”分隔符时启动该模式。如：rsync -avz foo:src/bar /data 从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含”::”分隔符时启动该模式。如：rsync -av root@192.168.78.192::www /databack 从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含”::”分隔符时启动该模式。如：rsync -av /databack root@192.168.78.192::www 列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。如：rsync -v rsync://192.168.78.192/www 10.29/10.30 rsync常用选项12345678910111213141516常用选项:-a 包含-rtplgoD等选项-r 同步目录时要加上，类似cp时的-r选项-v 同步时显示一些信息，让我们知道同步的过程-l 保留软连接-L 加上该选项后，同步软链接时会把源文件给同步-p 保持文件的权限属性-o 保持文件的属主-g 保持文件的属组-D 保持设备文件信息-t 保持文件的时间属性--delte 删除DEST中SRC没有的文件--exclude 过滤指定文件，如--exclude “logs”会把文件名包含logs的文件或者目录过滤掉，不同步-P 显示同步过程，比如速率，比-v更加详细-u 加上该选项后，如果DEST中的文件比SRC新，则不同步-z 传输时压缩 10.31 rsync通过ssh同步1234567rsync通过ssh方式同步rsync -av test1/ 192.168.133.132:/tmp/test2/rsync -av -e &quot;ssh -p 22&quot; test1/ 192.168.133.132:/tmp/test2/rsync 通过服务的方式同步要编辑配置文件/etc/rsyncd.conf启动服务rsync --daemon格式：rsync -av test1/ 192.168.133.130::module/dir/ 实例 SSH方式 首先在服务端启动ssh服务： 12service sshd start 启动 sshd： [确定] 使用rsync进行同步 接下来就可以在客户端使用rsync命令来备份服务端上的数据了，SSH方式是通过系统用户来进行备份的，如下： 123456789101112rsync -vzrtopg --progress -e ssh --delete work@172.16.78.192:/www/* /databack/experiment/rsync work@172.16.78.192&apos;s password: receiving file list ... 5 files to consider test/ a 0 100% 0.00kB/s 527:35:41 (1, 20.0% of 5) b 67 100% 65.43kB/s 0:00:00 (2, 40.0% of 5) c 0 100% 0.00kB/s 527:35:41 (3, 60.0% of 5) dd 100663296 100% 42.22MB/s 0:00:02 (4, 80.0% of 5) sent 96 bytes received 98190 bytes 11563.06 bytes/sec total size is 100663363 speedup is 1024.19 上面的信息描述了整个的备份过程，以及总共备份数据的大小。 后台服务方式 启动rsync服务，编辑/etc/xinetd.d/rsync文件，将其中的disable=yes改为disable=no，并重启xinetd服务，如下： 1234567891011121314vi /etc/xinetd.d/rsync #default: off # description: The rsync server is a good addition to an ftp server, as it \ # allows crc checksumming etc. service rsync &#123; disable = no socket_type = stream wait = no user = root server = /usr/bin/rsync server_args = --daemon log_on_failure += USERID &#125; 123/etc/init.d/xinetd restart 停止 xinetd： [确定] 启动 xinetd： [确定] 创建配置文件，默认安装好rsync程序后，并不会自动创建rsync的主配置文件，需要手工来创建，其主配置文件为“/etc/rsyncd.conf”，创建该文件并插入如下内容： 1234567891011121314151617vi /etc/rsyncd.conf uid=root gid=root max connections=4 log file=/var/log/rsyncd.log pid file=/var/run/rsyncd.pid lock file=/var/run/rsyncd.lock secrets file=/etc/rsyncd.passwd hosts deny=172.16.78.0/22 [www] comment= backup web path=/www read only = no exclude=test auth users=work 创建密码文件，采用这种方式不能使用系统用户对客户端进行认证，所以需要创建一个密码文件，其格式为“username:password”，用户名可以和密码可以随便定义，最好不要和系统帐户一致，同时要把创建的密码文件权限设置为600，这在前面的模块参数做了详细介绍。 12echo &quot;work:abc123&quot; &gt; /etc/rsyncd.passwd chmod 600 /etc/rsyncd.passwd 备份，完成以上工作，现在就可以对数据进行备份了，如下： 123456789101112rsync -avz --progress --delete work@172.16.78.192::www /databack/experiment/rsync Password: receiving file list ... 6 files to consider ./ files... a 0 100% 0.00kB/s 528:20:41 (1, 50.0% of 6) b 67 100% 65.43kB/s 0:00:00 (2, 66.7% of 6) c 0 100% 0.00kB/s 528:20:41 (3, 83.3% of 6) dd 100663296 100% 37.49MB/s 0:00:02 (4, 100.0% of 6) sent 172 bytes received 98276 bytes 17899.64 bytes/sec total size is 150995011 speedup is 1533.75 恢复，当服务器的数据出现问题时，那么这时就需要通过客户端的数据对服务端进行恢复，但前提是服务端允许客户端有写入权限，否则也不能在客户端直接对服务端进行恢复，使用rsync对数据进行恢复的方法如下： 123456789101112rsync -avz --progress /databack/experiment/rsync/ work@172.16.78.192::www Password: building file list ... 6 files to consider ./ a b 67 100% 0.00kB/s 0:00:00 (2, 66.7% of 6) c sent 258 bytes received 76 bytes 95.43 bytes/sec total size is 150995011 speedup is 452080.87]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux任务计划和systemd管理]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F10.23%20-%2010.27%20linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8Csystemd%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[10.23 linux任务计划cron12345678910111213141516171819202122232425262728293031323334353637383940414243[root@host ~]# cat /etc/crontab 任务计划的配置文件SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59) 表示分钟# | .------------- hour (0 - 23) 表示日# | | .---------- day of month (1 - 31) 表示月份# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat 表示星期。0或者7都是表示周日# | | | | |# * * * * * user-name command to be executed 最后一列是执行的命令[root@host ~]# crontab -e 定义任务计划配置，和vim使用方式差不多0 3 * * * /bin/bash /usr/local/sbin/123.sh &gt;&gt;/tmp/123.log 2&gt;&gt;/tmp/123.log从凌晨的3点开始执行一个脚本，并把脚本的正确输出，与错误的输出重定向到123.log里去。格式解读：分,时，日，月，周，后跟执行的命令，*表示为所有的。0 3 1-10 */2 2,5 /bin/bash /usr/local/sbin/123.sh &gt;&gt;/tmp/123.log 2&gt;&gt;/tmp/123.log其中1-10表示1到10天，*/2 表示被2整除的数字比如月份就是双月的。2，5表示周二或周五开始执行命令，逗号表示或。[root@host ~]# systemctl start crond 启动服务[root@host ~]# systemctl status crond 查看crond的服务状态● crond.service - Command Scheduler Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2017-07-16 23:39:04 EDT; 13h agoMain PID: 796 (crond) CGroup: /system.slice/crond.service └─796 /usr/sbin/crond -nJul 16 23:39:04 host.localdomain crond[796]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 35% if used.)Jul 16 23:39:04 host.localdomain crond[796]: (CRON) INFO (running with inotify support)Jul 16 23:39:04 host.localdomain systemd[1]: Started Command Scheduler.Jul 16 23:39:04 host.localdomain systemd[1]: Starting Command Scheduler...crontab -l 列出任务计划crontab -r 删除任务计划crontab -u root -l 制定一个用户，列出它的任务计划 10.24 chkconfig工具 chkconfig命令检查、设置系统的各种服务。这是Red Hat公司遵循GPL规则所开发的程序，它可查询操作系统在每一个执行等级中会执行哪些系统服务，其中包括各类常驻服务。谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。 12345678910111213141516171819202122232425262728语法: chkconfig(选项)选项:--add：增加所指定的系统服务，让chkconfig指令得以管理它，并同时在系统启动的叙述文件内增加相关数据；--del：删除所指定的系统服务，不再由chkconfig指令管理，并同时在系统启动的叙述文件内删除相关数据；--level&lt;等级代号&gt;：指定读系统服务要在哪一个执行等级中开启或关毕。等级代号列表： 等级0表示：表示关机 等级1表示：单用户模式 等级2表示：无网络连接的多用户命令行模式 等级3表示：有网络连接的多用户命令行模式 等级4表示：不可用 等级5表示：带图形界面的多用户模式 等级6表示：重新启动 需要说明的是，level选项可以指定要查看的运行级而不一定是当前运行级。对于每个运行级，只能有一个启动脚本或者停止脚本。当切换运行级时，init不会重新启动已经启动的服务，也不会再次去停止已经停止的服务。 运行级文件： 每个被chkconfig管理的服务需要在对应的init.d下的脚本加上两行或者更多行的注释。第一行告诉chkconfig缺省启动的运行级以及启动和停止的优先级。如果某服务缺省不在任何运行级启动，那么使用-代替运行级。第二行对服务进行描述，可以用\跨行注释。 例如random.init包含三行： # chkconfig: 2345 20 80# description: Saves and restores system entropy pool for \# higher quality random number generation. 实例 1234567891011121314151617181920212223[root@host ~]# chkconfig --list 列出所有的系统服务注意：该输出结果只显示 SysV 服务，并不包含原生 systemd 服务。SysV 配置数据可能被原生 systemd 配置覆盖。 如果您想列出 systemd 服务,请执行 &apos;systemctl list-unit-files&apos;。 欲查看对特定 target 启用的服务请执行 &apos;systemctl list-dependencies [target]&apos;。netconsole 0:off 1:off 2:off 3:off 4:off 5:off 6:offnetwork 0:off 1:off 2:on 3:on 4:on 5:on 6:offqemukvmga 0:off 1:off 2:on 3:on 4:on 5:on 6:offshadowsocks 0:off 1:off 2:on 3:on 4:on 5:on 6:off[root@host ~]# ls /etc/init.d/ chkconfig 服务的脚本所在位置functions netconsole network qemukvmga README shadowsockschkconfig network off chkconfig 关闭一个服务chkconfig --level 3 network off 关闭3级别的服务centos7之前系统的更改系统级别 vi /etc/inittab centos7已不再使用chkconfig --level 345 network off 关闭3，4,5级别的服务chkconfig --del network 删除chkconfig --add network 增加 10.25 systemd管理服务1234567891011121314151617181920212223242526systemctl list-units-files 把systemd下所有的socket，target，service都列出来systemctl list-units --all --type=service 把systemd下service都列出来systemctl list-units --type=service 把systemd下所有激活的service都列出来几个常用的服务相关的命令 @重点 需要记住systemctl enable crond.service 让服务开机启动（.service可以省略）systemctl disable crond 不让开机启动systemctl status crond 查看状态systemctl stop crond 停止服务systemctl start crond 启动服务systemctl restart crond 重启服务systemctl is-enabled crond 检查服务是否开机启动system的控制service的开机启动，实际是把service源路径的软连接，添加和删除到/etc/systemd/system/multi-user.target.wants/目录的的过程[root@host ~]# systemctl is-enabled crondenabled[root@host ~]# systemctl disable crondRemoved symlink /etc/systemd/system/multi-user.target.wants/crond.service.[root@host ~]# systemctl enable crondCreated symlink from /etc/systemd/system/multi-user.target.wants/crond.service to /usr/lib/systemd/system/crond.service.[root@host ~]# ls -l /etc/systemd/system/multi-user.target.wants/crond.service to /usr/lib/systemd/system/crond.service.ls: cannot access to: No such file or directoryls: cannot access /usr/lib/systemd/system/crond.service.: No such file or directorylrwxrwxrwx 1 root root 37 Jul 18 10:04 /etc/systemd/system/multi-user.target.wants/crond.service -&gt; /usr/lib/systemd/system/crond.service[root@host ~]# ls -l /usr/lib/systemd/system/crond.service-rw-r--r--. 1 root root 284 Mar 31 2016 /usr/lib/systemd/system/crond.service 10.26 unit介绍123456789101112131415161718192021222324252627282930313233343536373839ls /usr/lib/systemd/system 系统所有unit[root@host ~]# ls /usr/lib/systemd/systemacpid.service dracut-pre-udev.service machine.slice rhel-autorelabel-mark.service sysinit.target systemd-readahead-done.serviceauditd.service dracut-shutdown.service machines.target rhel-autorelabel.service sysinit.target.wants systemd-readahead-done.timerautovt@.service ebtables.service messagebus.service rhel-configure.service sys-kernel-config.mount systemd-readahead-drop.servicebasic.target emergency.service microcode.service rhel-dmesg.service sys-kernel-debug.mount systemd-readahead-replay.servicebasic.target.wants emergency.target multi-user.target rhel-domainname.service syslog.socket systemd-reboot.serviceblk-availability.service final.target multi-user.target.wants rhel-import-state.service syslog.target.wants systemd-remount-fs.servicebluetooth.target firewalld.service NetworkManager-dispatcher.service rhel-loadmodules.service systemd-ask-password-console.path systemd-rfkill@.servicebrandbot.path fstrim.service NetworkManager.service rhel-readonly.service systemd-ask-password-console.service systemd-shutdownd.servicebrandbot.service fstrim.timer NetworkManager-wait-online.service rpcbind.target systemd-ask-password-plymouth.path systemd-shutdownd.socketchrony-dnssrv@.service getty@.service network-online.target rsyncd.service systemd-ask-password-plymouth.service systemd-suspend.servicechrony-dnssrv@.timer getty.target network-online.target.wants rsyncd@.service systemd-ask-password-wall.path systemd-sysctl.servicechronyd.service graphical.target network-pre.target rsyncd.socket systemd-ask-password-wall.service systemd-timedated.servicechrony-wait.service graphical.target.wants network.target rsyslog.service systemd-backlight@.service systemd-tmpfiles-clean.serviceconsole-getty.service halt-local.service nss-lookup.target runlevel0.target systemd-binfmt.service systemd-tmpfiles-clean.timerconsole-shell.service halt.target nss-user-lookup.target runlevel1.target systemd-bootchart.service systemd-tmpfiles-setup-dev.servicecontainer-getty@.service halt.target.wants paths.target runlevel1.target.wants systemd-firstboot.service systemd-tmpfiles-setup.servicecpupower.service haveged.service plymouth-halt.service runlevel2.target systemd-fsck-root.service systemd-udevd-control.socketcrond.service hibernate.target plymouth-kexec.service runlevel2.target.wants systemd-fsck@.service systemd-udevd-kernel.socketcryptsetup-pre.target hybrid-sleep.target plymouth-poweroff.service runlevel3.target systemd-halt.service systemd-udevd.servicecryptsetup.target initrd-cleanup.service plymouth-quit.service runlevel3.target.wants systemd-hibernate-resume@.service systemd-udev-settle.servicectrl-alt-del.target initrd-fs.target plymouth-quit-wait.service runlevel4.target systemd-hibernate.service systemd-udev-trigger.service......---系统所有unit，分为以下类型:service 系统服务 target 多个unit组成的组device 硬件设备mount 文件系统挂载点automount 自动挂载点path 文件或路径scope 不是由systemd启动的外部进程slice 进程组snapshot systemd快照socket 进程间通信套接字swap swap文件timer 定时器 unit相关的命令12345systemctl list-units 列出正在运行的unitsystemctl list-units --all 列出所有，包括失败的或者inactive的systemctl list-units --all --state=inactive 列出inactive的unitsystemctl list-units --type=service 列出状态为active的servicesystemct is-active crond.service 查看某个服务是否为active 10.27 target介绍 系统为了方便管理用target来管理unit 1234systemctl list-unit-files --type=target 查看所有的targetsystemctl list-dependencies multi-user.target 查看指的定target下面有哪些unit（target下面还可以有target）systemctl get-default 查看系统默认的targetsystemctl set-default multi-user.target 一个service属于一种类型的unit 多个unit组成了一个target 一个target里面包含了多个service 1cat /usr/lib/systemd/system/sshd.service 看[install]部分 扩展 anacron http://blog.csdn.net/strikers1982/article/details/4787226 xinetd服(默认机器没有安装这个服务，需要yum install xinetd安装） http://blog.sina.com.cn/s/blog_465bbe6b010000vi.html systemd自定义启动脚本 http://www.jb51.net/article/100457.htm]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>cron</tag>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables学习03-firewalld的使用]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F10.19%20-%2010.22%20iptables%E5%AD%A6%E4%B9%A003-firewalld%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[10.19 iptables规则备份和恢复 保存和备份iptables规则 12service iptables save 会把规则保存到/etc/sysconfig/iptables如果想要一开机就启动规则，最好把规则保存到配置文件中 有时候想把iptables规则备份其他文件中，比如到my.ipt文件中 1iptables-save &gt; my.ipt 清空iptables规则 1iptables -t nat -F 恢复刚才备份的规则 1iptables-restore &lt; my.ipt 10.20 firewalld的9个zone 打开firewalld，禁掉iptables 1234systemctl disable iptablessystemctl stop iptablessystemctl enable firewalldsystemctl start firewalld firewalld自带规则，默认有9个zone 默认zone为public，每个zone好比一个规则集 1234567891011121314firewall-cmd --get-zones 查看所有zoneblock dmz drop external home internal public trusted workblock：拒绝所有外部连接，允许内部发起的连接dmz：和硬件防火墙一样，受限制的公共连接可以进入drop：丢弃接收到的所有网络数据包external：允许指定的外部连接home：用于家庭组网络，允许指定的外部连接internal：用于内部网络，允许指定的外部连接public：公共区域内使用，允许指定的外部连接trusted：信任所有网络连接work：用于工作区，允许指定的外部连接firewall-cmd --get-default-zone 查看默认zone 10.21 firewalld关于zone的操作1234567ls /usr/lib/firewalld/zones/ 查看zone的配置文件模板firewall-cmd --set-default-zone=work 设定默认zonefirewall-cmd --get-zone-of-interface=ens33 查指定网卡firewall-cmd --zone=public --add-interface=lo 给指定网卡设置zone firewall-cmd --zone=dmz --change-interface=lo 针对网卡更改zonefirewall-cmd --zone=dmz --remove-interface=lo 针对网卡删除zone firewall-cmd --get-active-zones 查看系统所有网卡所在的zone 10.22 firewalld关于service的操作12345678firewall-cmd --get-services 查看所有的serviesfirewall-cmd --list-services //查看当前zone下有哪些servicefirewall-cmd --zone=work --list-services//查看work下有哪些servicefirewall-cmd --zone=public --add-service=http //把http增加到public的zone下面firewall-cmd --zone=public --remove-service=http//移除public的zone的http服务firewall-cmd --zone=public --add-service=http --permanent //更改配置文件，新增的service会得到保存，之后会在/etc/firewalld/zones目录下面生成配置文件ls /etc/firewalld/zones/ls /usr/lib/firewalld/services/ //查看service的配置文件模板]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>iptables</tag>
        <tag>firewalld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables学习02-nat表应用]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F10.16%20-%2010.18%20iptables%E5%AD%A6%E4%B9%A002-nat%E8%A1%A8%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[10.16/10.17/10.18 iptables nat表应用nat表应用实验第一步 准备工作 A机器两块网卡ens33(192.168.2.106)、再添加一块自定义网卡ens37(192.168.100.1)，添加到LAN内网区段（自定义名字，写什么无所谓），ens33可以上外网，ens37仅仅是内部网络。 B机器是虚拟机里克隆A机器的，把ens33禁掉，只有ens37（192.168.100.100），和A机器ens37可以通信互联。1234567891011121314151617181920先在虚拟机里面设置一下，添加一块网卡Aifconfig ens37 192.168.2.106/24 自定义网卡IP把网卡配置文件的MAC什么的再修改一下Bifdown ens33 ban掉网卡ifconfig ens37 192.168.100.100/24 自定义网卡IPAping ens37 192.168.100.100 yesBping ens37 192.168.100.1 yesping www.baidu.com noWindows CMDping 192.168.100.1 noping 192.168.100.100 no 第二步 需求1：可以让B机器连接外网 （小路由器的功能） A机器打开端口转发 123echo &quot;1&quot;&gt;/proc/sys/net/ipv4/ip_forward 端口转发配置文件默认是0，表示关闭。iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -o ens33 -j MASQUERADE 增加一条规则，有了这条规则，可以把100.0这个网段做一个欺骗，让它们可以上网，记住这个用法就可以了。 B机器要设置一个网关 1234567891011121314route add default gw 192.168.100.1route -n 确认网关ping 192.168.2.106 yesvi /etc/resolv.conf 设置DNS233.5.5.5ping 233.5.5.5 yesping www.baidu.com yesWindows CMDping 192.168.100.100 noB可以连接外网了，但是外网还是ping不通这个100的ip 第三步 需求2：C机器只能和A通信，让C机器可以直接连通B机器的22端口 A机器打开端口转发，并添加规则 12345678echo &quot;1&quot;&gt;/proc/sys/net/ipv4/ip_forward 端口转发配置文件默认是0，表示关闭。iptables -t nat -D POSTROUTING -s 192.168.100.0/24 -o ens33 -j MASQUERADE 删除上面那个之前的规则添加新规则iptables -t nat -A POSTROUTING -d 192.168.2.106 -p tcp --dport 1122 -j DNAT --to 192.168.100.100:22 进来的包，130转发到100IP的22端口iptables -t nat -A POSTROUTING -s 192.168.100.100 -j SNAT --to 192.168.2.106 传出的包，100回到130的包，设置来源IP为130 B机器要设置一个网关 123route add default gw 192.168.100.1route -n 确认网关ping 192.168.2.106 yes 测试是否可以用xshell登录A机器 123456789101112131415161718ssh 主机 192.168.2.106端口 1122密码 ***连接OKifconfig... ...ens33 无ens37 192.168.100.100ping www.qq.com yes，可以连接外网wfrom192.168.2.1 上网是从windows机器上的 扩展 iptables应用在一个网段http://www.aminglinux.com/bbs/thread-177-1-1.html sant,dnat,masqueradehttp://www.aminglinux.com/bbs/thread-7255-1-1.html iptables限制syn速率http://www.aminglinux.com/bbs/thread-985-1-1.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>iptables</tag>
        <tag>nat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables学习01-linux网络相关和防火墙介绍]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F10.11%20-%2010.14%20iptables%E5%AD%A6%E4%B9%A001-linux%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%92%8C%E9%98%B2%E7%81%AB%E5%A2%99%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[10.11 Linux网络相关123456789101112131415161718192021222324252627282930ifconfig查看网卡ip（需要安装包yum install net-tools）ifconfig -a 当网卡down掉也可以查看到ifdown ens33 关闭网卡ens33ifup ens33 开启网卡ens33如果在远程连接，想重启网卡，那么不能使用ifdown两种方法：1. ifdown ens33 &amp;&amp; ifup ens332. 设定虚拟网卡ens331cd etcsysconfignetwork-scriptscp ifcfg-ens33 ifcfg-ens330 这里的脱义的vi !$ 修改配置文件NAME=ens330IP=......ifdown ens33 &amp;&amp; ifup ens33查看网卡是否连接有网线mii-tool ens33 查看网卡是否连接有网线查看link detectedyes 这一行是否存在，有的话，表示有网线连接ethtool ens33 也可以查看网卡是否连接更改主机名 hostnamectl set-hostname aminglinux 想要改过来，需要重新登录账户主机名配置文件 etchostnameDNS配置文件 etcresolv.confhost配置文件 etchosts文件 只在本机生效格式：ip 域名（www.百度.com） 域名 支持1个IP配多个域名 10.12 firewalld和netfilter1. seLinux selinux临时关闭 setenforce 0 selinux永久关闭 vi etcselinuxconfig 把SELINUX=enforcing 改为SELINUX=disabled selinux平时运维都是关闭的 2. firewalld和netfilter centos7之前使用netfilter防火墙 centos7开始使用firewalld防火墙 firewalld和netfilter机制不太一样，但是都支持iptables 命令 CentOS7默认是关闭netfilter开启firewalld的 3. 怎么启用CentOS7的netfilter呢？123456789systemctl stop firewalld 关闭firewalld 开启netfilter 之前需要安装iptables-service 包，就会产生iptables服务yum install -y iptables-servicessystemctl disable firewalled 开启netfilter开启iptables工具systemctl enable iptablessystemctl start iptables 10.13 netfilter5表5链介绍netfilter的5个表 filter表用于过滤包，最常用的表，有INPUT、FORWARD、OUTPUT三个链 nat表用于网络地址转换，有PREROUTING、OUTPUT、POSTROUTING三个链，可以用于共享上网，和端口映射 managle表用于给数据包做标记，几乎用不到 raw表可以实现不追踪某些数据包，阿铭从来不用 security表在centos6中并没有，用于强制访问控制（MAC）的网络规则，阿铭没用过（CentOS6只有4个表，没有security） 数据包流向与netfilter的5个链 PREROUTING：数据包进入路由表之前 INPUT：通过路由表后目的地为本机 FORWARD：通过路由表后，目的地不为本机 OUTPUT：由本机产生，向外发出 POSTROUTING：发送到网卡接口之前 10.14 iptables语法 iptables命令是Linux上常用的防火墙软件，是netfilter项目的一部分。可以直接配置，也可以通过许多前端和图形界面配置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758语法 iptables(选项)(参数)选项 -t表：指定要操纵的表；-A：向规则链中添加条目；-D：从规则链中删除条目；-i：向规则链中插入条目；-R：替换规则链中的条目；-L：显示规则链中已有的条目；-F：清楚规则链中已有的条目；-Z：清空规则链中的数据包计算器和字节计数器；-N：创建新的用户自定义规则链；-P：定义规则链中的默认目标；-h：显示帮助信息；-p：指定要匹配的数据包协议类型；-s：指定要匹配的数据包源ip地址；-j目标：指定要跳转的目标；-i网络接口：指定数据包进入本机的网络接口；-o网络接口：指定数据包要离开本机所使用的网络接口。使用：iptables -nvL 查看iptables规则规则保存在 catetcsysconfigiptables 文件iptables -F 清空规则清空规则之后，文件etcsysconfigiptables还是有的service iptables save 保存规则把当前的规则保存到文件里service iptables restart 重启服务把规则加载回来iptables -t filter 以上操作都是针对filter表，默认的表iptables -t nat 查看nat 规则， -t 指定表iptables -Z 可以把计数器清零iptables -A INPUT -s 192.168.188.1 -p tcp --sport 1234 -s 192.168.188.128 --dport 80 -j DROP -A 增加一条规则INPUT 针对INPUT链-s 指定来源ip s=source-p 指定协议-sport 1234 来源的端口1234-d 目标的ip-dport 80 目标的端口DROP 直接扔掉数据，不接受REJECT 拒绝数据，但是先查看一下扔掉和拒绝，是为了封掉数据包，相当于封掉ipiptables -I INPUT -s 1.1.1.1 -j DROP 插入优先规则，该IP输入的数据直接扔掉iptables -A INPUT -s 1.1.1.1 -j DROP 新增规则，该IP输入的数据直接扔掉iptables -D INPUT -s 1.1.1.1 -j DROP 删除规则：该IP输入的数据直接扔掉iptables -I INPUT -s 192.168.1.024 -i eth0 -j ACCEPT 插入优先规则，该IP出入数据从eth0网卡进入，将会接收iptables -nvL --line-numbers 打印iptables规则的序列号iptables -D INPUT 1 删除对应编号的规则iptables -P INPUT DROP 默认的规则，输入的数据都扔掉（输出的数据不能直接扔掉，不然会连不上机器） 平时一些iptables规则 1234567891011121314151617181920212223242526[root@desktop log]# iptables -S-P INPUT DROP-P FORWARD ACCEPT-P OUTPUT DROP-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 111 -j ACCEPT-A INPUT -p udp -m state --state NEW -m udp --dport 111 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 892 -j ACCEPT-A INPUT -p udp -m state --state NEW -m udp --dport 892 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 2049 -j ACCEPT-A INPUT -p udp -m state --state NEW -m udp --dport 2049 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 32803 -j ACCEPT-A INPUT -j LOG --log-prefix hua-IN --log-level 1-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibited-A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -p icmp -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -p tcp -m state --state NEW -m tcp --dport 21 -j ACCEPT-A OUTPUT -p udp -m state --state NEW -m udp --dport 53 -j ACCEPT-A OUTPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT-A OUTPUT -p tcp -m state --state NEW -m tcp --dport 443 -j ACCEPT-A OUTPUT -j LOG --log-prefix hua-OUT --log-level 1 扩展（selinux了解即可）1. selinux教程httpos.51cto.comart201209355490.htm 2.selinux pdf电子书httppan.baidu.coms1jGGdExK]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统运维监控命令02-iostat、iotop、free、ps、netstat、ss、tcpdump、tshark]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F10.6%20-%2010.10%20%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A402-iostat%E3%80%81iotop%E3%80%81free%E3%80%81ps%E3%80%81netstat%E3%80%81ss%E3%80%81tcpdump%E3%80%81tshark%2F</url>
    <content type="text"><![CDATA[10.6 监控io性能 iostat主要用于监控系统设备的IO负载情况，iostat首次运行时显示自系统启动开始的各项统计信息，之后运行iostat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。iotop是一个用来监视磁盘I/O使用状况的 top 类工具，可监测到哪一个程序使用的磁盘IO的信息. 1. iostat和iotop命令iostat的包和sar的包是一起的，已经和sar一起安装了 123456789101112131415161718192021222324252627[zhouqun@localhost ~]$ iostat -d -x 显示和I/O相关的扩展信息Linux 3.10.0-514.el7.x86_64 (localhost.localdomain) 2017年07月11日 _x86_64_ (1 CPU)Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s avgrq-sz avgqu-sz await svctm %utilvda 0.00 1.06 0.01 1.16 0.27 17.77 15.41 0.01 4.28 1.45 0.17vdb 0.00 0.00 0.00 0.00 0.00 0.00 9.70 0.00 0.74 0.74 0.00[zhouqun@localhost ~]$ sudo iotop 动态显示磁盘I/O使用状况-bash: iotop: 未找到命令[zhouqun@localhost ~]$ yum install -y iotop[zhouqun@localhost ~]$ iotopTotal DISK READ : 0.00 B/s | Total DISK WRITE : 0.00 B/sActual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/s*****总结*****rrqm/s： 每秒这个设备相关的读取请求有多少被Merge了wrqm/s： 每秒这个设备相关的写入请求有多少被Merge了r/s： 每秒读取的数据量w/s： 每秒写入的数据量rsec/s： 每秒读取的扇区数wsec/s： 每秒写入的扇区数avgrq-sz：平均请求扇区的大小avgqu-sz：平均请求队列的长度await： I/O的响应时间（以毫秒为单位），这个时间包括了队列时间和服务时间svctm： 表示平均每次设备I/O操作的服务时间（以毫秒为单位）%util： 设备处理I/O的时间占命令统计总时间的百分比 2. 如何通过这些值分析设备的I/O情况？ avgqu-sz：平均请求的队列长度值，越小越好 await：系统I/O的响应时间一般低于5ms，大于10ms就比较大了 await和svctm的差值：await &gt;&gt; svctm表示I/O队列等待时间过长，则系统运行应用程序会很慢await ~~ svctm表示几乎没有等待时间，说明磁盘性能良好 %util：该参数暗示了设备的繁忙程度。一般地，如果该参数是100%表示设备已经接近满负荷运行了（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈） 10.7 free命令 free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。 12345678910111213141516171819202122232425262728293031323334语法：free [选项]选项：-b：以Byte为单位显示内存使用情况；-k：以KB为单位显示内存使用情况；-m：以MB为单位显示内存使用情况；-h：适当的单位显示-o：不显示缓冲区调节列；-s&lt;间隔秒数&gt;：持续观察内存使用状况；-t：显示内存总和列；-V：显示版本信息。[zhouqun@localhost ~]$ free 查看内存使用情况 total used free shared buff/cache availableMem: 1530368 110844 1255360 8780 164164 1249284Swap: 819196 0 819196[zhouqun@localhost ~]$ free -m 查看内存使用情况，以兆M做单位 total used free shared buff/cache availableMem: 1494 108 1225 8 160 1219Swap: 799 0 799[zhouqun@localhost ~]$ free -h 查看内存使用情况，以合适的单位做统计，并显示出来 total used free shared buff/cache availableMem: 1.5G 108M 1.2G 8.6M 160M 1.2GSwap: 799M 0B 799M*****总结*****1. used+free 等于total, 是因为linux系统会预留部分内存给buff和catch2. buff 和catch 的区别：buff（缓冲）：当CPU向磁盘写入数据时，由于磁盘存储速率低于CPU，所以CPU工作时先将写好的数据存放在内存中，该部分内存即为缓冲内存。cache（缓存）：当CPU从磁盘读取数据时，由于磁盘输出速率低于CPU的读取速度，所以磁盘的数据会预先存放在内存中，该部分内存即为缓存内存。3. available 包含free 和buffer/catch 剩余部分4. 公式：total=used+free+buffer/catch5. Shared：多个进程共享的内存总额 10.8 ps命令 ps命令用于报告当前系统的进程状态。可以搭配kill指令随时中断、删除不必要的程序。ps命令是最基本同时也是非常强大的进程查看命令，使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等，总之大部分信息都是可以通过执行该命令得到的。 123456789101112131415161718192021222324252627282930313233343536373839语法： ps [选项]选项：a：显示现行终端机下的所有程序，包括其他用户的程序。u：以用户为主的格式来显示系统状况。x：显示所有程序，包括历史进程。-e：显示所有进程（同a）-f：显示UID、PPIP、C与STIME栏-l：显示进程详细信息[zhouqun@localhost ~]# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.2 125604 4140 ? Ss 09:41 0:01 /usr/lib/systemd/systemd --switched-rroot 2 0.0 0.0 0 0 ? S 09:41 0:00 [kthreadd]root 3 0.0 0.0 0 0 ? S 09:41 0:00 [ksoftirqd/0]root 5 0.0 0.0 0 0 ? S&lt; 09:41 0:00 [kworker/0:0H]......STAT表示进程状态：D：不能中断的进程R：run状态的进程：在一个时间内使用的cpu进程，并不是一直运行的进程S：sleep状态的进程：使用完CPU后，先暂停，过一段时间后继续使用s：主进程T：暂停的进程Z：僵尸进程&lt;：高优先级进程N：低优先级进程L：内存中被锁定了内存分页l：多线程进程+：前台进程[zhouqun@localhost ~]$ ps elfF S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD4 S root 1 0 0 80 0 - 32855 ep_pol 10:28 ? 00:00:01 /usr/lib/system1 S root 2 0 0 80 0 - 0 kthrea 10:28 ? 00:00:00 [kthreadd]关于PID进程序列号1. 杀死进程kill 1246 后面跟的是PID2. 假如系统被黑了，遇到不知道的进程，先要找到PID 在哪里启动的ls -l /proc/505/ 每一个进程都有一个目录 10.9 查看网络状态1. netstat命令 netstat命令用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849语法： netstat [选项]选项：-a：或--all 显示所有连线中的socket-l：或--listening 显示监控中的服务器的socket-n：或--numeric 直接使用IP地址-p：或--programs 显示正在使用socket的程序识别码和程序名称-t：或--tcp 显示tcp传输协议的连接状况[root@localhost ~]# netstat -lnp 打印当前系统启动哪些端口Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 929/sshdtcp 0 0 :::80 :::* LISTEN 25005/httpdtcp 0 0 :::22 :::* LISTEN 929/sshdudp 0 0 0.0.0.0:68 0.0.0.0:* 1597/dhclientActive UNIX domain sockets (only servers)Proto RefCnt Flags Type State I-Node PID/Program name Pathunix 2 [ ACC ] STREAM LISTENING 6783 1/init @/com/ubuntu/upstart[root@localhost ~]# netstat -lutnp 只查看tcpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1734/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 2599/master tcp6 0 0 :::22 :::* LISTEN 1734/sshd tcp6 0 0 ::1:25 [root@localhost ~]# netstat -an 打印网络连接状况Active Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN tcp 0 52 192.168.60.107:22 192.168.60.107:406 ESTABLISHEDtcp6 0 0 :::22 :::* LISTEN tcp6 0 0 ::1:25 :::* LISTEN raw6 0 0 :::58 :::* 7 Active UNIX domain sockets (servers and established)netstat -an |grep 80如果你所管理的服务器是一台提供web服务（80端口）的服务器，查看当前连接web服务的有哪些IP.*****扩展****查看tcp协议状态的命令[root@localhost ~]# netstat -an | awk &apos;/^tcp/ &#123;++sta[$NF]&#125; END &#123;for(key in sta) print key,&quot;\t&quot;,sta[key]&#125;&apos; LISTEN 4ESTABLISHED 1与awk一起使用，可以查看tcp的状态的次数，需要关注established 状态，如果这个数字很大，说明系统很忙。 2. ss命令 ss命令用来显示处于活动状态的套接字信息。ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。 当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢。可能你不会有切身的感受，但请相信我，当服务器维持的连接达到上万个的时候，使用netstat等于浪费 生命，而用ss才是节省时间。 天下武功唯快不破。ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。 1234567891011121314151617181920212223242526语法： ss [选项]选项：-a：显示所有套接字（socket）-n：不解析服务器名称，以数字方式显示-h：显示帮助信息；-V：显示指令版本信息；-l：显示处于监听状态的套接字；-o：显示计时器信息；-m：显示套接字的内存使用情况；-p：显示使用套接字的进程信息；-i：显示内部的TCP信息；-4：只显示ipv4的套接字；-6：只显示ipv6的套接字；-t：只显示tcp套接字；-u：只显示udp套接字；-d：只显示DCCP套接字；-w：仅显示RAW套接字；-x：仅显示UNIX域套接字。[root@localhost ~]## ss -an Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port nl UNCONN 0 0 0:0 * nl UNCONN 0 0 0:-1442840033 *结合grep 命令查看Listen状态ss -an | grep -i Listen 10.10 linux下抓包1. tcpdump 命令 tcpdump命令是一款sniffer工具，它可以打印所有经过网络接口的数据包的头信息，也可以使用-w选项将数据包保存到文件中，方便以后分析。 123456789101112131415161718192021222324252627282930313233语法： tcpdump [选项]选项：-i：指定网卡名，使用指定的网络送出数据包-c：指定数量-w：指定存放位置-r：=read，从指定文件查看数据包数据有时候，也许你会有这样的需求，想看一下某个网卡上都有哪些数据包，尤其是当你初步判定你的服务器上有流量攻击。这时，使用抓包工具来抓一下数据包，就可以知道有哪些IP在攻击你了。eg：[root@localhost ~]# yum install -y tcpdump[root@localhost ~]# tcpdump -nn -i eth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes19:13:56.689147 IP 10.72.137.159.22 &gt; 10.72.137.53.50827: Flags [P.], seq 2793829986:2793830182, ack 1384443306, win 1067, length 19619:13:56.691389 IP 10.72.137.159.22 &gt; 10.72.137.53.50827: Flags [P.], seq 196:376, ack 1, win 1067, length 18019:13:56.691541 IP 10.72.137.53.50827 &gt; 10.72.137.159.22: Flags [.], ack 376, win 16266, length 019:13:56.694499 IP 10.72.137.159.22 &gt; 10.72.137.53.50827: Flags [P.], seq 376:636, ack 1, win 1067, length 26019:13:56.695659 IP 10.72.137.159.22 &gt; 10.72.137.53.50827: Flags [P.], seq 636:800, ack 1, win 1067, length 16419:13:56.695793 IP 10.72.137.53.50827 &gt; 10.72.137.159.22: Flags [.], ack 800, win 16160, length 019:13:56.698429 IP 10.72.137.159.22 &gt; 10.72.137.53.50827: Flags [P.], seq 800:1060, ack 1, win 1067, length 26019:13:56.700332 IP 10.72.137.159.22 &gt; 10.72.137.53.50827: Flags [P.], seq 1060:1224, ack 1, win 1067, length 16419:13:56.700419 IP 10.72.137.53.50827 &gt; 10.72.137.159.22: Flags [.], ack 1224, win 16425, length 0如果没有tcpdump 这个命令，需要用 yum install -y tcpdump 命令去安装一下。上例中第三列和第四列显示的信息为哪一个IP+port在连接哪一个IP+port，后面的信息是该数据包的相关信息，如果不懂也没有关系，毕竟我们不是专门搞网络的，而这里需要关注的只是第三列以及第四列。-i 选项后面跟设备名称，如果你想抓eth1网卡的包，后面则要跟eth1.至于-nn选项的作用是让第三列和第四列显示成IP+端口号的形式，如果不加-nn则显示的是主机名+服务名称。tcpdump -nn -i ens33 指定网卡的名字 - nn 第一个n表示ip 用数字的形式显示出来，如果不加n，会用主机名显示;tcpdump -nn ens33 port 80 指定端口为80的包tcpdump -nn ens33 not port 22 and host 192.168.8.1 可以排除，比如不要22端口，只要其中1个ip的包（host：主机，后面跟主机名或IP）tcpdump -nn -i ens33 -c 100 -w /tmp/1.cap 指定抓包数量和存放位置file /tmp/1.cap 查看1.cap文件，这个文件是从网卡捕获的数据包信息tcpdump -r /tmp/1.cap 查看这个文件,，显示的是数据流 -r read 2. tshark命令 专门的抓包工具 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162语法：tshark [ -a &lt;capture autostop condition&gt; ] ... [ -b &lt;capture ring buffer option&gt;] ... [ -B &lt;capture buffer size (Win32 only)&gt; ] [ -c &lt;capture packet count&gt; ] [ -d &lt;layer type&gt;==&lt;selector&gt;,&lt;decode-as protocol&gt; ] [ -D ] [ -f &lt;capture filter&gt; ] [ -F &lt;file format&gt; ] [ -h ] [ -i &lt;capture interface&gt;|- ] [ -l ] [ -L ] [ -n ] [ -N &lt;name resolving flags&gt; ] [ -o &lt;preference setting&gt; ] ... [ -p ] [ -q ] [ -r &lt;infile&gt; ] [ -R &lt;read (display) filter&gt; ] [ -s &lt;capture snaplen&gt; ] [ -S ] [ -t ad|a|r|d ] [ -T pdml|psml|ps|text ] [ -v ] [ -V ] [ -w &lt;outfile&gt;|- ] [ -x ] [ -X &lt;eXtension option&gt;] [ -y &lt;capture link type&gt; ] [ -z &lt;statistics&gt; ]根据试验，参数的书写有讲究。模仿tcpdump，可以把抓包过滤表达式写在命令的最后。 一般将抓包表达式用引号quote起来（在windows上是双引号&quot;），一是为了视觉方便，一是为了逃避其中字符和shell语法的冲突（如“&gt;”，“||”等）。抓包过滤表达式也可以写在-f参数的后面，注意，此时更应该使用引号或者将-f放在最后。否则，它们会认为-f（可省）后面 的参数都是表达式的一部分，而导致命令格式混乱。选项： 1. 抓包接口类-i 设置抓包的网络接口，不设置则默认为第一个非自环接口。-D 列出当前存在的网络接口。在不了解OS所控制的网络设备时，一般先用“tshark -D”查看网络接口的编号以供-i参数使用。-f 设定抓包过滤表达式（capture filter expression）。抓包过滤表达式的写法雷同于tcpdump，可参考tcpdump man page的有关部分。-s 设置每个抓包的大小，默认为65535，多于这个大小的数据将不会被程序记入内存、写入文件。（这个参数相当于tcpdump的-s，tcpdump默认抓包的大小仅为68）-p 设置网络接口以非混合模式工作，即只关心和本机有关的流量。-B 设置内核缓冲区大小，仅对windows有效。-y 设置抓包的数据链路层协议，不设置则默认为-L找到的第一个协议，局域网一般是EN10MB等。-L 列出本机支持的数据链路层协议，供-y参数使用。 2. 抓包停止条件-c 抓取的packet数，在处理一定数量的packet后，停止抓取，程序退出。-a 设置tshark抓包停止向文件书写的条件，事实上是tshark在正常启动之后停止工作并返回的条件。条件写为test:value的形式，如“-a duration:5”表示tshark启动后在5秒内抓包然后停止；“-a filesize:10”表示tshark在输出文件达到10kB后停止；“-a files:n”表示tshark在写满n个文件后停止。（windows版的tshark0.99.3用参数“-a files:n”不起作用——会有无数多个文件生成。由于-b参数有自己的files参数，所谓“和-b的其它参数结合使用”无从说起。这也许是一个bug，或tshark的man page的书写有误。）3. 文件输出控制-b 设置ring buffer文件参数。ring buffer的文件名由-w参数决定。-b参数采用test:value的形式书写。“-b duration:5”表示每5秒写下一个ring buffer文件；“-b filesize:5”表示每达到5kB写下一个ring buffer文件；“-b files:7”表示ring buffer文件最多7个，周而复始地使用，如果这个参数不设定，tshark会将磁盘写满为止。4. 文件输入-r 设置tshark分析的输入文件。tshark既可以抓取分析即时的网络流量，又可以分析dump在文件中的数据。-r不能是命名管道和标准输入。5. 处理类-R 设置读取（显示）过滤表达式（read filter expression）。不符合此表达式的流量同样不会被写入文件。注意，读取（显示）过滤表达式的语法和底层相关的抓包过滤表达式语法不相同，它的语法表达要丰富得多，请参考http://www.ethereal.com/docs/dfref/和http://www.ethereal.com/docs/man-pages/ethereal-filter.4.html。类似于抓包过滤表达式，在命令行使用时最好将它们quote起来。-n 禁止所有地址名字解析（默认为允许所有）。-N 启用某一层的地址名字解析。“m”代表MAC层，“n”代表网络层，“t”代表传输层，“C”代表当前异步DNS查找。如果-n和-N参数同时存在，-n将被忽略。如果-n和-N参数都不写，则默认打开所有地址名字解析。-d 将指定的数据按有关协议解包输出。如要将tcp 8888端口的流量按http解包，应该写为“-d tcp.port==8888,http”。注意选择子和解包协议之间不能留空格。6. 输出类-w 设置raw数据的输出文件。这个参数不设置，tshark将会把解码结果输出到stdout。“-w-”表示把raw输出到stdout。如果要把解码结果输出到文件，使用重定向“&gt;”而不要-w参数。-F 设置输出raw数据的格式，默认为libpcap。“tshark -F”会列出所有支持的raw格式。-V 设置将解码结果的细节输出，否则解码结果仅显示一个packet一行的summary。-x 设置在解码输出结果中，每个packet后面以HEX dump的方式显示具体数据。-T 设置解码结果输出的格式，包括text,ps,psml和pdml，默认为text。-t 设置解码结果的时间格式。“ad”表示带日期的绝对时间，“a”表示不带日期的绝对时间，“r”表示从第一个包到现在的相对时间，“d”表示两个相邻包之间的增量时间（delta）。-S 在向raw文件输出的同时，将解码结果打印到控制台。-l 在处理每个包时即时刷新输出。-X 扩展项。-q 设置安静的stdout输出（例如做统计时）-z 设置统计参数。7. 其它-h 显示命令行帮助。-v 显示tshark的版本信息。-o 重载选项。yum install -y wireshark 安装1. 显示访问http请求的域名以及uritshark -n -t a -R http.request -T fields -e &quot;frame.time&quot; -e &quot;ip.src&quot; -e &quot;http.host&quot; -e &quot;http.request.method&quot; -e &quot;http.request .uri&quot;2. 抓取mysql的查询tshark -n -i eth1 -R &apos;mysql.query&apos; -T fields -e &quot;ip.src&quot; -e &quot;mysql.query&quot;或者tshark -i eth1 port 3307 -d tcp.port==3307,mysql -z &quot;proto,colinfo,mysql.query,mysql.query&quot;3. 抓取指定类型的MySQL查询tshark -n -i eth1 -R &apos;mysql matches &quot;SELECT|INSERT|DELETE|UPDATE&quot;&apos; -T fields -e &quot;ip.src&quot; -e &quot;mysql.query&quot;4. 统计http的状态tshark -n -q -z http,stat, -z http,tree 这个命令，直到你ctrl + c 才会显示出结果5. tshark 增加时间标签 tshark -t ad 扩展tcp三次握手四次挥手http://www.doc88.com/p-9913773324388.html tshark几个用法http://www.aminglinux.com/bbs/thread-995-1-1.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>iostat</tag>
        <tag>iotop</tag>
        <tag>free</tag>
        <tag>ps</tag>
        <tag>netstat</tag>
        <tag>ss</tag>
        <tag>tcpdump</tag>
        <tag>tshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统运维监控命令01-w、uptime、vmstat、top、sar、nload]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F10.1%20-%2010.5%20%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A401-w%E3%80%81uptime%E3%80%81vmstat%E3%80%81top%E3%80%81sar%E3%80%81nload%2F</url>
    <content type="text"><![CDATA[10.1 使用w查看系统负载1. w命令查看监控系统状态 系统负载（System Load）：系统CPU繁忙程度的度量，即有多少进程在等待被CPU调度 平均负载（Load Average）：一段时间内系统的平均负载，这个一段时间一般取1分钟、5分钟、15分钟 1234567891011[zhouqun@localhost ~]$ w08:02:12 up 4 min, 2 users, load average: 3.37, 1.81, 0.74USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATzhouqun :0 :0 08:01 ?xdm? 1:04 0.61s gdm-session-worzhouqun pts/0 :0 08:02 4.00s 0.28s 0.11s w最应该关注的应该是第一行中的&apos;load average:&apos;后面的三个数值。第一个数值表示1分钟内系统的平均负载 最关注这个值第二个数值表示5分钟内系统的平均负载第三个数值表示15分钟系统的平均负载值1分钟平均负载，5分钟平均负载，15分钟平均负载分别是0.00、0.01、0.05 ==注意： 单位时间段内CPU活动进程数，当平均负载值越大代表服务器压力越大。一般情况下这个值不超过服务器的cpu的数量就没有关系。比如说服务器有8个CPU，那么这个值不高于8表示没问题，但是变成9了就要注意问题了。== 2. 那么如何查看服务器有几个CPU呢？1234567891011121314[zhouqun@localhost ~]$ cat /proc/cpuinfo 这里的CPU数量是指的逻辑数量processor : 0vendor_id : GenuineIntelcpu family : 6model : 58model name : Intel(R) Core(TM) i5-3230M CPU @ 2.60GHzstepping : 9microcode : 0x16cpu MHz : 2593.840cache size : 3072 KB...[zhouqun@localhost ~]$ grep -c &apos;processor&apos; /proc/cpuinfo 查看实际的物理CPU数量1 3. uptime命令因为和w命令几乎一样，还没有w命令显示的信息多，所以只做了解。 12[zhouqun@localhost ~]$ uptime08:06:08 up 8 min, 2 users, load average: 0.15, 0.85, 0.59 10.2 vmstat命令当系统负载值超高时，cpu不够用时，要排查是什么进程使用了cpu内存，用vmstat命令。它的作用还可以报告关于进程、内存、I/O等系统整体的运行状态。 123456789101112131415[zhouqun@localhost ~]$ vmstat 1 每1秒种动态显示一次procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----r b swpd free buff cache si so bi bo in cs us sy id wa st1 0 4500 98600 36 361848 0 5 869 27 280 377 10 7 81 2 00 0 4500 98600 36 361880 0 0 0 0 262 360 17 3 80 0 0^C 每秒刷新，Ctrl+c强制结束[zhouqun@localhost ~]$ vmstat 1 5 每1秒种动态显示一次，总共只显示5次结束procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----r b swpd free buff cache si so bi bo in cs us sy id wa st4 0 8336 63032 36 349424 0 7 792 50 340 529 11 10 77 3 01 0 8336 63032 36 349424 0 0 0 0 277 344 19 4 77 0 00 0 8336 63032 36 349424 0 0 0 0 524 528 26 5 68 0 02 0 8336 63008 36 349424 0 0 0 0 276 278 21 4 75 0 00 0 8336 63032 36 349424 0 0 0 0 278 260 21 3 76 0 0 1. procs（显示进程相关信息） r：表示运行和等待cpu时间片的进程数，如果长期大于服务器CPU的个数，说明CPU不够用了。 b：表示等待资源的进程数，比如等待I/O、内存等等。这列的值如果长时间大于1，则需要关注。 2. Memory（内存） swap：使用虚拟内存大小，如果swap的值不为0，但是SI,SO的值长期为0，不会影响系统性能。 free：空闲物理内存大小。 buff：用作缓冲的内存大小。 cache：用作缓存的内存大小，如果cache的值大的时候，说明cache处理的文件多，如果频繁访问到的文件都能被cache处理，那么磁盘的读IO bi会非常小。 3.swap （内存交换情况） si：由交换区写入到内存的数据量。 so：由内存写入到交换区的数据量。 4. IO（磁盘使用情况）bi：从块设备读取数据的量（读磁盘）。bo：从块设备写入数据的量（写磁盘）。 5. system （显示采集间隔内发生的中断次数） in：表示在某一时间中观测到的每秒设备中断数。 cs：表示每秒产生的上下文切换次数。 6. CPU（CPU的使用状态） us：显示用户所花费cpu时间百分比。 sy：显示系统花费cpu时间百分比。 id：表示cpu处于空闲状态的时间百分比。 us+sy+id=100 wa：表示I/O等待所占用cpu时间百分比。 st：表示被偷走的cpu所占百分比。（一般都为0，不用关注） ==我们经常会关注r b wa列，三列的含义上面解释的很清楚。IO部分的bi以及bo也是要经常参考的对象，如果磁盘IO压力很大时，这两列的数值会比较高。另外当si，so两列的数值比较高，并在不断变化时，说明内存不够了。内存中的数据频繁交换到交换分区中，这往往对系统的性能影响极大。== 10.3 top命令 这个命令用于动态监控进程所占系统资源，每隔3秒变一次。他的特点是把占用系统资源最高的进程放到最前面。 默认是按CPU照使用的百分比来排序的，需要以内存排序，按一下Shift+m，需要重新按CPU来，按下Shift+p，（数字1）可以来回切换某一个CPU使用的详细信息，可以来回切换，q退出当前执行的top。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[zhouqun@localhost ~]$ toptop - 08:48:06 up 50 min, 2 users, load average: 0.00, 0.03, 0.10Tasks: 168 total, 1 running, 167 sleeping, 0 stopped, 0 zombie%Cpu(s): 45.5 us, 6.7 sy, 0.0 ni, 47.5 id, 0.0 wa, 0.0 hi, 0.3 si, 0.0 stKiB Mem : 1008392 total, 70308 free, 600640 used, 337444 buff/cacheKiB Swap: 2097148 total, 2088836 free, 8312 used. 190500 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3291 zhouqun 20 0 1509800 183756 40740 S 28.9 18.2 1:05.66 gnome-shell 1369 root 20 0 231332 37232 9148 S 17.8 3.7 0:24.68 Xorg 4102 zhouqun 20 0 574748 23900 14364 S 3.6 2.4 0:06.17 gnome-terminal- 47382 zhouqun 20 0 157708 2276 1556 R 0.7 0.2 0:00.27 top 902 root 20 0 4368 588 492 S 0.3 0.1 0:02.87 rngd 3376 zhouqun 20 0 574600 8764 5180 S 0.3 0.9 0:01.58 caribou 3439 zhouqun 20 0 377564 13344 9644 S 0.3 1.3 0:05.73 vmtoolsd 1 root 20 0 128224 5608 3064 S 0.0 0.6 0:08.34 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:00.49 ksoftirqd/0 7 root rt 0 0 0 0 S 0.0 0.0 0:00.00 migration/0 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 0:03.34 rcu_sched 10 root rt 0 0 0 0 S 0.0 0.0 0:00.14 watchdog/0 12 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 khelper 13 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kdevtmpfs 14 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 netns 15 root 20 0 0 0 0 S 0.0 0.0 0:00.00 khungtaskd 16 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 writeback 17 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kintegrityd 18 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 bioset 19 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kblockd 20 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 md 26 root 20 0 0 0 0 S 0.0 0.0 0:00.62 kswapd0 27 root 25 5 0 0 0 S 0.0 0.0 0:00.00 ksmd 28 root 39 19 0 0 0 S 0.0 0.0 0:00.16 khugepaged 29 root 20 0 0 0 0 S 0.0 0.0 0:00.00 fsnotify_mark 30 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 crypto PID：进程号USER：登录的用户PR：优先级NI：nice级值VIRT：进程使用的虚拟内存总量RES：物理内存大小SHR：共享内存大小S：进程的状态。%CPU：进程占用cpu的百分比%MEM：进程占用物理内存的百分比TIME+：进程使用cpu的总时间COMMAND：命令行 ‘top -bn1’ 经常用于shell脚本中，打印的是静态的系统资源使用情况。 10.4 sar命令 sar命令是Linux下系统运行状态统计工具，它将指定的操作系统状态计数器显示到标准输出设备。sar工具将对系统当前的状态进行取样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统取样，获得大量的取样数据。取样数据和分析的结果都可以存入文件，使用它时消耗的系统资源很小。 使用sar命令需要先安装一个包 [root@localhost ~]# yum install -y sysstat 1. 语法sar(选项)(参数) 2. 选项 -A：显示所有的报告信息； -b：显示I/O速率； -B：显示换页状态； -c：显示进程创建活动； -d：显示每个块设备的状态； -e：设置显示报告的结束时间； -f：从指定文件提取报告； -i：设状态信息刷新的间隔时间； -P：报告每个CPU的状态； -R：显示内存状态； -u：显示CPU利用率； -v：显示索引节点，文件和其他内核表的状态； -w：显示交换分区状态； -x：显示给定进程的状态。 3. 参数间隔时间：每次报告的间隔时间（秒）；次数：显示报告的次数。 4. 实例 实时查看网卡流量：12345678910111213141516171819202122232425262728293031323334[zhouqun@localhost ~]$ sar -n DEV 1 2Linux 3.10.0-514.el7.x86_64 (localhost.localdomain) 2017年07月11日 _x86_64_ (1 CPU)00时13分32秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s00时13分33秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0000时13分33秒 ens33 1.02 1.02 0.06 0.19 0.00 0.00 0.0000时13分33秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s00时13分34秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0000时13分34秒 ens33 1.98 1.98 0.12 0.45 0.00 0.00 0.00平均时间: IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s平均时间: lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: ens33 1.51 1.51 0.09 0.32 0.00 0.00 0.00内容解释 ● IFACE：这列表示设备名称; ● rxpck/s：表示每秒进入收取的包的数量; ● txpck/s：表示每秒发送出去的包的数量 ● rxbyt/s：表示每秒收取的数据量（单位Byte）; ● txbyt/s：表示每秒发送的数据量。``` ==**注意** rxcmp/s txcmp/s rxmcst/s：这三列不用管，因为从来不会动。 如果某一天，你所管的服务器丢包很严重，就应该看看网卡流量是否异常。如果rxpck/s那一列的数值大于4000，或者rxbyt/s那列大于500 0000则很有可能是被攻击了，正常的网卡流量不会有那么高，除非是自己在拷贝数据。==2. 查看某一天的历史数据： `sar -f`/var/log/sa/sa11目录下除了saXX这个文件还有一个sarXX的文件。 sarXX一天才生成一个。 两个文件的区别分别是：- sa文件是二进制文件，不能cat。- sar文件是普通文件，是可以直接cat的。 [zhouqun@localhost ~]$ ls /var/log/sa/sa11/var/log/sa/sa11[zhouqun@localhost ~]$ sar -n DEV -f /var/log/sa/sa11Linux 3.10.0-514.el7.x86_64 (localhost.localdomain) 2017年07月11日 x86_64 (1 CPU) 04时18分16秒 LINUX RESTART 04时20分02秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s04时30分01秒 lo 0.23 0.23 0.02 0.02 0.00 0.00 0.0004时30分01秒 virbr0-nic 0.00 0.00 0.00 0.00 0.00 0.00 0.0004时30分01秒 virbr0 0.00 0.00 0.00 0.00 0.00 0.00 0.0004时30分01秒 ens33 0.00 0.00 0.00 0.00 0.00 0.00 0.0004时40分01秒 lo 0.11 0.11 0.01 0.01 0.00 0.00 0.0004时40分01秒 virbr0-nic 0.00 0.00 0.00 0.00 0.00 0.00 0.0004时40分01秒 virbr0 0.00 0.00 0.00 0.00 0.00 0.00 0.0004时40分01秒 ens33 0.02 0.00 0.00 0.00 0.00 0.00 0.00平均时间: lo 0.17 0.17 0.01 0.01 0.00 0.00 0.00平均时间: virbr0-nic 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: virbr0 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: ens33 0.01 0.00 0.00 0.00 0.00 0.00 0.00 1233. 查看系统的负载： [zhouqun@localhost ~]$ sar -qLinux 3.10.0-514.el7.x86_64 (localhost.localdomain) 2017年07月11日 x86_64 (1 CPU) 04时18分16秒 LINUX RESTART 04时20分02秒 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 blocked04时30分01秒 3 273 0.00 0.32 0.43 004时40分01秒 1 273 0.08 0.06 0.23 0平均时间: 2 273 0.04 0.19 0.33 0 07时58分28秒 LINUX RESTART 08时00分01秒 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 blocked08时10分02秒 2 357 0.00 0.39 0.46 008时20分01秒 2 360 0.11 0.35 0.40 108时30分01秒 1 358 0.00 0.06 0.22 008时40分01秒 2 358 0.00 0.02 0.13 008时50分02秒 3 361 0.11 0.10 0.12 009时00分01秒 2 358 0.01 0.06 0.11 009时10分01秒 3 363 0.18 0.10 0.09 0平均时间: 2 359 0.06 0.15 0.22 0 124. 查看磁盘的读和写： [zhouqun@localhost ~]$ sar -b 1 3Linux 3.10.0-514.el7.x86_64 (localhost.localdomain) 2017年07月11日 x86_64 (1 CPU) 09时17分23秒 tps rtps wtps bread/s bwrtn/s09时17分24秒 0.00 0.00 0.00 0.00 0.0009时17分25秒 0.00 0.00 0.00 0.00 0.0009时17分26秒 0.00 0.00 0.00 0.00 0.00平均时间: 0.00 0.00 0.00 0.00 0.00 1234567# 10.5 nload命令&gt; nload命令用来即时监看网路状态和各ip所使用的频宽nload 默认分为上下两块：上半部分是：Incoming也就是进入网卡的流量，下半部分是：Outgoing，也就是从这块网卡出去的流量，每部分都有当前流量（Curr），平均流量（Avg），最小流量（Min），最大流量（Max），总和流量（Ttl）这几个部分，看起来还是蛮直观的。 注意：使用这个包需依赖epel源的，所以要先安装好epel。[root@localhost ~]# yum install -y nload [zhouqun@localhost ~]$ nload ens33 Device ens33 [192.168.2.130] (1/2):Incoming: Curr: 942.00 Bit/s Avg: 9866.00 kBit/s Min: 936.00 Bit/s Max: 1.84 kBit/s Ttl: 6.71 MByteOutgoing: Curr: 8.03 kBit/s Avg: 8.01 kBit/s Min: 4.25 kBit/s Max: 8.51 kBit/s Ttl: 694.55 kByteCurr: 当前流量Avg: 平均流量Min: 最小流量Max: 最大流量Ttl: 总和流量可以使用键盘的左右键来切换网卡查看。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>w</tag>
        <tag>uptime</tag>
        <tag>vmstat</tag>
        <tag>top</tag>
        <tag>sar</tag>
        <tag>nload</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则拓展2]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F9.9%20%E6%AD%A3%E5%88%99%E6%8B%93%E5%B1%952%2F</url>
    <content type="text"><![CDATA[1. awk 中使用外部shell变量123456789101112131415161718192021222324252627如：A=44echo &quot;ABCD&quot; | awk -v GET_A=$A ’&#123;print GET_A&#125;’说明：-v选项用于定义参数，这里表示将变量A的值赋予GET_A。有多少个变量需要赋值，就需要多少个-v选项。与之等价的：应用于脚本中：#! /bin/bashsort -n filename |awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos;|uniq &gt;id.txtfor id in `cat id.txt`; do echo &quot;[$id]&quot; awk -v id2=$id -F &apos;:&apos; &apos;$1==id2 &#123;print $2&#125;&apos; filename // 另外的方式为: awk -F &apos;:&apos; &apos;$1==&quot;&apos;$id&apos;&quot; &#123;print $2&#125;&apos; filename done附件：cat filename1111111:134432534562222222:132112221221111111:136435435443333333:123412431232222222:12123123123运行脚本后结果为：[1111111]1344325345613643543544[2222222]1321122212212123123123[3333333]12341243123 2. awk 合并一个文件12345678910111213141516171819202122232425262728293031323334需要把两个文件中，第一列相同的行合并到同一行中。举个例子，有两个文件，内容如下cat 1.txt1 aa2 bb3 ee4 sscat 2.txt1 ab2 cd3 ad4 bd5 de合并后的结果为：1 ab aa2 cd bb3 ad ee4 bd ss5 de实现的命令为：awk &apos;NR==FNR&#123;a[$1]=$2&#125;NR&gt;FNR&#123;print $0,a[$1]&#125;&apos; 1.txt 2.txt解释：NR表示读取的行数，FNR表示读取的当前行数所以其实NR==FNR 就表示读取2.txt的时候。 同理NR&gt;FNR表示读取1.txt的时候数组a其实就相当于一个map总结： 完全不懂$1 当前记录的第1个字段，比如n为1表示第一个字段，n为2表示第二个字段$0 这个变量包含执行过程中当前行的文本内容FNR 同NR，表示行号，但相对于当前文件 3. 把一个文件多行连接成一行 - 不懂1234567891011121314151617181920212223242526272829303132333435例子1：a=`cat file`;echo $a awk &apos;&#123;printf(&quot;%s &quot;,$0)&#125;&apos; file ## %s 后记得要有一空格，否则出来就是完全连在一起的，中间连空格都没有cat file |xargs例子2：一个文件每行都有一个数字，现在需要把每行的数字用“+”连接起来。cat a96109318551253136413322308258925311239216428262787214526174311181021151235awk &apos;&#123;printf (&quot;%s+&quot;,$0)&#125;&apos; a; echo &quot;&quot;96+1093+1855+1253+1364+1332+2308+2589+2531+1239+2164+2826+2787+2145+2617+4311+1810+2115+1235+这里注意，最后一个是带“+”的。echo &quot;&quot; 的作用是换行。另外的方法是 cat a|xargs|sed &apos;s/ /+/g&apos;96+1093+1855+1253+1364+1332+2308+2589+2531+1239+2164+2826+2787+2145+2617+4311+1810+2115+1235 4. awk中gsub函数的使用123456awk &apos;gsub(/www/,&quot;abc&quot;)&apos; /etc/passwd passwd文件中把所有www替换为abcawk -F &apos;:&apos; &apos;gsub(/www/,&quot;abc&quot;,$1) &#123;print $0&#125;&apos; /etc/passwd 替换$1中的www为abc总结：gsub函数则使得在所有正则表达式被匹配的时候都发生替换gsub匹配所有的符合模式的字符串，相当于 sed &apos;s//g&apos; 。 5. awk 截取指定多个域为一行123456789for j in `seq 0 20`; do let x=100*$j let y=$x+1 let z=$x+100 for i in `seq $y $z` ; do awk -v a=$i &apos;&#123;printf $a &quot; &quot;&#125;&apos; example.txt &gt;&gt;/tmp/test.txt echo &quot; &quot; &gt;&gt;/tmp/test.txt donedone 6. 过滤两个或多个关键词123grep -E &apos;123|abc&apos; filename 找出文件（filename）中包含123或者包含abc的行egrep &apos;123|abc&apos; filename 用egrep同样可以实现awk &apos;/123|abc/&apos; filename awk 的实现方式 7. 用awk生成以下结构文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354用awk编写生成以下结构文件的程序。( 最后列使用现在的时间，时间格式为YYYYMMDDHHMISS) 各列的值应如下所示，每增加一行便加1，共500万行。1,1,0000000001,0000000001,0000000001,0000000001,0000000001,0000000001,20051001101012,2,0000000002,0000000002,0000000002,0000000002,0000000002,0000000002,2005100110101用shell搞起。#! /bin/bashfor i in `seq 1 5000000`; do n=`echo &quot;$i&quot;|awk &apos;&#123;print length($0)&#125;&apos;` export m=$[10-$n] export o=`perl -e &apos;$a=&apos;0&apos;; $b=$a x $ENV&#123;&quot;m&quot;&#125;; print $b;&apos;` export j=$i p=`perl -e &apos;$c=$ENV&#123;&quot;o&quot;&#125;.$ENV&#123;&quot;j&quot;&#125;; print $c;&apos;` echo &quot;$i,$i,$p,$p,$p,$p,$p,$p,`date +%Y%m%d%H%M%S`&quot;done其中用到了perl，所以脚本整体看起来比较啰嗦，希望能找到更好的解决办法。PS: shell 执行效率很低，so 该脚本运行时间会很漫长！awk搞起awk &apos;BEGIN&#123;for(i=1;i&lt;=10;i++)printf(&quot;%d,%d,%010d,%010d,%010d,%010d,%010d,%010d,%d\n&quot;,i,i,i,i,i,i,i,i,strftime(&quot;%Y%m%d%H%M&quot;))&#125;&apos;python搞起#!/usr/bin/python# -*- coding: utf-8 -*-import datetimedef get_data(num, time_now): list_num = [num]*8 list_num.append(time_now) return &quot;%d,%d,0d,0d,0d,0d,0d,0d,%s&quot; % tuple(list_num)def loop_count(times): for i in xrange(times): time_now = datetime.datetime.now().strftime(&quot;%Y%m%d%H%M%S&quot;) write_file(get_data(i+1, time_now))def write_file(string): with open(&quot;output&quot;, &apos;a+&apos;) as filename: filename.write(string+&apos;\n&apos;)if __name__ == &quot;__main__&quot;: loop_count(1000*1000) 8. awk用print打印单引号123456awk &apos;&#123;print &quot;This is a &apos;&quot;&apos;&quot;&apos;&quot;$1&#125; filename 解释一下：在awk中使用脱义字符\是起不到作用的，如果想打印特殊字符，只能使用&apos;&quot;&quot;&apos; 这样的组合才可以。这里自左至右为单引号 双引号 双引号单引号其中两个单引号为一对，两个双引号为一对。想脱义$那就是&apos;&quot;$&quot;&apos;脱义单引号那就是 &apos;&quot;&apos;&quot;&apos; 9. 合并两个文件123456789101112131415161718192021222324paste filename1 filename2 这样就可以实现了。举个例子。cat a.txt1 2 3 4 5 6 a b ccat b.txt3 2 1 6 5 4 c b a 则 paste a.txt b.txt 结果为1 2 3 3 2 14 5 6 6 5 4a b c c b a如果，你想在两个文件连接处用一个指定的字符连接，还可以用-d来指定paste -d &apos;+&apos; a.txt b.txt结果为1 2 3+3 2 14 5 6+6 5 4a b c+c b a 10. awk的参考教程地址[http://www.cnblogs.com/emanlee/p/3327576.html] 1234567#awk -F \| &apos;NR==FNR&#123;a[$2]=$0;next&#125;&#123;print a[$1]&quot;|&quot;$2&#125;&apos; account cdr注释:由NR=FNR为真时,判断当前读入的是第一个文件account,然后使用&#123;a[$2]=$0;next&#125;循环将account文件的每行记录都存入数组a,并使用$2第2个字段作为下标引用.由NR=FNR为假时,判断当前读入了第二个文件cdr,然后跳过&#123;a[$2]=$0;next&#125;,对第二个文件cdr的每一行都无条件执行 &#123;print a[$1]&quot;|&quot;$2&#125;,此时变量$1为第二个文件的第一个字段,与读入第一个文件时,采用第一个文件第二个字段$2为数组下标相同.因此可以在此使用 a[$1]引用数组。 awk运算符 运算符 描述 = += -= = /= %= ^= *= 赋值 ?: C条件表达式 双竖线 逻辑或 &amp;&amp; 逻辑与 ~ ~! 匹配正则表达式和不匹配正则表达式 &lt; &lt;= &gt; &gt;= != == 关系运算符 空格 连接 + - 加，减 * / &amp; 乘，除与求余 + - ! 一元加，减和逻辑非 ^ *** 求幂 ++ – 增加或减少，作为前缀或后缀 $ 字段引用 in 数组成员]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则拓展1]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F9.8%20%E6%AD%A3%E5%88%99%E6%8B%93%E5%B1%951%2F</url>
    <content type="text"><![CDATA[1. 打印某行到某行之间的内容12345678910111213141516171819202122232425有个文件test的内容如下：ertfff**[abcfd]123324444[rty]**fgfgf怎么能截取[abcfd]123324444[rty]这一部分出来呢？答案： sed -n &apos;/\[abcfd\]/,/\[rty\]/p&apos; test之所以不用-r，是应为会使中间,失效总结：sed -n &apos;/a/,/b/p&apos; filename 截取a和b之间的一节， 2. sed转换大小写123456789101112sed中，使用\u 表示大写，\l 表示小写1. 把每个单词的第一个小写字母变大写：sed &apos;s/\b[a-z]/\u&amp;/g&apos; filename\b 元字符集 是边际符，匹配的是离他最近的字符的前或者后一个位置，也起到隔离的作用。比如：很多单词里包含hi这两个连续的字符，比如him,history,high等等。用hi来查找的话，这里边的hi也会被找出来。如果要精确地查找hi这个单词的话，我们应该使用\bhi\b&amp; 替换标记 已匹配字符串标记，表示前面要替换的字符集2. 把所有小写变大写：sed &apos;s/[a-z]/\u&amp;/g&apos; filename3. 大写变小写：sed &apos;s/[A-Z]/\l&amp;/g&apos; filename 3. sed在某一行最后添加一个数字1234567891011121314151617181920#cat testaskdjaslkd aslkdjf3eskdjfsdfjsdkfjkfsdkfjksdjfkjsdf12sdfesdfaslkdjfkasdjf asdlfkjaskdfj#sed &apos;s/\(^a.*\)/\1 12/&apos; test .* 贪婪匹配 \1 表示一段匹配标记，askdj 12aslkd aslkdjf3e 12skdjfsdfjsdkfjkfsdkfjksdjfkjsdf12sdfesdfaslkdjfkasdjf asdlfkjaskdfj 12sed &apos;s/a/b/&apos; filename 实际还是一个sed替换的使用 4. 删除某行到最后一行12345678910111213141516171819202122232425262728293031323334[root@test200 ~]# cat testabcdef[root@test200 ~]# sed &apos;/c/&#123;p;:a;N;$!ba;d&#125;&apos; testabc定义一个标签a，匹配c，然后N把下一行加到模式空间里，匹配最后一行时，才退出标签循环，然后命令d，把这个模式空间里的内容全部清除。if 匹配&quot;c&quot;:a追加下一行if 不匹配&quot;$&quot;goto a最后退出循环，d命令删除。阿铭解释：sed -i &apos;/sample/&#123;N;d&#125;&apos; filename通过sed删除匹配行以及匹配行下一行sample是匹配字符，N在这里就是下一行，d是删除总结：还是看不懂这个命令p 打印模板块的行N 追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码$ 匹配行尾! 表示后面的命令对所有没有被选定的行发生作用d 删除，删除选择的行 5. 打印1到100行含某个字符串的行12sed -n &apos;1,100&#123;/abc/p&#125;&apos; 1.txt 打印1到100行含有abc字符串的行sed -n &apos;1,50&#123;/login/p&#125;&apos; /etc/passwd 打印1到50行含有login字符串的行]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk命令学习笔记]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F9.6%20-%209.7%20awk%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[9.6 - 9.7 awk命令学习笔记1. awk命令介绍 awk是一种编程语言，用于在linux/unix下对文本和数据进行处理。数据可以来自标准输入(stdin)、一个或多个文件，或其它命令的输出。它支持用户自定义函数和动态正则表达式等先进功能，是linux/unix下的一个强大编程工具。它在命令行中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。 2. 语法形式12awk [options] &apos;script&apos; var=value file(s) awk [options] -f scriptfile var=value file(s) 3. 常用命令选项 -F fs fs指定输入分隔符，fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk -f scripfile 从脚本文件中读取awk命令 4. awk的模式和操作4.1 awk的模式模式可以是以下任意一个： /正则表达式/：使用通配符的扩展集。 关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试。 模式匹配表达式：用运算符（匹配）和!（不匹配）。 BEGIN语句块、pattern语句块、END语句块：参见awk的工作原理 4.2 awk的操作操作由一个或多个命令、函数、表达式组成，之间由换行符或分号隔开，并位于大括号内，主要部分是： 变量或数组赋值 输出命令 内置函数 控制流语句 5. awk脚本基本结构1awk &apos;BEGIN&#123; print &quot;start&quot; &#125; pattern&#123; commands &#125; END&#123; print &quot;end&quot; &#125;&apos; file 一个awk脚本通常由：++BEGIN语句块++、++能够使用模式匹配的通用语句块++、++END语句块++3部分组成，这三个部分是可选的。任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中，例如： 12awk &apos;BEGIN&#123; i=0 &#125; &#123; i++ &#125; END&#123; print i &#125;&apos; filename awk &quot;BEGIN&#123; i=0 &#125; &#123; i++ &#125; END&#123; print i &#125;&quot; filename 6. awk的工作原理1awk &apos;BEGIN&#123; commands &#125; pattern&#123; commands &#125; END&#123; commands &#125;&apos; 第一步：执行BEGIN{ commands }语句块中的语句； 第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。 第三步：当读至输入流末尾时，执行END{ commands }语句块。 BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。 END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。 pattern语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。 7. awk内置变量（预定义变量）说明：[A][N][P][G]表示第一个支持变量的工具，[A]=awk、[N]=nawk、[P]=POSIXawk、[G]=gawk 12345678910111213141516171819202122$n 当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。 $0 这个变量包含执行过程中当前行的文本内容。 [N] ARGC 命令行参数的数目。 [G] ARGIND 命令行中当前文件的位置（从0开始算）。 [N] ARGV 包含命令行参数的数组。 [G] CONVFMT 数字转换格式（默认值为%.6g）。 [P] ENVIRON 环境变量关联数组。 [N] ERRNO 最后一个系统错误的描述。 [G] FIELDWIDTHS 字段宽度列表（用空格键分隔）。 [A] FILENAME 当前输入文件的名。 [P] FNR 同NR，但相对于当前文件。 [A] FS 字段分隔符（默认是任何空格）。 [G] IGNORECASE 如果为真，则进行忽略大小写的匹配。 [A] NF 表示字段数，在执行过程中对应于当前的字段数。 [A] NR 表示记录数，在执行过程中对应于当前的行号。 [A] OFMT 数字的输出格式（默认值是%.6g）。 [A] OFS 输出字段分隔符（默认值是一个空格）。 [A] ORS 输出记录分隔符（默认值是一个换行符）。 [A] RS 记录分隔符（默认是一个换行符）。 [N] RSTART 由match函数所匹配的字符串的第一个位置。 [N] RLENGTH 由match函数所匹配的字符串的长度。 [N] SUBSEP 数组下标分隔符（默认值是34）。 8. awk命令实际应用8.1. 截取文档中的一段123head -n2 test.txt|awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos; -F 指定分隔符号为：head -n2 test.txt|awk -F &apos;:&apos; &apos;&#123;print $0&#125;&apos;$0表示全部段 $1表示第1段 8.2. 也可以使用自定义字符连接每个段1234awk -F &apos;:&apos; &apos;&#123;print $1&quot;#&quot;$2&quot;#&quot;$3&quot;#&quot;$4&#125;&apos; 或者使用awk内部变量OFS，格式如下：awk -F &apos;:&apos; &apos;&#123;OFS=&quot;#&quot;&#125; &#123;print $1,$2,$3,$4&#125;&apos; 1.txtawk 如果没有用-F 指定分割符，会默认用空格或者空白字符为分隔符 8.3. 匹配字符或字符串12awk &apos;/oo/&apos; test.txt 把包含oo的行打印出来awk -F &apos;:&apos; &apos;$1 ~ /o+/&apos; test.txt 精确匹配第一段包含o一次或多次的行 支持正则表达式 8.4 针对某个段匹配1awk -F &apos;:&apos; &apos;$1 ~/oo/&apos; test.txt 精确匹配第一段包含oo的行 8.5 多次匹配123awk -F &apos;:&apos; &apos;/root/ &#123;print $1&quot;@&quot;$3&#125; /user/ &#123;print $2,$3&#125;&apos; test.txt 匹配root的行打印第1段和第3段并且使用@隔断；且同时匹配user的行打印第2段和第3段多个表达式一起写 8.6 运用数学运算功能条件操作符 == , &gt; , != , &gt;= , &lt;= 匹配第三段是0的 12awk -F &apos;:&apos; &apos;$3==&quot;0&quot;&apos; /etc/passwd 2个==号，第1个=相当于赋值 需求是数字的要加双引号 匹配第三段大于等于500的 12awk -F &apos;:&apos; &apos;$3&gt;=500&apos; /etc/passwd当用与数字比较时，500不能加双引号，这点要注意区分含义 第七段不是 ‘/sbin/nologin’ 1awk -F &apos;:&apos; &apos;$7!=&quot;/sbin/nologin&quot;&apos; /etc/passwd 字符串要加双引号 把第3段和第4段值相加，并赋予给第7段 123awk -F &apos;:&apos; &apos;&#123;$7=$3+$4; print $0&#125;&apos; 1.txt注意，这样会改变文本的结构，所以print $0就不会显示分隔符了，需要借助OFSawk -F &apos;:&apos; &apos;&#123;OFS=&quot;:&quot;&#125; &#123;$7=$3+$4; print $0&#125;&apos; 1.txt 8.7 2个字段的比较1awk -F &apos;:&apos; &apos;$3&lt;$4&apos; /etc/passwd 匹配第3段小于第4段的 8.8 2个条件一起使用，条件且 &amp;&amp;12awk -F &apos;:&apos; &apos;$3&gt;5 &amp;&amp; $3&lt;7&apos; /etc/passwd 第3段大于5，且第3段小于7，&amp;&amp; 条件且，表示必须要同时满足两个条件 8.9 条件或者 ||1awk -F &apos;:&apos; &apos;$3&gt;1000 || $7==&quot;/bin/bash&quot;&apos; /etc/passwd 第3段大于5或者第7段为&apos;/bin/bash&apos; 8.10 awk内置变量 NR 表示行，NF表示段12head -n3 /etc/passwd | awk -F &apos;:&apos; &apos;&#123;print NF&#125;&apos;head -n3 /etc/passwd | awk -F &apos;:&apos; &apos;&#123;print NR&#125;&apos; 打印40行以后的行1awk &apos;NR&gt;40&apos; /etc/passwd -打印20行以后并且第1段包含 root 的行 1awk -F &apos;:&apos; &apos;NR&lt;20 &amp;&amp; $1 ~ /roo/&apos; /etc/passwd 8.11 赋值，更改某个段的值1head -n 3 /etc/passwd |awk -F &apos;:&apos; &apos;$1=&quot;root&quot;&apos; 8.12 计算第3段的总和1awk -F &apos;:&apos; &apos;&#123;(tot=tot+$3)&#125;; END &#123;print tot&#125;&apos; /etc/passwd tot=total 求和的意思 8.13 使用if关键词1awk -F &apos;:&apos; &apos;&#123;if ($1==&quot;root&quot;) &#123;print $0&#125;&#125;&apos; /etc/passwd]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sed命令学习笔记]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F9.4%20-%209.5%20sed%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[9.4 - 9.5 sed命令1. sed命令介绍 sed是一种流编辑器，它是文本处理中非常中的工具，能够完美的配合正则表达式使用，功能不同凡响。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 sed可以实现grep的大部分功能，但sed无法显示颜色，sed的强项在于替换。 2. sed的用法2.1 功能说明：利用script来处理文本文件。2.2 语 法1sed [-hnV][-e&lt;script&gt;][-f&lt;script文件&gt;][文本文件] 补充说明：sed可依照script的指令，来处理、编辑文本文件。 2.3 选项12345-e&lt;script&gt;或—expression=&lt;script&gt; 以选项中指定的script来处理输入的文本文件。 -f&lt;script文件&gt;或—file=&lt;script文件&gt; 以选项中指定的script文件来处理输入的文本文件。 -h或—help 显示帮助。 -n或—quiet或--silent 仅显示script处理后的结果。 -V或—version 显示版本信息。 2.4 参数123456789101112131415161718192021222324a\ 在当前行下面插入文本。 i\ 在当前行上面插入文本。 c\ 把选定的行改为新的文本。 d 删除，删除选择的行。 D 删除模板块的第一行。 s 替换指定字符 h 拷贝模板块的内容到内存中的缓冲区。 H 追加模板块的内容到内存中的缓冲区。 g 获得内存缓冲区的内容，并替代当前模板块中的文本。 G 获得内存缓冲区的内容，并追加到当前模板块文本的后面。 l 列表不能打印字符的清单。 n 读取下一个输入行，用下一个命令处理新的行而不是用第一个命令。 N 追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码。 p 打印模板块的行。 P(大写) 打印模板块的第一行。 q 退出Sed。 b lable 分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾。 r file 从file中读行。 t label if分支，从最后一行开始，条件一旦满足或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 T label 错误分支，从最后一行开始，一旦发生错误或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 w file 写并追加模板块到file末尾。 W file 写并追加模板块的第一行到file末尾。 ! 表示后面的命令对所有没有被选定的行发生作用。 = 打印当前行号码。 # 把注释扩展到下一个换行符以前。 2.5 替换标记1234567g 表示行内全面替换。 p 表示打印行。 w 表示把行写入一个文件。 x 表示互换模板块中的文本和缓冲区中的文本。 y 表示把一个字符翻译为另外的字符（但是不用于正则表达式） \1 子串匹配标记 &amp; 已匹配字符串标记 2.6 sed元字符集123456789101112^ 匹配行开始，如：/^sed/匹配所有以sed开头的行。 $ 匹配行结束，如：/sed$/匹配所有以sed结尾的行。 . 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。 * 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。 [] 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。 [^] 匹配一个不在指定范围内的字符，如：/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。 \(..\) 匹配子串，保存匹配的字符，如s/\(love\)able/\1rs，loveable被替换成lovers。 &amp; 保存搜索字符用来替换其他字符，如s/love/**&amp;**/，love这成**love**。 \&lt; 匹配单词的开始，如:/\ 匹配单词的结束，如/love\&gt;/匹配包含以love结尾的单词的行。 x\&#123;m\&#125; 重复字符x，m次，如：/0\&#123;5\&#125;/匹配包含5个0的行。 x\&#123;m,\&#125; 重复字符x，至少m次，如：/0\&#123;5,\&#125;/匹配至少有5个0的行。 x\&#123;m,n\&#125; 重复字符x，至少m次，不多于n次，如：/0\&#123;5,10\&#125;/匹配5~10个0的行。 2.7 sed用法实例实现grep匹配功能1234sed -n &apos;/root/&apos;p test.txt root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin说明：这里的p是print，加上-n后就可以只打印符合规则的行，如果不加则会把test.txt从头到尾打印一遍。 使用+ ？ | () {} 等特殊符号1234567sed -n &apos;/o.t/&apos;p test.txt sed -n &apos;/o*t/&apos;p test.txt sed -n &apos;/o\+t/&apos;p test.txt sed中+ ？ | () &#123;&#125; 等符号的使用和grep一样需要加、去意符号，否则，必须加 -r参数sed -nr &apos;/o+t/&apos;p test.txtsed -nr &apos;/o&#123;2&#125;/&apos;p test.txt sed -nr &apos;/root|bus/&apos;p test.txt 打印指定的行12345sed -n &apos;5&apos;p test.txt 打印第5行sed -n &apos;1,5&apos;p test.txt 打印1到5行sed -n &apos;1,$&apos;p test.txt 打印1到最后一行，即打印全部sed -n &apos;/^1/&apos;p test.txt 打印所有以1开头的行sed -nr &apos;/(bash)$/&apos;p test.txt 打印所有以bash结尾的行 同时匹配多个条件123456789sed -e &apos;1&apos;p -e &apos;/bus/&apos;p -n test.txt sed -e &apos;1&apos;p -e &apos;/root/&apos;p -n test.txt-e 实现同时进行多个任务，上面这个也可以用sed -n &apos;1p ; /root/p&apos; test.txtsed -n -e &apos;1&apos;p -e &apos;/root/&apos;p test.txt root:x:0:0:root:/root:/bin/bashroot:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin当前后两个命令结果一样的时候，两个命令还是都执行了一遍，互不影响 sed也有 类似grep -i不区分大小写的用法1234sed -n &apos;/bus/&apos;Ip test.txtdbus:x:81:81:System message bus:/:/sbin/nologinBUS:Ip中I（大写的i）表示不区分大小写 删除功能12345678910111213sed &apos;1&apos;d test.txtsed &apos;1,3&apos;d test.txtsed &apos;/oot/&apos;d test.txtd表示删除，但并不修改目标文件;如果加上 -i参数，会直接修改文件的内容sed -i &apos;/nologin/&apos;d test.txtcat test.txt r1oot:x:0:0:root:/root:/bin/bashsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltgavin:x:1000:1000::/home/gavin:/bin/bashzhang:x:1001:1001::/home/zhang:/bin/bashuser:x:1002:1002::/home/user:/bin/bash 替换功能123456789101112131415161718192021222324sed &apos;1,2s/root/admin/g&apos; test.txt 上面命令中，1,2表示1到2行；s表示替换；g表示全局替换，否则的话只替第一个的。里面的/符号可以替换成#或者@sed &apos;s#root#admin#g&apos; test.txtsed &apos;s/[a-zA-Z]//g&apos; test.txt 删除文件中所有的字母sed &apos;s/[0-9]//g&apos; test.txt 删除文件中所有的数字sed &apos;s/[^0-9]//g&apos; test.txt 删除文件中所有的非数字head test.txt | sed -r &apos;s/([^:]+):(.*):([^:]+)/\3:\2:\1/g&apos;上面的命令中，-r是用来脱意的，括号()是用来调用的，后面\3 \2 \1是 子串匹配标记，表示把前面的顺序倒过来排序([^:]+)表示非冒号的字符串(.*) 表示任意字符串([^:]+)表示非冒号的字符串head test.txt |sed -r &apos;s/(.*)/aaa:&amp;/&apos;给所有行前面加上 aaa: 字符sed &apos;s/^.*$/123&amp;/&apos; test.txt给文件的所有行前面加上 123 字符sed -i &apos;s/ot/to/g&apos; test.txt替换文件中所有ot成为to，并打印出来，且把替换结果存到文件中]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep学习笔记]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F9.1%20-%209.3%20grep%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[9.1 正则介绍_grep上9.2 grep中9.3 grep下1. 正则介绍 在计算机科学中，正则表达式是这样解释的：它是指一个用来描述或者匹配一系列符合某个句法规则的字符串的单个字符串。 正则就是一串有规律的字符串 在很多文本编辑器或其他工具里，正则表达式通常被用来检索和/或替换那些符合某个模式的文本内容。许多程序设计语言都支持利用正则表达式进行字符串操作。对于系统管理员来讲，正则表达式贯穿在我们的日常运维工作中，无论是查找某个文档，抑或查询某个日志文件分析其内容，都会用到正则表达式。 其实正则表达式，只是一种思想，一种表示方法。只要我们使用的工具支持表示这种思想那么这个工具就可以处理正则表达式的字符串。常用的工具有grep, sed, awk 等.。 2. grep命令 是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 grep在centOS6和centOS7中的区别，centOS7中自带–color属性， ，就是把匹配到的关键字用颜色标注出来了。 123456789101112语法： grep [-cinvABC] ‘word’ filename-c ：打印符合要求的行数-i ：忽略大小写-n ：在输出符合要求的行的同时连同行号一起输出-v ：打印不符合要求的行，取反-r : 遍历所有子目录-A ：后跟一个数字（有无空格都可以），例如 –A2则表示打印符合要求的行以及下面两行-B ：后跟一个数字，例如 –B2 则表示打印符合要求的行以及上面两行-C ：后跟一个数字，例如 –C2 则表示打印符合要求的行以及上下各两行-w ：只显示全字符合的列。 -x ：只显示全列符合的列。 3. 实例3.1 过滤出带有某个关键词的行并输出行号123grep -n &apos;root&apos; /etc/passwd1:root:x:0:0:root:/root:/bin/bash10:operator:x:11:0:operator:/root:/sbin/nologin 3.2 过滤不带有某个关键词的行，并输出行号1234567grep -vn &apos;nologin&apos; /etc/passwd 1:root:x:0:0:root:/root:/bin/bash6:sync:x:5:0:sync:/sbin:/bin/sync7:shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown8:halt:x:7:0:halt:/sbin:/sbin/halt25:admin:x:1000:1000::/home/admin:/bin/bash26:nginx:x:1001:1001::/home/nginx:/bin/bash 3.3 过滤出所有包含数字的行“[ ]”的应用，如果是数字的话就用[0-9]这样的形式，当然有时候也可以用这样的形式[15]即只含有1或者5，注意，它不会认为是15。如果要过滤出数字以及大小写字母则要这样写[0-9a-zA-Z]。另外[ ]还有一种形式，就是[^字符] 表示除[ ]内的字符之外的字符。 1234567891011121314151617181920212223grep &apos;[0-9]&apos; /etc/inittab 过滤出所有包含0-9数字的行# multi-user.target: analogous to runlevel 3# graphical.target: analogous to runlevel 5...grep -v &apos;[0-9]&apos; /etc/inittab 过滤出所有不包含0-9数字的行，-v是取反# inittab is no longer used when using systemd.## ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.## Ctrl-Alt-Delete is handled by /usr/lib/systemd/system/ctrl-alt-del.target## systemd uses &apos;targets&apos; instead of runlevels. By default, there are two main targets:### To view current default target, run:# systemctl get-default## To set a default target, run:# systemctl set-default TARGET.target#grep &apos;^[^a-zA-Z]&apos; test.txt 过滤出所有不以英文字母开头的行，[^字符]表示除[ ]内的字符之外的字符 3.4 过滤出文档中以某个字符开头或者以某个字符结尾的行在正则表达式中，“^”表示行的开始，”$” 表示行的结尾，那么空行则表示 “^$”。 1234grep -v &apos;^$&apos; /etc/inittab 筛选出非空行grep -v &apos;^#&apos; /etc/inittab | grep -v &apos;^$&apos; 筛选出文档中以‘#’开头的且为非空的行grep &apos;sh$&apos; /etc/passwd 筛选出以“sh”结尾的行 3.5 过滤任意一个字符与重复字符12345678grep &apos;r.o&apos; test.txt“.”表示任意一个字符grep &apos;oo*&apos; test.txt“*”表示零个或多个前面的字符grep &apos;.*&apos; test.txt 正则中的贪婪匹配“.*”表示零个或多个任意字符，空行也包含在内 3.6 指定要过滤字符出现的次数这里用到了{ }，其内部为数字，表示前面的字符要重复的次数 1234grep &apos;o\&#123;2\&#125;&apos; /etc/passwd 匹配o出在过2次的某段字符. 里面用到了\拖意符号root:x:0:0:root:/root:/bin/bashlp:x:4:7:lp:/var/spoonl/lpd:/sbin/nologinmail:x:8:12:mail:/var/spooooooooonl/mail:/sbin/nologin 花括号表示前面字符的重复范围，花括号在使用的时候就是这样用的。 脱义符号用起来很麻烦，这里就可以用到-E的选项，或者是egrep。 3.7 使用egrep可以代替grep的所有命令12grep -E &apos;o&#123;2&#125;&apos; /etc/passwd passwdegrep &apos;o&#123;2&#125;&apos; /etc/passwd 4. egrep命令egrep命令是grep的扩展版本，但是实际工作中，只用会一种就够用了。 4.1 筛选一个或一个以上前面的字符1egrep &apos;o+&apos; /etc/passwd 4.2 筛选零个或一个前面的字符123区别egrep &apos;oo?&apos; /etc/passwd 要把 “oo?” 看成 “o” 和 “o?”egrep &apos;o?&apos; /etc/passwd 那么“o?” 表示零个或一个o字符 4.3 筛选字符串1或者字符串2中间有一个‘|’表示或者的意思，这个用的比较多 1egrep &apos;root|nologin&apos; /etc/passwd 4.4 egrep中‘( )’的应用用‘( )’表示一个整体，例如(oo)+就表示1个‘oo’或者多个‘oo’ 1egrep &apos;(oo)&#123;2&#125;&apos; /etc/passwd 4.5. 总结字符用法12345678&apos;.&apos; 任意一个字符，包括特殊字符，下划线，空格，&apos;*&apos; 0个或者多个 *前面的字符&apos;.*&apos; 任意数量任意字符，包括空行&apos;+&apos; 表示1个或多个 + 前面的字符 (限egrep)&apos;？&apos; 表示0个或1个 ？前面的字符 (限egrep)[] 范围内任意一个字符&#123;&#125; ^ []里表示取反，外面表示行首 ==# （） { } | + ？这些符号用的时候需要用egrep或者用grep -E 或者用grep要配合用\脱义== 5 . 扩展–include 指定文件 12345grep 其实还可以这样使用:在tmp目录下，过滤所有 *.txt 文档中含有root的行grep -r --include=&quot;*.txt&quot; &apos;root&apos; /tmpdata目录下，所有 *.php 文档中包含eval的行egrep -rhn --include=&quot;*.php&quot; &apos;eval&apos; 1.txt]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>grep</tag>
        <tag>egrep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell基础介绍03-cut、sort、wc、unoq、tee、tr、split]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F8.10%20-%208.13%20Shell%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D03-cut%E3%80%81sort%E3%80%81wc%E3%80%81unoq%E3%80%81tee%E3%80%81tr%E3%80%81split%2F</url>
    <content type="text"><![CDATA[8.10 shell特殊符号cut命令8.11 sort_wc_uniq命令8.12 tee_tr_split命令8.13 shell特殊符号下1. 特殊符号123456789101112131415* 通配，任意多个任意字符? 通配，任意一个字符# 注释字符\ 脱义字符| 管道符 $ 变量前缀，!$组合，正则里面表示行尾；多条命令写到一行，用分号分割，不管前面的命令执行成功与否，后面的命令都执行~ 用户家目录，后面正则表达式表示匹配符&amp; 放到命令后面，会把命令丢到后台&gt; &gt;&gt; 2&gt; 2&gt;&gt; &amp;&gt;（&amp;&gt;表示把正确和错误结果都定向出来）[ ] 指定字符中的一个，[0-9],[a-zA-Z],[abc]|| 和 &amp;&amp; ，用于命令之间|| 只有前面的命令执行失败，后面命令才执行&amp;&amp; 只有后面的命令执行成功，后面命令才执行 2. 和管道符相关的命令cut一般用来截取字符串 -d 分隔符 -f 指定段号，可以是号码，中间用1,2隔开，也可以是区间1-3 -c 指定第几个字符,同上，可以是号码，中间用1,2隔开，也可以是区间1-312345cat /etc/passwd | head 显示passwd的前10行（默认10）cat /etc/passwd | haed -3 显示passwd的前3行（指定）cat /etc/passwd | haed -2 | cut -c 1-10 显示/etc/passwd前2行，1到10个字符cat /etc/passwd | haed -2 | cut -d “:” -f 1，2 显示passwd的第一段和第二段cat /etc/passwd | haed -2 | cut -d “:” -f 1-3 显示passwd的第一段到第三段 sort sort命令是在Linux里非常有用，一般sort会和uniq合用。它将文件进行排序，并将排序结果标准输出。sort命令既可以从特定的文件，也可以从stdin中获取输入。- 来自 http://man.linuxde.net/sort sort将文件的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。 参数 -n 以数字大小排序，字母和特殊符号默认为0 -r 反向排序 -t 指定分隔符 -k 指定需要排序的栏位 （-t 不经常用） 例子 123456789101112131415161718192021222324# cat sort.txt AAA:BB:CC aaa:30:1.6 ccc:50:3.3 ddd:20:4.2 bbb:10:2.5 eee:40:5.4 eee:60:5.1# sort -nk 2 -t: sort.txt 将BB列按照数字从小到大顺序排列AAA:BB:CC bbb:10:2.5 ddd:20:4.2 aaa:30:1.6 eee:40:5.4 ccc:50:3.3 eee:60:5.1# sort -nrk 3 -t: sort.txt 将CC列数字从大到小顺序排列eee:40:5.4 eee:60:5.1 ddd:20:4.2 ccc:50:3.3 bbb:10:2.5 aaa:30:1.6 AAA:BB:CC wc wc命令用来计算数字。利用wc指令我们可以计算文件的Byte数、字数或是列数，若不指定文件名称，或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据。 -l 统计行数 -m 统计字符数 -w 统计词数12345678# wc -l 1.txt 统计行数 11 1.txt# wc -w 1.txt 统计词数22 1.txt# wc -m 1.txt 统计字符数 620 1.txt# wc 1.txt 统计行数 词数 字符数 11 22 620 1.txt uniq uniq命令用于报告或忽略文件中的重复行，一般与sort命令结合使用 -c 统计行数 1234567删除重复行uniq file.txt sort file.txt | uniq sort -u file.txtsort file.txt | uniq -c 统计各行在文件中出现的次数sort file.txt | uniq -d 在文件中找出重复的行 tee tee命令用于将数据重定向到文件，另一方面还可以提供一份重定向数据的副本作为后续命令的stdin。简单的说就是把数据重定向到给定文件和屏幕上。 -a 追加重定向 123456789101112ls | tee out.txt | cat -n 显示行号并打印out.txt，同时重定向到文件中1 1.sh 2 1.txt 3 2.txt 4 eee.tst 5 EEE.tst 6 one 7 out.txt 8 string2 9 www.pdf 10 WWW.pdf 11 WWW.pef tr tr命令可以对来自标准输入的字符进行替换、压缩和删除。它可以将一组字符变成另一组字符，经常用来编写优美的单行命令，作用很强大。常用来处理文档中出现的特殊符号。 -c：取代所有不属于第一字符集的字符； -d：删除所有属于第一字符集的字符； -s：把连续重复的字符以单独一个字符表示； -t：先删除第一字符集较第二字符集多出的字符； 字符集：指定要转换或删除的原字符集。当执行转换操作时，必须使用参数“字符集2”指定转换的目标字符集。但执行删除操作时，不需要参数“字符集2”。 来自: http://man.linuxde.net/tr 123456789echo &quot;HELLO WORLD&quot; | tr &apos;A-Z&apos; &apos;a-z&apos; 将输入字符HELLO WORLD由大写转换为小写hello world &apos;A-Z&apos; 和 &apos;a-z&apos;都是集合，集合是可以自己制定的，例如：&apos;ABD-&#125;&apos;、&apos;bB.,&apos;、&apos;a-de-h&apos;、&apos;a-c0-9&apos;都属于集合， 集合里可以使用&apos;\n&apos;、&apos;\t&apos;，可以可以使用其他ASCII字符。echo &quot;thissss is a text linnnnnnne.&quot; | tr -s &apos; sn&apos; 压缩输入中重复的字符this is a text line.echo aa.,a 1 b#$bb 2 c*/cc 3 ddd 4 | tr -d -c &apos;0-9 \n&apos; 字符集补集，从输入文本中将不在补集中的所有字符删除1 2 3 4 split split命令可以将一个大文件分割成很多个小文件，有时需要将文件分割成更小的片段，比如为提高可读性，生成日志等。 -b：值为每一输出档案的大小，单位为 byte。 -l：值为每一输出档的列数大小。 12345678910dd if=/dev/zero bs=100k count=1 of=date.file 生成一个大小为100KB的测试文件split -b 10k date.file 将date.file文件分割成大小为10KB的小文件lsdate.file xaa xab xac xad xae xaf xag xah xai xajsplit -l 10 date.file 把文件分割成每个包含10行的小文件split -b 50k date.file new_ 把文件分割成每个50k的小文件，切割成的文件以new_开头命名lsnew_aa new_ab new_ac date.file]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>cut</tag>
        <tag>sort</tag>
        <tag>wc</tag>
        <tag>unoq</tag>
        <tag>tee</tag>
        <tag>tr</tag>
        <tag>split</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell基础介绍02-管道符、作业控制、变量和环境变量]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F8.6%20-%208.9%20Shell%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D02-%E7%AE%A1%E9%81%93%E7%AC%A6%E3%80%81%E4%BD%9C%E4%B8%9A%E6%8E%A7%E5%88%B6%E3%80%81%E5%8F%98%E9%87%8F%E5%92%8C%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[8.6 管道符和作业控制1. 管道符“|” 管道符“|”将两个命令隔开，管道符左边命令的输出就会作为管道符右边命令的输入。连续使用管道意味着第一个命令的输出会作为第二个命令的输入，第二个命令的输出又会作为第三个命令的输入，依此类推。 123cat 1.txt | wc -l cat 1.txt |grep &apos;aaa&apos;find ./ -type f | wc -l 2. 作业控制2.1 作业和进程的区别 进程和作业的概念也有区别。一个正在执行的进程称为一个作业，而且作业可以包含一个或多个进程，尤其是当使用了管道和重定向命令。例如“nroff -man ps.1|grep kill|more”这个作业就同时启动了三个进程。 2.2 作业控制 作业控制指的是控制正在运行的进程的行为。比如，用户可以挂起一个进程，等一会儿再继续执行该进程。shell将记录所有启动的进程情况，在每个进程过程中，用户可以任意地挂起进程或重新启动进程。作业控制是许多shell（包括bash和tcsh）的一个特性，使用户能在多个独立作业间进行切换。 使用 Ctrl + z 停止进程并放到后台 1234vim 1.txt[1]+ 已停止 vim 1.txtvim aa.txt[2]+ 已停止 vim aa.txt 使用jobs命令查看后台所有运行的进程 123jobs[1]- 已停止 vim 1.txt[2]+ 已停止 vim aa.txt 使用fg[id号]将任务调到前台 1fg 1 再查看进程 123jobs[1]+ 已停止 sleep 200[2]- 运行中 sleep 100 &amp; 使用bg[id号]将任务调到后台，如果进程还在不断刷新运行的话，其实进程没有停止 1234bg 1 [1]+ vim 1.txt &amp;[1]+ 已停止 vim 1.txt 使用sleep停止 123456sleep 1000 停止1000秒jobs[1] 已停止 vim 1.txt[2] 已停止 vim aa.txt[3]- 已停止 sleep 1000 8.7/8.8 shell变量1. 变量 在shell中有3种变量：系统变量，环境变量和用户自定义变量，其中系统变量在对参数判断和命令返回值判断时会使用，环境变量主要是在程序运行时需要，用户自定义变量在编程过程中使用量最多。==系统内置变量一般都是大写，而自己定义的变量尽量写成小写区分。== 2. 显示系统的内置变量命令 env12345678910env 显示系统的内置变量命（只保留一部分）HOSTNAME=localhost.localdomain SHELL=/bin/bash HISTSIZE=1000 USER=root MAIL=/var/spool/mail/root PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin PWD=/root LANG=zh_CN.UTF-8 ... 3. 显示系统内的变量也可以用户自定义变量 set12345a=1 自定义变量1=a 错误的格式-bash: 1=a: 未找到命令set |grep 1 查看是1的自定义变量a=1 4. shell变量的格式 变量名规则：可以是字母、数字下划线，首位不能为数字 变量值有特殊符号时需要用单引号括起来，比如 a=’a b c’，a=’a$b#C’ 尽量少用大写字母，因为大写字母大多都是系统的一些变量 有很多特殊的关键字，最好不要用作变量名，比如 if for do done 变量的累加 1234567891011121314151617a=1b=2echo $a$b12a=&apos;a$bc&apos;echo $a$ba$bc2c=&quot;a$bc&quot; **?是$bc没定义，不能识别的原因吗？** echo $c ac=&quot;a$b&quot;cecho $ca2cc=&apos;a$b&apos;cecho $ca$bca=a&quot;$b&quot;c 学会这样使用&quot;&quot;,是命令更清晰 全局变量 export命令 设置或显示环境变量在shell中执行程序时，shell会提供一组环境变量,这也使shell变量只能在当前使用。export可新增，修改或删除环境变量，供后续执行的程序使用，已达到使shell达到类似全局变量的目的。export的效力仅及于该此登陆操作，shell退出时失效。 ==父shell中定义的NAME环境变量传递到了子shell中，在子shell中定义的NAME环境变量没有被带到父shell中。如何改变呢？== 永久的：需要修改/etc/profile配置文件，export变量永久生效。 1打开这个文件后，会看到里面有很多已经定义好的变量,按照格式把自定义变量写入进去，然后source /etc/profile重启服务就可以生效了 临时的：使用export命令进行全局行声明即可，变量在关闭shell时失效 12345678910111213aming=linuxecho $aminglinuxbash 进入bashecho $aming 无结果exit 退出bashexport aming=linux 全局声明bash echo $aminglinux 查看当前用户在哪个shell中 pstree命令pstree命令可以把linux系统中所有进程通过树形结构打印出来 1234567pstree |grep bash |-login---bash |-sshd---sshd---bash-+-grepbashpstree |grep bash |-login---bash |-sshd---sshd---bash---bash-+-grep 取消变量 unset命令 unset + 变量名 把设置的变量取消掉 1234echo $aminglinuxunset amingecho $aming 8.9 环境变量配置文件1. 系统级环境变量配置文件12/etc/profile 用户环境变量，交互，登录才执行/etc/bashrc 用户不用登录，执行shell就生效 2. 普通用户级境变量配置文件1234~/.bashrc 该文件包含专用于你的shell的bash信息,当登录时以及每次打开新的shell时,该该文件被读取。例如你可以将用户自定义的alias或者自定义变量写到这个文件中。~/.bash_profile 定义了用户的个人化路径与环境变量的文件名称。每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次。~/.bash_history 记录命令历史用的。~/.bash_logout 当退出shell时，会执行该文件。可以把一些清理的工作放到这个文件中。 扩展bashrc和bash_profile的区别 [http://www.apelearn.com/bbs/thread-7719-1-1.html]]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>env</tag>
        <tag>bashrc</tag>
        <tag>profile</tag>
        <tag>jobs</tag>
        <tag>sleep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.1 - 8.5 Shell基础介绍01-History、Tab、alias、通配符和重定向]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F8.1%20-%208.5%20Shell%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D01-History%E3%80%81Tab%E3%80%81alias%E3%80%81%E9%80%9A%E9%85%8D%E7%AC%A6%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[8.1 shell介绍 shell是一个命令解释器，它在操作系统的最外层，负责直接与用户对话，把用户的输入解释给操作系统，并处理各种各样的操作系统的输出结果，输出到屏幕返回给用户。这种对话方式可以是交互的方式（从键盘输入命令，可以立即得到shell的回应），或非交互（脚本）的方式。 1. 常用操作系统的默认Shell linux是Bourne Again shell(bash) Solaris和FreeBSD缺省的是Bourne shell(sh) AIX下是Korn Shell(ksh) HP-UX缺省的是POSIX shell(sh) Centos linux系统默认的shell是bash 2. Shell运行过程用户-shell命令解释器-内核-硬件-内核-shell命令解释器-用户 8.2 命令历史1. history 命令历史Linux可以记录敲过的命令，预设的是可以记录1000条。这些命令历史记录会保存在.bash_history文件里面。只有退出该终端的时候，才会保存到这个文件里。 更改环境变量HISTSIZE，是系统能保存更多的命令历史记录 123456vim /etc/profile 环境变量HISTSIZE 在路径/etc/profile里面 ... 找到HISTSIZE这一行HISTSIZE=1000 系统默认保存是1000条命令历史记录，可以在这里面修改改成 HISTSIZE=2000 改成2000条qw 保存退出soure /etc/peofile 刷新一下配置文件 清除history里面的命令记录 1history -c 但是之前保存在 .bash_history 文件的记录不会掉 关于history的一些高级用法 1234567891011让history详细显示命令历史格式HISTTIMEFORMAT=&quot;%Y/%m/%d %H:%M:%S&quot;在/etc/peofile 里面添加 HISTTIMEFORMAT=&quot;%Y/%m/%d %H:%M:%S&quot; ，保存刷新，就可以了让history命令历史永久保存chaeer +a ~/.bash_history和history有关的快捷键!! 执行上一条命令!761 执行第761条命令！echo 运行 从命令历史里面从下往上找，以echo开头的命令 8.3 命令补全和别名1. Tab键不仅可以补全命令也可以补全路径，敲一个tab会补全一个路径或者一个文件名或者一个命令。 敲两下就会把所有的命令或者文件名都列出来。 另外，centOS7中，tab已经支持补全参数了， 需要安装一个软件包。 1yum install -y bash-completion 安装完成之后重启一下系统即可 例如，systemctl restart network 就是参数的一种，centOS6的时候需要全部手打出来，centOS7不用了。输入到一半就可使用tab就可以补全。 2. aliasalias命令命名的别名记录配置文件有2个 用户家目录下的.bashrc /etc/profile.d (但最好编辑上一个，这个别动) 8.4 通配符 通配符 通配符含义 * 匹配所有字符 ？ 匹配一个任意字符，如果文件名为两个或者两个以上的，将不在匹配范围内 [0-9] 中括号 匹配0-9范围内的，也可以是字母 a-z、A-Z；可以同时写多个[0-9a-zA-Z] {1,2,3} 花括号 匹配范围内的字符，需要以 ， 逗号分隔， 8.5 输入输出重定向 重定向符号 例子 重定向符含义 &gt; 重定向 cat 1.txt &gt; 2.txt 把 1.txt 的输出结果，输入到2.txt内，输入过程，会把2.txt内的内容删除，然后再把内容写入2.txt 内 &gt;&gt; 追加重定向 cat 1.txt &gt; 2.txt 把 1.txt 的输出结果，添加到2.txt内，输入过程，会直接把内容追加到2.txt内，在末行进行添加 2&gt; 错误信息重定向 lsaaa 2&gt; a.txt 把运行的错误信息，输入到 a.txt 下，输入过程，如果发生错误信息，会把a.txt内的内容删除，然后再把内容写入a.txt 内]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>alias</tag>
        <tag>history</tag>
        <tag>shell</tag>
        <tag>tab</tag>
        <tag>通配符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YUM工具、epel源和源码包的使用]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F7.6%20-%207.9%20YUM%E5%B7%A5%E5%85%B7%E3%80%81epel%E6%BA%90%E5%92%8C%E6%BA%90%E7%A0%81%E5%8C%85%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[7.6 yum更换国内源1. 原因因为系统里自带的很多源都是国外的，有时候下载大一点的包就会很慢。这个时候就可以更换成国内的源，如 163、搜狐，这样会快很多，也稳定很多。 2. 步骤2.1 备份原来的yum源12yum install -y wget 安装wget工具cp -r /etc/yum.repos.d /etc/yum.repos.d.bak 将原配置文件进行备份 2.2 设置aliyun的yum源123wget http://mirrors.163.com/.help/CentOS7-Base-163 http://mirrors.163.com/.help/CentOS7-Base-163.repo或者 在没有wget的情况下curl -O http://mirrors.163.com/.help/CentOS7-Base-163.repo 2.3 安装扩展源epel有的包，163的基础源里面也会没有，这种时候，就需要安装一个扩展源了（epel） 123456yum install -y epel-release 安装扩展源ls /etc/yum.repos.d/ 查看epel扩展源安装好了没 CentOS7-Base-163.repo CentOS-Debuginfo.repo CentOS-Sources.repo epel-testing.repo CentOS-Base.repo.bak CentOS-fasttrack.repo CentOS-Vault.repo CentOS-CR.repo CentOS-Media.repo epel.repoyum list |grep epel 过滤出epel扩展包 2.4 清理缓存12yum clean all 清除缓存yum repolist all 查看拥有仓库的状态 7.7 yum下载rpm包前面讲的都是直接安装，然而有些时候，我们需要下载一个安装包但不需要安装它，或者帮内网其他用户下载一个安装包该怎么处理呢？ 12345yum install 包名 -y --downloadonly 仅下载一个没有安装过的包 yum install 包名 -y --downloadonly --downloaddir=路径 下载一个包，并指定路径yum reinstall -y 包名 -–downloadonly -–downloaddir=路径如果一个包，已经安装过了，你就不能再次安装下载，只有重新安装一下，才可以下载这个包 7.8/7.9 源码包安装1. LINUX安装源码软件经典三部曲1231. ./configure [options]2. make3. make install 第一步，就是configure配置。配置项还是很多的，可以通过./configure –help查看有哪些配置项。很多源码的readme文档直接指出，一般使用./configure就可以看了。我个人喜欢将源码安装到指定的位置，使用./configure –prefix=我安装的目录。这样做的好处就是我知道将软件装在哪里了，将来还有他用； 第二步，使用make开始编译。这一步是根据上一步configure的结果来编译的； 第三步，使用make install开始安装，这一步结束后，软件就被安装到我指定的目录下； 注意：有时候使用系统自带的make时，编译会报出一些错误，原因是系统自带的make版本太老了，可以装个新的，官网可以再百度上搜下。 这里再补充几点： 1. 上面make后，可以使用make clean将编译参数清空，接着重新make； 2. 上面configure发现错误，可以使用make distclean，将configure参数全部清空，接着重新./configure–&gt;make。 出自：http://www.cnblogs.com/itblog/archive/2011/11/20/2255953.html 2. 源码包安装步骤==按照铭哥的约定，一定要把自己所需的源码包下载到此目录 cd /usr/local/src/，方便别人，也方便自己。== 1234567891011cd /usr/local/src/ 按照约定，一定要把自己所需的源码包下载到此目录wget http://mirrors.cnnic.cn/apache/httpd/httpd-2.2.32.tar.gz 从官网获取下载地址tar zxvf httpd-2.2.32.tar.gz 解压下载的源码包cd httpd-2.2.32 切换到目录下more INSTALL 查看如何安装,养成习惯去查看 ./configure –prefix=/usr/local/apache2 配置安装位置如果看不出自己安装的是否对，使用命令 echo $? 来查看， 0 即为正确，其它均为没有正常安装下面几步，一定要用 echo $? 来步步检查，为了防止后期不必要的错误！！！make 编译make install 编译安装 3. 卸载源码包12例如：rm -rf /usr/local/apache2 卸载上面的源码包 扩展 配置yum源优先级 http://www.aminglinux.com/bbs/thread-7168-1-1.html 把源码包打包成rpm包 http://www.linuxidc.com/Linux/2012-09/70096.htm]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>epel</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPM和YUM工具]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F7.1%20-%207.5%20RPM%E5%92%8CYUM%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[7.1 安装软件包的三种方法三种方法 rpm工具 yum工具 源码包 7.2 rpm包介绍安装或卸载rpm包，如果该包有依赖则要先安装或卸载其依赖包。 设置光驱并挂载 12345mount /dev/cdrom /mnt/ 把光驱挂载到mnt目录下其中，package目录下面都是rpm包，64位系统是可以安装32位的rpm包的rpm包名 lynx-2.8.5-23.i386.rpmrpm包格式 包名、版本号、发布版本号、平台 rpm常用参数 123456789-i, --install 安装-v, --verbose 信息可视化-h, --hash 人性化显示-e, --erase 卸载-U, --upgrade=&lt;packagefile&gt;+ 升级--replacepkge 无论软件包是否已被安装，都强行安装软件包--test 安装测试，并不实际安装--nodeps 忽略软件包的依赖关系强行安装--force 忽略软件包及文件的冲突 7.3 rpm工具用法12345678rpm -ivh rpm包文件 安装rpm -Uvh rpm包文件 升级rpm -e 包名 卸载rpm -qa 查询安装的包rpm -q 包名 查询指定包是否安装rpm -qi 包名 查询指定包信息rpm -ql 包名 列出包安装的文件rpm -qf 文件绝对路径 查看一个文件是由哪个包安装的 7.4 yum工具用法用yum工具安装包，不需要先安装其依赖包。 1. yum 红帽子公司开发的专门管理rpm包的工具 可以自动解决rpm安装时候产生的依赖关系 可以自动的在指定的源（网址，rpm包的集合库），下载指定的包 2. yum用法1234567891011121314151617yum list 列出可用rpm包ls /etc/yum.repos.d/ 所有yum配置文件CentOS-Base.repo（主配置文件） CentOS-CR.repo CentOS-Debuginfo.repoCentOS-fasttrack.repo CentOS-Media.repo CentOS-Sources.repoCentOS-Vault.repo epel.repo epel-testing.repoyum search vim 搜索包yum list | grep &apos;vim&apos; 包名含有vim的包yum install [-y] 包名 直接安装yum grouplist 列出已经安装过和可安装的套件，因为是中文的，必须换成英文才能使用，套件相当于一堆包的集合yum groupinstall [-y] 安装套件yum remove [-y] 卸载一个rpm包，一般不加yyum groupremove 卸载套件yum update [-y] 升级一个rpm包，一般不用，升级包会牵涉到很多支持包的支持问题yum provides “/*/vim” 搜索vim命令是由哪个包安装的yum provides &quot;/*/命令&quot; 搜索一个命令是由哪个包安装的 7.5 yum搭建本地仓库 实操全过程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485实际操作全过程[root@localhos]# mount /dev/cdrom /mnt **挂载CD安装光盘到mnt**[root@localhost etc]# cd /etc/yum.repos.d/ **进入目录**[root@localhost yum.repos.d]# ls **查看目录**CentOS-Base.repo CentOS-CR.repo CentOS-Debuginfo.repo CentOS-fasttrack.repo CentOS-Media.repo CentOS-Sources.repo CentOS-Vault.repo[root@localhost yum.repos.d]# cp -r yum.repos.d/ yum.repos.d.bak **备份yum配置文件**cp: 无法获取&quot;yum.repos.d/&quot; 的文件状态(stat): 没有那个文件或目录[root@localhost yum.repos.d]# cd ..[root@localhost etc]# cp -r yum.repos.d/ yum.repos.d.bak **备份yum配置文件**[root@localhost etc]# cd /etc/yum.repos.d/[root@localhost yum.repos.d]# lsCentOS-Base.repo CentOS-CR.repo CentOS-Debuginfo.repo CentOS-fasttrack.repo CentOS-Media.repo CentOS-Sources.repo CentOS-Vault.repo[root@localhost yum.repos.d]# rm -rf CentOS-Base.repo **删除配置文件**[root@localhost yum.repos.d]# yum list **查看yum仓库**xmlrpc3-common-devel.noarch 3.0-4.15.el6 basexmlrpc3-javadoc.noarch 3.0-4.15.el6 basexmlrpc3-server.noarch 3.0-4.15.el6 basexmlrpc3-server-devel.noarch 3.0-4.15.el6 basexmlsec1.i686 1.2.20-4.el6 basexmlsec1-devel.i686 1.2.20-4.el6 basexmlsec1-gcrypt.i686 1.2.20-4.el6 basexmlsec1-gcrypt-devel.i686 1.2.20-4.el6 basexmlsec1-gnutls.i686 1.2.20-4.el6 basexmlsec1-gnutls-devel.i686 1.2.20-4.el6 basexmlsec1-nss.i686 1.2.20-4.el6 basexmlsec1-nss-devel.i686 1.2.20-4.el6 basexmlsec1-openssl.i686 1.2.20-4.el6 base......[root@localhost yum.repos.d]# vim CentOS-Media.repo **新建并编辑yum仓库配置文件**entOS-Media.repo## This repo can be used with mounted DVD media, verify the mount point for# CentOS-7. You can use this repo and yum to install items directly off the# DVD ISO that we release.## To use this repo, put in your DVD and use it with the other repos too:# yum --enablerepo=c7-media [command]# # or for ONLY the media repo, do this:## yum --disablerepo=\* --enablerepo=c7-media [command][c7-media] name=CentOS-$releasever - Mediabaseurl=file:///media/CentOS/ file:///media/cdrom/ file:///media/cdrecorder/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7改成[local_cdrom] **路径名字**name=cd **名字**baseurl=file:///mnt **绝对路径地方**gpgcheck=0 **不检测**enabled=1 **生效**#gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 **不要** ~ ~ ~ ~ ~ -- 插入 -- ：wq 保存并退出# yum clean all **清除缓存**# yum list **再次查看yum仓库，已经成为本地yum仓库**perl-SNMP_Session.noarch 1.13-5.el7 local_cdromperl-Socket6.x86_64 0.23-15.el7 local_cdromperl-String-ShellQuote.noarch 1.04-10.el7 local_cdromperl-Sub-Install.noarch 0.926-6.el7 local_cdromperl-Sys-CPU.x86_64 0.54-4.el7 local_cdromperl-Sys-Guestfs.x86_64 1:1.32.7-3.el7.centos local_cdromperl-Sys-MemInfo.x86_64 0.91-7.el7 local_cdromperl-Sys-Syslog.x86_64 0.33-3.el7 local_cdromperl-Sys-Virt.x86_64 2.0.0-1.el7 local_cdromperl-Term-UI.noarch 0.36-2.el7 local_cdrom...... 扩展1. yum保留已经安装过的包可以设置使yum保留已经下载的rpm包，供以后升级或重新安装时使用。 1234567修改/etc/yum.conf即可：[main]cachedir=/home/soft1/yumcachekeepcache=1debuglevel=2chchedir是放置下载的包的地方，可以修改为自己想放置的位置。keepcache为1时表示保存已经下载的rpm包。 2. 搭建局域网yum源12345678910111213141516171819202122232425262728293031323334353637383940414243441、搭建Apache服务器或ftp服务器yum安装或二进制包安装2、准备RPM包把CentOS的DVD1和DVD2.iso都下载下来，把DVD1.iso里的所有内容解压出来，放到/var/www/html/centos-6目录下，然后把DVD2.iso解压出来的Packages目录下的rpm包复制到/var/html/centos-6/Packages目录下，这样/var/html/centos-6/Packages里面就有了6000多个rpm包。3、创建yum仓库准备createrepo：yum -y install createrepo创建repository：createrepo /var/www/html/centos-6/创建完成之后，会在/var/www/html/centos-6/repodata下生成一些文件。4、使用软件源在其他centos机器上试试软件源能不能用。首先修改机器上软件源配置文件：# cd /etc/yum.repos.d/# mkdir bk# mv *.repo bk/# cp bk/CentOS-Base.repo ./# vi CentOS-Base.repoCentOS-Base.repo文件修改之后如下：[base]name=CentOS-$releasever - Basebaseurl=http://*.*.*.*/centos-6/gpgcheck=1(改成0下面那行就不用设置了)gpgkey=http:///*.*.*.*/centos-6/RPM-GPG-KEY-CentOS-6enabled=1#released updates #[updates]#name=CentOS-$releasever - Updates#baseurl=http:///*.*.*.*/centos-6/#gpgcheck=1#gpgkey=http:///*.*.*.*/centos-6/RPM-GPG-KEY-CentOS-6#enabled = 1保存之后，就可以使用局域网的软件源了：# yum update]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>RPM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下压缩打包工具02-zip、tar]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F6.5%20-%206.7%20linux%E4%B8%8B%E5%8E%8B%E7%BC%A9%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B702-zip%E3%80%81tar%2F</url>
    <content type="text"><![CDATA[6.5 zip压缩工具 Windows 的zip文件传送到Linux时，是可以通过Linux的zip工具进行解压缩。压缩文件或目录时，源文件不会消失 zip文件不可以直接查看文件的内容。 在Linux（CentOS）中，安装zip压缩工具命令1yum install zip unzip 1. zip压缩1234压缩文件zip 123.txt.zip 123.txt压缩目录zip -r 345.zip 345/ /tmp/ 2. zip解压缩123unzip 1.txt.zip \\压缩、解压缩源文件均不删除unzip 123.zip -d /root/456/ \\-d：解压到指定目录unzip -l 123.zip \\查看123目录内的列表 6.6 tar打包 tar打包不会改变文件的大小。即打包不压缩 1. tar命令1234567891011121314tar-z: 同时用gzip压缩-j: 同时用bzip2压缩-J: 同时用xz压缩-x: 解包或者解压缩-t: 查看tar包里面的文件-c: 建立一个tar包或者压缩文件-v: 可视化-f: 后面跟文件名，压缩时跟 “-f 文件名”，意思是压缩后的文件名为filename， 解压时跟 “-f 文件名”，意思是解压后的文件名为filename 请注意，多个参数组合的情况下，带有-f，请把-f写到最后面-p: 使用源文件的属性，压缩前什么属性，压缩后就是什么属性。 （不常用）-P: 可以使用绝对路径。 （不常用）--exclude 2. tar运用123456tar -cvf 123.tar 123tar -cvf zhouqun.tar 1.txt 123tar -xvf zhouqun.tar tar -tf zhouqun.tar tar -cvf zhouqun.tar –exclude 1.txt –exclude 2 123tar -vcf zhouqun.tar –exclude 22 “*.txt” 123 6.7 打包并压缩12345678910111213141516171819202122232425打包、解包 tar -zcvf 1.tar.gz 111 222 打包gzip tar -zxvf 1.tar.gz 解包gziptar -jcvf 1.tar.bz2 111 222 打包bzip2 tar -jxvf 1.tar.zh2 解包bzip2 tar -Jcvf 1.tar.xz 111 222 打包xz tar -Jxvf 1.tar.xz 解包xz查看包tar -tf 1.tar.gztar -tf 1.tar.bz2tar -tJf 1.tar.xz过滤tar --exclude 456 --exclude 5.txt -zcvf 3.tar.gz 111 222打包和压缩111，222目录到3.tar.gz 但是排除111目录内的456子目录和5.txt---111目录结构如下111 234 456 5.txt zhouqunic]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>zip</tag>
        <tag>unzip</tag>
        <tag>tar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下压缩打包工具01-bzip2、xz、gzip]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F6.1%20-%206.4%20linux%E4%B8%8B%E5%8E%8B%E7%BC%A9%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B701-bzip2%E3%80%81xz%E3%80%81gzip%2F</url>
    <content type="text"><![CDATA[6.1 压缩打包介绍1. windows压缩工具.rar .zip .7z 2. linux压缩工具.zip, .gz, .bz2, .xz,.tar.gz,tar.bz2,.tar.xz 6.2 gzip压缩工具123456gzip [-d#] filename 其中#为1-9的数字gzip压缩有10个级别，默认是gzip -6 级别的，1是压缩最少，速度最快，10是压缩最大，速度最慢压缩的文件后缀位.gz解压缩位gzip -dgzip不支持压缩目录zcat 直接查看.gz压缩包的内容 1. 将etc目录中含有conf文件名的文件列并追加都1.txt1[root@localhost]# find /etc/ -type f -name &quot;*conf&quot; -exec cat &#123;&#125; &gt;&gt;1.txt \ 2. 压缩文件 文件压缩之后再解压，就会将原文件中虚的空间挤掉。 12345[root@localhost]# gzip 1.txt[root@localhost]# ls1.txt.gz[root@localhost]# du -sh 1.txt.gz596K 1.txt.gz 3. 解压文件： 1.txt压缩前是4M，压缩再解压变成了2.3M，文件内容的行数是不变的。 压缩等级1~9，默认是6级，1级别压缩后，压缩文件稍大，9级压缩文件文件最小。 123[root@localhost]# gzip -d 1.txt.gz[root@localhost]# du -sh 1.txt2.3M 1.txt 4. 其他 使用1级别压缩 1[root@localhost]# gzip -1 1.txt 其他压缩方法 1[root@localhost]# gunzip 1.txt.gz 解压并查看内容 1[root@localhost]# zcat 1.txt.gz 压缩文件到指定目录并且原文件不消失 gzip不能压缩目录 1[root@localhost]# gzip -c 1.txt &gt; /tmp/1.txt.gz 6.3 bzip2压缩工具1234567bzip2 [-d] [-d] filename不支持压缩目录压缩级别10 默认压缩级别是9-d 解压缩bzcat 可以直接查看.bz2压缩包的内容[root@localhost]# bzcat 1.txt.bz2 1. 压缩文件1234[root@localhost tmp]# bzip2 1.txt压缩到指定目录下：[root@localhost]# bzip2 -c 1.txt &gt; /tmp/1.txt.bz2 2. 解压123[root@localhost]# bzip2 -d 1.txt.bz2或者[root@localhost]# bunzip2 1.txt.bz2 6.4 xz压缩工具1234567（1）xz压缩工具与gzip,bzip2的压缩方式类似，只是压缩算法不一样，喜欢用哪个，就用哪个（2）xz压缩文件时，源文件会消失（3）通过xzcat可以看xz文件（4）xz也是与bzip2一样有压缩级别的（5）如果想解压到指定目录可以用-c选项（6）xz不能压缩目录(7) 默认压缩级别为9, 压缩最狠的是xz，其次是bzip2，最不狠的是gzip 1. 压缩文件12345[root@localhost]# xz 2.txt压缩文件到指定目录[root@localhost]# xz -c 2.txt &gt;/tmp/d6z/2.txt.xz 2. 解压1234567[root@localhost]# xz -d 2.txt.xz或者[root@localhost]# unxz 2.txt.xz解压文件并指定目录：[root@localhost]# xz -d -c /tmp/d6z/2.txt.xz &gt; ./4.txt 3. 查看压缩文件内容1[root@localhost]# xzcat /tmp/2.txt.xz]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>bzip2</tag>
        <tag>xz</tag>
        <tag>gzip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim入门02]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F5.5%20-%205.7%20Vim%E5%85%A5%E9%97%A802%2F</url>
    <content type="text"><![CDATA[5.5 进入编辑模式1. 进入vim编辑模式vim命令后，输入 i 键，进入编辑模式（i, I, a, A, o,O,r,R都可以），按 Esc 键退出。 2. 输入不同字母，进入编辑模式后的情况不同123456（1）按 i 键，此时光标在当前位置，并进入编辑模式（2）按 I 键，此时光标移动到当前行的行首，并进入编辑模式（3）按 a 键，此时光标向后移动一个位置，并进入编辑模式（4）按 A 键，此时光标移动到当前行的末尾一个位置，并进入编辑模式（5）按 o 键，此时光标移动到当前行的下一新插的行的行首，并进入编辑模式（6）按 O 键，此时光标移动到当前行的上一新插的行的行首，并进入编辑模式 5.6 vim命令模式1. 如何进图vim命令行模式在一般模式，输入 : 或者 / 就可以进入命令模式，在改模式下，可以搜索，保存，替换，退出，显示行号等等操作。 2. 命令 命令模式下查找和替换 命令 结果 /word 向光标之后寻找一个字符串位word，按n向后继续 ?word 向光标之前寻找一个字符串位word，按n向后继续 :n1,n2s/word1/word2/g 在n1,n2行之间查找word1并替换位word2，不加g则只替换每行的第一个word1 :1,$s/word1/word2/g 替换文档中所有的word1位word2，不加g只替换每行的第一个 命令模式其他功能 命令 结果 :w 保存文本 :q 退出vim :w! 强制保存，root用户下即使文本只读也可以完成保存 :q！ 强制退出，所有改动不生效 :wq 保存并退出 : set nu 显示行号 : set nonu 不显示行号 :nohl 取消文档中的高亮 3. 示例12345678910111,100s/iptables/seLinux**把1到100行之间的iptables替换位seLinux，只替换每行的第一个iptables**1,$s/iptables/seLinux/g **把文件中所有的iptables替换位seLinux**%s/iptables/seLinux/g **把文件中所有的iptables替换位seLinux**解释： %=1,s%s/ \ /etc \ /init.d/ \ /bin/ \ ls **把文件中，所有的 /etc/init.d替换为 /bin/ls， 其中 \ 为退意符号，因为目录用的/和命令中的/有意义冲突，那么在目录中的/前面使用\符号，可以使冲突的意义去掉，只保留原来的意义。 5.7 vim实践123456789101112131415161718192021222324252627282930cp /etc/dnsmasq.conf /tmp/1.txt(1) 分别向下、向右、向左、向上移动6个字符（6j 6l 6h 6k）。(2) 分别向下、向上翻两页（分别按两次ctrl+f和ctrl+b）。(3) 把光标移动到第49行（49G）。(4) 把光标移动到行尾，再移动到行首（Shift+4, Shift+6）。(5) 移动到1.txt文件的最后一行（G）。(6) 移动到文件的首行（gg）。(7) 搜索文件中出现的“dnsmasq”，并数一下该字符串出现的次数（/dnsmsq 然后按n）。(8) 把从第1行到第10行出现的dnsmasq替换成dns（:1,10s/dnsmasq/dns/g）。(9) 还原上一步操作（u）。(10) 把整个文件中所有的etc替换成cte（:1,$s/etc/cte/g）。(11) 把光标移动到第25行，删除字符串 “ly”（25G 然后按j向右移动光标找到&quot;ly&quot;，按v选中，然后按x）。(12) 还原上一步操作（u）。(13) 删除第50行（50G dd）。(14) 还原上一步操作（u）。(15) 删除第37-42行的所有内容（37G 6dd）。(16) 还原上一步操作（u）。(17) 复制第48行的内容并粘贴到第52行下面（48G yy 52G p）。(18) 还原上一步操作（u）。(19) 复制第37-42行的内容并粘贴到第44行上面（37G 6yy 44G P）。(20) 还原上一步操作（按u）。(21) 把第37-42行的内容移动到第19行下面（37G 6dd 19G p）。(22) 还原上一步操作（按u）。(23) 把光标移动到首行，把第1行内容改为“#!/bin/bash”（先按gg，把光标定位到第1行，然后按字母A，进入编辑模式，同时&gt;光标到行末尾，进行修改操作，完成后按ESC）。(24) 在第1行下面插入新的一行，并输入“# Hello!”（按o进入编辑模式，同时光标向下另起一行，输入“# Hello!”）。(25) 保存文档并退出（按Esc键，输入“:wq”）。 练习题123456789101112131415（1）vim下:/keyword,可以查找全文的关键字。假设我只想在1-50行之间查找这个关键字，要怎么写？ （感觉应该是没有这种写法的吧）aming没有。870566512**可以通过替换的方式实现**:1,10s/111/111/g（2）用什么方法可以在vim里面搜索关键词？ 错误答案 ABA 一般模式下，直接输入/wordB 一般模式下，直接输入?wordC 一般模式下，直接输入:wordD 一般模式下，直接输入:/word正确答案: A,B,D 拓展1234567891011121314151617vim的特殊用法 http://www.apelearn.com/bbs/thread-9334-1-1.htmlvim常用快捷键总结http://www.apelearn.com/bbs/thread-407-1-1.htmlvim快速删除一段字符http://www.apelearn.com/bbs/thread-842-1-1.htmlvim乱码 http://www.apelearn.com/bbs/thread-6753-1-1.html小键盘问题 http://www.apelearn.com/bbs/thread-7215-1-1.htmlvim加密 http://www.apelearn.com/bbs/thread-7750-1-1.html]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim命令入门01]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F5.1%20-%205.4%20Vim%E5%91%BD%E4%BB%A4%E5%85%A5%E9%97%A801%2F</url>
    <content type="text"><![CDATA[5.1 vim介绍vi 和 vim 的区别vi 是早期版本，vim是后来改进版本。直观的是，vim编辑文件可以显示不同颜色，一般电脑都有vi，而vim有的没有，需要安装。 12yum install vim-enhanced安装vim包的命令 2. vim和vi的一些用法12345vim 1.txtvim /etc/init.d/iptablesvi !$ \\在这里，!$=/etc/init.d/iptables.表示上一条命令中，如果有空格隔开的命令，那么!$可以代指它。vim +10 !$ \\打开/etc/init.d/iptables文件的第十行。 5.2 vim颜色显示和移动光标1. vim颜色显示配置文件12345678vimrc 的存放位置： 系统 vimrc 文件: &quot;$VIM/vimrc&quot; 用户 vimrc 文件: &quot;$HOME/.vimrc&quot; 用户 exrc 文件: &quot;$HOME/.exrc&quot; 系统 gvimrc 文件: &quot;$VIM/gvimrc&quot; 用户 gvimrc 文件: &quot;$HOME/.gvimrc&quot; 系统菜单文件: &quot;$VIMRUNTIME/menu.vim&quot; $VIM 预设值: &quot;/usr/share/vim&quot; 2. vim的3种模式 一般模式 光标移动 复制 粘贴 剪切 编辑模式 输入字母 命令模式 使用命令 5.3 vim一般模式下移动光标1234567891011j 光标向下k 光标向上h 光标左移l 光标右移Ctrl+b 或者 Pageup 页面内容上翻一页Ctrl+f 或者 Pagedown 页面内容下翻一页gg 光标移到首行G 光标移到尾行0或者shift+6 光标移动到本行行首shift+4 光标移动到本行行尾nG（n是任意一个数字） 光标移动到第n行 5.4 vim一般模式下复制、剪切和粘贴 命令 结果 x 向后删除一个字符 X 向前删除一个字符 dd 剪切光标所在的那一行 ndd 剪切光标所在的那一行以及向下行一起的n行 p 粘贴到光标所在行的下一行 P 粘贴到光标所在行的上一行 u 还原上一步操作（最多50步） Ctrl+r 反撤销 yy 复制光标所在行 nyy 复制光标所在的那一行以及向下行一起的n行 v 按v后移动光标会选中指定字符，然后可以复制、粘贴等 练习题1. 出错题目123456781. vim一般模式下，如何快速删除某些字符串（这些字符串并非为一整行）？ (错误答案 B)A 先按v（小写）进入可选模式，然后移动光标选择要删除的字符串，选好后按xB 先按v进入可选模式，然后移动光标选择要删除的字符串，选好后按ddC 先按V（大写）进入可选模式，然后移动光标选择要删除的字符串，选好后按xD 先按V进入可选模式，然后移动光标选择要删除的字符串，选好后按dd正确答案: A因为dd是指删除/剪切一整行，而选中的字符删除需要用x/X。 2. 实操练习题123456789101112131415161718192021222324252627282930cp /etc/dnsmasq.conf /tmp/1.txt(1) 分别向下、向右、向左、向上移动6个字符（6j 6l 6h 6k）。(2) 分别向下、向上翻两页（分别按两次ctrl+f和ctrl+b）。(3) 把光标移动到第49行（49G）。(4) 把光标移动到行尾，再移动到行首（Shift+4, Shift+6）。(5) 移动到1.txt文件的最后一行（G）。(6) 移动到文件的首行（gg）。(7) 搜索文件中出现的“dnsmasq”，并数一下该字符串出现的次数（/dnsmsq 然后按n）。(8) 把从第1行到第10行出现的dnsmasq替换成dns（:1,10s/dnsmasq/dns/g）。(9) 还原上一步操作（u）。(10) 把整个文件中所有的etc替换成cte（:1,$s/etc/cte/g）。(11) 把光标移动到第25行，删除字符串 “ly”（25G 然后按j向右移动光标找到&quot;ly&quot;，按v选中，然后按x）。(12) 还原上一步操作（u）。(13) 删除第50行（50G dd）。(14) 还原上一步操作（u）。(15) 删除第37-42行的所有内容（37G 6dd）。(16) 还原上一步操作（u）。(17) 复制第48行的内容并粘贴到第52行下面（48G yy 52G p）。(18) 还原上一步操作（u）。(19) 复制第37-42行的内容并粘贴到第44行上面（37G 6yy 44G P）。(20) 还原上一步操作（按u）。(21) 把第37-42行的内容移动到第19行下面（37G 6dd 19G p）。(22) 还原上一步操作（按u）。(23) 把光标移动到首行，把第1行内容改为“#!/bin/bash”（先按gg，把光标定位到第1行，然后按字母A，进入编辑模式，同时&gt;光标到行末尾，进行修改操作，完成后按ESC）。(24) 在第1行下面插入新的一行，并输入“# Hello!”（按o进入编辑模式，同时光标向下另起一行，输入“# Hello!”）。(25) 保存文档并退出（按Esc键，输入“:wq”）。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVM学习]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F4.10%20-%204.13%20LVM%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[1. LVM简介 LVM是 Logical Volume Manager(逻辑卷管理)的简写，它由Heinz Mauelshagen在Linux 2.4内核上实现。LVM利用Linux内核的device-mapper来实现存储系统的虚拟化（系统分区独立于底层硬件）。 通过LVM，你可以实现存储空间的抽象化并在上面建立虚拟分区（virtual partitions），可以更简便地扩大和缩小分区，可以增删分区时无需担心某个硬盘上没有足够的连续空间，而不会被卷入使用中的磁盘的问题（并且想知道内核是使用旧的还是新的分区表），而不必将其他分区移开。 LVM是用来方便管理的，不会提供额外的数据安全保证。 2. LVM的基本组 物理卷Physical volume - (PV)：可以在上面建立卷组的媒介，可以是硬盘分区，也可以是硬盘本身或者回环文件（loopback file）。 物理卷包括一个特殊的header，其余部分被切割为一块块物理区域（physical extents）。 卷组Volume group (VG)：将一组物理卷收集为一个管理单元。 逻辑卷Logical volume (LV)：虚拟分区，由物理区域（physical extents）组成。 物理区域Physical extent (PE)：硬盘可供指派给逻辑卷的最小单位（通常为4MB）。 物理存储介质（The physical media）：这里指系统的存储设备：硬盘，如：/dev/hda1、/dev/sda等等，是存储系统最低层的存储单元。 物理卷（physical volume）：物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备(如RAID)，是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数。 卷组（Volume Group）：LVM卷组类似于非LVM系统中的物理硬盘，其由物理卷组成。可以在卷组上创建一个或多个“LVM分区”（逻辑卷），LVM卷组由一个或多个物理卷组成。 逻辑卷（logical volume）：LVM的逻辑卷类似于非LVM系统中的硬盘分区，在逻辑卷之上可以建立文件系统(比如/home或者/usr等)。 PE（physical extent）：每一个物理卷被划分为称为PE(Physical Extents)的基本单元，具有唯一编号的PE是可以被LVM寻址的最小单元。PE的大小是可配置的，默认为4MB。 LE（logical extent）：逻辑卷也被划分为被称为LE(Logical Extents) 的可被寻址的基本单位。在同一个卷组中，LE的大小和PE是相同的，并且一一对应。 简单来说就是： PV:是物理的磁盘分区 VG:LVM中的物理的磁盘分区，也就是PV，必须加入VG，可以将VG理解为一个仓库或者是几个大的硬盘。 LV：也就是从VG中划分的逻辑分区 3. 使用LVM的基本步骤3.1 准备磁盘分区123456789101112131415-fdisk /dev/sdb-n 创建三个新分区，分别1G-t 改变分区类型为8e设备 Boot Start End Blocks Id System/dev/sdb1 2048 2099199 1048576 8e Linux LVM/dev/sdb2 2099200 4196351 1048576 8e Linux LVM/dev/sdb3 4196352 6293503 1048576 8e Linux LVM---partprobe 将磁盘分区表变化信息通知内核，请求操作系统重新加载分区表 3.2 准备物理卷123456789101112131415-pvcreate /dev/sdb1WARNING: xfs signature detected on /dev/sdb1 at -offset 0. Wipe it? [y/n]: y Wiping xfs signature on /dev/sdb1. Physical volume &quot;/dev/sdb1&quot; successfully created.-pvcreate /dev/sdb2 Physical volume &quot;/dev/sdb2&quot; successfully created.-pvcreate /dev/sdb3 Physical volume &quot;/dev/sdb3&quot; successfully created.---pvdisplay 列出当前的物理卷pvs 列出当前的物理卷(更直观)pvremove /dev/sdb3 删除物理卷yun -y install lvm 安装lvm包 3.3 准备卷组123456789-vgcreate vg1 /dev/sdb1 /dev/sdb2 Volume group &quot;vg1&quot; successfully created-vgs VG #PV #LV #SN Attr VSize VFree cl 1 2 0 wz--n- 19.00g 0 vg1 2 0 0 wz--n- 1.99g 1.99gvgdisplay列出卷组 / vgs 列出卷组（更直观）vgrmove vg1 删除物理卷 3.4 创建逻辑卷123456789101112131415161718192021222324252627282930313233343536373839404142-lvcreate -L 100M -n lv1 vg1Logical volume &quot;lv1&quot; created.-lva 列出逻辑卷 LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- 17.00g swap cl -wi-ao---- 2.00g lv1 vg1 -wi-a----- 100.00m -mkfs.xfs /dev/vg1/lv1 格式化,再挂载(实际上，格式化为ext4更好，后面会讲到)meta-data=/dev/vg1/lv1 isize=512 agcount=4, agsize=6400 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0data = bsize=4096 blocks=25600, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0 ftype=1log =internal log bsize=4096 blocks=855, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0-mount /dev/vg1/lv1 /mnt/ 挂载逻辑卷lv1到mnt目录下-ls -l /dev/vg1/lv1lrwxrwxrwx 1 root root 7 6月 19 22:07 /dev/vg1/lv1 -&gt; ../dm-2-df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/cl-root 17G 4.5G 13G 27% /devtmpfs 906M 0 906M 0% /devtmpfs 916M 84K 916M 1% /dev/shmtmpfs 916M 9.0M 907M 1% /runtmpfs 916M 0 916M 0% /sys/fs/cgroup/dev/sda1 1014M 139M 876M 14% /boottmpfs 184M 16K 184M 1% /run/user/42tmpfs 184M 0 184M 0% /run/user/0/dev/mapper/vg1-lv1 97M 5.2M 92M 6% /mnt写开机启动挂载vi /etc/fstab---lvremove /dev/vg1/lv1 删除逻辑卷lvdisplay列出逻辑卷 / lvs 列出逻辑卷（更直观） 3.5 扩容逻辑卷针对ext2,3,4格式 123456-umount /mnt/ 规范操作是先把挂载点卸掉-lvresize -L 300M /dev/vg1/lv1 重新设置卷大小-e2fsck -f /dev/vg1/lv1 检查磁盘错误 (ext执行)-resize2fs /dev/vg1/lv1 更新逻辑卷信息，识别新的大小(ext执行) xfs_growfs /dev/vg1/lv1 xfs文件系统需要执行 针对xfs格式 12-lvresize -L 300M /dev/vg1/lv1 重新设置卷大小-xfs_growfs /dev/vg1/lv1 xfs文件系统需要执行 3.6 缩减逻辑卷（xfs不支持）1234-umount /mnt/ 卸载挂载点-e2fsck -f /dev/vg1/lv1 检查磁盘错误（ext）-resize2fs /dev/vg1/lv1 100M 更新逻辑卷信息（ext）-lvresize -L 100M /dev/vg1/lv1 重新设置卷大小 3.7 扩展卷组12345678910-fdisk /dev/sdb 新增/dev/sdb5(逻辑分区8e) 1G-n-p-5+1G-t-8e-pvcreate /dev/sdb5 设置物理卷-vgextend vg1 /dev/sdb5 把该物理卷扩展到卷组-lvresize -L 100M /dev/vg1/lv1 重新设置逻辑卷大小 4. 磁盘故障小案例当我们配置完LVM，并将lvm分区挂载文件写入到/etc/fstab后重启 （这种问题在生产环境有可能遇到），开机会遇到如下问题 ==解决方案== 输入root密码 进入系统，vim /etc/fstab dd 刚刚写入文件的那一行分区挂载命令 保存并退出 reboot重启]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>LVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘格式化与挂载]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F4.5%20-%204.9%20%E7%A3%81%E7%9B%98%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%B8%8E%E6%8C%82%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[4.5/4.6 磁盘格式化1. mke2fs命令被用于创建磁盘分区上文件系统（格式化） 123456789101112mke2fs -t ext4 -b 2048 -m 1 -L yule /dev/sdb1-t 指定磁盘格式 mke2fs目前不支持xfs格式-b 指定块block大小，默认值是4K-m 指定给root保留区块的比例，默认值是5%-L 设定磁盘分区的卷标mke2fs -i 8192 -t ext4 /dev/sdb1-i 指定&quot;字节/inode&quot;的比例，最低至少一个块对应一个inode。默认大概是4个块对应一个inode，4个块=16K=16,384b；那么默认的&quot;字节/inode&quot;的比例是16384；将数字改小的话，inode数量就会变多，相反，改大的话，inode数量就会变少，最小值为4096。 2. 格式化分区的一些注意事项 新添加的磁盘分好区以后，不能直接使用，得先格式化 主分区和逻辑分区可以被格式化，扩展分区不能格式化。只能格式化扩展下面的逻辑分区。 查看Linux系统支持的磁盘文件系统格式的配置文件cat /etc/filesystems 查看一个分区的文件系统是什么mount后，查看dev/开头的文件全名就可以知道了，如 1/dev/mapper/cl-root on / type xfs (rw,relatime,attr2,inode64,noquota) 3. 如何格式化新的磁盘分区3.1. 创建新的分区123456fdisk /dev/sdbnp+3Gwfdisk -l 3.2. 格式化分区（2种方法） 用mkfs命令 1234mkfs -t ext4 /dev/sdb5将磁盘分区sdb5格式化为ext4格式分区，默认会给root用户预留原有的2%的空间在centos7中，如果想把分区格式化位xfs格式，只有使用mkfs.xfs或mkfs -t /dev/sdb5mke2fs默认不支持格式化为xfs格式 用mke2fs命令 (mke2fs是mkfs命令的进化版本，功能更加丰富) 12mke2fs -t ext4 -b 2048 -m 1 -L game /dev/sdb1将分区sdb1格式化为ext4文件系统，块大小设为2048b，预留1%空间其中给root用户，并将磁盘命名位 game 3.3 mkfs补充 mkfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.ext4dev mkfs.msdos mkfs.vfat mkfs.xfs 这里面mkfs -t ext4 == mkfs.ext4mkfs -t ext3 == mkfs.ext3所以，直接可以用 mkfs.ext4命令 来代替 mkfs -t ext4 4. blkid命令主要用来对系统的块设备（包括交换分区）所使用的文件系统类型、LABEL、UUID等信息进行查询。 12345678910111213[root@zhouqunic-01 ~]# blkid /dev/sdb1/dev/sdb1: UUID=&quot;95ed0ccb-c6ff-4b65-9921-a68dd5d7035b&quot; TYPE=&quot;xfs&quot;可以用来查看为挂载分区的文件类型[root@zhouqunic-01 ~]# blkid/dev/sdb1: UUID=&quot;95ed0ccb-c6ff-4b65-9921-a68dd5d7035b&quot; TYPE=&quot;xfs&quot; /dev/sdb3: UUID=&quot;a17dcca1-6da1-42f1-b955-caacc22bb1fc&quot; TYPE=&quot;ext4&quot; /dev/sda1: UUID=&quot;0ae79bcd-e732-46fc-9213-6118c491a714&quot; TYPE=&quot;xfs&quot; /dev/sda2: UUID=&quot;AwDLCG-5vsY-OMmL-XeKE-RNEr-y12K-styMJV&quot; TYPE=&quot;LVM2_member&quot; /dev/sr0: UUID=&quot;2016-12-05-13-55-45-00&quot; LABEL=&quot;CentOS 7 x86_64&quot; TYPE=&quot;iso9660&quot; PTTYPE=&quot;dos&quot; /dev/mapper/cl-root: UUID=&quot;120c5b93-2bee-4af8-9868-140e9de6f281&quot; TYPE=&quot;xfs&quot; /dev/mapper/cl-swap: UUID=&quot;49d49d46-b6c2-4a1c-925a-a8e68bdc79b2&quot; TYPE=&quot;swap&quot; 列出当前系统中所有文件系统的类型 4.7/4.8 磁盘挂载1. 挂载1.1 路径 挂载123mount /dev/sdb5 /mnt/ /mnt/挂载点 df -T 查看磁盘类型df -h 查看磁盘信息 不管有没有分区，都可以格式化，磁盘分完区以后，需要挂载 才能写文件进去 一个挂载点只能给一个分区进行服务， 假设有两个分区放在一个挂载点下，只能服务第二个分区,第二个会遮盖第一个，但是卸载掉第二个，第一个分区的数据就会出现 1.2 label卷标/UUID 挂载 通过blkid来获得要挂载分区的UUID1234mount LABEL=aming /home/aming/123/mount UUID=&quot;95ed0ccb-c6ff-4b65-9921-a68dd5d7035b&quot; /mnt/umount /mnt/ 卸载 或者 umount /dev/dev1/umount -l 直接卸载(无需退出挂载点) 2. mount命令用于加载文件系统到指定的加载点 1234567mount [-t vfstype(ext4,ntfs...)] [-o options(rw,ro...)] device dir-l 无需退出卸出挂载 remount 重新挂载mount -o remount,rw /dev/foo /dir 重新挂载 umount（卸载）磁盘分区 3. /etc/fstab配置文件fstab包含了开机需要挂载的设备，相应的挂载点，以及属性等。 123456789101112131415[root@zhouqunic-01 ~]# cat /etc/fstab**6列分别表示：设备号，挂载点，分区格式，挂载选项，是否备份，设置优先级，（1，2要检测，1级别更高，0 不检测）**## /etc/fstab# Created by anaconda on Fri May 26 06:46:23 2017## Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/cl-root / xfs defaults 0 0UUID=0ae79bcd-e732-46fc-9213-6118c491a714 /boot xfs defaults 0 0/dev/mapper/cl-swap swap swap defaults 0 0把分区挂载到挂载点 添加进去mount UUID=&quot;95ed0ccb-c6ff-4b65-9921-a68dd5d7035b&quot; /mnt/ xfs defaults 0 0 4.9 手动增加swap空间当某一个服务就是需要比较大的swap空间的时候，我们可以手动增加swap空间 1234567891011121314151617181920首先弄一个模拟磁盘，在服务器的文件系统里模拟一个100M 的磁盘dd if=/dev/zero of=/tmp/newdisk bs=1M count=100&gt; dd 用于操作磁盘，可以写可以读 &gt; if 指定从哪里去读 &gt; /dev/zero 是Linux系统里面的一个造零器，可以产生无数的&quot;0&quot; &gt; of 将/dev/zero 造出来的&quot;0&quot;，写到哪里去 &gt; bs 指定块的大小 &gt; count 计数，总共多少个块 创建虚拟磁盘以后，需要进行格式化 mkswap -f /tmp/newdisk格式化以后进行挂载swapon /tmp/newdisk执行命令之后会提示“权限不安全”。为了安全起见，建议使用0600的权限chmod 0600 /tmp/newdisk当使用完毕以后，卸载swap挂载swapoff /tmp/newdisk free -m 可以查看 swap 的使用情况 拓展：LVM 学习 LVM(Logical Volume Manager)逻辑卷管理，是一种将一个或多个硬盘的分区在逻辑上集合，相当于一个大硬盘来使用，当硬盘的空间不够使用的时候，可以继续将其它的硬盘的分区加入其中，这样可以事项一种磁盘空间的动态管理，相对于普通的磁盘分区有很大的灵活性，使用普通的磁盘分区，当一个磁盘的分区空间不够使用的时候，可能就会带来很大的麻烦。使用LVM在一定程度上就可以解决普通磁盘分区带来的问题。 1234567891011121314151617181920212223242526创建分区--更改类型t(8e)---创建物理卷--创建卷组 pvcreate /dev/sdb1 以此类推创建见三个物理卷 pvdisplay 查看LVM物理卷=pvs vgcreate vg1 /dev/sdb(物理卷 vgcdisplay查看VM物理卷组=vgs lvcreate -L 100M(指定大小） -n lv1(lvm）vg1(卷组） ##以此类推做LV2.LV3 mkfs.ext4 /dev/vh1/lv1 格式化lv1 mount /dev/vg1/lv1 /mnt 挂载到/mnt扩容逻辑卷 lvresize -L 300M /dev/vg1/lv1 重新设置卷大小 e2fsck -f /dev/vg1/lv1 检查磁盘错误(ext4执行） resize2fs /dev/vg1/lv1 更新逻辑卷信息（ext4执行） xfs_growfs /dev/vg1/lv1 xfs文件系统需要执行缩减逻辑卷（xfs不支持） 先卸载umount e2fsck -f /dev/vg1/lv1 检查磁盘错误(ext) resize2fs /dev/vg1/lv1 100M 更新逻辑卷信息（ext) lvresize -L 100M /dev/vg1/lv1 更新设置卷大小 扩展卷组 fdisk /dev/sdb 新增/dev/sdb5(辑分区8e) 2G pvcreate /dev/sdb5 vgextend vg1 /dev/sdb5 创建物理卷 lvresize -L 100M /dev/vg1/lv1 重新设置卷大小]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>LVM</tag>
        <tag>blkid</tag>
        <tag>fstab</tag>
        <tag>mke2fs</tag>
        <tag>mkfs</tag>
        <tag>mount</tag>
        <tag>UUID</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘管理]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F4.1-4.4%20%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[4.1 df命令1. df命令1234567891011121314151617df \\可以查看到系统一共有几个分区，但swap（虚拟交换分区，内存）不会显示在此。df -h \\自动变换单位*文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/cl-root 17G 4.5G 13G 27% /devtmpfs 906M 0 906M 0% /devtmpfs 916M 100K 916M 1% /dev/shmtmpfs 916M 9.0M 907M 1% /runtmpfs 916M 0 916M 0% /sys/fs/cgroup/dev/sda1 1014M 139M 876M 14% /boottmpfs 184M 52K 184M 1% /run/user/0df -k \\以K为单位df -m \\以M为单位df -i \\查看到系统分区下的inode情况df -T \\会看到分区文件系统类型free \\可以查看到swap状态* 2. @重点 每次登录服务器，第一件事 用df -h 看磁盘空间满了没 用df -i 看磁盘inode空间占满没有最好，用shell监控起来。 4.2 du命令1. du命令123456du \\查看目录或者文件的占用磁盘空间大小，默认以K为单位du -a \\显示所有下面的文件和目录，不加的话，不会显示下面目录内的文件du -b \\以b为单位du -m \\以M为单位du -h \\自动匹配合适的单位du -s \\只显示总和 2. 常用的 du -shdu -sh 和 ls -sh 的区别 (涉及 块block 的概念) du -sh是查询文件占用磁盘空间的大小 ls -sh 是文件实际的大小 4.3/4.4 磁盘分区1. fdisk命令1234567891011121314151617181920212223242526fdisk -l查看所有磁盘的分区状况fdisk /dev/sdb \\给小于2T的硬盘分区p 打印分区表n 新增一个分区w 保存q 退出d 删除分区关于分区- 主分区：一块物理硬盘上可以被独立使用的一部分，一个硬盘最多可以有4个主分区。- 扩展分区：为了突破一个物理硬盘只能有4个分区的限制，引入了扩展分区。扩展分区和主分区的地位相当，但是扩展分区本身不能被直接使用，然而可以被继续划分成多个逻辑分区。- 逻辑分区：逻辑分区可以有任意多个，但是不能独立存在，多个连续的逻辑分区可做为一个扩展分区。一个硬盘只能有一个扩展分区。 e扩展分区 逻辑分区是从扩展分区分出来的 p主分区 p+e不大于4- 关于分区号1-4是主分区和扩展分区，5和以后是逻辑分区- 主分区可以分零个- 扩展分区只能分一个- 逻辑分区的序列号一定从5开始，而主分区和扩展分区随意1-4**parted命令 是专门给大于2T的硬盘分区的** 拓展parted分区GPT[http://ask.apelearn.com/question/7243]fdisk分区工具，它的分区格式为MBR，特点是，最多分4个主分区，磁盘大小不能超过2T。而GPT分区格式，突破了这些限制，它没有主分区、扩展分区、逻辑分区之分，在一块磁盘上最多可以分128个分区出来，支持大于2T的分区，最大卷可达18EB。 相信，随着存储级别的升级，将来的分区格式逐渐会淘汰MBR，而GPT成为主流。]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>df</tag>
        <tag>du</tag>
        <tag>fdisk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[su和sudo用户切换]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F3.7%20-3.9%20su%E5%92%8Csudo%E7%94%A8%E6%88%B7%E5%88%87%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[3.7 su命令su 命令就是切换用户的工具 1. su 命令的用法su+ [参数] [用户名] -；-l 登录并改变到所切换的用户环境 -c 执行一个命令，然后退出所切换到的用户环境 2. su 命令的范例su 在不加任何参数，默认为切换到root用户，但没有转到root用户家目录下，也就是说这时虽然是切换为root用户了，但并没有改变root登录环境；用户默认的登录环境，可以在/etc/passwd 中查得到，包括家目录，SHELL定义等 3.8 sudo命令1. sudo的使用范围sudo 执行命令的流程是当前用户切换到root（或其它指定切换到的用户），然后以root（或其它指定的切换到的用户）身份执行命令，执行完成后，直接退回到当前用户；而这些的前提是要通过sudo的配置文件/etc/sudoers来进行授权；但是不直接vi编辑，因为系统不能识别语法错误，所以我们使用visudo命令。为了更好的审计各个用户。 2. sudo的配置文件sudo的配置文件/etc/sudoers，但是不直接vi编辑，我们使用使用visudo命令（需要root权限才能使用），因为系统可以通过visudo命令来识别修改后配置文件的语法错误。 为什么需要使用sodo而不直接使用root直接登录了？是为了更好的审计各个用户的使用历史，最大限度的规范行为和杜绝二次发生。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118[root@zhouqunic-01 ~]# visudo## Sudoers allows particular users to run various commands as ## the root user, without needing the root password. ## 该文件允许特定用户像root用户一样使用各种各样的命令，而不需要root用户的密码 ## ## Examples are provided at the bottom of the file for collections ## of related commands, which can then be delegated out to particular ## users or groups. ## 在文件的底部提供了很多相关命令的示例以供选择，这些示例都可以被特定用户或 ## 用户组所使用 ## ## This file must be edited with the &apos;visudo&apos; command. ## 该文件必须使用&quot;visudo&quot;命令编辑 ## Host Aliases ## Groups of machines. You may prefer to use hostnames (perhaps using ## wildcards for entire domains) or IP addresses instead. ## 对于一组服务器，你可能会更喜欢使用主机名（可能是全域名的通配符）、或IP地址，这时可以配置主机别名 # Host_Alias FILESERVERS = fs1, fs2 # Host_Alias MAILSERVERS = smtp, smtp2 ## User Aliases ## These aren&apos;t often necessary, as you can use regular groups ## (ie, from files, LDAP, NIS, etc) in this file - just use %groupname ## rather than USERALIAS ## 这并不很常用，因为你可以通过使用组来代替一组用户的别名 # User_Alias ADMINS = jsmith, mikem ## Command Aliases ## These are groups of related commands... ## 指定一系列相互关联的命令（当然可以是一个）的别名，通过赋予该别名sudo权限， ## 可以通过sudo调用所有别名包含的命令，下面是一些示例 ## Networking 网络操作相关命令别名 # Cmnd_Alias NETWORKING = /sbin/route, /sbin/ifconfig, /bin/ping, /sbin/dhclient , /usr/bin/net, /sbin/iptables, /usr/bin/rfcomm, /usr/bin/wvdial, /sbin/iwconfig , /sbin/mii-tool ## Installation and management of software 软件安装管理相关命令别名 # Cmnd_Alias SOFTWARE = /bin/rpm, /usr/bin/up2date, /usr/bin/yum ## Services 服务相关命令别名 # Cmnd_Alias SERVICES = /sbin/service, /sbin/chkconfig ## Updating the locate database 本地数据库升级命令别名 # Cmnd_Alias LOCATE = /usr/bin/updatedb ## Storage 磁盘操作相关命令别名 # Cmnd_Alias STORAGE = /sbin/fdisk, /sbin/sfdisk, /sbin/parted, /sbin/partprobe , /bin/mount, /bin/umount ## Delegating permissions 代理权限相关命令别名 # Cmnd_Alias DELEGATING = /usr/sbin/visudo, /bin/chown, /bin/chmod, /bin/chgrp ## Processes 进程相关命令别名 # Cmnd_Alias PROCESSES = /bin/nice, /bin/kill, /usr/bin/kill, /usr/bin/killall ## Drivers 驱动命令别名 # Cmnd_Alias DRIVERS = /sbin/modprobe # Defaults specification # # Disable &quot;ssh hostname sudo &lt;cmd&gt;&quot;, because it will show the password in clear. # You have to run &quot;ssh -t hostname sudo &lt;cmd&gt;&quot;. # 一些环境变量的相关配置，具体情况可见man soduers Defaults requiretty Defaults env_reset Defaults env_keep = &quot;COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR LS_COLORS&quot; Defaults env_keep += &quot;MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE&quot; Defaults env_keep += &quot;LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES&quot; Defaults env_keep += &quot;LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE&quot; Defaults env_keep += &quot;LC_TIME LC_ALL LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY&quot; Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin ## Next comes the main part: which users can run what software on ## which machines (the sudoers file can be shared between multiple ## systems). ## 下面是规则配置：什么用户在哪台服务器上可以执行哪些命令（sudoers文件可以在多个系统上共享） ## Syntax(语法): ## ## user MACHINE=COMMANDS 用户 登录的主机=（可以变换的身份） 可以执行的命令 ## ## The COMMANDS section may have other options added to it. ## 命令部分可以附带一些其它的选项 ## ## Allow root to run any commands anywhere ## 允许root用户执行任意路径下的任意命令 root ALL=(ALL) ALL ## Allows members of the &apos;sys&apos; group to run networking, software, ## service management apps and more. ## 允许sys中户组中的用户使用NETWORKING等所有别名中配置的命令 # %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE , DRIVERS ## Allows people in group wheel to run all commands ## 允许wheel用户组中的用户执行所有命令 %wheel ALL=(ALL) ALL ## Same thing without a password ## 允许wheel用户组中的用户在不输入该用户的密码的情况下使用所有命令 # %wheel ALL=(ALL) NOPASSWD: ALL ## Allows members of the users group to mount and unmount the ## cdrom as root ## 允许users用户组中的用户像root用户一样使用mount、unmount、chrom命令 # %users ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom ## Allows members of the users group to shutdown this system ## 允许users用户组中的用户关闭localhost这台服务器 # %users localhost=/sbin/shutdown -h now ## Read drop-in files from /etc/sudoers.d (the # here does not mean a comment) ## 读取放置在/etc/sudoers.d/文件夹中的文件（此处的#不意味着这是一个声明） #includedir /etc/sudoers.d 特别要注意的是==别名==一定要==使用大写== 3.9 限制root远程登录1. 思路 禁止root用户登录 允许用户 aming user5 user6 使用 su - root root‘s passwd xxxx 禁止登录 普通用户使用 sudo su - root 2. 方法 配置/etc/ssh/sshd_config，使系统禁止root用户登录 12345vi /etc/ssh/sshd_config/Root 搜索Root#PermitRootLogin yes 允许Root远程登录，将此选项改为 no &gt;&gt;PermitRootLogin no &gt;&gt; ：wqsystemctl restart sshd.service 重启服务 配置visudo，使普通用户可以临时用root权限使用sudo命令 1234567visudoUser_Alias AMINGS = aming, user5, user6AMINGS ALL=(ALL) NOPASSWD: /usr/bin/su:wqsudo su -whoamiroot 拓展123sudo su - 约等于 sudo -i sudo -s 完全等于 sudo /bin/bash 约等于 sudo su sudo 终究被一个&quot;临时权限的帽子&quot;扣住，不能等价于纯粹的登录到系统里。 sudo配置文件样例[www.opensource.apple.com/source/sudo/sudo-16/sudo/sample.sudoers]]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>su</tag>
        <tag>sudo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用户属性和密码管理]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F3.4%20-%203.6%20%E7%94%A8%E6%88%B7%E5%B1%9E%E6%80%A7%E5%92%8C%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[3.4 usermod命令usermod 更改用户的属性-u 更改用户的uid-g 更改用户属组，后面可以跟组id，也可以跟组名-d 更改用户的家目录-s 更改用户的shell-G 更改用户的扩展组一个用户可以属于多个组，但只有一个gid，除了gid组之外的，就是扩展组 1usermod -G grp2,grp5 aming \\给aming用户定义2个扩展组 3.5 用户密码管理1. passwd 修改当前用户的密码 如果是root用户，可以在后面家其他用户名，来修改其他用户的密码 -l + [用户名] 锁定用户的密码（密码文件会显示 ！！ ）用户密码显示 ！！ ，表示密码为空,用户不能登录用户密码显示 * ，表示用户密码被锁定，用户不能登录 -u + [用户名] 解锁用户的密码\ usermod -L + [用户名] 也可以锁定用户（密码文件会变成 ！ ） usermod -U + [用户名] 可以解锁上面用户 @重点 passwd –stdin + [用户名] 更改用户密码，只输入一次新密码，而且会明文显示（用于shell脚本） 用法： 12345echo &quot;123456&quot; | passwd --stdin user5 \\直接修改用户密码echo -e &quot;123\nsss&quot;123sssecho -e &quot;123456789\n123456789&quot; |passwd user3 \\用于需要2次输入用户密码的shell命令 3.6 mkpasswd命令mkpasswd 自动生成密码需要expect包的支持 123456789mkpasswd命令-l 制定位数-s 指定特殊字符的个数-d 指定数字的个数mkpasswd -l 12 生成12位长的密码j2zo9PlnM&#123;tqmkpasswd -l 12 -s 0 -d 3 指定密码中有几个特殊字符和几个数字eu8e2fJ7sjtE 密码设置原则： 大于或等于10位 包含数字、大小写字母和特殊符号 不要有规律性，不要包含个人的姓名、生日、住址、电话号码]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>passwd</tag>
        <tag>mkpasswd</tag>
        <tag>usermod</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统目录结构]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F3.1%20-%203.3%20%E7%94%A8%E6%88%B7%E6%96%87%E4%BB%B6%E5%8F%8A%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. / - 根每一个文件和目录从根目录开始。只有root用户具有该目录下的写权限。请注意，/root是root用户的主目录，这与/.不一样 2. /bin - 用户二进制文件包含二进制可执行文件。在单用户模式下，你需要使用的常见Linux命令都位于此目录下。系统的所有用户使用的命令都设在这里。例如：ps、ls、ping、grep、cp 3. /boot - 引导加载程序文件包含引导加载程序相关的文件。内核的initrd、vmlinux、grub文件位于/boot下。例如：initrd.img-2.6.32-24-generic、vmlinuz-2.6.32-24-generic 4. /dev - 设备文件包含设备文件。这些包括终端设备、USB或连接到系统的任何设备。例如：/dev/tty1、/dev/usbmon0 5. /etc - 配置文件包含所有程序所需的配置文件。也包含了用于启动/停止单个程序的启动和关闭shell脚本。例如：/etc/resolv.conf、/etc/logrotate.conf 6. /home - HOME目录所有用户用home目录来存储他们的个人档案。例如：/home/john、/home/nikita 7./lib 和 /lib64 - 系统库包含支持位于/bin和/sbin下的二进制文件的库文件.库文件名为 ld或lib.so.*例如：ld-2.11.1.so，libncurses.so.5.7 8. /media - 可移动媒体设备用于挂载可移动设备的临时目录。举例来说，挂载CD-ROM的/media/cdrom，挂载软盘驱动器的/media/floppy 9. /mnt - 挂载目录临时安装目录，系统管理员可以挂载文件系统 10. /opt - 可选的附加应用程序opt代表可选的。包含从个别厂商的附加应用程序。附加应用程序应该安装在/opt/或者/opt/的子目录下 11. /proc - 进程信息包含系统进程的相关信息。这是一个虚拟的文件系统，包含有关正在运行的进程的信息。例如：/proc/{pid}目录中包含的与特定pid相关的信息。这是一个虚拟的文件系统，系统资源以文本信息形式存在。例如：/proc/uptime 12. /root - 系统数据root根用户目录。包含root配置文件。 13. /run 运行数据run代表运行。包含运行时相关的数据。例如，ssid.pid、syslogs.pid等相关数据 14. /sbin 系统二进制文件二进制文件 = 可执行文件。在这个目录下的linux命令通常由系统管理员使用，对系统进行维护。例如：iptables、reboot、fdisk、ifconfig、swapon命令 15. /srv 服务数据srv代表服务。包含服务器特定服务相关的数据。例如，/srv/cvs/包含cvs相关的数据。 16. /sys 系统数据sys代表系统。包含系统进程数据文件。例如，/sys/fs/包含文件、/sys/bus/包含总线等相关数据 17. /tmp 临时文件包含系统和用户创建的临时文件。 当系统重新启动时，这个目录下的文件都将被删除。 18. /usr 用户程序包含二进制文件、库文件、文档和二级程序的源代码。/usr/bin中包含用户程序的二进制文件。如果你在/bin中找不到用户二进制文件，到/usr/bin目录看看。例如：at、awk、cd、less、scp。/usr/sbin中包含系统管理员的二进制文件。如果在/sbin/中找不到系统二进制文件，到/usr/sbin目录看看。例如：atd、cron、sshd、useradd、userdel。/usr/lib中包含了/usr/bin和/usr/sbin用到的库。/usr/local中包含了从源安装的用户程序。 19. /var 变量文件包含变量文件这个目录下可以找到内容可能增长的文件。例如：系统日志文件（/var/log）;包和数据库文件（/var/lib）；电子邮件（/var/mail）；打印队列（/var/spool）；锁文件（var/lock）；多次重新启动需要的临时文件（/var/tmp）]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>系统目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用户文件及管理]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F2.1-2.2%20%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[3.1 用户配置文件和密码配置文件1. /etc/passwd 文件解释1234567891011[root@zhouqunic-01 ~]# cat /etc/passwd | headroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologin /etc/passwd 文件分7个字段 用户名(login_name) 密码(passwd) 实际密码数据放在/etc/shadow 中，所以此处显示为× UID 用户标识符 GID 组名 用户名(user_name) 用户主目录(home_directory) 命令解释程序(Shell) 2. /etc/shadow 文件解释1234567891011[root@zhouqunic-01 ~]# cat /etc/shadow | headroot:$6$s8WMXWea$YBPEIrOm8djENWPVaXQizcZ5..aQkMn3r/tbeQLitob.p/4YyHN54FD9AJeCwfiS0a2wK8aubDrM7j1LZrpTj1:17318:0:99999:7:::bin:*:17110:0:99999:7:::daemon:*:17110:0:99999:7:::adm:*:17110:0:99999:7:::lp:*:17110:0:99999:7:::sync:*:17110:0:99999:7:::shutdown:*:17110:0:99999:7:::halt:*:17110:0:99999:7:::mail:*:17110:0:99999:7:::operator:*:17110:0:99999:7::: /etc/shadow 文件分为9个字段 用户名（也被称为登录名），在/etc/shadow中，用户名和/etc/passwd 是相同的，这样就把passwd 和shadow中用的用户记录联系在一起；这个字段是非空的； 密码（已被加密），如果是有些用户在这段是x，表示这个用户不能登录到系统；这个字段是非空的； 上次修改口令的时间；这个时间是从1970年01月01日算起到最近一次修改口令的时间间隔（天数），您可以通过passwd 来修改用户的密码，然后查看/etc/shadow中此字段的变化； 两次修改口令间隔最少的天数；如果设置为0,则禁用此功能；也就是说用户必须经过多少天才能修改其口令；此项功能用处不是太大；默认值是通过/etc/login.defs文件定义中获取，PASS_MIN_DAYS 中有定义； 两次修改口令间隔最多的天数；这个能增强管理员管理用户口令的时效性，应该说在增强了系统的安全性；如果是系统默认值，是在添加用户时由/etc/login.defs文件定义中获取，在PASS_MAX_DAYS 中定义； 提前多少天警告用户口令将过期；当用户登录系统后，系统登录程序提醒用户口令将要作废；如果是系统默认值，是在添加用户时由/etc/login.defs文件定义中获取，在PASS_WARN_AGE 中定义； 在口令过期之后多少天禁用此用户；此字段表示用户口令作废多少天后，系统会禁用此用户，也就是说系统会不能再让此用户登录，也不会提示用户过期，是完全禁用； 用户过期日期；此字段指定了用户作废的天数（从1970年的1月1日开始的天数），如果这个字段的值为空，帐号永久可用； 保留字段，目前为空，以备将来Linux发展之用。 3.2 用户组管理groupadd 用户组管理命令 groupadd 增加组 123[root@localhost ~]# groupadd grouptest1[root@localhost ~]# tail -n1 /etc/groupgrouptest1:x:501: groupadd -g uid groupname -g 指定所增加组的uid 123[root@localhost ~]# groupadd -g 520 grouptest2[root@localhost ~]# tail -n1 /etc/groupgrouptest2:x:520: groupdel 删除组若组里含有用户则不可以删除该组。 3.3 用户管理1. useradd 增加用户命令-u 自定义UID-g 使其属于已经存在的某个组，后面可跟组名or组id号-d 自定义用户的家目录-M 不建立家目录-s 自定义shell 1234567891011121314151617[root@zhouqunic-01 ~]# useradd user2[root@zhouqunic-01 ~]# tail -n2 /etc/passwdzhouqunic:x:1000:1000:zhouqunic:/home/zhouqunic:/bin/bashuser2:x:1001:1001::/home/user2:/bin/bash[root@zhouqunic-01 ~]# groupadd grp2[root@zhouqunic-01 ~]# useradd -u 1004 -g grp2 user3[root@zhouqunic-01 ~]# tail -n3 /etc/passwdzhouqunic:x:1000:1000:zhouqunic:/home/zhouqunic:/bin/bashuser2:x:1001:1001::/home/user2:/bin/bashuser3:x:1004:1002::/home/user3:/bin/bash[root@zhouqunic-01 ~]# useradd -u 1009 -g grp2 -d /home/aming/ -s /sbin/nologin user5[root@zhouqunic-01 ~]# tail -n5 /etc/passwdzhouqunic:x:1000:1000:zhouqunic:/home/zhouqunic:/bin/bashuser2:x:1001:1001::/home/user2:/bin/bashuser3:x:1004:1002::/home/user3:/bin/bashuser4:x:1008:1002::/home/zhouqunic/:/sbin/nologinuser5:x:1009:1002::/home/aming/:/sbin/nologin 2. userdel 删除用户-r 删除账户的时候，连带账户的家目录一起删除]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>passwd</tag>
        <tag>useradd</tag>
        <tag>userdel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ls命令]]></title>
    <url>%2Flinux%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F2.3%20ls%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[ls123456常用命令：ls -a 列出所有文件和目录，包括隐藏的。ls -l 查看文件和目录的详细信息。ls -d 查看这个目录本身,如果不加d，是查看这个目录下的文件。ls -t 按时间排序，从新到旧，新上面，旧下面。ls -i 查看文件的inode号 组合命令123ls -lh 已合适单位显示文件/目录的详细信息ls -la 显示所有文件和目录的详细信息，包括隐藏的文件ll =ls -l 特殊意义的1234目录下面的文件. 点表示当前目录.. 点点表示上一级目录.ssh 前面加点，表示隐藏文件]]></content>
      <categories>
        <category>linux入门笔记</category>
      </categories>
      <tags>
        <tag>ls</tag>
      </tags>
  </entry>
</search>
